<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Fairness | Valentin Barriere</title>
    <link>http://localhost:1313/tags/fairness/</link>
      <atom:link href="http://localhost:1313/tags/fairness/index.xml" rel="self" type="application/rss+xml" />
    <description>Fairness</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Jan 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu6033596820838205990.png</url>
      <title>Fairness</title>
      <link>http://localhost:1313/tags/fairness/</link>
    </image>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Xenophobias -- Deteccion y reduccion de sesgos etnicos en LLM</title>
      <link>http://localhost:1313/job_offers/thesis-postgrado-bias/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-postgrado-bias/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;Classical bias detection methods used in Machine Learning are themselves biased because of the different confounding variables implied in the assessment of the initial biases.¬†First they are using templates that are syntactically simple and distant from the target data on which the model will be applied. Second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms.¬†
We propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. The idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes.¬†&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-non-causal-changes-such-as-in-names-can-cause-differences-in-the-model-outputs-which-should-not-happen&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;figure_v5&#34; srcset=&#34;
               /job_offers/thesis-postgrado-bias/figure_v5_hu8972351964426249376.webp 400w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu11092428002217262131.webp 760w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu3423759269590890690.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-postgrado-bias/figure_v5_hu8972351964426249376.webp&#34;
               width=&#34;760&#34;
               height=&#34;154&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Non-causal changes such as in names can cause differences in the model outputs, which should not happen.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Our work offers a fine-grained analysis of the interactions between names and languages, revealing significant biases in multilingual models, but also strong biases towards some countries&amp;rsquo; names. We linked this with the pre-training data used to pre-train the LLM, by the mean of the Language Model&amp;rsquo;s (pseudo-)likelihood and found out very socially interesting resuts. For example, a sentence containing a Moroccan name will be more likely to be tagged as positive, and less likely to be tagged as hate speech.¬†&lt;/p&gt;
&lt;p&gt;In other words we want to answer the questions: (i) are LLM xenophobic? (ii) how to quantify it? (iii) how to remove this bias?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Funds will be available to support the research of the student.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;We started to answer these questions in two papers (one to be presented at COLING24 and one submitted at ACL24), and would like to continue the adventure with you! We plan to submit our future work at another international NLP/ML/AI conference.&lt;/p&gt;
&lt;p&gt;We have several possibilities regarding the works that can be tackled in this tesis:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM to generate data fitting to production data distribution (KL‚Äî&amp;gt;0)‚Ä®&lt;/li&gt;
&lt;li&gt;Generate more target-groups attributes (more fine-grained, since not relying on template; how to validate them)‚Ä®&lt;/li&gt;
&lt;li&gt;Method to reduce the bias of the trained model¬†‚Ä®&lt;/li&gt;
&lt;li&gt;Test current method on bigger LLM classifiers‚Ä®&lt;/li&gt;
&lt;li&gt;Our method is quantitative and require classes that can manually be seen as positives and negatives. How to extend this to any classification, how to check this bias qualitatively using an algorithm on the distribution (Optimal Transport distance or others‚Ä¶)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Fondecyt de Iniciacionüó£Ô∏èüí¨ü§ñ</title>
      <link>http://localhost:1313/project/mmodal_eca/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/mmodal_eca/</guid>
      <description>&lt;p&gt;Multimodal Argumentation Mining in Groups Assisted by an Embodied Conversational Agent&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Principal Investigator of this project&lt;/strong&gt;. This is a 3 years &lt;a href=&#34;https://anid.cl/concursos/concurso-de-proyectos-fondecyt-de-iniciacion-en-investigacion-2025/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fondecyt&lt;/a&gt; grant of of 90.000.000,00 CLP&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; from the Chilean National Research Agency. This is a colaboration with the Universit√© Paris Saclay, the European Commission&amp;rsquo;s DGIT, Sorbonne Universit√© and Bamberg University.&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;Interactions and Multimodality are crucial in the development of intelligent AI models that can understand human-like communication. Human learning occurs through interactions with the environment and other humans, which involves the integration of information from multiple modalities such as vision, language but also touch and hearing that enable us to understand the subtle social meanings behind communication.&lt;/p&gt;
&lt;p&gt;Therefore, to create intelligent machines that can understand human non-verbal communication, it is essential to train them on &lt;strong&gt;multimodal interactions that mimic those of humans to ensure that they can understand and respond appropriately to complex social phenomena&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The recent computational boom has seen the emergence of seminal studies focusing on Multimodal data (Cho, Lu, Schwenk, Hajishirzi, &amp;amp; Kembhavi, 2020; Hasan et al., 2019; Jaegle et al., 2021; J. Li, Li, Xiong, &amp;amp; Hoi, 2022; J. Wang et al., 2022; Zadeh, Chan, Liang, Tong, &amp;amp; Morency, 2019)‚Å† and Interactions, whether these ones are textual like OpenIA&amp;rsquo;s InstructGPT or Anthropic&amp;rsquo;s Claude  (Bai et al., 2022; Ouyang et al., 2022; Schulman et al., 2022)‚Å†, or multimodal like Google&amp;rsquo;s PaLM (Chowdhery et al., n.d.; Chung et al., 2022; Schick, Lomeli, Dwivedi-yu, &amp;amp; Dess√¨, 2022)‚Å† or GPT-4 (Bubeck et al., 2023; OpenAI, 2023; Wu et al., 2023)‚Å†.&lt;/p&gt;
&lt;p&gt;These advancements show the potential for machines to learn from multimodal interactions and understand human communication, which could revolutionize the way humans socially interact with machines in the future. &lt;strong&gt;Nevertheless, nowadays generative agents are restraint to unimodal data or not using the full time-series of every modality of a real human-machine social interaction&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Interaction and multimodality are vital contexts in many social situations. They are also mandatory to make a machine understand the world and get commonsense knowledge, which is essential when tackling human-related complex tasks. Indeed, &lt;strong&gt;humans are social animals&lt;/strong&gt; and they interact with one another. In a general way, the integration of more context is the key to a deep understanding of many phenomena, in order to disambiguate a situation or to reinforce the current estimation: interaction is a crucial context in many social situations. Multimodal interactions allow understanding in a deeper way human behavior. In this particular setting, it is possible to understand a broader part of the multimodal natural language (see Figure 1). Studying the affective and &lt;strong&gt;social phenomena like Opinions, Emotions, Empathy, Distress, Stances, Persuasiveness or speaker traits allows to greatly improves the response from the machine&lt;/strong&gt; (Pelachaud, Busso, &amp;amp; Heylen, 2021; Zhao, Sinha, Black, &amp;amp; Cassell, 2016)‚Å†, but this task is difficult even using multimodal data. My research focuses on designing and developing methods that integrate the multimodal context and how humans influence each other in discussion situations. The research goals of this project fall into this general research area: &lt;strong&gt;how to use interactions and multimodality of non-verbal language to enhance social AI systems&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-examples-of-non-verbal-language-involved-in-a-social-interaction-from-vinciarelli-2009&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;interaction&#34; srcset=&#34;
               /project/mmodal_eca/interaction_hu15794327103315274671.webp 400w,
               /project/mmodal_eca/interaction_hu15612226579774470620.webp 760w,
               /project/mmodal_eca/interaction_hu8198735632516945012.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/mmodal_eca/interaction_hu15794327103315274671.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Examples of non-verbal language involved in a social interaction from Vinciarelli (2009)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;multimodality&#34;&gt;Multimodality:&lt;/h4&gt;
&lt;p&gt;Communication is not just limited to language, and it is essential to consider other modalities such as vision or audio when building natural language processing (NLP) systems (Baltru≈°aitis, Ahuja, &amp;amp; Morency, 2017; Liang, Zadeh, &amp;amp; Morency, 2022)‚Å†. &lt;strong&gt;Incorporating multiple modalities, or multimodality, is critical in creating more human-like interactions between humans and machines&lt;/strong&gt;. For instance, while language is the primary means of communication for humans, it is often supplemented by visual and auditory cues such as facial expressions, tone of voice, and gestures. Therefore, it is important building multimodal machine learning systems that can interpret and respond to these cues in a human-like manner.&lt;/p&gt;
&lt;p&gt;According to (Fr√∂hlich, Sievers, Townsend, Gruber, &amp;amp; van Schaik, 2019)‚Å†, both human and non-human primate communication is inherently multimodal. As an example, (Mehrabian, 1971)‚Å† even states that 55% of the emotional content is in the visual signal (facial expressions and body language), 38% in the vocal signal (intonation and sound of the voice) and 7% in the verbal signal (through the meaning of the words and the arrangement of the sentence).&lt;/p&gt;
&lt;h4 id=&#34;interactions-dynamics&#34;&gt;Interactions dynamics:&lt;/h4&gt;
&lt;p&gt;It is essential to consider the interactive nature of human communication and incorporate it into natural language processing (NLP) systems. By allowing the machine to understand the context and flow of the conversation, it can provide a more natural and seamless interaction with users (Sutskever, Vinyals, &amp;amp; Le, 2014)‚Å†. (Z. Li, Wallace, Shen, &amp;amp; Lin, 2020)‚Å† suggested that these systems can provide tailored content and services based on the user&amp;rsquo;s interests and preferences, leading to more engaging and personalized interactions with the user. &lt;strong&gt;As humans, we are not learnig by looking at or enviroment, but by interacting with it and with our peers&lt;/strong&gt;. By considering the interactive nature of human communication and incorporating it into NLP systems, machines can learn to communicate in a way that is more similar to humans, making interactions more engaging and effective.&lt;/p&gt;
&lt;h4 id=&#34;proposed-research-project&#34;&gt;Proposed research project:&lt;/h4&gt;
&lt;p&gt;This research project aims at studying the complex phenomena characterizing social interactions between humans using different media, implying different modalities and data domains. My research objective is to design adaptive models that take as a starting point the specificities of the multimodal interaction: the media used to communicate, the interactants&amp;rsquo; social relationship, and the communication modalities used to transfer the information. &lt;strong&gt;The general goals stand to: understand what the users are trying to achieve as a group, what is the output of this interaction, how a social agent helps reaching it&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-beatrice-bianccardihttpsbeatricebiancardigitlabio-interacting-with-the-virtual-agent-greta&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;beatrice_eca&#34; srcset=&#34;
               /project/mmodal_eca/beatrice_eca_hu9343440991652273668.webp 400w,
               /project/mmodal_eca/beatrice_eca_hu1100368193974869717.webp 760w,
               /project/mmodal_eca/beatrice_eca_hu13291684369485421113.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/mmodal_eca/beatrice_eca_hu9343440991652273668.webp&#34;
               width=&#34;430&#34;
               height=&#34;279&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;a href=&#34;https://beatricebiancardi.gitlab.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Beatrice Bianccardi&lt;/a&gt; interacting with the virtual agent Greta
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In particlar, this project aims to explore the dynamics of how a group of individuals with polarized opinions can reach a consensus. In this work, within groups of individuals debating hot societal topics and issues, the aim will be to automatically detect and retrieve stances and arguments towards the debate question and to ultimately moderate the debate using a human-computer interface that would be specific to such an interaction. To this aim, we think that an &lt;strong&gt;Embodied Conversational Agent&lt;/strong&gt; (Cassell, 2001; Pelachaud, 2005)‚Å† like the one illustrated in Figure 2, would be the most relevant. Indeed bodily representations structure the way humans perceive the world and the way they perceive other people. Cognitive sciences and social sciences altogether have stressed &lt;strong&gt;the importance of embodiment in social interaction, highlighting how interacting with others influences how we behave, perceive and think&lt;/strong&gt; (Smith &amp;amp; Neff, 2018; Tieri, Morone, Paolucci, &amp;amp; Iosa, 2018)‚Å†, including our social behaviors with embodied intelligent agents such as virtual humans and robots (Holz, Dragone, &amp;amp; O‚ÄôHare, 2009)‚Å†.&lt;/p&gt;
&lt;p&gt;Another goal is to explore the polarization of society&amp;rsquo;s attitudes towards hot political topics and study the &lt;strong&gt;difference in terms of the difficulty of finding a consensus&lt;/strong&gt; regarding the type of topics, and the human values involved in classical argumentation (Kiesel, Weimar, Handke, &amp;amp; Weimar, 2022; Mirzakhmedova et al., 2023)‚Å†. In today&amp;rsquo;s society, the polarization of opinions on political topics is a common phenomenon that can be observed in many different areas. Debates about societal topics and issues can be especially polarizing and lead to a lack of understanding and cooperation between groups with different perspectives (Livingstone, Fern√°ndez Rodriguez, &amp;amp; Rothers, 2020)‚Å†. Therefore, &lt;strong&gt;it is crucial to understand how individuals with polarized opinions can reach a consensus&lt;/strong&gt;, and this is the aim of this research project. To achieve it, this project plans to develop an automatic approach to &lt;strong&gt;detect and retrieve the stance and arguments&lt;/strong&gt; of individuals involved in real-time multimodal debates about hot societal topics.&lt;/p&gt;
&lt;p&gt;This research aims to delve into the complexities of group dynamics in polarized debates on societal issues. To achieve this, we will not only automatically detect and retrieve stances and their arguments toward the debate question, but also take into account the multimodal aspects of the debate, such as &lt;strong&gt;body language, facial expressions and acoustics&lt;/strong&gt;, which are shown to be important for persuasion in a Vlog (Nojavanasghari, Gopinath, Koushik, Baltru≈°aitis, &amp;amp; Morency, 2016; S. Park, Shim, Chatterjee, Sagae, &amp;amp; Morency, 2014; Siddiquie, Chisholm, &amp;amp; Divakaran, 2015)‚Å† or within a debate (Brilman &amp;amp; Scherer, 2015; Mestre et al., 2021)‚Å†. Real-time interaction within the group will be analyzed to understand &lt;strong&gt;how individuals respond to each other and how the group as whole moves toward a consensus&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 100k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Tackling Biases In or Using Generative AI @ JSIC&#39;24</title>
      <link>http://localhost:1313/event/jsic/</link>
      <pubDate>Wed, 04 Dec 2024 08:30:00 +0000</pubDate>
      <guid>http://localhost:1313/event/jsic/</guid>
      <description>&lt;p&gt;In this talk, I am focusing on several methods based on data perturbation to detect biases in Large Language Models (LLMs) and Large Multimodal Models (LMMs). We have observed cases where these systems leverage gender, race, or even socioeconomic class information inappropriately for task resolution. Instead of employing real causal reasoning, they often rely on spurious correlations‚Äîa phenomenon commonly referred to as bias.&lt;/p&gt;
&lt;p&gt;We will demystify the concept of bias, explaining why biases are ubiquitous, why they can sometimes be useful, and proposing a method to detect harmful biases.&lt;/p&gt;
&lt;p&gt;First, we will introduce a method we developed to detect biases in LLMs toward different countries using the most common names as proxies. Our findings reveal very negative biases toward certain countries, using widely utilized open-source classifiers for social media analysis. Furthermore, we demonstrate that the same multilingual model tends to favor names from countries that speak the language of the sentence‚Äîa phenomenon we call AI Xenophobia. This phenomenon has significant social implications. Our study, which examined the perplexity of language models and classifier outputs, shows that the model reacts differently to completely unknown languages compared to familiar ones and exhibits similar behavior toward names as it does with unfamiliar languages.&lt;/p&gt;
&lt;p&gt;Second, we present a method to mitigate biases in Vision-Language Models, particularly in image captioning models. By perturbing the training data through data augmentation with a Text-to-Image generative model, we enhance variability in the dataset. This approach not only reduces gender bias but also improves the model&amp;rsquo;s performance in tasks such as counting objects and detecting colors.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers</title>
      <link>http://localhost:1313/publication/emnlp24-ppl/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/emnlp24-ppl/</guid>
      <description>&lt;p&gt;This work is driven by the results of a &lt;a href=&#34;http://localhost:1313/publication/LREC24-XENOPHOBIA/&#34;&gt;previous paper&lt;/a&gt; on country-level bias detection in LLMs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>XenophoBiasüè≥Ô∏è‚Äçüåà</title>
      <link>http://localhost:1313/project/xenophobias/</link>
      <pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/xenophobias/</guid>
      <description>&lt;p&gt;Multicultural Bias Recognition to Detect and Mitigate Racism, Xenophobia and Geographic Inequalities in Multilingual Large Language Models.&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Principal Investigator of this project&lt;/strong&gt;. This is a 2 years &lt;a href=&#34;https://uchile.cl/convocatorias/216327/concurso-u-inicia-2024&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;U-inicia&lt;/a&gt; grant from the University with a total budget of 8,000,000 CLP.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;Classical bias detection methods used in Machine Learning and Natural Language Processing (NLP) are themselves biased because of the different confounding variables implied in the assessment of the initial biases. First they are using templates that are syntactically simple and distant from the target data on which the model will be applied. Second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;counfounding&#34; srcset=&#34;
               /project/xenophobias/featured_hu4709178623435340922.webp 400w,
               /project/xenophobias/featured_hu2414093935314123718.webp 760w,
               /project/xenophobias/featured_hu9909048982336450453.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/featured_hu4709178623435340922.webp&#34;
               width=&#34;449&#34;
               height=&#34;587&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. The idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes. We focus on named entity perturbations by applying a &lt;strong&gt;Named Entity Recognition&lt;/strong&gt; (NER) on target-domain data and modifying them accordingly to most common names or location of a target group (gender and/or country), and this for several morphosynctactically different languages spoken in relation with the countries of the target groups. &lt;strong&gt;The idea is that perturbing the input data with a non-causal change should not impact the output distribution of a model&lt;/strong&gt;, but it actually does with respect to the languages and the country of provenance of the added entity perturbing the sentence. An analysis of the changes helps practitioners getting a deeper understanding of how a model can react to different target groups.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-we-use-the-target-domain-data-to-create-templates&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overall&#34; srcset=&#34;
               /project/xenophobias/figure_v9_1_hu1431973182623297372.webp 400w,
               /project/xenophobias/figure_v9_1_hu5426821930535034716.webp 760w,
               /project/xenophobias/figure_v9_1_hu13032372178332810117.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/figure_v9_1_hu1431973182623297372.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      We use the target-domain data to create templates.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Here is an example with two sentences, $S^n$
 being ambiguous and $S^1$
 obvious hate speech. The model output of the perturbated versions is highly variable for the multilingual variations of &lt;em&gt;Alexander&lt;/em&gt;. With some name variations, such as the Turkish or Indian, the models classify the sentences as more negative or detect less hate speech. Meaning it will not moderate the content of an insult toward this person (see below):
















&lt;figure  id=&#34;figure-the-templates-obtained-from-target-domain-data-are-filled-with-common-names-from-various-countries-the-difference-in-the-models-output-is-significative-of-a-bias-regarding-the-names&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overall&#34; srcset=&#34;
               /project/xenophobias/figure_v9_2_hu5969773204992941524.webp 400w,
               /project/xenophobias/figure_v9_2_hu408390470316705406.webp 760w,
               /project/xenophobias/figure_v9_2_hu4458702702344355493.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/figure_v9_2_hu5969773204992941524.webp&#34;
               width=&#34;760&#34;
               height=&#34;334&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The templates obtained from target-domain data are filled with common names from various countries. The difference in the model&amp;rsquo;s output is significative of a bias regarding the names.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We will then focus on &lt;strong&gt;how to leverage LLM in order to create sentences from the target-domain data distribution&lt;/strong&gt;, with entites, then with more fine-grained named concepts related to the countries, such as local meals, celebrations, or regional slang.
We want first to use our method on models available in open-source that are likely to be deployed by industry, i.e., widely used classifiers for subjectivity analysis, including sentiment, emotion, hate speech, and offensive text using Twitter data. &lt;strong&gt;We will assess the bias of a variety of models&lt;/strong&gt; such as an open-source multilingual sentiment analysis model trained over multiple-languages tweets, a multilingual stance recognition model trained over several languages and assessed over English language, an English hate speech classifier, an English large language model, and a multilingual large language model such as Llama-3.
Our work offers a fine-grained analysis of the interactions between names and languages, aiming to reveal significant biases in multilingual models, but also strong biases towards some countries‚Äô names. &lt;strong&gt;We want to link this with the pre-training data used to pre-train the LLM, by the mean of the Language Model‚Äôs (pseudo-)likelihood&lt;/strong&gt;. We hope to find out very socially interesting/impacting results such as a sentence containing a name from an arabic or slavic country will more likely to be tagged as negative, and less likely to be tagged as hate speech.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;In other words we want to answer the questions:&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Are LLM xenophobic?&lt;/li&gt;
&lt;li&gt;How to quantify it?&lt;/li&gt;
&lt;li&gt;How to remove this bias?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;schedule&#34;&gt;Schedule&lt;/h3&gt;
&lt;p&gt;Milestones will follow the project objectives and milestones are defined as a group of objectives with a publication at an A(*)-ranked conference or in a journal to complete the milestone.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Milestone 1&lt;/strong&gt; consists of objectives 1 and 2 as well as the publication of a paper at an A(*) conference. The method developed above will be applied to different types of classifiers and generative models. A perplexity analysis will be performed to try to quantify the visible bias of the internal states of neural networks. I plan 5 months to adapt the method that already exists for LLM and use perplexity to find lassos between frequencies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Milestone 2&lt;/strong&gt; consists of objectives 3 and 4, as well as the publication of a paper in a conference A. I plan 4 months for the artificial data generation because it is not so straightforward and we will have to work on the generation in the target distribution per se, and also on the collection and how to add in the generation the socio-cultural attributes of the different countries (2 months + 2 months).&lt;/p&gt;
&lt;p&gt;The last &lt;strong&gt;Milestone 3&lt;/strong&gt; contains the final objective concerning the reduction of bias, with the aggregation of all previous results in a journal publication.  Working on bias reduction based on our method will be quite straightforward. The writing of a journal paper where we will have all the results of the project will be longer than the previous conference papers, which will have more specific and limited contents. For that I plan 4 months for the reduction and 3 months for the writing, with 2 overlapping months.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;gantt&#34; srcset=&#34;
               /project/xenophobias/gantt_hu3088727843124199660.webp 400w,
               /project/xenophobias/gantt_hu11767512201186597748.webp 760w,
               /project/xenophobias/gantt_hu16173524106031046137.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/gantt_hu3088727843124199660.webp&#34;
               width=&#34;760&#34;
               height=&#34;272&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 8k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>WASSA Workshop @ ACL 24</title>
      <link>http://localhost:1313/event/wassa24/</link>
      <pubDate>Thu, 15 Aug 2024 09:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/wassa24/</guid>
      <description>&lt;p&gt;We are orgnizing the 14th edition of the WASSA workshop this year at &lt;a href=&#34;https://2024.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL24&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Our keynote speaker will be Debora Nozza&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://workshop-wassa.github.io/assets/images/debora_nozza.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;The proliferation of hate speech on social media platforms has been rising, with (pseudo-)anonymity allowing individuals to target others without being recognized or easily traced. While this societal issue has garnered significant attention in the NLP community, it presents three major challenges. Hate speech detection models need to be fair, work across all languages, and incorporate personalization while balancing privacy concerns. Addressing these challenges will revolutionize the field of hate speech detection and contribute to the development of a ‚Äúuniversal‚Äù model that can adapt to individual user perspectives. In this talk, I will present my contributions in this area along with my perspectives on future directions.&lt;/p&gt;
&lt;h4 id=&#34;bio&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;Debora Nozza is an Assistant Professor in Computing Sciences at Bocconi University. Her research interests mainly focus on Natural Language Processing, specifically on the detection and counter-acting of hate speech and algorithmic bias on Social Media data in multilingual context&lt;/p&gt;
&lt;h2 id=&#34;about-wassa&#34;&gt;About WASSA&lt;/h2&gt;
&lt;p&gt;The aim of WASSA 2024 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text. For this edition, we encourage the submission of long and short research and demo papers including, but not restricted to the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resources for subjectivity, sentiment, emotion and social media analysis&lt;/li&gt;
&lt;li&gt;Opinion retrieval, extraction, categorization, aggregation and summarization&lt;/li&gt;
&lt;li&gt;Humor, Irony and Sarcasm detection&lt;/li&gt;
&lt;li&gt;Mis- and disinformation analysis and the role of affective attributes&lt;/li&gt;
&lt;li&gt;Aspect and topic-based sentiment and emotion analysis&lt;/li&gt;
&lt;li&gt;Analysis of stable traits of social media users, incl. personality analysis and profiling&lt;/li&gt;
&lt;li&gt;Transfer learning for domain, language and genre portability of sentiment analysis&lt;/li&gt;
&lt;li&gt;Modelling commonsense knowledge for subjectivity, sentiment or emotion analysis&lt;/li&gt;
&lt;li&gt;Improvement of NLP tasks using subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;Intrinsic and extrinsic evaluation of subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;The role of emotions in argument mining&lt;/li&gt;
&lt;li&gt;Application of theories from related fields to subjectivity and sentiment analysis&lt;/li&gt;
&lt;li&gt;Multimodal emotion detection and classification&lt;/li&gt;
&lt;li&gt;Applications of sentiment and emotion mining&lt;/li&gt;
&lt;li&gt;Public sentiments and communication patterns of public health emergencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the past years we have noticed that WASSA offers a platform to researchers investigating sentiment and emotion in lesser-resourced languages. The 2023 edition featured work on no less than 23 different languages and two papers specifically targeted multilingual emotion detection. We wish to continue these efforts as we find it important to consider and publish advances in any language as this helps to underline the wealth of our research community and to diminish the dominance of English-language research. To this purpose we propose a Special track on multilinguality and social bridge between high- and lesser-resourced languages/communities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fantastic Biases (What are They) and Where to Find Them</title>
      <link>http://localhost:1313/publication/bits24-biases/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/bits24-biases/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Are Text Classifiers Xenophobic? A Country-Oriented Bias Detection Method with Least Confounding Variables</title>
      <link>http://localhost:1313/publication/lrec24-xenophobia/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec24-xenophobia/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Targeted Image Data Augmentation Increases Basic Skills Captioning Robustness</title>
      <link>http://localhost:1313/publication/gem23-tida/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/gem23-tida/</guid>
      <description></description>
    </item>
    
    <item>
      <title>WASSA Workshop @ ACL 23</title>
      <link>http://localhost:1313/event/wassa23/</link>
      <pubDate>Fri, 14 Jul 2023 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/wassa23/</guid>
      <description>&lt;p&gt;We are orgnizing the 13th edition of the WASSA workshop this year at &lt;a href=&#34;https://2023.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL23&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Our keynote speakers will be David Jurgens and Emily √ñhman&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-david-jurgens&#34;&gt;Invited Talk: David Jurgens&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://wassa-workshop.github.io/assets/images/david_jurgens.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;the-social-dimensions-of-communication-how-context-shapes-language-use-and-interpretation&#34;&gt;The Social Dimensions of Communication: How Context Shapes Language Use and Interpretation&lt;/h4&gt;
&lt;p&gt;NLP studies of communication often focus on the individual: What we say, when we say it, and how we say it. Yet, the larger social context beyond the individual also plays an important role in our communication ‚Äî just think of things you can say to your friends but not your parents. How does the social context influence our communication style and content? In this talk, I will describe recent work from my group studying the influence of this context by examining how we choose who to communicate with, how we interpret messages, and how we phrase messages. Across these studies, I will motivate a causal approach for NLP when studying communication behavior to move beyond descriptive analyses to more precise estimates of the effects of social context.&lt;/p&gt;
&lt;h4 id=&#34;bio&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;David Jurgens is an assistant professor at the University of Michigan School of Information where he leads the Blablablab. He holds a PhD in Computer Science from the University of California, Los Angeles. His research focuses on the intersection between NLP and computational social science venues and has won the Cozzarelli Prize, Cialdini Prize, best paper at ICWSM and W-NUT, and best paper nomination at ACL and Web Science.&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-emily-√∂hman&#34;&gt;Invited Talk: Emily √ñhman&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://wassa-workshop.github.io/assets/images/emilyohman.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;affective-datafication-of-narratives-measuring-affect-emotion-and-mood-in-literary-texts&#34;&gt;Affective Datafication of Narratives: measuring affect, emotion, and mood in literary texts&lt;/h4&gt;
&lt;p&gt;Our understanding of affect, emotion, and mood - despite the distinct nuances each term holds - often becomes blurred, leading to a usage that is almost interchangeable, particularly within sentiment analysis and NLP. In contrast, traditional fields such as literary studies hold on to more rigid definitions of these terms and how they are understood both in theory and practice. This can easily foster a disconnect between emerging fields such as computational literary studies and the more established qualitative counterparts. This disconnect unfortunately hinders the free exchange of innovative research ideas and methodologies. This talk aims to bridge this gap, highlighting the unique roles of affect, emotion, and mood in narratives and how we can attempt to robustly measure them. We will delve into the interplay of these terms, exploring how they shape and are shaped by authors, readers, and researchers focusing on the operationalization and translation involved in the analysis of emotion-laden phenomena. This exploration will underscore the need for a more comprehensive and nuanced understanding, encouraging synergy between tradition and innovation in emotion detection in general and literary research in particular.&lt;/p&gt;
&lt;h4 id=&#34;bio-1&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;Emily √ñhman is currently a tenure-track Assistant professor of Digital Humanities at Waseda University. She received her PhD in Language Technology from the University of Helsinki, where her work centered on building multilingual emotion detection resources for downstream tasks.&lt;/p&gt;
&lt;p&gt;Her research interests lie within digital humanities and NLP, more specifically sentiment analysis and emotion detection, often doing collaborations with various disciplines such as history, literature, and political science. Her recent projects have focused on negative emotions in literature using affect as a proxy for the literary concept of mood and most recently contrasting the semantic spaces of shame and guilt in Japanese and English social media posts.&lt;/p&gt;
&lt;h2 id=&#34;about-wassa&#34;&gt;About WASSA&lt;/h2&gt;
&lt;p&gt;The aim of WASSA 2023 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text. For this edition, we encourage the submission of long and short research and demo papers including, but not restricted to the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resources for subjectivity, sentiment, emotion and social media analysis&lt;/li&gt;
&lt;li&gt;Opinion retrieval, extraction, categorization, aggregation and summarization&lt;/li&gt;
&lt;li&gt;Humor, Irony and Sarcasm detection&lt;/li&gt;
&lt;li&gt;Mis- and disinformation analysis and the role of affective attributes&lt;/li&gt;
&lt;li&gt;Aspect and topic-based sentiment and emotion analysis&lt;/li&gt;
&lt;li&gt;Analysis of stable traits of social media users, incl. personality analysis and profiling&lt;/li&gt;
&lt;li&gt;Transfer learning for domain, language and genre portability of sentiment analysis&lt;/li&gt;
&lt;li&gt;Modelling commonsense knowledge for subjectivity, sentiment or emotion analysis&lt;/li&gt;
&lt;li&gt;Improvement of NLP tasks using subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;Intrinsic and extrinsic evaluation of subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;The role of emotions in argument mining&lt;/li&gt;
&lt;li&gt;Application of theories from related fields to subjectivity and sentiment analysis&lt;/li&gt;
&lt;li&gt;Multimodal emotion detection and classification&lt;/li&gt;
&lt;li&gt;Applications of sentiment and emotion mining&lt;/li&gt;
&lt;li&gt;Public sentiments and communication patterns of public health emergencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We furthermore encourage submissions to the special theme Ethics in Affective Computing, including opinion papers, as well as experimental papers. This includes the following topics, but is not limited to them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Which properties of a model render a automatic analysis task unethical?&lt;/li&gt;
&lt;li&gt;Which characteristics of an annotation task are to be considered in ethical considerations?&lt;/li&gt;
&lt;li&gt;What are appropriate methods to analyze data and models from an ethical perspective?&lt;/li&gt;
&lt;li&gt;What aspects are particular important for affective analysis tasks, in contrast to other NLP settings?&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
