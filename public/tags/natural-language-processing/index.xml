<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Natural Language Processing | Valentin Barriere</title>
    <link>http://localhost:1313/tags/natural-language-processing/</link>
      <atom:link href="http://localhost:1313/tags/natural-language-processing/index.xml" rel="self" type="application/rss+xml" />
    <description>Natural Language Processing</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Jan 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu6033596820838205990.png</url>
      <title>Natural Language Processing</title>
      <link>http://localhost:1313/tags/natural-language-processing/</link>
    </image>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Change my view! -- Analisis de argumentacion multimodal</title>
      <link>http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt; Interactions and Multimodality are crucial in the development of intelligent AI models that can understand human-like communication. Human learning occurs through interactions with the environment and other humans, which involves the integration of information from multiple modalities such as vision, language but also touch and hearing that enable us to understand the subtle social meaning behind communication. 
Therefore, to create intelligent machines that can understand human communication, it is essential to train them on multimodal interactions that mimic those of humans to ensure that they can understand and respond appropriately to complex social phenomena. 
The research objective is to design adaptive models that take as a starting point the specificities of the multimodal interaction: the media used to communicate, the way the users are socially linked together, and the modalities used by them to transfer information. 
For this reason, we aim to study multimodal argumentation mining as a starting point. Dialog systems helps to improve the quality of a debate [1,2,3,4]. But phenomena related to argumentation relies on multimodal communication and are related to persuasion, or communication skills [5,6,7,8]. For this, we are focusing on multimodal argument mining [9,10,11,12]. &lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig_tesis_proposicion&#34; srcset=&#34;
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu700631809574394399.webp 400w,
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu1221762742450276794.webp 760w,
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu4398504731950838957.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu700631809574394399.webp&#34;
               width=&#34;760&#34;
               height=&#34;241&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;The student will engage in the construction of multimodal machine learning models that take as input video and are able to detect complex social phenomena such as empathy, persuasion and emotion but also text-based argumentation models. During the thesis, we will also focus on the construction of a debate dataset in Chilean Spanish (and hopefully  in French), on political hot topics that are seen as polarizing in both countries. 
s
In a few bullet-points, different research axis will be explored regarding the available time (w.r.t. the type of tesis/memoria): &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creation of mutlimodal models aiming to detect social phenomena in discourse and also in a dyadic or group interaction&lt;/li&gt;
&lt;li&gt;Adaptation or creation of an text-based argumentation annotation scheme for multimodal data&lt;/li&gt;
&lt;li&gt;Creation of the chilean part of a multicultural database of debates on polarizing topics  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Funds will be available to support the research of the student.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; ### Bibliography&lt;/p&gt;
&lt;p&gt;[1] V. Petukhova, T. Mayer, A. Malchanau, and H. Bunt, “Virtual debate coach design: Assessing multimodal argumentation performance,” ICMI 2017 - Proc. 19th ACM Int. Conf. Multimodal Interact., vol. 2017-Janua, no. 1, pp. 41–50, 2017. &lt;/p&gt;
&lt;p&gt;[2] N. Rach, E. André, K. Weber, W. Minker, L. Pragst, and S. Ultes, “EVA: A multimodal argumentative dialogue system,” ICMI 2018 - Proc. 2018 Int. Conf. Multimodal Interact., no. October, pp. 551–552, 2018. &lt;/p&gt;
&lt;p&gt;[3] A. Khan, J. Hughes, D. Valentine, L. Ruis, K. Sachan, and A. Radhakrishnan, “Debating with More Persuasive LLMs Leads to More Truthful Answers,” 2024. &lt;/p&gt;
&lt;p&gt;[4] L. P. Argyle et al., “AI Chat Assistants can Improve Conversations about Divisive Topics,” ArXiv, 2023. &lt;/p&gt;
&lt;p&gt;[5] T. Ohba, C. O. Mawalim, S. Katada, H. Kuroki, and S. Okada, “Multimodal Analysis for Communication Skill and Self-Efficacy Level Estimation in Job Interview Scenario,” ACM Int. Conf. Proceeding Ser., pp. 110–120, 2022. &lt;/p&gt;
&lt;p&gt;[6] S. Park, H. S. Shim, M. Chatterjee, K. Sagae, and L.-P. Morency, “Computational Analysis of Persuasiveness in Social Multimedia: A Novel Dataset and Multimodal Prediction Approach,” Proc. 16th Int. Conf. Multimodal Interact. - ICMI ’14, pp. 50–57, 2014. &lt;/p&gt;
&lt;p&gt;[7] B. Siddiquie, D. Chisholm, and A. Divakaran, “Exploiting multimodal affect and semantics to identify politically persuasive web videos,” in ICMI 2015 - Proceedings of the 2015 ACM International Conference on Multimodal Interaction, 2015, pp. 203–210. &lt;/p&gt;
&lt;p&gt;[8] B. Nojavanasghari, D. Gopinath, J. Koushik, T. Baltrušaitis, and L.-P. Morency, “Deep Multimodal Fusion for Persuasiveness Prediction,” in ICMI 2016 - Proceedings of the 2016 ACM International Conference on Multimodal Interaction, 2016, pp. 1–5. &lt;/p&gt;
&lt;p&gt;[9] R. Mestre, R. Milicin, S. E. Middleton, M. Ryan, J. Zhu, and T. J. Norman, “M-Arg: Multimodal Argument Mining Dataset for Political Debates with Audio and Transcripts,” 8th Work. Argument Mining, ArgMining 2021 - Proc., no. 2014, pp. 78–88, 2021. &lt;/p&gt;
&lt;p&gt;[10] M. Brilman and S. Scherer, “A Multimodal Predictive Model of Successful Debaters or How I Learned to Sway Votes,” Proc. 23rd ACM Int. Conf. Multimed., pp. 149–158, 2015. &lt;/p&gt;
&lt;p&gt;[11] E. Mancini, F. Ruggeri, A. Galassi, and P. Torroni, “Multimodal Argument Mining: A Case Study in Political Debates,” Proc. 9th Work. Argument Min., pp. 158–170, 2022. &lt;/p&gt;
&lt;p&gt;[12] T. Shiota and K. Shimada, “The Discussion Corpus toward Argumentation Quality Assessment in Multi-Party Conversation,” Proc. - 2020 9th Int. Congr. Adv. Appl. Informatics, IIAI-AAI 2020, pp. 280–283, 2020.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Xenophobias -- Deteccion y reduccion de sesgos etnicos en LLM</title>
      <link>http://localhost:1313/job_offers/thesis-postgrado-bias/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-postgrado-bias/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;Classical bias detection methods used in Machine Learning are themselves biased because of the different confounding variables implied in the assessment of the initial biases. First they are using templates that are syntactically simple and distant from the target data on which the model will be applied. Second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms. 
We propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. The idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes. &lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-non-causal-changes-such-as-in-names-can-cause-differences-in-the-model-outputs-which-should-not-happen&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;figure_v5&#34; srcset=&#34;
               /job_offers/thesis-postgrado-bias/figure_v5_hu8972351964426249376.webp 400w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu11092428002217262131.webp 760w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu3423759269590890690.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-postgrado-bias/figure_v5_hu8972351964426249376.webp&#34;
               width=&#34;760&#34;
               height=&#34;154&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Non-causal changes such as in names can cause differences in the model outputs, which should not happen.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Our work offers a fine-grained analysis of the interactions between names and languages, revealing significant biases in multilingual models, but also strong biases towards some countries&amp;rsquo; names. We linked this with the pre-training data used to pre-train the LLM, by the mean of the Language Model&amp;rsquo;s (pseudo-)likelihood and found out very socially interesting resuts. For example, a sentence containing a Moroccan name will be more likely to be tagged as positive, and less likely to be tagged as hate speech. &lt;/p&gt;
&lt;p&gt;In other words we want to answer the questions: (i) are LLM xenophobic? (ii) how to quantify it? (iii) how to remove this bias?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Funds will be available to support the research of the student.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;We started to answer these questions in two papers (one to be presented at COLING24 and one submitted at ACL24), and would like to continue the adventure with you! We plan to submit our future work at another international NLP/ML/AI conference.&lt;/p&gt;
&lt;p&gt;We have several possibilities regarding the works that can be tackled in this tesis:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM to generate data fitting to production data distribution (KL—&amp;gt;0) &lt;/li&gt;
&lt;li&gt;Generate more target-groups attributes (more fine-grained, since not relying on template; how to validate them) &lt;/li&gt;
&lt;li&gt;Method to reduce the bias of the trained model  &lt;/li&gt;
&lt;li&gt;Test current method on bigger LLM classifiers &lt;/li&gt;
&lt;li&gt;Our method is quantitative and require classes that can manually be seen as positives and negatives. How to extend this to any classification, how to check this bias qualitatively using an algorithm on the distribution (Optimal Transport distance or others…)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Fondecyt de Iniciacion🗣️💬🤖</title>
      <link>http://localhost:1313/project/mmodal_eca/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/mmodal_eca/</guid>
      <description>&lt;p&gt;Multimodal Argumentation Mining in Groups Assisted by an Embodied Conversational Agent&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Principal Investigator of this project&lt;/strong&gt;. This is a 3 years &lt;a href=&#34;https://anid.cl/concursos/concurso-de-proyectos-fondecyt-de-iniciacion-en-investigacion-2025/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fondecyt&lt;/a&gt; grant of of 90.000.000,00 CLP&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; from the Chilean National Research Agency. This is a colaboration with the Université Paris Saclay, the European Commission&amp;rsquo;s DGIT, Sorbonne Université and Bamberg University.&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;Interactions and Multimodality are crucial in the development of intelligent AI models that can understand human-like communication. Human learning occurs through interactions with the environment and other humans, which involves the integration of information from multiple modalities such as vision, language but also touch and hearing that enable us to understand the subtle social meanings behind communication.&lt;/p&gt;
&lt;p&gt;Therefore, to create intelligent machines that can understand human non-verbal communication, it is essential to train them on &lt;strong&gt;multimodal interactions that mimic those of humans to ensure that they can understand and respond appropriately to complex social phenomena&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The recent computational boom has seen the emergence of seminal studies focusing on Multimodal data (Cho, Lu, Schwenk, Hajishirzi, &amp;amp; Kembhavi, 2020; Hasan et al., 2019; Jaegle et al., 2021; J. Li, Li, Xiong, &amp;amp; Hoi, 2022; J. Wang et al., 2022; Zadeh, Chan, Liang, Tong, &amp;amp; Morency, 2019)⁠ and Interactions, whether these ones are textual like OpenIA&amp;rsquo;s InstructGPT or Anthropic&amp;rsquo;s Claude  (Bai et al., 2022; Ouyang et al., 2022; Schulman et al., 2022)⁠, or multimodal like Google&amp;rsquo;s PaLM (Chowdhery et al., n.d.; Chung et al., 2022; Schick, Lomeli, Dwivedi-yu, &amp;amp; Dessì, 2022)⁠ or GPT-4 (Bubeck et al., 2023; OpenAI, 2023; Wu et al., 2023)⁠.&lt;/p&gt;
&lt;p&gt;These advancements show the potential for machines to learn from multimodal interactions and understand human communication, which could revolutionize the way humans socially interact with machines in the future. &lt;strong&gt;Nevertheless, nowadays generative agents are restraint to unimodal data or not using the full time-series of every modality of a real human-machine social interaction&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Interaction and multimodality are vital contexts in many social situations. They are also mandatory to make a machine understand the world and get commonsense knowledge, which is essential when tackling human-related complex tasks. Indeed, &lt;strong&gt;humans are social animals&lt;/strong&gt; and they interact with one another. In a general way, the integration of more context is the key to a deep understanding of many phenomena, in order to disambiguate a situation or to reinforce the current estimation: interaction is a crucial context in many social situations. Multimodal interactions allow understanding in a deeper way human behavior. In this particular setting, it is possible to understand a broader part of the multimodal natural language (see Figure 1). Studying the affective and &lt;strong&gt;social phenomena like Opinions, Emotions, Empathy, Distress, Stances, Persuasiveness or speaker traits allows to greatly improves the response from the machine&lt;/strong&gt; (Pelachaud, Busso, &amp;amp; Heylen, 2021; Zhao, Sinha, Black, &amp;amp; Cassell, 2016)⁠, but this task is difficult even using multimodal data. My research focuses on designing and developing methods that integrate the multimodal context and how humans influence each other in discussion situations. The research goals of this project fall into this general research area: &lt;strong&gt;how to use interactions and multimodality of non-verbal language to enhance social AI systems&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-examples-of-non-verbal-language-involved-in-a-social-interaction-from-vinciarelli-2009&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;interaction&#34; srcset=&#34;
               /project/mmodal_eca/interaction_hu15794327103315274671.webp 400w,
               /project/mmodal_eca/interaction_hu15612226579774470620.webp 760w,
               /project/mmodal_eca/interaction_hu8198735632516945012.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/mmodal_eca/interaction_hu15794327103315274671.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Examples of non-verbal language involved in a social interaction from Vinciarelli (2009)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;multimodality&#34;&gt;Multimodality:&lt;/h4&gt;
&lt;p&gt;Communication is not just limited to language, and it is essential to consider other modalities such as vision or audio when building natural language processing (NLP) systems (Baltrušaitis, Ahuja, &amp;amp; Morency, 2017; Liang, Zadeh, &amp;amp; Morency, 2022)⁠. &lt;strong&gt;Incorporating multiple modalities, or multimodality, is critical in creating more human-like interactions between humans and machines&lt;/strong&gt;. For instance, while language is the primary means of communication for humans, it is often supplemented by visual and auditory cues such as facial expressions, tone of voice, and gestures. Therefore, it is important building multimodal machine learning systems that can interpret and respond to these cues in a human-like manner.&lt;/p&gt;
&lt;p&gt;According to (Fröhlich, Sievers, Townsend, Gruber, &amp;amp; van Schaik, 2019)⁠, both human and non-human primate communication is inherently multimodal. As an example, (Mehrabian, 1971)⁠ even states that 55% of the emotional content is in the visual signal (facial expressions and body language), 38% in the vocal signal (intonation and sound of the voice) and 7% in the verbal signal (through the meaning of the words and the arrangement of the sentence).&lt;/p&gt;
&lt;h4 id=&#34;interactions-dynamics&#34;&gt;Interactions dynamics:&lt;/h4&gt;
&lt;p&gt;It is essential to consider the interactive nature of human communication and incorporate it into natural language processing (NLP) systems. By allowing the machine to understand the context and flow of the conversation, it can provide a more natural and seamless interaction with users (Sutskever, Vinyals, &amp;amp; Le, 2014)⁠. (Z. Li, Wallace, Shen, &amp;amp; Lin, 2020)⁠ suggested that these systems can provide tailored content and services based on the user&amp;rsquo;s interests and preferences, leading to more engaging and personalized interactions with the user. &lt;strong&gt;As humans, we are not learnig by looking at or enviroment, but by interacting with it and with our peers&lt;/strong&gt;. By considering the interactive nature of human communication and incorporating it into NLP systems, machines can learn to communicate in a way that is more similar to humans, making interactions more engaging and effective.&lt;/p&gt;
&lt;h4 id=&#34;proposed-research-project&#34;&gt;Proposed research project:&lt;/h4&gt;
&lt;p&gt;This research project aims at studying the complex phenomena characterizing social interactions between humans using different media, implying different modalities and data domains. My research objective is to design adaptive models that take as a starting point the specificities of the multimodal interaction: the media used to communicate, the interactants&amp;rsquo; social relationship, and the communication modalities used to transfer the information. &lt;strong&gt;The general goals stand to: understand what the users are trying to achieve as a group, what is the output of this interaction, how a social agent helps reaching it&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-beatrice-bianccardihttpsbeatricebiancardigitlabio-interacting-with-the-virtual-agent-greta&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;beatrice_eca&#34; srcset=&#34;
               /project/mmodal_eca/beatrice_eca_hu9343440991652273668.webp 400w,
               /project/mmodal_eca/beatrice_eca_hu1100368193974869717.webp 760w,
               /project/mmodal_eca/beatrice_eca_hu13291684369485421113.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/mmodal_eca/beatrice_eca_hu9343440991652273668.webp&#34;
               width=&#34;430&#34;
               height=&#34;279&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;a href=&#34;https://beatricebiancardi.gitlab.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Beatrice Bianccardi&lt;/a&gt; interacting with the virtual agent Greta
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In particlar, this project aims to explore the dynamics of how a group of individuals with polarized opinions can reach a consensus. In this work, within groups of individuals debating hot societal topics and issues, the aim will be to automatically detect and retrieve stances and arguments towards the debate question and to ultimately moderate the debate using a human-computer interface that would be specific to such an interaction. To this aim, we think that an &lt;strong&gt;Embodied Conversational Agent&lt;/strong&gt; (Cassell, 2001; Pelachaud, 2005)⁠ like the one illustrated in Figure 2, would be the most relevant. Indeed bodily representations structure the way humans perceive the world and the way they perceive other people. Cognitive sciences and social sciences altogether have stressed &lt;strong&gt;the importance of embodiment in social interaction, highlighting how interacting with others influences how we behave, perceive and think&lt;/strong&gt; (Smith &amp;amp; Neff, 2018; Tieri, Morone, Paolucci, &amp;amp; Iosa, 2018)⁠, including our social behaviors with embodied intelligent agents such as virtual humans and robots (Holz, Dragone, &amp;amp; O’Hare, 2009)⁠.&lt;/p&gt;
&lt;p&gt;Another goal is to explore the polarization of society&amp;rsquo;s attitudes towards hot political topics and study the &lt;strong&gt;difference in terms of the difficulty of finding a consensus&lt;/strong&gt; regarding the type of topics, and the human values involved in classical argumentation (Kiesel, Weimar, Handke, &amp;amp; Weimar, 2022; Mirzakhmedova et al., 2023)⁠. In today&amp;rsquo;s society, the polarization of opinions on political topics is a common phenomenon that can be observed in many different areas. Debates about societal topics and issues can be especially polarizing and lead to a lack of understanding and cooperation between groups with different perspectives (Livingstone, Fernández Rodriguez, &amp;amp; Rothers, 2020)⁠. Therefore, &lt;strong&gt;it is crucial to understand how individuals with polarized opinions can reach a consensus&lt;/strong&gt;, and this is the aim of this research project. To achieve it, this project plans to develop an automatic approach to &lt;strong&gt;detect and retrieve the stance and arguments&lt;/strong&gt; of individuals involved in real-time multimodal debates about hot societal topics.&lt;/p&gt;
&lt;p&gt;This research aims to delve into the complexities of group dynamics in polarized debates on societal issues. To achieve this, we will not only automatically detect and retrieve stances and their arguments toward the debate question, but also take into account the multimodal aspects of the debate, such as &lt;strong&gt;body language, facial expressions and acoustics&lt;/strong&gt;, which are shown to be important for persuasion in a Vlog (Nojavanasghari, Gopinath, Koushik, Baltrušaitis, &amp;amp; Morency, 2016; S. Park, Shim, Chatterjee, Sagae, &amp;amp; Morency, 2014; Siddiquie, Chisholm, &amp;amp; Divakaran, 2015)⁠ or within a debate (Brilman &amp;amp; Scherer, 2015; Mestre et al., 2021)⁠. Real-time interaction within the group will be analyzed to understand &lt;strong&gt;how individuals respond to each other and how the group as whole moves toward a consensus&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 100k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Large Multimodal Models @ CENIAMODAL</title>
      <link>http://localhost:1313/event/ceniamodal/</link>
      <pubDate>Tue, 17 Dec 2024 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/ceniamodal/</guid>
      <description>&lt;p&gt;We are organizing the first edition of the Chilean Workshop on Multimodal Machine Learning in the Universidad Catolica del Norte in Coquimbo!&lt;/p&gt;
&lt;p&gt;Our keynote speakers will be Mohammad Soleymani and Paul Liang&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-mohammad-soleymani&#34;&gt;Invited Talk: Mohammad Soleymani&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image&#34; srcset=&#34;
               /event/ceniamodal/mohammad_hu16140766223214765226.webp 400w,
               /event/ceniamodal/mohammad_hu6648946481130016374.webp 760w,
               /event/ceniamodal/mohammad_hu17490119621469978857.webp 1200w&#34;
               src=&#34;http://localhost:1313/event/ceniamodal/mohammad_hu16140766223214765226.webp&#34;
               width=&#34;256&#34;
               height=&#34;318&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;multimodal-emotion-recognition&#34;&gt;Multimodal Emotion Recognition&lt;/h4&gt;
&lt;p&gt;Mohammad Soleymani is a research associate professor with the USC Institute for Creative Technologies. He received his PhD in computer science from the University of Geneva in 2011. From 2012 to 2014, he was a Marie Curie fellow at Imperial College London. Prior to joining ICT, he was a research scientist at the Swiss Center for Affective Sciences, University of Geneva. His main line of research involves machine learning for emotion recognition and behavior understanding. He is a recipient of the Swiss National Science Foundation Ambizione grant and the EU Marie Curie fellowship. He has served on multiple conference organization committees and editorial roles, most notably as associate editor for the IEEE Transactions on Affective Computing (2015-2021), general chair for ICMI 2024 and ACII 2021 and technical program chair for ACM ICMI 2018 and ACII 2017. He was the president of the Association for the Advancement of Affective Computing (AAAC) (2019-2021).&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-paul-liang&#34;&gt;Invited Talk: Paul Liang&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image&#34; srcset=&#34;
               /event/ceniamodal/paul-liang-headshot-small_hu7254305025386846404.webp 400w,
               /event/ceniamodal/paul-liang-headshot-small_hu7504278872317812574.webp 760w,
               /event/ceniamodal/paul-liang-headshot-small_hu11974117804273599440.webp 1200w&#34;
               src=&#34;http://localhost:1313/event/ceniamodal/paul-liang-headshot-small_hu7254305025386846404.webp&#34;
               width=&#34;290&#34;
               height=&#34;303&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;fundamentals-of-multimodal-representation-learning&#34;&gt;Fundamentals of Multimodal Representation Learning&lt;/h4&gt;
&lt;p&gt;Paul Liang is an Assistant Professor at the MIT Media Lab and MIT EECS. His research advances the foundations of multisensory artificial
intelligence to enhance the human experience. He is a recipient of the Siebel Scholars Award, Waibel Presidential Fellowship, Facebook
PhD Fellowship, Center for ML and Health Fellowship, Rising Stars in Data Science, and 3 best paper awards. Outside of research, he
received the Alan J. Perlis Graduate Student Teaching Award for developing new courses on multimodal machine learning.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tackling Biases In or Using Generative AI @ JSIC&#39;24</title>
      <link>http://localhost:1313/event/jsic/</link>
      <pubDate>Wed, 04 Dec 2024 08:30:00 +0000</pubDate>
      <guid>http://localhost:1313/event/jsic/</guid>
      <description>&lt;p&gt;In this talk, I am focusing on several methods based on data perturbation to detect biases in Large Language Models (LLMs) and Large Multimodal Models (LMMs). We have observed cases where these systems leverage gender, race, or even socioeconomic class information inappropriately for task resolution. Instead of employing real causal reasoning, they often rely on spurious correlations—a phenomenon commonly referred to as bias.&lt;/p&gt;
&lt;p&gt;We will demystify the concept of bias, explaining why biases are ubiquitous, why they can sometimes be useful, and proposing a method to detect harmful biases.&lt;/p&gt;
&lt;p&gt;First, we will introduce a method we developed to detect biases in LLMs toward different countries using the most common names as proxies. Our findings reveal very negative biases toward certain countries, using widely utilized open-source classifiers for social media analysis. Furthermore, we demonstrate that the same multilingual model tends to favor names from countries that speak the language of the sentence—a phenomenon we call AI Xenophobia. This phenomenon has significant social implications. Our study, which examined the perplexity of language models and classifier outputs, shows that the model reacts differently to completely unknown languages compared to familiar ones and exhibits similar behavior toward names as it does with unfamiliar languages.&lt;/p&gt;
&lt;p&gt;Second, we present a method to mitigate biases in Vision-Language Models, particularly in image captioning models. By perturbing the training data through data augmentation with a Text-to-Image generative model, we enhance variability in the dataset. This approach not only reduces gender bias but also improves the model&amp;rsquo;s performance in tasks such as counting objects and detecting colors.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] [Tesis pre/postgrado] JAJAJJJJJ -- Deteccion de humor en videos de stand-up comedy</title>
      <link>http://localhost:1313/job_offers/thesis-jajaja/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-jajaja/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;Humour is a key dimension in human-human communication and is used constantly, in a wide variety of contexts. It is used for its pleasing effect as it can help explain complex ideas during important presentations or it can serve as pure entertainment like in movies or stand up comedy. Sometimes, it can also be used in a less deliberate manner, unconsciously, as a way to regulate the inherent stress and tension arising in conversations, by presenting one’s ideas and intentions in an alternate way.&lt;/p&gt;
&lt;p&gt;While Human-Agent interactions are growing in popularity due to the recent thrive of Large Language Models, the resulting conversations still remain frustrating for the users when they start to use subtle conversational strategies and skills such as irony, euphemism, hyperbolism and humour.&lt;/p&gt;
&lt;p&gt;Today, when a human is using humour during a human-agent interaction, this tends to interrupt the flow of the interaction. Agents interpret quite literally what a human is saying and as the agent does not react as the human would expect from a fellow conversational partner this leads to rephrasing, repeating and eventually frustration.&lt;/p&gt;
&lt;p&gt;Our vision for the future of conversational agents is that agents should be able at least to detect humorous attempts and to redirect the flow of the conversation accordingly. In this project, our main objective is to endow conversational agents with the ability to recognize when humour is being used by a human during human-agent interactions. Towards this goal, we will be relying on a multimodal approach and we will investigate how multimodal computational models can achieve this.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-example-taken-from-the-ur-funny-dataset-6&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;UR_FUNNY&#34; srcset=&#34;
               /job_offers/thesis-jajaja/UR_FUNNY_hu10620972935419908973.webp 400w,
               /job_offers/thesis-jajaja/UR_FUNNY_hu12261418939102111829.webp 760w,
               /job_offers/thesis-jajaja/UR_FUNNY_hu2094234890411483346.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-jajaja/UR_FUNNY_hu10620972935419908973.webp&#34;
               width=&#34;760&#34;
               height=&#34;296&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Example taken from the UR-FUNNY dataset [6]
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;On this project, we will focus on the use of multimodal models with or without interactions [1,2] that can be also multilingual [3]. We would focus on multimodal but also multicultural specific social context [4], showing that multimodal is essential to detect complex human cultural and social phenonema such as sarcasm [5] or humour detection [6]. For group interactions, modelization of the speakers will be done using special architecture such as DialogueRNN [7].&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;Here, we will focus on the first brick of this amazing human-machine project, which is the characterization and detection of humor using verbal and non-verbal language. First, we will study this complex phenomena in various languages using stand-up comedy videos. Second, if time allows it, we would focus on dyad or group interactions, such as TV-shows or better, naturalistic interactions.&lt;/p&gt;
&lt;p&gt;The student will have to work on the several tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collection of a dataset of stand-up comedy videos on youtube&lt;/li&gt;
&lt;li&gt;Cleaning and analysis of the dataset&lt;/li&gt;
&lt;li&gt;Multimodal modelization of human verbal and non-verbal language using binary classification&lt;/li&gt;
&lt;li&gt;Possibility to think about a more fine-grained humour taxonomy (more than just binary, how to propagate laugh, etc…)&lt;/li&gt;
&lt;li&gt;Collection of a dataset of humor in interactions&lt;/li&gt;
&lt;li&gt;Modelization more complex of multi-party interactions&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bibliography&#34;&gt;Bibliography&lt;/h3&gt;
&lt;p&gt;[1] P. P. Liang, Y. Cheng, R. Salakhutdinov, and L. P. Morency, “Multimodal Fusion Interactions: A Study of Human and Automatic Quantification,” ACM Int. Conf. Proceeding Ser., pp. 425–435, 2023.&lt;/p&gt;
&lt;p&gt;[2] A. Zadeh, P. P. Liang, N. Mazumder, S. Poria, E. Cambria, and L.-P. Morency, “Memory Fusion Network for Multi-view Sequential Learning,” in AAAI, 2018.&lt;/p&gt;
&lt;p&gt;[3] A. Zadeh, Y. S. Cao, S. Hessner, P. P. Liang, S. Poria, and L. Morency, “CMU-MOSEAS : A Multimodal Language Dataset for Spanish , Portuguese , German and French,” in EMNLP, 2020, vol. 1, no. 1, pp. 1801–1812.&lt;/p&gt;
&lt;p&gt;[4] M. Sap, S. Gabriel, L. Qin, D. Jurafsky, N. A. Smith, and Y. Choi, “Social Bias Frames: Reasoning about Social and Power Implications of Language,” Proc. ofthe 58th Annu. Meet. ofthe Assoc. Comput. Linguist., pp. 5477–5490, 2020.&lt;/p&gt;
&lt;p&gt;[5] P. Desai, T. Chakraborty, and M. S. Akhtar, “Nice perfume. How long did you marinate in it? Multimodal Sarcasm Explanation,” in AAAI, 2022.&lt;/p&gt;
&lt;p&gt;[6] M. K. Hasan et al., “UR-FUNNY: A Multimodal Language Dataset for Understanding Humor,” 2019.&lt;/p&gt;
&lt;p&gt;[7] N. Majumder, S. Poria, D. Hazarika, R. Mihalcea, A. Gelbukh, and E. Cambria, “DialogueRNN: An Attentive RNN for Emotion Detection in Conversations,” in AAAI, 2019.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers</title>
      <link>http://localhost:1313/publication/emnlp24-ppl/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/emnlp24-ppl/</guid>
      <description>&lt;p&gt;This work is driven by the results of a &lt;a href=&#34;http://localhost:1313/publication/LREC24-XENOPHOBIA/&#34;&gt;previous paper&lt;/a&gt; on country-level bias detection in LLMs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>XenophoBias🏳️‍🌈</title>
      <link>http://localhost:1313/project/xenophobias/</link>
      <pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/xenophobias/</guid>
      <description>&lt;p&gt;Multicultural Bias Recognition to Detect and Mitigate Racism, Xenophobia and Geographic Inequalities in Multilingual Large Language Models.&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Principal Investigator of this project&lt;/strong&gt;. This is a 2 years &lt;a href=&#34;https://uchile.cl/convocatorias/216327/concurso-u-inicia-2024&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;U-inicia&lt;/a&gt; grant from the University with a total budget of 8,000,000 CLP.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;Classical bias detection methods used in Machine Learning and Natural Language Processing (NLP) are themselves biased because of the different confounding variables implied in the assessment of the initial biases. First they are using templates that are syntactically simple and distant from the target data on which the model will be applied. Second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;counfounding&#34; srcset=&#34;
               /project/xenophobias/featured_hu4709178623435340922.webp 400w,
               /project/xenophobias/featured_hu2414093935314123718.webp 760w,
               /project/xenophobias/featured_hu9909048982336450453.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/featured_hu4709178623435340922.webp&#34;
               width=&#34;449&#34;
               height=&#34;587&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. The idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes. We focus on named entity perturbations by applying a &lt;strong&gt;Named Entity Recognition&lt;/strong&gt; (NER) on target-domain data and modifying them accordingly to most common names or location of a target group (gender and/or country), and this for several morphosynctactically different languages spoken in relation with the countries of the target groups. &lt;strong&gt;The idea is that perturbing the input data with a non-causal change should not impact the output distribution of a model&lt;/strong&gt;, but it actually does with respect to the languages and the country of provenance of the added entity perturbing the sentence. An analysis of the changes helps practitioners getting a deeper understanding of how a model can react to different target groups.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-we-use-the-target-domain-data-to-create-templates&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overall&#34; srcset=&#34;
               /project/xenophobias/figure_v9_1_hu1431973182623297372.webp 400w,
               /project/xenophobias/figure_v9_1_hu5426821930535034716.webp 760w,
               /project/xenophobias/figure_v9_1_hu13032372178332810117.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/figure_v9_1_hu1431973182623297372.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      We use the target-domain data to create templates.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Here is an example with two sentences, $S^n$
 being ambiguous and $S^1$
 obvious hate speech. The model output of the perturbated versions is highly variable for the multilingual variations of &lt;em&gt;Alexander&lt;/em&gt;. With some name variations, such as the Turkish or Indian, the models classify the sentences as more negative or detect less hate speech. Meaning it will not moderate the content of an insult toward this person (see below):
















&lt;figure  id=&#34;figure-the-templates-obtained-from-target-domain-data-are-filled-with-common-names-from-various-countries-the-difference-in-the-models-output-is-significative-of-a-bias-regarding-the-names&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overall&#34; srcset=&#34;
               /project/xenophobias/figure_v9_2_hu5969773204992941524.webp 400w,
               /project/xenophobias/figure_v9_2_hu408390470316705406.webp 760w,
               /project/xenophobias/figure_v9_2_hu4458702702344355493.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/figure_v9_2_hu5969773204992941524.webp&#34;
               width=&#34;760&#34;
               height=&#34;334&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The templates obtained from target-domain data are filled with common names from various countries. The difference in the model&amp;rsquo;s output is significative of a bias regarding the names.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We will then focus on &lt;strong&gt;how to leverage LLM in order to create sentences from the target-domain data distribution&lt;/strong&gt;, with entites, then with more fine-grained named concepts related to the countries, such as local meals, celebrations, or regional slang.
We want first to use our method on models available in open-source that are likely to be deployed by industry, i.e., widely used classifiers for subjectivity analysis, including sentiment, emotion, hate speech, and offensive text using Twitter data. &lt;strong&gt;We will assess the bias of a variety of models&lt;/strong&gt; such as an open-source multilingual sentiment analysis model trained over multiple-languages tweets, a multilingual stance recognition model trained over several languages and assessed over English language, an English hate speech classifier, an English large language model, and a multilingual large language model such as Llama-3.
Our work offers a fine-grained analysis of the interactions between names and languages, aiming to reveal significant biases in multilingual models, but also strong biases towards some countries’ names. &lt;strong&gt;We want to link this with the pre-training data used to pre-train the LLM, by the mean of the Language Model’s (pseudo-)likelihood&lt;/strong&gt;. We hope to find out very socially interesting/impacting results such as a sentence containing a name from an arabic or slavic country will more likely to be tagged as negative, and less likely to be tagged as hate speech.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;In other words we want to answer the questions:&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Are LLM xenophobic?&lt;/li&gt;
&lt;li&gt;How to quantify it?&lt;/li&gt;
&lt;li&gt;How to remove this bias?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;schedule&#34;&gt;Schedule&lt;/h3&gt;
&lt;p&gt;Milestones will follow the project objectives and milestones are defined as a group of objectives with a publication at an A(*)-ranked conference or in a journal to complete the milestone.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Milestone 1&lt;/strong&gt; consists of objectives 1 and 2 as well as the publication of a paper at an A(*) conference. The method developed above will be applied to different types of classifiers and generative models. A perplexity analysis will be performed to try to quantify the visible bias of the internal states of neural networks. I plan 5 months to adapt the method that already exists for LLM and use perplexity to find lassos between frequencies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Milestone 2&lt;/strong&gt; consists of objectives 3 and 4, as well as the publication of a paper in a conference A. I plan 4 months for the artificial data generation because it is not so straightforward and we will have to work on the generation in the target distribution per se, and also on the collection and how to add in the generation the socio-cultural attributes of the different countries (2 months + 2 months).&lt;/p&gt;
&lt;p&gt;The last &lt;strong&gt;Milestone 3&lt;/strong&gt; contains the final objective concerning the reduction of bias, with the aggregation of all previous results in a journal publication.  Working on bias reduction based on our method will be quite straightforward. The writing of a journal paper where we will have all the results of the project will be longer than the previous conference papers, which will have more specific and limited contents. For that I plan 4 months for the reduction and 3 months for the writing, with 2 overlapping months.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;gantt&#34; srcset=&#34;
               /project/xenophobias/gantt_hu3088727843124199660.webp 400w,
               /project/xenophobias/gantt_hu11767512201186597748.webp 760w,
               /project/xenophobias/gantt_hu16173524106031046137.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/gantt_hu3088727843124199660.webp&#34;
               width=&#34;760&#34;
               height=&#34;272&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 8k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>WASSA Workshop @ ACL 24</title>
      <link>http://localhost:1313/event/wassa24/</link>
      <pubDate>Thu, 15 Aug 2024 09:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/wassa24/</guid>
      <description>&lt;p&gt;We are orgnizing the 14th edition of the WASSA workshop this year at &lt;a href=&#34;https://2024.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL24&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Our keynote speaker will be Debora Nozza&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://workshop-wassa.github.io/assets/images/debora_nozza.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;The proliferation of hate speech on social media platforms has been rising, with (pseudo-)anonymity allowing individuals to target others without being recognized or easily traced. While this societal issue has garnered significant attention in the NLP community, it presents three major challenges. Hate speech detection models need to be fair, work across all languages, and incorporate personalization while balancing privacy concerns. Addressing these challenges will revolutionize the field of hate speech detection and contribute to the development of a “universal” model that can adapt to individual user perspectives. In this talk, I will present my contributions in this area along with my perspectives on future directions.&lt;/p&gt;
&lt;h4 id=&#34;bio&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;Debora Nozza is an Assistant Professor in Computing Sciences at Bocconi University. Her research interests mainly focus on Natural Language Processing, specifically on the detection and counter-acting of hate speech and algorithmic bias on Social Media data in multilingual context&lt;/p&gt;
&lt;h2 id=&#34;about-wassa&#34;&gt;About WASSA&lt;/h2&gt;
&lt;p&gt;The aim of WASSA 2024 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text. For this edition, we encourage the submission of long and short research and demo papers including, but not restricted to the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resources for subjectivity, sentiment, emotion and social media analysis&lt;/li&gt;
&lt;li&gt;Opinion retrieval, extraction, categorization, aggregation and summarization&lt;/li&gt;
&lt;li&gt;Humor, Irony and Sarcasm detection&lt;/li&gt;
&lt;li&gt;Mis- and disinformation analysis and the role of affective attributes&lt;/li&gt;
&lt;li&gt;Aspect and topic-based sentiment and emotion analysis&lt;/li&gt;
&lt;li&gt;Analysis of stable traits of social media users, incl. personality analysis and profiling&lt;/li&gt;
&lt;li&gt;Transfer learning for domain, language and genre portability of sentiment analysis&lt;/li&gt;
&lt;li&gt;Modelling commonsense knowledge for subjectivity, sentiment or emotion analysis&lt;/li&gt;
&lt;li&gt;Improvement of NLP tasks using subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;Intrinsic and extrinsic evaluation of subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;The role of emotions in argument mining&lt;/li&gt;
&lt;li&gt;Application of theories from related fields to subjectivity and sentiment analysis&lt;/li&gt;
&lt;li&gt;Multimodal emotion detection and classification&lt;/li&gt;
&lt;li&gt;Applications of sentiment and emotion mining&lt;/li&gt;
&lt;li&gt;Public sentiments and communication patterns of public health emergencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the past years we have noticed that WASSA offers a platform to researchers investigating sentiment and emotion in lesser-resourced languages. The 2023 edition featured work on no less than 23 different languages and two papers specifically targeted multilingual emotion detection. We wish to continue these efforts as we find it important to consider and publish advances in any language as this helps to underline the wealth of our research community and to diminish the dominance of English-language research. To this purpose we propose a Special track on multilinguality and social bridge between high- and lesser-resourced languages/communities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Findings of WASSA 2024 Shared Task on Empathy and Personality Detection in Interactions</title>
      <link>http://localhost:1313/publication/wassa24-task/</link>
      <pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wassa24-task/</guid>
      <description>&lt;p&gt;Fourth shared task related to Empathy we organized at WASSA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Are Text Classifiers Xenophobic? A Country-Oriented Bias Detection Method with Least Confounding Variables</title>
      <link>http://localhost:1313/publication/lrec24-xenophobia/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec24-xenophobia/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Touché23-ValueEval Dataset for Identifying Human Values behind Arguments</title>
      <link>http://localhost:1313/publication/lrec24-touche/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec24-touche/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep Natural Language Feature Learning for Interpretable Prediction</title>
      <link>http://localhost:1313/publication/emnlp23-nllf/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/emnlp23-nllf/</guid>
      <description></description>
    </item>
    
    <item>
      <title>WASSA Workshop @ ACL 23</title>
      <link>http://localhost:1313/event/wassa23/</link>
      <pubDate>Fri, 14 Jul 2023 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/wassa23/</guid>
      <description>&lt;p&gt;We are orgnizing the 13th edition of the WASSA workshop this year at &lt;a href=&#34;https://2023.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL23&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Our keynote speakers will be David Jurgens and Emily Öhman&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-david-jurgens&#34;&gt;Invited Talk: David Jurgens&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://wassa-workshop.github.io/assets/images/david_jurgens.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;the-social-dimensions-of-communication-how-context-shapes-language-use-and-interpretation&#34;&gt;The Social Dimensions of Communication: How Context Shapes Language Use and Interpretation&lt;/h4&gt;
&lt;p&gt;NLP studies of communication often focus on the individual: What we say, when we say it, and how we say it. Yet, the larger social context beyond the individual also plays an important role in our communication — just think of things you can say to your friends but not your parents. How does the social context influence our communication style and content? In this talk, I will describe recent work from my group studying the influence of this context by examining how we choose who to communicate with, how we interpret messages, and how we phrase messages. Across these studies, I will motivate a causal approach for NLP when studying communication behavior to move beyond descriptive analyses to more precise estimates of the effects of social context.&lt;/p&gt;
&lt;h4 id=&#34;bio&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;David Jurgens is an assistant professor at the University of Michigan School of Information where he leads the Blablablab. He holds a PhD in Computer Science from the University of California, Los Angeles. His research focuses on the intersection between NLP and computational social science venues and has won the Cozzarelli Prize, Cialdini Prize, best paper at ICWSM and W-NUT, and best paper nomination at ACL and Web Science.&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-emily-öhman&#34;&gt;Invited Talk: Emily Öhman&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://wassa-workshop.github.io/assets/images/emilyohman.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;affective-datafication-of-narratives-measuring-affect-emotion-and-mood-in-literary-texts&#34;&gt;Affective Datafication of Narratives: measuring affect, emotion, and mood in literary texts&lt;/h4&gt;
&lt;p&gt;Our understanding of affect, emotion, and mood - despite the distinct nuances each term holds - often becomes blurred, leading to a usage that is almost interchangeable, particularly within sentiment analysis and NLP. In contrast, traditional fields such as literary studies hold on to more rigid definitions of these terms and how they are understood both in theory and practice. This can easily foster a disconnect between emerging fields such as computational literary studies and the more established qualitative counterparts. This disconnect unfortunately hinders the free exchange of innovative research ideas and methodologies. This talk aims to bridge this gap, highlighting the unique roles of affect, emotion, and mood in narratives and how we can attempt to robustly measure them. We will delve into the interplay of these terms, exploring how they shape and are shaped by authors, readers, and researchers focusing on the operationalization and translation involved in the analysis of emotion-laden phenomena. This exploration will underscore the need for a more comprehensive and nuanced understanding, encouraging synergy between tradition and innovation in emotion detection in general and literary research in particular.&lt;/p&gt;
&lt;h4 id=&#34;bio-1&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;Emily Öhman is currently a tenure-track Assistant professor of Digital Humanities at Waseda University. She received her PhD in Language Technology from the University of Helsinki, where her work centered on building multilingual emotion detection resources for downstream tasks.&lt;/p&gt;
&lt;p&gt;Her research interests lie within digital humanities and NLP, more specifically sentiment analysis and emotion detection, often doing collaborations with various disciplines such as history, literature, and political science. Her recent projects have focused on negative emotions in literature using affect as a proxy for the literary concept of mood and most recently contrasting the semantic spaces of shame and guilt in Japanese and English social media posts.&lt;/p&gt;
&lt;h2 id=&#34;about-wassa&#34;&gt;About WASSA&lt;/h2&gt;
&lt;p&gt;The aim of WASSA 2023 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text. For this edition, we encourage the submission of long and short research and demo papers including, but not restricted to the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resources for subjectivity, sentiment, emotion and social media analysis&lt;/li&gt;
&lt;li&gt;Opinion retrieval, extraction, categorization, aggregation and summarization&lt;/li&gt;
&lt;li&gt;Humor, Irony and Sarcasm detection&lt;/li&gt;
&lt;li&gt;Mis- and disinformation analysis and the role of affective attributes&lt;/li&gt;
&lt;li&gt;Aspect and topic-based sentiment and emotion analysis&lt;/li&gt;
&lt;li&gt;Analysis of stable traits of social media users, incl. personality analysis and profiling&lt;/li&gt;
&lt;li&gt;Transfer learning for domain, language and genre portability of sentiment analysis&lt;/li&gt;
&lt;li&gt;Modelling commonsense knowledge for subjectivity, sentiment or emotion analysis&lt;/li&gt;
&lt;li&gt;Improvement of NLP tasks using subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;Intrinsic and extrinsic evaluation of subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;The role of emotions in argument mining&lt;/li&gt;
&lt;li&gt;Application of theories from related fields to subjectivity and sentiment analysis&lt;/li&gt;
&lt;li&gt;Multimodal emotion detection and classification&lt;/li&gt;
&lt;li&gt;Applications of sentiment and emotion mining&lt;/li&gt;
&lt;li&gt;Public sentiments and communication patterns of public health emergencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We furthermore encourage submissions to the special theme Ethics in Affective Computing, including opinion papers, as well as experimental papers. This includes the following topics, but is not limited to them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Which properties of a model render a automatic analysis task unethical?&lt;/li&gt;
&lt;li&gt;Which characteristics of an annotation task are to be considered in ethical considerations?&lt;/li&gt;
&lt;li&gt;What are appropriate methods to analyze data and models from an ethical perspective?&lt;/li&gt;
&lt;li&gt;What aspects are particular important for affective analysis tasks, in contrast to other NLP settings?&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Findings of WASSA 2023 Shared Task on Empathy, Emotion and Personality Detection in Conversation and Reactions to News Articles</title>
      <link>http://localhost:1313/publication/wassa23-task/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wassa23-task/</guid>
      <description>&lt;p&gt;Third shared task related to Empathy we organized at WASSA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multilingual Multi-Target Stance Recognition in Online Public Consultations</title>
      <link>http://localhost:1313/publication/mdpi23-participatory/</link>
      <pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/mdpi23-participatory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CoFE: A New Dataset of Intra-Multilingual Multi-target Stance Classification from an Online European Participatory Democracy Platform</title>
      <link>http://localhost:1313/publication/aacl22-cofe/</link>
      <pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/aacl22-cofe/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Debating Europe: A Multilingual Multi-Target Stance Classification Dataset of Online Debates</title>
      <link>http://localhost:1313/publication/lrec22-deurope/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec22-deurope/</guid>
      <description></description>
    </item>
    
    <item>
      <title>WASSA 2022 Shared Task: Predicting Empathy, Emotion and Personality in Reaction to News Stories</title>
      <link>http://localhost:1313/publication/wassa22-task/</link>
      <pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wassa22-task/</guid>
      <description>&lt;p&gt;Second shared task related to Empathy we organized at WASSA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How does a Pre-Trained Transformer Integrate Contextual Keywords? Application to Humanitarian Computing</title>
      <link>http://localhost:1313/publication/iscram21-meta/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/iscram21-meta/</guid>
      <description>&lt;p&gt;It is possible to integrate textual metadata into transformers in order to help the model improve its performances. We show the model uses the semantics of the keyword metadata analyzing the attention interaction between the metadata and the text to classify. We applied this to a humanitarian classification task over tweets, using the disaster event type as context, and finally show this method is also useful to caracterize a new event like a hurricane in a data-driven way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving Sentiment Analysis over non-English Tweets using Multilingual Transformers and Automatic Translation for Data-Augmentation</title>
      <link>http://localhost:1313/publication/coling20-mling/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/coling20-mling/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
