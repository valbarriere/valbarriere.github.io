<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Job/Thesis Offers | Valentin Barriere</title>
    <link>http://localhost:1313/job_offers/</link>
      <atom:link href="http://localhost:1313/job_offers/index.xml" rel="self" type="application/rss+xml" />
    <description>Job/Thesis Offers</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Jan 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu6033596820838205990.png</url>
      <title>Job/Thesis Offers</title>
      <link>http://localhost:1313/job_offers/</link>
    </image>
    
    <item>
      <title>[Tesis postgrado] [Pagada] Deteccion de Fuego en la naturaleza usando IA</title>
      <link>http://localhost:1313/job_offers/thesis-fairefighter/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-fairefighter/</guid>
      <description>&lt;p&gt;Early wildfire detection is of the utmost importance to enable rapid response efforts, and thus minimize the negative impacts of wildfire spreads. To this extent, we propose to install a networks of stations composed of cameras connected to Raspberry Pi that process the images in real time in order to automatically detect smoke plumes using Computer Vision algorithms. We scrapped the web in order to create &lt;a href=&#34;https://arxiv.org/abs/2402.05349&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a new database&lt;/a&gt; of smoke plumes&amp;rsquo; sequence of images (videos).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-overview-of-the-fairefighter-solution-using-object-detection-models-to-detect-smoke-plumes-in-the-wild&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overview_EWD&#34; srcset=&#34;
               /job_offers/thesis-fairefighter/overview_EWD_hu9830338541403336544.webp 400w,
               /job_offers/thesis-fairefighter/overview_EWD_hu2557711783386077624.webp 760w,
               /job_offers/thesis-fairefighter/overview_EWD_hu7278080974264488546.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-fairefighter/overview_EWD_hu9830338541403336544.webp&#34;
               width=&#34;760&#34;
               height=&#34;427&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Overview of the fAIrefighter solution, using object detection models to detect smoke plumes in the wild
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The challenges are various:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The detection is currently tackled using a classical state-of-the-art object detection model (Yolov8) that do not take into account the sequentiality&lt;/li&gt;
&lt;li&gt;The images are processed on a light computer, this makes space to work more frugal models&lt;/li&gt;
&lt;li&gt;A benchmark of the SOTA models is needed&lt;/li&gt;
&lt;li&gt;How to improve the quality of the dataset by using bigger models offline (even though they cannot be used online)&lt;/li&gt;
&lt;li&gt;Improve the model for early detection (&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S092427162200332X&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;an exemple&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a project in collaboration with the non-profit association PyroNear and the Corporacion Nacional Forestal.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Aprender a aprender -- IA y Meta-learning para datos Satelitales</title>
      <link>http://localhost:1313/job_offers/thesis-meta-deepcrop/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-meta-deepcrop/</guid>
      <description>&lt;p&gt;Recent trend in Deep Learning is to train in a self-supervised way models that create high-quality dense vector representation to be fine-tuned on downstream tasks, allowing to reach high results in text [1], computer vision [2] but also in speech [3]. This trend is also true when processing Remote Sensing data [4], [5], [6]. These models are pre-trained on a huge quantity of data without labels using techniques such as Masked Image Modeling  of the U-BARN [7]. They have been shown to reach higher results than the state-of-the-art approach for crop classification. Moreover, recent work [8] showed that they can also be pre-train using meta-learning methods, with available labeled data in order to adapt easily to a new unseen task with only a few training examples.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-meteor-model-learned-using-meta-learning-and-various-tasks-from-8&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;metalearning&#34; srcset=&#34;
               /job_offers/thesis-meta-deepcrop/metalearning_hu8736316492409248854.webp 400w,
               /job_offers/thesis-meta-deepcrop/metalearning_hu5378775358810166572.webp 760w,
               /job_offers/thesis-meta-deepcrop/metalearning_hu11622278346872266028.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-meta-deepcrop/metalearning_hu8736316492409248854.webp&#34;
               width=&#34;760&#34;
               height=&#34;505&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      METEOR model learned using Meta learning and various tasks from [8]
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Therefore, the development of state-of-the-art classification and estimation models, as well as technologies to collect necessary in-situ (ground truth) data, are crucially lacking in Chile. Importantly, given the violent climate changes and drought episodes Chile is currently facing, this technology is becoming imperative. In the project we describe below we propose an innovative way of developing such a technology, based on state-of-the-art deep learning models and remote sensing, that can efficiently, quickly and accurately generate estimates of field areas, crop types and yield estimations.&lt;/p&gt;
&lt;h3 id=&#34;task&#34;&gt;Task&lt;/h3&gt;
&lt;p&gt;Intensive pre-training of models of billions of parameters will be implemented, and we will further fine-tune them over several task using labels from chilean landsape delivered from our project partner the Centro de Información de Recursos Naturales (CIREN).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collect a huge dataset of open-source Sentinel2 data at the level of the whole country and for several years&lt;/li&gt;
&lt;li&gt;Train a foundational model in an auto-supervised way using the various spectrum of data from Chile (climate, vegetation, soil is very different)&lt;/li&gt;
&lt;li&gt;Use meta-learning algorithm in order to fine-tune the model for a broad set of different tasks using annotated dataset from Chile and from abroad&lt;/li&gt;
&lt;li&gt;Deliver the model as an open-source tool for the community&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bibliography&#34;&gt;Bibliography&lt;/h3&gt;
&lt;p&gt;[1]  J. Devlin, M. Chang, K. Lee, and K. Toutanova, ‘BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding’, 2018.
[2]  A. Dosovitskiy et al., ‘An image is worth 16x16 words: Transformers for image recognition at scale’, arXiv preprint arXiv:2010.11929, 2020.  
[3]  V. Pratap et al., ‘Scaling speech technology to 1,000+ languages’, arXiv preprint arXiv:2305.13516, 2023.  
[4]  M. J. Smith, L. Fleming, and J. E. Geach, ‘EarthPT: a foundation model for Earth Observation’, arXiv preprint arXiv:2309.07207, 2023.  
[5]  A. Lacoste et al., ‘Geo-bench: Toward foundation models for earth monitoring’, Adv Neural Inf Process Syst, vol. 36, 2024.  
[6]  Z. Xiong, Y. Wang, F. Zhang, and X. X. Zhu, ‘One for All: Toward Unified Foundation Models for Earth Vision’, arXiv preprint arXiv:2401.07527, 2024.  
[7]  I. Dumeur, S. Valero, and J. Inglada, ‘Self-supervised spatio-temporal representation learning of Satellite Image Time Series’, IEEE J Sel Top Appl Earth Obs Remote Sens, 2024.
[8]  M. Rußwurm, S. Wang, B. Kellenberger, R. Roscher, and D. Tuia, ‘Meta-learning to address diverse Earth observation problems across resolutions’, Commun Earth Environ, vol. 5, no. 1, p. 37, 2024.  &lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Change my view! -- Analisis de argumentacion multimodal</title>
      <link>http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt; Interactions and Multimodality are crucial in the development of intelligent AI models that can understand human-like communication. Human learning occurs through interactions with the environment and other humans, which involves the integration of information from multiple modalities such as vision, language but also touch and hearing that enable us to understand the subtle social meaning behind communication. 
Therefore, to create intelligent machines that can understand human communication, it is essential to train them on multimodal interactions that mimic those of humans to ensure that they can understand and respond appropriately to complex social phenomena. 
The research objective is to design adaptive models that take as a starting point the specificities of the multimodal interaction: the media used to communicate, the way the users are socially linked together, and the modalities used by them to transfer information. 
For this reason, we aim to study multimodal argumentation mining as a starting point. Dialog systems helps to improve the quality of a debate [1,2,3,4]. But phenomena related to argumentation relies on multimodal communication and are related to persuasion, or communication skills [5,6,7,8]. For this, we are focusing on multimodal argument mining [9,10,11,12]. &lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig_tesis_proposicion&#34; srcset=&#34;
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu700631809574394399.webp 400w,
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu1221762742450276794.webp 760w,
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu4398504731950838957.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu700631809574394399.webp&#34;
               width=&#34;760&#34;
               height=&#34;241&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;The student will engage in the construction of multimodal machine learning models that take as input video and are able to detect complex social phenomena such as empathy, persuasion and emotion but also text-based argumentation models. During the thesis, we will also focus on the construction of a debate dataset in Chilean Spanish (and hopefully  in French), on political hot topics that are seen as polarizing in both countries. 
s
In a few bullet-points, different research axis will be explored regarding the available time (w.r.t. the type of tesis/memoria): &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creation of mutlimodal models aiming to detect social phenomena in discourse and also in a dyadic or group interaction&lt;/li&gt;
&lt;li&gt;Adaptation or creation of an text-based argumentation annotation scheme for multimodal data&lt;/li&gt;
&lt;li&gt;Creation of the chilean part of a multicultural database of debates on polarizing topics  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Funds will be available to support the research of the student.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; ### Bibliography&lt;/p&gt;
&lt;p&gt;[1] V. Petukhova, T. Mayer, A. Malchanau, and H. Bunt, “Virtual debate coach design: Assessing multimodal argumentation performance,” ICMI 2017 - Proc. 19th ACM Int. Conf. Multimodal Interact., vol. 2017-Janua, no. 1, pp. 41–50, 2017. &lt;/p&gt;
&lt;p&gt;[2] N. Rach, E. André, K. Weber, W. Minker, L. Pragst, and S. Ultes, “EVA: A multimodal argumentative dialogue system,” ICMI 2018 - Proc. 2018 Int. Conf. Multimodal Interact., no. October, pp. 551–552, 2018. &lt;/p&gt;
&lt;p&gt;[3] A. Khan, J. Hughes, D. Valentine, L. Ruis, K. Sachan, and A. Radhakrishnan, “Debating with More Persuasive LLMs Leads to More Truthful Answers,” 2024. &lt;/p&gt;
&lt;p&gt;[4] L. P. Argyle et al., “AI Chat Assistants can Improve Conversations about Divisive Topics,” ArXiv, 2023. &lt;/p&gt;
&lt;p&gt;[5] T. Ohba, C. O. Mawalim, S. Katada, H. Kuroki, and S. Okada, “Multimodal Analysis for Communication Skill and Self-Efficacy Level Estimation in Job Interview Scenario,” ACM Int. Conf. Proceeding Ser., pp. 110–120, 2022. &lt;/p&gt;
&lt;p&gt;[6] S. Park, H. S. Shim, M. Chatterjee, K. Sagae, and L.-P. Morency, “Computational Analysis of Persuasiveness in Social Multimedia: A Novel Dataset and Multimodal Prediction Approach,” Proc. 16th Int. Conf. Multimodal Interact. - ICMI ’14, pp. 50–57, 2014. &lt;/p&gt;
&lt;p&gt;[7] B. Siddiquie, D. Chisholm, and A. Divakaran, “Exploiting multimodal affect and semantics to identify politically persuasive web videos,” in ICMI 2015 - Proceedings of the 2015 ACM International Conference on Multimodal Interaction, 2015, pp. 203–210. &lt;/p&gt;
&lt;p&gt;[8] B. Nojavanasghari, D. Gopinath, J. Koushik, T. Baltrušaitis, and L.-P. Morency, “Deep Multimodal Fusion for Persuasiveness Prediction,” in ICMI 2016 - Proceedings of the 2016 ACM International Conference on Multimodal Interaction, 2016, pp. 1–5. &lt;/p&gt;
&lt;p&gt;[9] R. Mestre, R. Milicin, S. E. Middleton, M. Ryan, J. Zhu, and T. J. Norman, “M-Arg: Multimodal Argument Mining Dataset for Political Debates with Audio and Transcripts,” 8th Work. Argument Mining, ArgMining 2021 - Proc., no. 2014, pp. 78–88, 2021. &lt;/p&gt;
&lt;p&gt;[10] M. Brilman and S. Scherer, “A Multimodal Predictive Model of Successful Debaters or How I Learned to Sway Votes,” Proc. 23rd ACM Int. Conf. Multimed., pp. 149–158, 2015. &lt;/p&gt;
&lt;p&gt;[11] E. Mancini, F. Ruggeri, A. Galassi, and P. Torroni, “Multimodal Argument Mining: A Case Study in Political Debates,” Proc. 9th Work. Argument Min., pp. 158–170, 2022. &lt;/p&gt;
&lt;p&gt;[12] T. Shiota and K. Shimada, “The Discussion Corpus toward Argumentation Quality Assessment in Multi-Party Conversation,” Proc. - 2020 9th Int. Congr. Adv. Appl. Informatics, IIAI-AAI 2020, pp. 280–283, 2020.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Xenophobias -- Deteccion y reduccion de sesgos etnicos en LLM</title>
      <link>http://localhost:1313/job_offers/thesis-postgrado-bias/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-postgrado-bias/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;Classical bias detection methods used in Machine Learning are themselves biased because of the different confounding variables implied in the assessment of the initial biases. First they are using templates that are syntactically simple and distant from the target data on which the model will be applied. Second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms.
We propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. The idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-non-causal-changes-such-as-in-names-can-cause-differences-in-the-model-outputs-which-should-not-happen&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;figure_v5&#34; srcset=&#34;
               /job_offers/thesis-postgrado-bias/figure_v5_hu4101750334257282784.webp 400w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu12014982446003253994.webp 760w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu11181646692821307121.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-postgrado-bias/figure_v5_hu4101750334257282784.webp&#34;
               width=&#34;760&#34;
               height=&#34;267&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Non-causal changes such as in names can cause differences in the model outputs, which should not happen.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Our work offers a fine-grained analysis of the interactions between names and languages, revealing significant biases in multilingual models, but also strong biases towards some countries&amp;rsquo; names. We linked this with the pre-training data used to pre-train the LLM, by the mean of the Language Model&amp;rsquo;s (pseudo-)likelihood and found out very socially interesting resuts. For example, a sentence containing a Moroccan name will be more likely to be tagged as positive, and less likely to be tagged as hate speech.&lt;/p&gt;
&lt;p&gt;In other words we want to answer the questions: (i) are LLM xenophobic? (ii) how to quantify it? (iii) how to remove this bias?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Funds will be available to support the research of the student.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;We started to answer these questions in two papers (one published at COLING24 and one published at EMNLP24), and would like to continue the adventure with you! We plan to submit our future work at another international NLP/ML/AI conference.&lt;/p&gt;
&lt;p&gt;We have several possibilities regarding the works that can be tackled in this tesis:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM to generate data fitting to production data distribution (KL—&amp;gt;0)&lt;/li&gt;
&lt;li&gt;Generate more target-groups attributes (more fine-grained, since not relying on template; how to validate them)&lt;/li&gt;
&lt;li&gt;Method to reduce the bias of the trained model&lt;/li&gt;
&lt;li&gt;Test current method on bigger LLM classifiers&lt;/li&gt;
&lt;li&gt;Our method is quantitative and require classes that can manually be seen as positives and negatives. How to extend this to any classification, how to check this bias qualitatively using an algorithm on the distribution (Optimal Transport distance or others…)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] Data Engineer for Geographic and Remote Sensing data</title>
      <link>http://localhost:1313/job_offers/data-eng-deepcrop/</link>
      <pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/data-eng-deepcrop/</guid>
      <description>&lt;p&gt;CIREN, in collaboration with CENIA, is looking for a Data Engineer to be part of the FONDEF Advanced Technologies project team: an ai system for nation-wide agricultural production monitoring based on crowd-sourced and remote-sensing data.&lt;/p&gt;
&lt;h3 id=&#34;what-are-we-looking-for&#34;&gt;What are we looking for?&lt;/h3&gt;
&lt;p&gt;We are looking for a professional with strong technical competencies and interpersonal skills that include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Professionals in the areas of Computer Engineering, Mathematics, Statistics, Physics, Industrial Engineering or related disciplines, preferably with a Master&amp;rsquo;s degree.&lt;/li&gt;
&lt;li&gt;1 to 3 years of professional or project experience.&lt;/li&gt;
&lt;li&gt;Experience in Python, R or SQL&lt;/li&gt;
&lt;li&gt;Knowledge in Machine Learning libraries (scikit-learn, TensorFlow, PyTorch).&lt;/li&gt;
&lt;li&gt;Knowledge in tools to manage geographic data: geopandas, postGIS, geoSQL.&lt;/li&gt;
&lt;li&gt;Knowledge in spatial data processing: Sentinel2, LANDSAT, etc.&lt;/li&gt;
&lt;li&gt;Familiarity with data visualization tools (Power BI, Tableau, Matplotlib, Seaborn).&lt;/li&gt;
&lt;li&gt;Experience in data cleansing and data management in large volumes.&lt;/li&gt;
&lt;li&gt;Knowledge in statistics and advanced probability.&lt;/li&gt;
&lt;li&gt;Familiarity with relational and non-relational databases (PostgreSQL, MongoDB).&lt;/li&gt;
&lt;li&gt;Intermediate or advanced technical English (desirable).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-will-you-do&#34;&gt;What will you do?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Design, implement and optimize Machine Learning and predictive analytics models.&lt;/li&gt;
&lt;li&gt;Collect, clean and structure large volumes of data for analysis.&lt;/li&gt;
&lt;li&gt;Generate actionable insights to support strategic decision making.&lt;/li&gt;
&lt;li&gt;Collaborate with cross-functional teams (developers, analysts, business leaders).&lt;/li&gt;
&lt;li&gt;Visualize data using tools such as Power BI, Tableau or similar.&lt;/li&gt;
&lt;li&gt;Document processes, methodologies and key findings of the projects.&lt;/li&gt;
&lt;li&gt;Ensure the quality and security of the data handled.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-do-we-offer&#34;&gt;What do we offer?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Total gross remuneration of &lt;strong&gt;$2.500.000&lt;/strong&gt;. 2 year fixed term project contract with CIREN.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Offer in the CENIA website &lt;a href=&#34;https://cenia.cl/2024/12/07/buscamos-ingenieroa-de-datos/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] Machine Learning Engineer for Geographic and Remote Sensing data</title>
      <link>http://localhost:1313/job_offers/ml-eng-deepcrop/</link>
      <pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/ml-eng-deepcrop/</guid>
      <description>&lt;p&gt;We are looking for a Machine Learning / Deep Learning research engineer to work on large multi-modal and multi-resolution representation parsing models with satellite data (image sequences).&lt;/p&gt;
&lt;h3 id=&#34;what-will-you-do&#34;&gt;What will you do?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Participate in FONDEF Advanced Technologies project: an ai system for nation-wide agricultural production monitoring based on crowd-sourced and remote-sensing data.&lt;/li&gt;
&lt;li&gt;Develop end-to-end AI solutions.&lt;/li&gt;
&lt;li&gt;Collection of relevant information and design of solutions focused on the optimization of industrial processes.&lt;/li&gt;
&lt;li&gt;Industrial data processing and analysis.&lt;/li&gt;
&lt;li&gt;Development and implementation of advanced predictive models to model subsections of the process.&lt;/li&gt;
&lt;li&gt;Integration and deployment of solutions in production environments.&lt;/li&gt;
&lt;li&gt;Design and build machine learning pipelines focused on optimization and prediction.&lt;/li&gt;
&lt;li&gt;Collaborate on projects within asset-intensive industries such as mining, energy, pulp and paper, among others, applying ML techniques to improve efficiency and productivity.&lt;/li&gt;
&lt;li&gt;Utilize cloud and high performance computing technologies.&lt;/li&gt;
&lt;li&gt;Continuously improve ML solutions through experimentation and iteration.&lt;/li&gt;
&lt;li&gt;Keep up to date with the latest trends and developments in ML and optimization technologies.&lt;/li&gt;
&lt;li&gt;Work closely with the CopernicusLAC team, the European Space Agency&amp;rsquo;s satellite constellation data hub.&lt;/li&gt;
&lt;li&gt;Work on the creation of a satellite data dataset (Sentinel2, Sentinel3, Sentinel5) throughout Latin America and the Caribbean.&lt;/li&gt;
&lt;li&gt;Design and create foundational models for satellite data processing in conjunction with researchers from CENIA and profe from the University of Chile:&lt;/li&gt;
&lt;li&gt;Use multi-scale self-supervised learning techniques on satellite data.&lt;/li&gt;
&lt;li&gt;Use meta-learning algorithms to learn the model to learn new tasks: crop-land mapping, land-use mapping, drought detection, illegal deforestation, etc.&lt;/li&gt;
&lt;li&gt;Participate in writing scientific papers on data creation and modeling, participate in presentation at appropriate conferences: CVPR, ICCV, ECCV, WACAV, NeurIPS, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-are-we-looking-for&#34;&gt;What are we looking for?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Bachelor&amp;rsquo;s degree in Computer Science, Mathematics, Statistics, Engineering or a related field.&lt;/li&gt;
&lt;li&gt;1 to 3 years of professional or ML project experience.&lt;/li&gt;
&lt;li&gt;Verifiable experience in software and/or software development based on machine learning, computer vision and satellite data management.&lt;/li&gt;
&lt;li&gt;Knowledge and previous experience with Python and some of the following libraries: PyTorch, Huggingface, TensorFlow, Scikit-Learn or other related libraries (Excluded)&lt;/li&gt;
&lt;li&gt;Knowledge in tools to manage geographic data: geopandas, postGIS, geoSQL, etc&amp;hellip;&lt;/li&gt;
&lt;li&gt;Knowledge in spatial data processing: Sentinel2 data, LANDSAT, GEE, etc&amp;hellip;&lt;/li&gt;
&lt;li&gt;Demonstrated experience in the design and construction of machine learning pipelines (Excluded).&lt;/li&gt;
&lt;li&gt;Demonstrated experience in the use and development of vision projects (Excluding)&lt;/li&gt;
&lt;li&gt;Familiarity with Machine Learning Operations (MLOps) development practices (Required).&lt;/li&gt;
&lt;li&gt;Experience in consulting projects (Desirable).&lt;/li&gt;
&lt;li&gt;Development experience in Cloud platforms (Desirable).&lt;/li&gt;
&lt;li&gt;Experience with cloud computing platforms, in particular GCP. (Desirable)&lt;/li&gt;
&lt;li&gt;Knowledge of deploying ML models in production environments (Desirable).&lt;/li&gt;
&lt;li&gt;Development experience with code versioning in Git (Desirable).&lt;/li&gt;
&lt;li&gt;Experience with Docker (desirable).&lt;/li&gt;
&lt;li&gt;Experience with Python packages and environments (desirable).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-do-we-offer&#34;&gt;What do we offer?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Total gross remuneration of &lt;strong&gt;$2.500.000&lt;/strong&gt;. Fixed term project contract 2 years.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of our benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;🏡Hybrid work system: Home office combined with face-to-face workday.&lt;/li&gt;
&lt;li&gt;👣Comfortable offices close to San Joaquín subway station.&lt;/li&gt;
&lt;li&gt;🚲Access to bike rack and dressing rooms.&lt;/li&gt;
&lt;li&gt;Parking at preferential price.&lt;/li&gt;
&lt;li&gt;Casual Dress Code.&lt;/li&gt;
&lt;li&gt;🎁Birthday free day.&lt;/li&gt;
&lt;li&gt;🎄Advance disconnection for the holidays.&lt;/li&gt;
&lt;li&gt;✉️ Day off for Vocal de mesa.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CENIA site offer &lt;a href=&#34;https://cenia.cl/2024/12/06/buscamos-igenieroa-en-machine-learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aca&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] [Tesis pre/postgrado] JAJAJJJJJ -- Deteccion de humor en videos de stand-up comedy</title>
      <link>http://localhost:1313/job_offers/thesis-jajaja/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-jajaja/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;Humour is a key dimension in human-human communication and is used constantly, in a wide variety of contexts. It is used for its pleasing effect as it can help explain complex ideas during important presentations or it can serve as pure entertainment like in movies or stand up comedy. Sometimes, it can also be used in a less deliberate manner, unconsciously, as a way to regulate the inherent stress and tension arising in conversations, by presenting one’s ideas and intentions in an alternate way.&lt;/p&gt;
&lt;p&gt;While Human-Agent interactions are growing in popularity due to the recent thrive of Large Language Models, the resulting conversations still remain frustrating for the users when they start to use subtle conversational strategies and skills such as irony, euphemism, hyperbolism and humour.&lt;/p&gt;
&lt;p&gt;Today, when a human is using humour during a human-agent interaction, this tends to interrupt the flow of the interaction. Agents interpret quite literally what a human is saying and as the agent does not react as the human would expect from a fellow conversational partner this leads to rephrasing, repeating and eventually frustration.&lt;/p&gt;
&lt;p&gt;Our vision for the future of conversational agents is that agents should be able at least to detect humorous attempts and to redirect the flow of the conversation accordingly. In this project, our main objective is to endow conversational agents with the ability to recognize when humour is being used by a human during human-agent interactions. Towards this goal, we will be relying on a multimodal approach and we will investigate how multimodal computational models can achieve this.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-example-taken-from-the-ur-funny-dataset-6&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;UR_FUNNY&#34; srcset=&#34;
               /job_offers/thesis-jajaja/UR_FUNNY_hu10620972935419908973.webp 400w,
               /job_offers/thesis-jajaja/UR_FUNNY_hu12261418939102111829.webp 760w,
               /job_offers/thesis-jajaja/UR_FUNNY_hu2094234890411483346.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-jajaja/UR_FUNNY_hu10620972935419908973.webp&#34;
               width=&#34;760&#34;
               height=&#34;296&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Example taken from the UR-FUNNY dataset [6]
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;On this project, we will focus on the use of multimodal models with or without interactions [1,2] that can be also multilingual [3]. We would focus on multimodal but also multicultural specific social context [4], showing that multimodal is essential to detect complex human cultural and social phenonema such as sarcasm [5] or humour detection [6]. For group interactions, modelization of the speakers will be done using special architecture such as DialogueRNN [7].&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;Here, we will focus on the first brick of this amazing human-machine project, which is the characterization and detection of humor using verbal and non-verbal language. First, we will study this complex phenomena in various languages using stand-up comedy videos. Second, if time allows it, we would focus on dyad or group interactions, such as TV-shows or better, naturalistic interactions.&lt;/p&gt;
&lt;p&gt;The student will have to work on the several tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collection of a dataset of stand-up comedy videos on youtube&lt;/li&gt;
&lt;li&gt;Cleaning and analysis of the dataset&lt;/li&gt;
&lt;li&gt;Multimodal modelization of human verbal and non-verbal language using binary classification&lt;/li&gt;
&lt;li&gt;Possibility to think about a more fine-grained humour taxonomy (more than just binary, how to propagate laugh, etc…)&lt;/li&gt;
&lt;li&gt;Collection of a dataset of humor in interactions&lt;/li&gt;
&lt;li&gt;Modelization more complex of multi-party interactions&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bibliography&#34;&gt;Bibliography&lt;/h3&gt;
&lt;p&gt;[1] P. P. Liang, Y. Cheng, R. Salakhutdinov, and L. P. Morency, “Multimodal Fusion Interactions: A Study of Human and Automatic Quantification,” ACM Int. Conf. Proceeding Ser., pp. 425–435, 2023.&lt;/p&gt;
&lt;p&gt;[2] A. Zadeh, P. P. Liang, N. Mazumder, S. Poria, E. Cambria, and L.-P. Morency, “Memory Fusion Network for Multi-view Sequential Learning,” in AAAI, 2018.&lt;/p&gt;
&lt;p&gt;[3] A. Zadeh, Y. S. Cao, S. Hessner, P. P. Liang, S. Poria, and L. Morency, “CMU-MOSEAS : A Multimodal Language Dataset for Spanish , Portuguese , German and French,” in EMNLP, 2020, vol. 1, no. 1, pp. 1801–1812.&lt;/p&gt;
&lt;p&gt;[4] M. Sap, S. Gabriel, L. Qin, D. Jurafsky, N. A. Smith, and Y. Choi, “Social Bias Frames: Reasoning about Social and Power Implications of Language,” Proc. ofthe 58th Annu. Meet. ofthe Assoc. Comput. Linguist., pp. 5477–5490, 2020.&lt;/p&gt;
&lt;p&gt;[5] P. Desai, T. Chakraborty, and M. S. Akhtar, “Nice perfume. How long did you marinate in it? Multimodal Sarcasm Explanation,” in AAAI, 2022.&lt;/p&gt;
&lt;p&gt;[6] M. K. Hasan et al., “UR-FUNNY: A Multimodal Language Dataset for Understanding Humor,” 2019.&lt;/p&gt;
&lt;p&gt;[7] N. Majumder, S. Poria, D. Hazarika, R. Mihalcea, A. Gelbukh, and E. Cambria, “DialogueRNN: An Attentive RNN for Emotion Detection in Conversations,” in AAAI, 2019.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
