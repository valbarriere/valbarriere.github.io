<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Valentin Barriere</title>
    <link>http://localhost:1313/</link>
      <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <description>Valentin Barriere</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu6033596820838205990.png</url>
      <title>Valentin Barriere</title>
      <link>http://localhost:1313/</link>
    </image>
    
    <item>
      <title>[Tesis postgrado] [Pagada] Deteccion de Fuego en la naturaleza usando IA</title>
      <link>http://localhost:1313/job_offers/thesis-fairefighter/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-fairefighter/</guid>
      <description>&lt;p&gt;Early wildfire detection is of the utmost importance to enable rapid response efforts, and thus minimize the negative impacts of wildfire spreads. To this extent, we propose to install a networks of stations composed of cameras connected to Raspberry Pi that process the images in real time in order to automatically detect smoke plumes using Computer Vision algorithms. We scrapped the web in order to create &lt;a href=&#34;https://arxiv.org/abs/2402.05349&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a new database&lt;/a&gt; of smoke plumes&amp;rsquo; sequence of images (videos).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-overview-of-the-fairefighter-solution-using-object-detection-models-to-detect-smoke-plumes-in-the-wild&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overview_EWD&#34; srcset=&#34;
               /job_offers/thesis-fairefighter/overview_EWD_hu9830338541403336544.webp 400w,
               /job_offers/thesis-fairefighter/overview_EWD_hu2557711783386077624.webp 760w,
               /job_offers/thesis-fairefighter/overview_EWD_hu7278080974264488546.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-fairefighter/overview_EWD_hu9830338541403336544.webp&#34;
               width=&#34;760&#34;
               height=&#34;427&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Overview of the fAIrefighter solution, using object detection models to detect smoke plumes in the wild
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The challenges are various:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The detection is currently tackled using a classical state-of-the-art object detection model (Yolov8) that do not take into account the sequentiality&lt;/li&gt;
&lt;li&gt;The images are processed on a light computer, this makes space to work more frugal models&lt;/li&gt;
&lt;li&gt;A benchmark of the SOTA models is needed&lt;/li&gt;
&lt;li&gt;How to improve the quality of the dataset by using bigger models offline (even though they cannot be used online)&lt;/li&gt;
&lt;li&gt;Improve the model for early detection (&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S092427162200332X&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;an exemple&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a project in collaboration with the non-profit association PyroNear and the Corporacion Nacional Forestal.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Aprender a aprender -- IA y Meta-learning para datos Satelitales</title>
      <link>http://localhost:1313/job_offers/thesis-meta-deepcrop/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-meta-deepcrop/</guid>
      <description>&lt;p&gt;Recent trend in Deep Learning is to train in a self-supervised way models that create high-quality dense vector representation to be fine-tuned on downstream tasks, allowing to reach high results in text [1], computer vision [2] but also in speech [3]. This trend is also true when processing Remote Sensing data [4], [5], [6]. These models are pre-trained on a huge quantity of data without labels using techniques such as Masked Image Modeling  of the U-BARN [7]. They have been shown to reach higher results than the state-of-the-art approach for crop classification. Moreover, recent work [8] showed that they can also be pre-train using meta-learning methods, with available labeled data in order to adapt easily to a new unseen task with only a few training examples.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-meteor-model-learned-using-meta-learning-and-various-tasks-from-8&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;metalearning&#34; srcset=&#34;
               /job_offers/thesis-meta-deepcrop/metalearning_hu8736316492409248854.webp 400w,
               /job_offers/thesis-meta-deepcrop/metalearning_hu5378775358810166572.webp 760w,
               /job_offers/thesis-meta-deepcrop/metalearning_hu11622278346872266028.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-meta-deepcrop/metalearning_hu8736316492409248854.webp&#34;
               width=&#34;760&#34;
               height=&#34;505&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      METEOR model learned using Meta learning and various tasks from [8]
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Therefore, the development of state-of-the-art classification and estimation models, as well as technologies to collect necessary in-situ (ground truth) data, are crucially lacking in Chile. Importantly, given the violent climate changes and drought episodes Chile is currently facing, this technology is becoming imperative. In the project we describe below we propose an innovative way of developing such a technology, based on state-of-the-art deep learning models and remote sensing, that can efficiently, quickly and accurately generate estimates of field areas, crop types and yield estimations.&lt;/p&gt;
&lt;h3 id=&#34;task&#34;&gt;Task&lt;/h3&gt;
&lt;p&gt;Intensive pre-training of models of billions of parameters will be implemented, and we will further fine-tune them over several task using labels from chilean landsape delivered from our project partner the Centro de Información de Recursos Naturales (CIREN).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collect a huge dataset of open-source Sentinel2 data at the level of the whole country and for several years&lt;/li&gt;
&lt;li&gt;Train a foundational model in an auto-supervised way using the various spectrum of data from Chile (climate, vegetation, soil is very different)&lt;/li&gt;
&lt;li&gt;Use meta-learning algorithm in order to fine-tune the model for a broad set of different tasks using annotated dataset from Chile and from abroad&lt;/li&gt;
&lt;li&gt;Deliver the model as an open-source tool for the community&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bibliography&#34;&gt;Bibliography&lt;/h3&gt;
&lt;p&gt;[1]  J. Devlin, M. Chang, K. Lee, and K. Toutanova, ‘BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding’, 2018.
[2]  A. Dosovitskiy et al., ‘An image is worth 16x16 words: Transformers for image recognition at scale’, arXiv preprint arXiv:2010.11929, 2020.  
[3]  V. Pratap et al., ‘Scaling speech technology to 1,000+ languages’, arXiv preprint arXiv:2305.13516, 2023.  
[4]  M. J. Smith, L. Fleming, and J. E. Geach, ‘EarthPT: a foundation model for Earth Observation’, arXiv preprint arXiv:2309.07207, 2023.  
[5]  A. Lacoste et al., ‘Geo-bench: Toward foundation models for earth monitoring’, Adv Neural Inf Process Syst, vol. 36, 2024.  
[6]  Z. Xiong, Y. Wang, F. Zhang, and X. X. Zhu, ‘One for All: Toward Unified Foundation Models for Earth Vision’, arXiv preprint arXiv:2401.07527, 2024.  
[7]  I. Dumeur, S. Valero, and J. Inglada, ‘Self-supervised spatio-temporal representation learning of Satellite Image Time Series’, IEEE J Sel Top Appl Earth Obs Remote Sens, 2024.
[8]  M. Rußwurm, S. Wang, B. Kellenberger, R. Roscher, and D. Tuia, ‘Meta-learning to address diverse Earth observation problems across resolutions’, Commun Earth Environ, vol. 5, no. 1, p. 37, 2024.  &lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Change my view! -- Analisis de argumentacion multimodal</title>
      <link>http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt; Interactions and Multimodality are crucial in the development of intelligent AI models that can understand human-like communication. Human learning occurs through interactions with the environment and other humans, which involves the integration of information from multiple modalities such as vision, language but also touch and hearing that enable us to understand the subtle social meaning behind communication. 
Therefore, to create intelligent machines that can understand human communication, it is essential to train them on multimodal interactions that mimic those of humans to ensure that they can understand and respond appropriately to complex social phenomena. 
The research objective is to design adaptive models that take as a starting point the specificities of the multimodal interaction: the media used to communicate, the way the users are socially linked together, and the modalities used by them to transfer information. 
For this reason, we aim to study multimodal argumentation mining as a starting point. Dialog systems helps to improve the quality of a debate [1,2,3,4]. But phenomena related to argumentation relies on multimodal communication and are related to persuasion, or communication skills [5,6,7,8]. For this, we are focusing on multimodal argument mining [9,10,11,12]. &lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig_tesis_proposicion&#34; srcset=&#34;
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu700631809574394399.webp 400w,
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu1221762742450276794.webp 760w,
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu4398504731950838957.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu700631809574394399.webp&#34;
               width=&#34;760&#34;
               height=&#34;241&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;The student will engage in the construction of multimodal machine learning models that take as input video and are able to detect complex social phenomena such as empathy, persuasion and emotion but also text-based argumentation models. During the thesis, we will also focus on the construction of a debate dataset in Chilean Spanish (and hopefully  in French), on political hot topics that are seen as polarizing in both countries. 
s
In a few bullet-points, different research axis will be explored regarding the available time (w.r.t. the type of tesis/memoria): &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creation of mutlimodal models aiming to detect social phenomena in discourse and also in a dyadic or group interaction&lt;/li&gt;
&lt;li&gt;Adaptation or creation of an text-based argumentation annotation scheme for multimodal data&lt;/li&gt;
&lt;li&gt;Creation of the chilean part of a multicultural database of debates on polarizing topics  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Funds will be available to support the research of the student.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; ### Bibliography&lt;/p&gt;
&lt;p&gt;[1] V. Petukhova, T. Mayer, A. Malchanau, and H. Bunt, “Virtual debate coach design: Assessing multimodal argumentation performance,” ICMI 2017 - Proc. 19th ACM Int. Conf. Multimodal Interact., vol. 2017-Janua, no. 1, pp. 41–50, 2017. &lt;/p&gt;
&lt;p&gt;[2] N. Rach, E. André, K. Weber, W. Minker, L. Pragst, and S. Ultes, “EVA: A multimodal argumentative dialogue system,” ICMI 2018 - Proc. 2018 Int. Conf. Multimodal Interact., no. October, pp. 551–552, 2018. &lt;/p&gt;
&lt;p&gt;[3] A. Khan, J. Hughes, D. Valentine, L. Ruis, K. Sachan, and A. Radhakrishnan, “Debating with More Persuasive LLMs Leads to More Truthful Answers,” 2024. &lt;/p&gt;
&lt;p&gt;[4] L. P. Argyle et al., “AI Chat Assistants can Improve Conversations about Divisive Topics,” ArXiv, 2023. &lt;/p&gt;
&lt;p&gt;[5] T. Ohba, C. O. Mawalim, S. Katada, H. Kuroki, and S. Okada, “Multimodal Analysis for Communication Skill and Self-Efficacy Level Estimation in Job Interview Scenario,” ACM Int. Conf. Proceeding Ser., pp. 110–120, 2022. &lt;/p&gt;
&lt;p&gt;[6] S. Park, H. S. Shim, M. Chatterjee, K. Sagae, and L.-P. Morency, “Computational Analysis of Persuasiveness in Social Multimedia: A Novel Dataset and Multimodal Prediction Approach,” Proc. 16th Int. Conf. Multimodal Interact. - ICMI ’14, pp. 50–57, 2014. &lt;/p&gt;
&lt;p&gt;[7] B. Siddiquie, D. Chisholm, and A. Divakaran, “Exploiting multimodal affect and semantics to identify politically persuasive web videos,” in ICMI 2015 - Proceedings of the 2015 ACM International Conference on Multimodal Interaction, 2015, pp. 203–210. &lt;/p&gt;
&lt;p&gt;[8] B. Nojavanasghari, D. Gopinath, J. Koushik, T. Baltrušaitis, and L.-P. Morency, “Deep Multimodal Fusion for Persuasiveness Prediction,” in ICMI 2016 - Proceedings of the 2016 ACM International Conference on Multimodal Interaction, 2016, pp. 1–5. &lt;/p&gt;
&lt;p&gt;[9] R. Mestre, R. Milicin, S. E. Middleton, M. Ryan, J. Zhu, and T. J. Norman, “M-Arg: Multimodal Argument Mining Dataset for Political Debates with Audio and Transcripts,” 8th Work. Argument Mining, ArgMining 2021 - Proc., no. 2014, pp. 78–88, 2021. &lt;/p&gt;
&lt;p&gt;[10] M. Brilman and S. Scherer, “A Multimodal Predictive Model of Successful Debaters or How I Learned to Sway Votes,” Proc. 23rd ACM Int. Conf. Multimed., pp. 149–158, 2015. &lt;/p&gt;
&lt;p&gt;[11] E. Mancini, F. Ruggeri, A. Galassi, and P. Torroni, “Multimodal Argument Mining: A Case Study in Political Debates,” Proc. 9th Work. Argument Min., pp. 158–170, 2022. &lt;/p&gt;
&lt;p&gt;[12] T. Shiota and K. Shimada, “The Discussion Corpus toward Argumentation Quality Assessment in Multi-Party Conversation,” Proc. - 2020 9th Int. Congr. Adv. Appl. Informatics, IIAI-AAI 2020, pp. 280–283, 2020.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Xenophobias -- Deteccion y reduccion de sesgos etnicos en LLM</title>
      <link>http://localhost:1313/job_offers/thesis-postgrado-bias/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-postgrado-bias/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;Classical bias detection methods used in Machine Learning are themselves biased because of the different confounding variables implied in the assessment of the initial biases. First they are using templates that are syntactically simple and distant from the target data on which the model will be applied. Second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms.
We propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. The idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-non-causal-changes-such-as-in-names-can-cause-differences-in-the-model-outputs-which-should-not-happen&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;figure_v5&#34; srcset=&#34;
               /job_offers/thesis-postgrado-bias/figure_v5_hu4101750334257282784.webp 400w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu12014982446003253994.webp 760w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu11181646692821307121.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-postgrado-bias/figure_v5_hu4101750334257282784.webp&#34;
               width=&#34;760&#34;
               height=&#34;267&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Non-causal changes such as in names can cause differences in the model outputs, which should not happen.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Our work offers a fine-grained analysis of the interactions between names and languages, revealing significant biases in multilingual models, but also strong biases towards some countries&amp;rsquo; names. We linked this with the pre-training data used to pre-train the LLM, by the mean of the Language Model&amp;rsquo;s (pseudo-)likelihood and found out very socially interesting resuts. For example, a sentence containing a Moroccan name will be more likely to be tagged as positive, and less likely to be tagged as hate speech.&lt;/p&gt;
&lt;p&gt;In other words we want to answer the questions: (i) are LLM xenophobic? (ii) how to quantify it? (iii) how to remove this bias?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Funds will be available to support the research of the student.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;We started to answer these questions in two papers (one published at COLING24 and one published at EMNLP24), and would like to continue the adventure with you! We plan to submit our future work at another international NLP/ML/AI conference.&lt;/p&gt;
&lt;p&gt;We have several possibilities regarding the works that can be tackled in this tesis:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM to generate data fitting to production data distribution (KL—&amp;gt;0)&lt;/li&gt;
&lt;li&gt;Generate more target-groups attributes (more fine-grained, since not relying on template; how to validate them)&lt;/li&gt;
&lt;li&gt;Method to reduce the bias of the trained model&lt;/li&gt;
&lt;li&gt;Test current method on bigger LLM classifiers&lt;/li&gt;
&lt;li&gt;Our method is quantitative and require classes that can manually be seen as positives and negatives. How to extend this to any classification, how to check this bias qualitatively using an algorithm on the distribution (Optimal Transport distance or others…)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Fondecyt de Iniciacion🗣️💬🤖</title>
      <link>http://localhost:1313/project/mmodal_eca/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/mmodal_eca/</guid>
      <description>&lt;p&gt;Multimodal Argumentation Mining in Groups Assisted by an Embodied Conversational Agent&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Principal Investigator of this project&lt;/strong&gt;. This is a 3 years &lt;a href=&#34;https://anid.cl/concursos/concurso-de-proyectos-fondecyt-de-iniciacion-en-investigacion-2025/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fondecyt&lt;/a&gt; grant of of 90.000.000,00 CLP&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; from the Chilean National Research Agency. This is a colaboration with the Université Paris Saclay, the European Commission&amp;rsquo;s DGIT, Sorbonne Université and Bamberg University.&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;Interactions and Multimodality are crucial in the development of intelligent AI models that can understand human-like communication. Human learning occurs through interactions with the environment and other humans, which involves the integration of information from multiple modalities such as vision, language but also touch and hearing that enable us to understand the subtle social meanings behind communication.&lt;/p&gt;
&lt;p&gt;Therefore, to create intelligent machines that can understand human non-verbal communication, it is essential to train them on &lt;strong&gt;multimodal interactions that mimic those of humans to ensure that they can understand and respond appropriately to complex social phenomena&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The recent computational boom has seen the emergence of seminal studies focusing on Multimodal data (Cho, Lu, Schwenk, Hajishirzi, &amp;amp; Kembhavi, 2020; Hasan et al., 2019; Jaegle et al., 2021; J. Li, Li, Xiong, &amp;amp; Hoi, 2022; J. Wang et al., 2022; Zadeh, Chan, Liang, Tong, &amp;amp; Morency, 2019)⁠ and Interactions, whether these ones are textual like OpenIA&amp;rsquo;s InstructGPT or Anthropic&amp;rsquo;s Claude  (Bai et al., 2022; Ouyang et al., 2022; Schulman et al., 2022)⁠, or multimodal like Google&amp;rsquo;s PaLM (Chowdhery et al., n.d.; Chung et al., 2022; Schick, Lomeli, Dwivedi-yu, &amp;amp; Dessì, 2022)⁠ or GPT-4 (Bubeck et al., 2023; OpenAI, 2023; Wu et al., 2023)⁠.&lt;/p&gt;
&lt;p&gt;These advancements show the potential for machines to learn from multimodal interactions and understand human communication, which could revolutionize the way humans socially interact with machines in the future. &lt;strong&gt;Nevertheless, nowadays generative agents are restraint to unimodal data or not using the full time-series of every modality of a real human-machine social interaction&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Interaction and multimodality are vital contexts in many social situations. They are also mandatory to make a machine understand the world and get commonsense knowledge, which is essential when tackling human-related complex tasks. Indeed, &lt;strong&gt;humans are social animals&lt;/strong&gt; and they interact with one another. In a general way, the integration of more context is the key to a deep understanding of many phenomena, in order to disambiguate a situation or to reinforce the current estimation: interaction is a crucial context in many social situations. Multimodal interactions allow understanding in a deeper way human behavior. In this particular setting, it is possible to understand a broader part of the multimodal natural language (see Figure 1). Studying the affective and &lt;strong&gt;social phenomena like Opinions, Emotions, Empathy, Distress, Stances, Persuasiveness or speaker traits allows to greatly improves the response from the machine&lt;/strong&gt; (Pelachaud, Busso, &amp;amp; Heylen, 2021; Zhao, Sinha, Black, &amp;amp; Cassell, 2016)⁠, but this task is difficult even using multimodal data. My research focuses on designing and developing methods that integrate the multimodal context and how humans influence each other in discussion situations. The research goals of this project fall into this general research area: &lt;strong&gt;how to use interactions and multimodality of non-verbal language to enhance social AI systems&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-examples-of-non-verbal-language-involved-in-a-social-interaction-from-vinciarelli-2009&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;interaction&#34; srcset=&#34;
               /project/mmodal_eca/interaction_hu15794327103315274671.webp 400w,
               /project/mmodal_eca/interaction_hu15612226579774470620.webp 760w,
               /project/mmodal_eca/interaction_hu8198735632516945012.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/mmodal_eca/interaction_hu15794327103315274671.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Examples of non-verbal language involved in a social interaction from Vinciarelli (2009)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;multimodality&#34;&gt;Multimodality:&lt;/h4&gt;
&lt;p&gt;Communication is not just limited to language, and it is essential to consider other modalities such as vision or audio when building natural language processing (NLP) systems (Baltrušaitis, Ahuja, &amp;amp; Morency, 2017; Liang, Zadeh, &amp;amp; Morency, 2022)⁠. &lt;strong&gt;Incorporating multiple modalities, or multimodality, is critical in creating more human-like interactions between humans and machines&lt;/strong&gt;. For instance, while language is the primary means of communication for humans, it is often supplemented by visual and auditory cues such as facial expressions, tone of voice, and gestures. Therefore, it is important building multimodal machine learning systems that can interpret and respond to these cues in a human-like manner.&lt;/p&gt;
&lt;p&gt;According to (Fröhlich, Sievers, Townsend, Gruber, &amp;amp; van Schaik, 2019)⁠, both human and non-human primate communication is inherently multimodal. As an example, (Mehrabian, 1971)⁠ even states that 55% of the emotional content is in the visual signal (facial expressions and body language), 38% in the vocal signal (intonation and sound of the voice) and 7% in the verbal signal (through the meaning of the words and the arrangement of the sentence).&lt;/p&gt;
&lt;h4 id=&#34;interactions-dynamics&#34;&gt;Interactions dynamics:&lt;/h4&gt;
&lt;p&gt;It is essential to consider the interactive nature of human communication and incorporate it into natural language processing (NLP) systems. By allowing the machine to understand the context and flow of the conversation, it can provide a more natural and seamless interaction with users (Sutskever, Vinyals, &amp;amp; Le, 2014)⁠. (Z. Li, Wallace, Shen, &amp;amp; Lin, 2020)⁠ suggested that these systems can provide tailored content and services based on the user&amp;rsquo;s interests and preferences, leading to more engaging and personalized interactions with the user. &lt;strong&gt;As humans, we are not learnig by looking at or enviroment, but by interacting with it and with our peers&lt;/strong&gt;. By considering the interactive nature of human communication and incorporating it into NLP systems, machines can learn to communicate in a way that is more similar to humans, making interactions more engaging and effective.&lt;/p&gt;
&lt;h4 id=&#34;proposed-research-project&#34;&gt;Proposed research project:&lt;/h4&gt;
&lt;p&gt;This research project aims at studying the complex phenomena characterizing social interactions between humans using different media, implying different modalities and data domains. My research objective is to design adaptive models that take as a starting point the specificities of the multimodal interaction: the media used to communicate, the interactants&amp;rsquo; social relationship, and the communication modalities used to transfer the information. &lt;strong&gt;The general goals stand to: understand what the users are trying to achieve as a group, what is the output of this interaction, how a social agent helps reaching it&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-beatrice-bianccardihttpsbeatricebiancardigitlabio-interacting-with-the-virtual-agent-greta&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;beatrice_eca&#34; srcset=&#34;
               /project/mmodal_eca/beatrice_eca_hu9343440991652273668.webp 400w,
               /project/mmodal_eca/beatrice_eca_hu1100368193974869717.webp 760w,
               /project/mmodal_eca/beatrice_eca_hu13291684369485421113.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/mmodal_eca/beatrice_eca_hu9343440991652273668.webp&#34;
               width=&#34;430&#34;
               height=&#34;279&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;a href=&#34;https://beatricebiancardi.gitlab.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Beatrice Bianccardi&lt;/a&gt; interacting with the virtual agent Greta
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In particlar, this project aims to explore the dynamics of how a group of individuals with polarized opinions can reach a consensus. In this work, within groups of individuals debating hot societal topics and issues, the aim will be to automatically detect and retrieve stances and arguments towards the debate question and to ultimately moderate the debate using a human-computer interface that would be specific to such an interaction. To this aim, we think that an &lt;strong&gt;Embodied Conversational Agent&lt;/strong&gt; (Cassell, 2001; Pelachaud, 2005)⁠ like the one illustrated in Figure 2, would be the most relevant. Indeed bodily representations structure the way humans perceive the world and the way they perceive other people. Cognitive sciences and social sciences altogether have stressed &lt;strong&gt;the importance of embodiment in social interaction, highlighting how interacting with others influences how we behave, perceive and think&lt;/strong&gt; (Smith &amp;amp; Neff, 2018; Tieri, Morone, Paolucci, &amp;amp; Iosa, 2018)⁠, including our social behaviors with embodied intelligent agents such as virtual humans and robots (Holz, Dragone, &amp;amp; O’Hare, 2009)⁠.&lt;/p&gt;
&lt;p&gt;Another goal is to explore the polarization of society&amp;rsquo;s attitudes towards hot political topics and study the &lt;strong&gt;difference in terms of the difficulty of finding a consensus&lt;/strong&gt; regarding the type of topics, and the human values involved in classical argumentation (Kiesel, Weimar, Handke, &amp;amp; Weimar, 2022; Mirzakhmedova et al., 2023)⁠. In today&amp;rsquo;s society, the polarization of opinions on political topics is a common phenomenon that can be observed in many different areas. Debates about societal topics and issues can be especially polarizing and lead to a lack of understanding and cooperation between groups with different perspectives (Livingstone, Fernández Rodriguez, &amp;amp; Rothers, 2020)⁠. Therefore, &lt;strong&gt;it is crucial to understand how individuals with polarized opinions can reach a consensus&lt;/strong&gt;, and this is the aim of this research project. To achieve it, this project plans to develop an automatic approach to &lt;strong&gt;detect and retrieve the stance and arguments&lt;/strong&gt; of individuals involved in real-time multimodal debates about hot societal topics.&lt;/p&gt;
&lt;p&gt;This research aims to delve into the complexities of group dynamics in polarized debates on societal issues. To achieve this, we will not only automatically detect and retrieve stances and their arguments toward the debate question, but also take into account the multimodal aspects of the debate, such as &lt;strong&gt;body language, facial expressions and acoustics&lt;/strong&gt;, which are shown to be important for persuasion in a Vlog (Nojavanasghari, Gopinath, Koushik, Baltrušaitis, &amp;amp; Morency, 2016; S. Park, Shim, Chatterjee, Sagae, &amp;amp; Morency, 2014; Siddiquie, Chisholm, &amp;amp; Divakaran, 2015)⁠ or within a debate (Brilman &amp;amp; Scherer, 2015; Mestre et al., 2021)⁠. Real-time interaction within the group will be analyzed to understand &lt;strong&gt;how individuals respond to each other and how the group as whole moves toward a consensus&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 100k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Large Multimodal Models @ CENIAMODAL</title>
      <link>http://localhost:1313/event/ceniamodal/</link>
      <pubDate>Tue, 17 Dec 2024 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/ceniamodal/</guid>
      <description>&lt;p&gt;We are organizing the first edition of the Chilean Workshop on Multimodal Machine Learning in the Universidad Catolica del Norte in Coquimbo!&lt;/p&gt;
&lt;p&gt;Our keynote speakers will be Mohammad Soleymani and Paul Liang&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-mohammad-soleymani&#34;&gt;Invited Talk: Mohammad Soleymani&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image&#34; srcset=&#34;
               /event/ceniamodal/mohammad_hu16140766223214765226.webp 400w,
               /event/ceniamodal/mohammad_hu6648946481130016374.webp 760w,
               /event/ceniamodal/mohammad_hu17490119621469978857.webp 1200w&#34;
               src=&#34;http://localhost:1313/event/ceniamodal/mohammad_hu16140766223214765226.webp&#34;
               width=&#34;256&#34;
               height=&#34;318&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;multimodal-emotion-recognition&#34;&gt;Multimodal Emotion Recognition&lt;/h4&gt;
&lt;p&gt;Mohammad Soleymani is a research associate professor with the USC Institute for Creative Technologies. He received his PhD in computer science from the University of Geneva in 2011. From 2012 to 2014, he was a Marie Curie fellow at Imperial College London. Prior to joining ICT, he was a research scientist at the Swiss Center for Affective Sciences, University of Geneva. His main line of research involves machine learning for emotion recognition and behavior understanding. He is a recipient of the Swiss National Science Foundation Ambizione grant and the EU Marie Curie fellowship. He has served on multiple conference organization committees and editorial roles, most notably as associate editor for the IEEE Transactions on Affective Computing (2015-2021), general chair for ICMI 2024 and ACII 2021 and technical program chair for ACM ICMI 2018 and ACII 2017. He was the president of the Association for the Advancement of Affective Computing (AAAC) (2019-2021).&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-paul-liang&#34;&gt;Invited Talk: Paul Liang&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image&#34; srcset=&#34;
               /event/ceniamodal/paul-liang-headshot-small_hu7254305025386846404.webp 400w,
               /event/ceniamodal/paul-liang-headshot-small_hu7504278872317812574.webp 760w,
               /event/ceniamodal/paul-liang-headshot-small_hu11974117804273599440.webp 1200w&#34;
               src=&#34;http://localhost:1313/event/ceniamodal/paul-liang-headshot-small_hu7254305025386846404.webp&#34;
               width=&#34;290&#34;
               height=&#34;303&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;fundamentals-of-multimodal-representation-learning&#34;&gt;Fundamentals of Multimodal Representation Learning&lt;/h4&gt;
&lt;p&gt;Paul Liang is an Assistant Professor at the MIT Media Lab and MIT EECS. His research advances the foundations of multisensory artificial
intelligence to enhance the human experience. He is a recipient of the Siebel Scholars Award, Waibel Presidential Fellowship, Facebook
PhD Fellowship, Center for ML and Health Fellowship, Rising Stars in Data Science, and 3 best paper awards. Outside of research, he
received the Alan J. Perlis Graduate Student Teaching Award for developing new courses on multimodal machine learning.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Experience</title>
      <link>http://localhost:1313/experience/</link>
      <pubDate>Sat, 14 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/experience/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tackling Biases In or Using Generative AI @ JSIC&#39;24</title>
      <link>http://localhost:1313/event/jsic/</link>
      <pubDate>Wed, 04 Dec 2024 08:30:00 +0000</pubDate>
      <guid>http://localhost:1313/event/jsic/</guid>
      <description>&lt;p&gt;In this talk, I am focusing on several methods based on data perturbation to detect biases in Large Language Models (LLMs) and Large Multimodal Models (LMMs). We have observed cases where these systems leverage gender, race, or even socioeconomic class information inappropriately for task resolution. Instead of employing real causal reasoning, they often rely on spurious correlations—a phenomenon commonly referred to as bias.&lt;/p&gt;
&lt;p&gt;We will demystify the concept of bias, explaining why biases are ubiquitous, why they can sometimes be useful, and proposing a method to detect harmful biases.&lt;/p&gt;
&lt;p&gt;First, we will introduce a method we developed to detect biases in LLMs toward different countries using the most common names as proxies. Our findings reveal very negative biases toward certain countries, using widely utilized open-source classifiers for social media analysis. Furthermore, we demonstrate that the same multilingual model tends to favor names from countries that speak the language of the sentence—a phenomenon we call AI Xenophobia. This phenomenon has significant social implications. Our study, which examined the perplexity of language models and classifier outputs, shows that the model reacts differently to completely unknown languages compared to familiar ones and exhibits similar behavior toward names as it does with unfamiliar languages.&lt;/p&gt;
&lt;p&gt;Second, we present a method to mitigate biases in Vision-Language Models, particularly in image captioning models. By perturbing the training data through data augmentation with a Text-to-Image generative model, we enhance variability in the dataset. This approach not only reduces gender bias but also improves the model&amp;rsquo;s performance in tasks such as counting objects and detecting colors.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] Data Engineer for Geographic and Remote Sensing data</title>
      <link>http://localhost:1313/job_offers/data-eng-deepcrop/</link>
      <pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/data-eng-deepcrop/</guid>
      <description>&lt;p&gt;CIREN, in collaboration with CENIA, is looking for a Data Engineer to be part of the FONDEF Advanced Technologies project team: an ai system for nation-wide agricultural production monitoring based on crowd-sourced and remote-sensing data.&lt;/p&gt;
&lt;h3 id=&#34;what-are-we-looking-for&#34;&gt;What are we looking for?&lt;/h3&gt;
&lt;p&gt;We are looking for a professional with strong technical competencies and interpersonal skills that include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Professionals in the areas of Computer Engineering, Mathematics, Statistics, Physics, Industrial Engineering or related disciplines, preferably with a Master&amp;rsquo;s degree.&lt;/li&gt;
&lt;li&gt;1 to 3 years of professional or project experience.&lt;/li&gt;
&lt;li&gt;Experience in Python, R or SQL&lt;/li&gt;
&lt;li&gt;Knowledge in Machine Learning libraries (scikit-learn, TensorFlow, PyTorch).&lt;/li&gt;
&lt;li&gt;Knowledge in tools to manage geographic data: geopandas, postGIS, geoSQL.&lt;/li&gt;
&lt;li&gt;Knowledge in spatial data processing: Sentinel2, LANDSAT, etc.&lt;/li&gt;
&lt;li&gt;Familiarity with data visualization tools (Power BI, Tableau, Matplotlib, Seaborn).&lt;/li&gt;
&lt;li&gt;Experience in data cleansing and data management in large volumes.&lt;/li&gt;
&lt;li&gt;Knowledge in statistics and advanced probability.&lt;/li&gt;
&lt;li&gt;Familiarity with relational and non-relational databases (PostgreSQL, MongoDB).&lt;/li&gt;
&lt;li&gt;Intermediate or advanced technical English (desirable).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-will-you-do&#34;&gt;What will you do?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Design, implement and optimize Machine Learning and predictive analytics models.&lt;/li&gt;
&lt;li&gt;Collect, clean and structure large volumes of data for analysis.&lt;/li&gt;
&lt;li&gt;Generate actionable insights to support strategic decision making.&lt;/li&gt;
&lt;li&gt;Collaborate with cross-functional teams (developers, analysts, business leaders).&lt;/li&gt;
&lt;li&gt;Visualize data using tools such as Power BI, Tableau or similar.&lt;/li&gt;
&lt;li&gt;Document processes, methodologies and key findings of the projects.&lt;/li&gt;
&lt;li&gt;Ensure the quality and security of the data handled.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-do-we-offer&#34;&gt;What do we offer?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Total gross remuneration of &lt;strong&gt;$2.500.000&lt;/strong&gt;. 2 year fixed term project contract with CIREN.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Offer in the CENIA website &lt;a href=&#34;https://cenia.cl/2024/12/07/buscamos-ingenieroa-de-datos/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] Machine Learning Engineer for Geographic and Remote Sensing data</title>
      <link>http://localhost:1313/job_offers/ml-eng-deepcrop/</link>
      <pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/ml-eng-deepcrop/</guid>
      <description>&lt;p&gt;We are looking for a Machine Learning / Deep Learning research engineer to work on large multi-modal and multi-resolution representation parsing models with satellite data (image sequences).&lt;/p&gt;
&lt;h3 id=&#34;what-will-you-do&#34;&gt;What will you do?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Participate in FONDEF Advanced Technologies project: an ai system for nation-wide agricultural production monitoring based on crowd-sourced and remote-sensing data.&lt;/li&gt;
&lt;li&gt;Develop end-to-end AI solutions.&lt;/li&gt;
&lt;li&gt;Collection of relevant information and design of solutions focused on the optimization of industrial processes.&lt;/li&gt;
&lt;li&gt;Industrial data processing and analysis.&lt;/li&gt;
&lt;li&gt;Development and implementation of advanced predictive models to model subsections of the process.&lt;/li&gt;
&lt;li&gt;Integration and deployment of solutions in production environments.&lt;/li&gt;
&lt;li&gt;Design and build machine learning pipelines focused on optimization and prediction.&lt;/li&gt;
&lt;li&gt;Collaborate on projects within asset-intensive industries such as mining, energy, pulp and paper, among others, applying ML techniques to improve efficiency and productivity.&lt;/li&gt;
&lt;li&gt;Utilize cloud and high performance computing technologies.&lt;/li&gt;
&lt;li&gt;Continuously improve ML solutions through experimentation and iteration.&lt;/li&gt;
&lt;li&gt;Keep up to date with the latest trends and developments in ML and optimization technologies.&lt;/li&gt;
&lt;li&gt;Work closely with the CopernicusLAC team, the European Space Agency&amp;rsquo;s satellite constellation data hub.&lt;/li&gt;
&lt;li&gt;Work on the creation of a satellite data dataset (Sentinel2, Sentinel3, Sentinel5) throughout Latin America and the Caribbean.&lt;/li&gt;
&lt;li&gt;Design and create foundational models for satellite data processing in conjunction with researchers from CENIA and profe from the University of Chile:&lt;/li&gt;
&lt;li&gt;Use multi-scale self-supervised learning techniques on satellite data.&lt;/li&gt;
&lt;li&gt;Use meta-learning algorithms to learn the model to learn new tasks: crop-land mapping, land-use mapping, drought detection, illegal deforestation, etc.&lt;/li&gt;
&lt;li&gt;Participate in writing scientific papers on data creation and modeling, participate in presentation at appropriate conferences: CVPR, ICCV, ECCV, WACAV, NeurIPS, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-are-we-looking-for&#34;&gt;What are we looking for?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Bachelor&amp;rsquo;s degree in Computer Science, Mathematics, Statistics, Engineering or a related field.&lt;/li&gt;
&lt;li&gt;1 to 3 years of professional or ML project experience.&lt;/li&gt;
&lt;li&gt;Verifiable experience in software and/or software development based on machine learning, computer vision and satellite data management.&lt;/li&gt;
&lt;li&gt;Knowledge and previous experience with Python and some of the following libraries: PyTorch, Huggingface, TensorFlow, Scikit-Learn or other related libraries (Excluded)&lt;/li&gt;
&lt;li&gt;Knowledge in tools to manage geographic data: geopandas, postGIS, geoSQL, etc&amp;hellip;&lt;/li&gt;
&lt;li&gt;Knowledge in spatial data processing: Sentinel2 data, LANDSAT, GEE, etc&amp;hellip;&lt;/li&gt;
&lt;li&gt;Demonstrated experience in the design and construction of machine learning pipelines (Excluded).&lt;/li&gt;
&lt;li&gt;Demonstrated experience in the use and development of vision projects (Excluding)&lt;/li&gt;
&lt;li&gt;Familiarity with Machine Learning Operations (MLOps) development practices (Required).&lt;/li&gt;
&lt;li&gt;Experience in consulting projects (Desirable).&lt;/li&gt;
&lt;li&gt;Development experience in Cloud platforms (Desirable).&lt;/li&gt;
&lt;li&gt;Experience with cloud computing platforms, in particular GCP. (Desirable)&lt;/li&gt;
&lt;li&gt;Knowledge of deploying ML models in production environments (Desirable).&lt;/li&gt;
&lt;li&gt;Development experience with code versioning in Git (Desirable).&lt;/li&gt;
&lt;li&gt;Experience with Docker (desirable).&lt;/li&gt;
&lt;li&gt;Experience with Python packages and environments (desirable).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-do-we-offer&#34;&gt;What do we offer?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Total gross remuneration of &lt;strong&gt;$2.500.000&lt;/strong&gt;. Fixed term project contract 2 years.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of our benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;🏡Hybrid work system: Home office combined with face-to-face workday.&lt;/li&gt;
&lt;li&gt;👣Comfortable offices close to San Joaquín subway station.&lt;/li&gt;
&lt;li&gt;🚲Access to bike rack and dressing rooms.&lt;/li&gt;
&lt;li&gt;Parking at preferential price.&lt;/li&gt;
&lt;li&gt;Casual Dress Code.&lt;/li&gt;
&lt;li&gt;🎁Birthday free day.&lt;/li&gt;
&lt;li&gt;🎄Advance disconnection for the holidays.&lt;/li&gt;
&lt;li&gt;✉️ Day off for Vocal de mesa.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CENIA site offer &lt;a href=&#34;https://cenia.cl/2024/12/06/buscamos-igenieroa-en-machine-learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aca&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CEDS 24 Conferencia Internacional del Espacio y Desarollo Sostenible</title>
      <link>http://localhost:1313/not_used/ceds24/</link>
      <pubDate>Wed, 27 Nov 2024 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/ceds24/</guid>
      <description>&lt;p&gt;&lt;strong&gt;La Conferencia Internacional Espacio y Desarrollo Sostenible (CEDS2024)&lt;/strong&gt; ha sido concebida como un espacio de conocimiento e intercambio de experiencias e ideas en torno a los desafíos y oportunidades que se presentan en los temas del espacio y a la búsqueda de estrategias y alternativas de acción que posibiliten su uso de manera sostenible. Con este objetivo se abordarán los ámbitos científico-tecnológicos, el desarrollo industrial y las estrategias nacionales incluyendo los marcos jurídicos y de colaboración necesarios para su uso en un mundo globalizado, único posible cuando de espacio se trata.&lt;/p&gt;
&lt;h2 id=&#34;ceds-y-la-universidad-de-chile&#34;&gt;CEDS y la Universidad de Chile&lt;/h2&gt;
&lt;p&gt;La Universidad de Chile, ha estado estrechamente vinculada a estos temas, desde que firmara el acuerdo en 1958 para apoyar los programas de la NASA y crear el Centro de Estudios Espaciales, o en 2017 cuando, a través del Programa SUCHAI de nano-satélites lanzara el primer nano-satélite chileno, base de la actual constelación de nano-satélites de Chile y, actualmente llevando cabo el proyecto &lt;a href=&#34;https://www.copernicuslac-chile.eu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Centro Regional Copernicus para América Latina y el Caribe: CopernicusLAC Chile&lt;/a&gt;, en el marco del acuerdo firmado con la Unión Europea, el que está desplegando una poderosa infraestructura para el almacenamiento y procesamiento de datos, entregando servicios a la región que beneficiarán la toma de decisiones en diversos ámbitos que afectan hoy a la sociedad. Por estas y otras razones, junto a instituciones nacionales e internacionales, tanto públicas como privadas, han decidido organizar la Conferencia Internacional Espacio y Desarrollo Sostenible (CEDS2024).&lt;/p&gt;
&lt;h2 id=&#34;ejes-temáticos&#34;&gt;Ejes temáticos&lt;/h2&gt;
&lt;p&gt;CEDS2024 es un espacio donde se analizará y discutirá acerca de:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Oportunidades y Desafíos en el desarrollo espacial&lt;/li&gt;
&lt;li&gt;Promoción del desarrollo de la Ciencia y Tecnología Espacial&lt;/li&gt;
&lt;li&gt;Promover la Innovación y el Desarrollo industrial en materia Espacial&lt;/li&gt;
&lt;li&gt;El Espacio en los Grandes Desafíos Globales&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] [Tesis pre/postgrado] JAJAJJJJJ -- Deteccion de humor en videos de stand-up comedy</title>
      <link>http://localhost:1313/job_offers/thesis-jajaja/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-jajaja/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;Humour is a key dimension in human-human communication and is used constantly, in a wide variety of contexts. It is used for its pleasing effect as it can help explain complex ideas during important presentations or it can serve as pure entertainment like in movies or stand up comedy. Sometimes, it can also be used in a less deliberate manner, unconsciously, as a way to regulate the inherent stress and tension arising in conversations, by presenting one’s ideas and intentions in an alternate way.&lt;/p&gt;
&lt;p&gt;While Human-Agent interactions are growing in popularity due to the recent thrive of Large Language Models, the resulting conversations still remain frustrating for the users when they start to use subtle conversational strategies and skills such as irony, euphemism, hyperbolism and humour.&lt;/p&gt;
&lt;p&gt;Today, when a human is using humour during a human-agent interaction, this tends to interrupt the flow of the interaction. Agents interpret quite literally what a human is saying and as the agent does not react as the human would expect from a fellow conversational partner this leads to rephrasing, repeating and eventually frustration.&lt;/p&gt;
&lt;p&gt;Our vision for the future of conversational agents is that agents should be able at least to detect humorous attempts and to redirect the flow of the conversation accordingly. In this project, our main objective is to endow conversational agents with the ability to recognize when humour is being used by a human during human-agent interactions. Towards this goal, we will be relying on a multimodal approach and we will investigate how multimodal computational models can achieve this.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-example-taken-from-the-ur-funny-dataset-6&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;UR_FUNNY&#34; srcset=&#34;
               /job_offers/thesis-jajaja/UR_FUNNY_hu10620972935419908973.webp 400w,
               /job_offers/thesis-jajaja/UR_FUNNY_hu12261418939102111829.webp 760w,
               /job_offers/thesis-jajaja/UR_FUNNY_hu2094234890411483346.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-jajaja/UR_FUNNY_hu10620972935419908973.webp&#34;
               width=&#34;760&#34;
               height=&#34;296&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Example taken from the UR-FUNNY dataset [6]
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;On this project, we will focus on the use of multimodal models with or without interactions [1,2] that can be also multilingual [3]. We would focus on multimodal but also multicultural specific social context [4], showing that multimodal is essential to detect complex human cultural and social phenonema such as sarcasm [5] or humour detection [6]. For group interactions, modelization of the speakers will be done using special architecture such as DialogueRNN [7].&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;Here, we will focus on the first brick of this amazing human-machine project, which is the characterization and detection of humor using verbal and non-verbal language. First, we will study this complex phenomena in various languages using stand-up comedy videos. Second, if time allows it, we would focus on dyad or group interactions, such as TV-shows or better, naturalistic interactions.&lt;/p&gt;
&lt;p&gt;The student will have to work on the several tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collection of a dataset of stand-up comedy videos on youtube&lt;/li&gt;
&lt;li&gt;Cleaning and analysis of the dataset&lt;/li&gt;
&lt;li&gt;Multimodal modelization of human verbal and non-verbal language using binary classification&lt;/li&gt;
&lt;li&gt;Possibility to think about a more fine-grained humour taxonomy (more than just binary, how to propagate laugh, etc…)&lt;/li&gt;
&lt;li&gt;Collection of a dataset of humor in interactions&lt;/li&gt;
&lt;li&gt;Modelization more complex of multi-party interactions&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bibliography&#34;&gt;Bibliography&lt;/h3&gt;
&lt;p&gt;[1] P. P. Liang, Y. Cheng, R. Salakhutdinov, and L. P. Morency, “Multimodal Fusion Interactions: A Study of Human and Automatic Quantification,” ACM Int. Conf. Proceeding Ser., pp. 425–435, 2023.&lt;/p&gt;
&lt;p&gt;[2] A. Zadeh, P. P. Liang, N. Mazumder, S. Poria, E. Cambria, and L.-P. Morency, “Memory Fusion Network for Multi-view Sequential Learning,” in AAAI, 2018.&lt;/p&gt;
&lt;p&gt;[3] A. Zadeh, Y. S. Cao, S. Hessner, P. P. Liang, S. Poria, and L. Morency, “CMU-MOSEAS : A Multimodal Language Dataset for Spanish , Portuguese , German and French,” in EMNLP, 2020, vol. 1, no. 1, pp. 1801–1812.&lt;/p&gt;
&lt;p&gt;[4] M. Sap, S. Gabriel, L. Qin, D. Jurafsky, N. A. Smith, and Y. Choi, “Social Bias Frames: Reasoning about Social and Power Implications of Language,” Proc. ofthe 58th Annu. Meet. ofthe Assoc. Comput. Linguist., pp. 5477–5490, 2020.&lt;/p&gt;
&lt;p&gt;[5] P. Desai, T. Chakraborty, and M. S. Akhtar, “Nice perfume. How long did you marinate in it? Multimodal Sarcasm Explanation,” in AAAI, 2022.&lt;/p&gt;
&lt;p&gt;[6] M. K. Hasan et al., “UR-FUNNY: A Multimodal Language Dataset for Understanding Humor,” 2019.&lt;/p&gt;
&lt;p&gt;[7] N. Majumder, S. Poria, D. Hazarika, R. Mihalcea, A. Gelbukh, and E. Cambria, “DialogueRNN: An Attentive RNN for Emotion Detection in Conversations,” in AAAI, 2019.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers</title>
      <link>http://localhost:1313/publication/emnlp24-ppl/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/emnlp24-ppl/</guid>
      <description>&lt;p&gt;This work is driven by the results of a &lt;a href=&#34;http://localhost:1313/publication/LREC24-XENOPHOBIA/&#34;&gt;previous paper&lt;/a&gt; on country-level bias detection in LLMs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>XenophoBias🏳️‍🌈</title>
      <link>http://localhost:1313/project/xenophobias/</link>
      <pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/xenophobias/</guid>
      <description>&lt;p&gt;Multicultural Bias Recognition to Detect and Mitigate Racism, Xenophobia and Geographic Inequalities in Multilingual Large Language Models.&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Principal Investigator of this project&lt;/strong&gt;. This is a 2 years &lt;a href=&#34;https://uchile.cl/convocatorias/216327/concurso-u-inicia-2024&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;U-inicia&lt;/a&gt; grant from the University with a total budget of 8,000,000 CLP.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;Classical bias detection methods used in Machine Learning and Natural Language Processing (NLP) are themselves biased because of the different confounding variables implied in the assessment of the initial biases. First they are using templates that are syntactically simple and distant from the target data on which the model will be applied. Second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;counfounding&#34; srcset=&#34;
               /project/xenophobias/featured_hu4709178623435340922.webp 400w,
               /project/xenophobias/featured_hu2414093935314123718.webp 760w,
               /project/xenophobias/featured_hu9909048982336450453.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/featured_hu4709178623435340922.webp&#34;
               width=&#34;449&#34;
               height=&#34;587&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. The idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes. We focus on named entity perturbations by applying a &lt;strong&gt;Named Entity Recognition&lt;/strong&gt; (NER) on target-domain data and modifying them accordingly to most common names or location of a target group (gender and/or country), and this for several morphosynctactically different languages spoken in relation with the countries of the target groups. &lt;strong&gt;The idea is that perturbing the input data with a non-causal change should not impact the output distribution of a model&lt;/strong&gt;, but it actually does with respect to the languages and the country of provenance of the added entity perturbing the sentence. An analysis of the changes helps practitioners getting a deeper understanding of how a model can react to different target groups.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-we-use-the-target-domain-data-to-create-templates&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overall&#34; srcset=&#34;
               /project/xenophobias/figure_v9_1_hu1431973182623297372.webp 400w,
               /project/xenophobias/figure_v9_1_hu5426821930535034716.webp 760w,
               /project/xenophobias/figure_v9_1_hu13032372178332810117.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/figure_v9_1_hu1431973182623297372.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      We use the target-domain data to create templates.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Here is an example with two sentences, $S^n$
 being ambiguous and $S^1$
 obvious hate speech. The model output of the perturbated versions is highly variable for the multilingual variations of &lt;em&gt;Alexander&lt;/em&gt;. With some name variations, such as the Turkish or Indian, the models classify the sentences as more negative or detect less hate speech. Meaning it will not moderate the content of an insult toward this person (see below):
















&lt;figure  id=&#34;figure-the-templates-obtained-from-target-domain-data-are-filled-with-common-names-from-various-countries-the-difference-in-the-models-output-is-significative-of-a-bias-regarding-the-names&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overall&#34; srcset=&#34;
               /project/xenophobias/figure_v9_2_hu5969773204992941524.webp 400w,
               /project/xenophobias/figure_v9_2_hu408390470316705406.webp 760w,
               /project/xenophobias/figure_v9_2_hu4458702702344355493.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/figure_v9_2_hu5969773204992941524.webp&#34;
               width=&#34;760&#34;
               height=&#34;334&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The templates obtained from target-domain data are filled with common names from various countries. The difference in the model&amp;rsquo;s output is significative of a bias regarding the names.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We will then focus on &lt;strong&gt;how to leverage LLM in order to create sentences from the target-domain data distribution&lt;/strong&gt;, with entites, then with more fine-grained named concepts related to the countries, such as local meals, celebrations, or regional slang.
We want first to use our method on models available in open-source that are likely to be deployed by industry, i.e., widely used classifiers for subjectivity analysis, including sentiment, emotion, hate speech, and offensive text using Twitter data. &lt;strong&gt;We will assess the bias of a variety of models&lt;/strong&gt; such as an open-source multilingual sentiment analysis model trained over multiple-languages tweets, a multilingual stance recognition model trained over several languages and assessed over English language, an English hate speech classifier, an English large language model, and a multilingual large language model such as Llama-3.
Our work offers a fine-grained analysis of the interactions between names and languages, aiming to reveal significant biases in multilingual models, but also strong biases towards some countries’ names. &lt;strong&gt;We want to link this with the pre-training data used to pre-train the LLM, by the mean of the Language Model’s (pseudo-)likelihood&lt;/strong&gt;. We hope to find out very socially interesting/impacting results such as a sentence containing a name from an arabic or slavic country will more likely to be tagged as negative, and less likely to be tagged as hate speech.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;In other words we want to answer the questions:&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Are LLM xenophobic?&lt;/li&gt;
&lt;li&gt;How to quantify it?&lt;/li&gt;
&lt;li&gt;How to remove this bias?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;schedule&#34;&gt;Schedule&lt;/h3&gt;
&lt;p&gt;Milestones will follow the project objectives and milestones are defined as a group of objectives with a publication at an A(*)-ranked conference or in a journal to complete the milestone.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Milestone 1&lt;/strong&gt; consists of objectives 1 and 2 as well as the publication of a paper at an A(*) conference. The method developed above will be applied to different types of classifiers and generative models. A perplexity analysis will be performed to try to quantify the visible bias of the internal states of neural networks. I plan 5 months to adapt the method that already exists for LLM and use perplexity to find lassos between frequencies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Milestone 2&lt;/strong&gt; consists of objectives 3 and 4, as well as the publication of a paper in a conference A. I plan 4 months for the artificial data generation because it is not so straightforward and we will have to work on the generation in the target distribution per se, and also on the collection and how to add in the generation the socio-cultural attributes of the different countries (2 months + 2 months).&lt;/p&gt;
&lt;p&gt;The last &lt;strong&gt;Milestone 3&lt;/strong&gt; contains the final objective concerning the reduction of bias, with the aggregation of all previous results in a journal publication.  Working on bias reduction based on our method will be quite straightforward. The writing of a journal paper where we will have all the results of the project will be longer than the previous conference papers, which will have more specific and limited contents. For that I plan 4 months for the reduction and 3 months for the writing, with 2 overlapping months.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;gantt&#34; srcset=&#34;
               /project/xenophobias/gantt_hu3088727843124199660.webp 400w,
               /project/xenophobias/gantt_hu11767512201186597748.webp 760w,
               /project/xenophobias/gantt_hu16173524106031046137.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/gantt_hu3088727843124199660.webp&#34;
               width=&#34;760&#34;
               height=&#34;272&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 8k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>(Preprint) Scrapping The Web For Early Wildfire Detection: A New Annotated Dataset of Images and Videos of Smoke Plumes In-the-wild</title>
      <link>http://localhost:1313/publication/preprint-scrapping/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/preprint-scrapping/</guid>
      <description>&lt;p&gt;This work goes directly in the context of the &lt;a href=&#34;http://localhost:1313/project/fAIrefighter/&#34;&gt;fAIrefighter🧯&lt;/a&gt; project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CopernicusLAC🛰️🇪🇺</title>
      <link>http://localhost:1313/project/copernicus/</link>
      <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/copernicus/</guid>
      <description>&lt;p&gt;Our project is located in Santiago de Chile and operates as a centre dedicated to the storage, processing, and distribution of satellite data of the Copernicus Programme and the provision of services of regional interest for the benefit of all countries in Latin America and the Caribbean (LAC).&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;I act as &lt;strong&gt;Scientific Advisor and Researcher Artificial Intelligence for Earth Observation&lt;/strong&gt; within the CopernicusLAC project, where I aim to be part of the team developing novel, large-scale, and generalizable vision models for remote sensing data processing.&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.copernicuslac-chile.eu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Copernicus Regional Centre for Latin America and the Caribbean&lt;/a&gt; (CopernicusLAC Chile) is a project funded by the European Union and the University of Chile and implemented by the Center for Mathematical Modeling (CMM).&lt;/p&gt;
&lt;p&gt;This project provides Copernicus data storage, processing, and distribution services for the region, as well as developing monitoring services in the areas of land use and land cover, urban areas and oceans and coasts, including the coordination of access to in situ data, i.e. data from land-based meteorological stations, ocean buoys and air quality monitoring networks, among others.&lt;/p&gt;
&lt;p&gt;Our mission is to meet the region’s needs for the storage, processing, and distribution of advanced Earth observation data for both the specialist community and the public. Our commitment is to offer innovative solutions, promoting collaboration and open access to information to drive socio-economic and environmental progress in Latin America and the Caribbean.&lt;/p&gt;
&lt;p&gt;Our vision is to be recognised as a leader in the Earth observation community for Latin America and the Caribbean. We seek to be a key source of information, contributing significantly to informed decision-making that transforms and promotes meaningful sustainable development for the region.&lt;/p&gt;
&lt;h3 id=&#34;copernicus-eu&#34;&gt;Copernicus EU&lt;/h3&gt;
&lt;p&gt;Copernicus is the European Earth observation system, which offers free and open access data and services through its network of Sentinel satellites, providing images of our planet with valuable information to be applied in areas such as agriculture, mining, urban planning, disaster management, environmental protection, among others.&lt;/p&gt;
&lt;p&gt;The programme is coordinated and managed by the European Commission and implemented in collaboration with the Member States, the European Space Agency (ESA), the European Organisation for the Exploitation of Meteorological Satellites (Eumetsat), the European Centre for Medium-Range Weather Forecasts, EU agencies and Mercator Ocean, among others.&lt;/p&gt;
&lt;p&gt;It uses vast amounts of global data from satellites and measurement systems on land, air and sea to provide information that helps service providers, public administrations and other international organisations to improve the quality of life of Europe’s citizens. The information services provided are freely and openly accessible to its users.&lt;/p&gt;
&lt;p&gt;(Source and more information: &lt;a href=&#34;https://www.copernicus.eu/en/about-copernicus&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Copernicus EU&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DeepCrop🛰️🌾🌽</title>
      <link>http://localhost:1313/project/deepcrop/</link>
      <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/deepcrop/</guid>
      <description>&lt;p&gt;We are creating an AI system for nation-wide agricultural production monitoring based on crowd-sourced and remote-sensing.&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Director of this project&lt;/strong&gt;, which is a collaboration between the University of Chile, (the Centre of Artificial Intelligence)[https://www.cenia.cl], (the Center of Natural Ressources)[https://www.ciren.cl] as principal institutions, and the &lt;a href=&#34;https://www.eurocrops.tum.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Technical University of Munich&lt;/a&gt;, the &lt;a href=&#34;https://www.jrc.eu.todo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;European Commission&amp;rsquo;s Joint Research Center&lt;/a&gt;, and the &lt;a href=&#34;https://www.epfl.ch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;École Polytechnique Fédérale de Lausanne&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is a 4 years &lt;a href=&#34;https://anid.cl/concursos/concurso-idea-id-tecnologias-avanzadas-2024/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Tecnologia Avanzada&lt;/em&gt;&lt;/a&gt; project funded to the tune of 660,000,000 CLP&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; coming as grant from the National Research and Development Agency (ANID).&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;This project aims to develop a crop map (like land-use but for crop i.e., which crop are cultivated where) at the country-level. To this aim we will leverage the capacity of general purpose model that we will trained over Chile. This is quite fun as Chile is a very long country with many different climates, making it the perfect place to test a model claiming to be general.&lt;/p&gt;
&lt;p&gt;The objectives are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gathering existing general crop data at the polygon- and pixel-level from open-source and in-house datasets&lt;/li&gt;
&lt;li&gt;Collecting Chilean crop data at the polygon- and pixel-level, including yield&lt;/li&gt;
&lt;li&gt;Implementing a parcel delineation model, with a polygon-level crop classifier&lt;/li&gt;
&lt;li&gt;Pre-training a large vision model on Worldwide, South American, and Chilean multimodal and multiresolution data&lt;/li&gt;
&lt;li&gt;Train the model to learn to learn various tasks using meta-learning algorithms&lt;/li&gt;
&lt;li&gt;Implement a dashboard using the model&amp;rsquo;s predictions&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 670k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>WASSA Workshop @ ACL 24</title>
      <link>http://localhost:1313/event/wassa24/</link>
      <pubDate>Thu, 15 Aug 2024 09:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/wassa24/</guid>
      <description>&lt;p&gt;We are orgnizing the 14th edition of the WASSA workshop this year at &lt;a href=&#34;https://2024.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL24&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Our keynote speaker will be Debora Nozza&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://workshop-wassa.github.io/assets/images/debora_nozza.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;The proliferation of hate speech on social media platforms has been rising, with (pseudo-)anonymity allowing individuals to target others without being recognized or easily traced. While this societal issue has garnered significant attention in the NLP community, it presents three major challenges. Hate speech detection models need to be fair, work across all languages, and incorporate personalization while balancing privacy concerns. Addressing these challenges will revolutionize the field of hate speech detection and contribute to the development of a “universal” model that can adapt to individual user perspectives. In this talk, I will present my contributions in this area along with my perspectives on future directions.&lt;/p&gt;
&lt;h4 id=&#34;bio&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;Debora Nozza is an Assistant Professor in Computing Sciences at Bocconi University. Her research interests mainly focus on Natural Language Processing, specifically on the detection and counter-acting of hate speech and algorithmic bias on Social Media data in multilingual context&lt;/p&gt;
&lt;h2 id=&#34;about-wassa&#34;&gt;About WASSA&lt;/h2&gt;
&lt;p&gt;The aim of WASSA 2024 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text. For this edition, we encourage the submission of long and short research and demo papers including, but not restricted to the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resources for subjectivity, sentiment, emotion and social media analysis&lt;/li&gt;
&lt;li&gt;Opinion retrieval, extraction, categorization, aggregation and summarization&lt;/li&gt;
&lt;li&gt;Humor, Irony and Sarcasm detection&lt;/li&gt;
&lt;li&gt;Mis- and disinformation analysis and the role of affective attributes&lt;/li&gt;
&lt;li&gt;Aspect and topic-based sentiment and emotion analysis&lt;/li&gt;
&lt;li&gt;Analysis of stable traits of social media users, incl. personality analysis and profiling&lt;/li&gt;
&lt;li&gt;Transfer learning for domain, language and genre portability of sentiment analysis&lt;/li&gt;
&lt;li&gt;Modelling commonsense knowledge for subjectivity, sentiment or emotion analysis&lt;/li&gt;
&lt;li&gt;Improvement of NLP tasks using subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;Intrinsic and extrinsic evaluation of subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;The role of emotions in argument mining&lt;/li&gt;
&lt;li&gt;Application of theories from related fields to subjectivity and sentiment analysis&lt;/li&gt;
&lt;li&gt;Multimodal emotion detection and classification&lt;/li&gt;
&lt;li&gt;Applications of sentiment and emotion mining&lt;/li&gt;
&lt;li&gt;Public sentiments and communication patterns of public health emergencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the past years we have noticed that WASSA offers a platform to researchers investigating sentiment and emotion in lesser-resourced languages. The 2023 edition featured work on no less than 23 different languages and two papers specifically targeted multilingual emotion detection. We wish to continue these efforts as we find it important to consider and publish advances in any language as this helps to underline the wealth of our research community and to diminish the dominance of English-language research. To this purpose we propose a Special track on multilinguality and social bridge between high- and lesser-resourced languages/communities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fantastic Biases (What are They) and Where to Find Them</title>
      <link>http://localhost:1313/publication/bits24-biases/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/bits24-biases/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Findings of WASSA 2024 Shared Task on Empathy and Personality Detection in Interactions</title>
      <link>http://localhost:1313/publication/wassa24-task/</link>
      <pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wassa24-task/</guid>
      <description>&lt;p&gt;Fourth shared task related to Empathy we organized at WASSA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>fAIrefighter🧯</title>
      <link>http://localhost:1313/project/fairefighter/</link>
      <pubDate>Sun, 09 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/fairefighter/</guid>
      <description>&lt;p&gt;A wildfire early detection and spread prediction AI-driven decision support tool.&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Director of this project&lt;/strong&gt;, which is a collaboration between the University of Chile, the &lt;a href=&#34;https://www.cenia.cl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Centre of Artificial Intelligence&lt;/a&gt;, the &lt;a href=&#34;https://www.puc.cl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Catholic University&lt;/a&gt;, the &lt;a href=&#34;https://www.conaf.cl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;National Forestry Corporation&lt;/a&gt;, and the Non-Governmental Organization &lt;a href=&#34;https://pyronear.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyroNear&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is a 2 years &lt;a href=&#34;https://anid.cl/concursos/concurso-idea-id-2024/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;IDeA&lt;/em&gt;&lt;/a&gt; project project funded to the tune of 220,000,000 CLP&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; coming as grant from the National Research and Development Agency (ANID).&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;In Chile, there are no technologies to perform early wildfire detection based on on computer vision. Moreover there is no decision support tool to inform authorities regarding predictive propagation of ongoing wildfires. However, there are huge consequences of not containing wildfires: economical, ecological, and societal.&lt;/p&gt;
&lt;p&gt;We propose a two-level plan to fight wildfire at different levels that are complementary. The first one to tackle the wildfire as soon as possible, the second to get information in order to distribute human, machine and water resources efficiently:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Early Wildfire Prediction (EWD): Perform early wildfire detection using computer vision&lt;/li&gt;
&lt;li&gt;Wildfire Spread Prediction (WSP): If the wildfire is getting out of control, an AI-based tool predict the wildfire spread using remote sensing and physics informed neural networks (PINNs).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A global overview of both the systems and how they are interacting is visible below:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image_all&#34; srcset=&#34;
               /project/fairefighter/fAIrefighter_all_hu1213781944679647980.webp 400w,
               /project/fairefighter/fAIrefighter_all_hu5711198834479959995.webp 760w,
               /project/fairefighter/fAIrefighter_all_hu17062598067408856427.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/fairefighter/fAIrefighter_all_hu1213781944679647980.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: The first part consists in installing stations that detect smoke plumes in the wild. The algorithms are frugal Computer Vision methods such as small neural networks implemented on mini-computers, in order to process the information locally and send flags and data when a wildfire is detected. It is necessary to install stations on the watchtowers, collect data, annotate them, and train the models in order to achieve this.
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image_all&#34; srcset=&#34;
               /project/fairefighter/fAIrefighter_ewd_hu15059260110091567817.webp 400w,
               /project/fairefighter/fAIrefighter_ewd_hu17704182685406066860.webp 760w,
               /project/fairefighter/fAIrefighter_ewd_hu8766366730088195042.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/fairefighter/fAIrefighter_ewd_hu15059260110091567817.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 0.1: Gather training set: Gather smoke plume images from open-source platforms from everywhere in the world, and train a first version on the model.&lt;/li&gt;
&lt;li&gt;Step 0.2: Train a model: Train a first version of the EWD, using a YoloV5.&lt;/li&gt;
&lt;li&gt;Step 1: Putting cameras on the watchtowers. Gather data for detection and annotation purposes.&lt;/li&gt;
&lt;li&gt;Step 2: Process chilean images on the annotation platform. The images where potential
smoke plumes are automatically detected by the model trained on phase 0 will be manually validated by humans, in order to enhance the quality of the dataset by adapting the model to in-domain images and reducing the number of false positives.&lt;/li&gt;
&lt;li&gt;Step 3: Gather in-domain training set: Combine the initial training set with the annotated chilean data in order to adapt the model to the environment.&lt;/li&gt;
&lt;li&gt;Step 4.1: Fine-tune the smoke plume detection model images: First, the model will be trained using available data that we are collecting, then it will be fine-tuned on multimodal Chilean data&lt;/li&gt;
&lt;li&gt;Step 4.2: Apply the model on new images in real time&lt;/li&gt;
&lt;li&gt;Step 5: Visualize the alerts on a web platform: using an interface to see where the watchtower is and where the camera is looking at, but also what are the images from the camera that triggered the alert. The platform will also have an interface allowing for validation or rejection of the smoke plumes detected, in order to enhance the quality of the model.&lt;/li&gt;
&lt;li&gt;Step Final: Resource deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: The second part consists in prediction of wildfire propagation using physics-informed machine learning model. It is necessary to collect a wildfire scar dataset, create a physical model of wildifre propgation based on it, to generate artificial data. On this generated data, a PINN can be trained and then fine-tuned on real chilean wildfires, and compared to reality.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image_all&#34; srcset=&#34;
               /project/fairefighter/fAIrefighter_wsp_hu13840030640784380258.webp 400w,
               /project/fairefighter/fAIrefighter_wsp_hu10695992529765654606.webp 760w,
               /project/fairefighter/fAIrefighter_wsp_hu13493718214921426331.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/fairefighter/fAIrefighter_wsp_hu13840030640784380258.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 0: Gather data from various sources, like wildfire scars, meteorological data, and more. This data forms the basis for studying wildfire patterns.&lt;/li&gt;
&lt;li&gt;Step 1: Use of the open-source tool called Cell2Fire to simulate how wildfires spread. This helps us understand fire behavior and make predictions.&lt;/li&gt;
&lt;li&gt;Step 2: Creation of artificial training data using simulator. We select specific wildfires and replicate their growth using Cell2Fire. This gives us data to analyze.&lt;/li&gt;
&lt;li&gt;Step3:Combinationofdataandscientificmodels.Byintegratingphysics-basedequations into neural networks we build a strong model for wildfire spread. This blends real data with scientific knowledge.&lt;/li&gt;
&lt;li&gt;Steps 4.1/4.2: Fine-tune the model and apply it on new remote sensing data: first, the model will be trained using available data that we are collecting, then it will be fine-tuned on Chilean data.&lt;/li&gt;
&lt;li&gt;Step 5: Visualize on a web platform.&lt;/li&gt;
&lt;li&gt;Step Final: Resource deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Overall&lt;/strong&gt;: There is no notion of intellectual property in our project. We will base our technology on open-source knowledge like published papers that we will re-implement ourselves or by using available online code without restrictive license. Subsequently, all our models and datasets will be published as open-source resources for the research community.&lt;/p&gt;
&lt;h3 id=&#34;objectives&#34;&gt;Objectives&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Main&lt;/strong&gt;:
Integrated, technology-driven wildfire management system active at two levels: &lt;em&gt;(i)&lt;/em&gt; to proactively detect early wildfire foci, &lt;em&gt;(ii)&lt;/em&gt; accurately predict wildfire spread in order to &lt;em&gt;(iii)&lt;/em&gt; facilitate real-time decision-making by allowing forest guards, firemen and policy-makers to get more information when allocating resources such as manpower, material and water or when planning evacuation&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Specific&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Early Wildfire Detection&lt;/li&gt;
&lt;li&gt;Wildfire Spread Prediction&lt;/li&gt;
&lt;li&gt;Decision Support Tool&lt;/li&gt;
&lt;li&gt;Impact Assessment&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 220k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>http://localhost:1313/deep-index/</link>
      <pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep-index/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Minerias de Datos</title>
      <link>http://localhost:1313/minerias-index/</link>
      <pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias-index/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>http://localhost:1313/projects/</link>
      <pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Are Text Classifiers Xenophobic? A Country-Oriented Bias Detection Method with Least Confounding Variables</title>
      <link>http://localhost:1313/publication/lrec24-xenophobia/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec24-xenophobia/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Touché23-ValueEval Dataset for Identifying Human Values behind Arguments</title>
      <link>http://localhost:1313/publication/lrec24-touche/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec24-touche/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Boosting crop classification by hierarchically fusing satellite, rotational, and contextual data</title>
      <link>http://localhost:1313/publication/rse24-boosting/</link>
      <pubDate>Mon, 01 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/rse24-boosting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Introduccion</title>
      <link>http://localhost:1313/deep/1_introduction/</link>
      <pubDate>Sat, 30 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/1_introduction/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides1_introductionpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/1_Introduction.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Introduccion</title>
      <link>http://localhost:1313/minerias/1_intro/</link>
      <pubDate>Sat, 30 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/1_intro/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_intro_generalpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Intro_general.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;h2 id=&#34;introducción-a-la-ciencia-de-datos-ia-y-machine-learning&#34;&gt;Introducción a la Ciencia de Datos, IA y Machine Learning&lt;/h2&gt;
&lt;p&gt;La &lt;strong&gt;Minería de Datos&lt;/strong&gt; (o Data Mining) es un campo que busca la &lt;strong&gt;extracción de conocimiento a partir de grandes cantidades de datos&lt;/strong&gt; mediante métodos automáticos o semiautomáticos. Se nutre de diversas disciplinas —como estadística, inteligencia artificial o informática— para &lt;strong&gt;encontrar patrones&lt;/strong&gt; y &lt;strong&gt;estructuras relevantes&lt;/strong&gt; en esos datos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Campos&#34; srcset=&#34;
               /minerias/1_intro/figures/DS_AI_ML_hu9447518532780869997.webp 400w,
               /minerias/1_intro/figures/DS_AI_ML_hu3965967255674636004.webp 760w,
               /minerias/1_intro/figures/DS_AI_ML_hu8785539472510587232.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/DS_AI_ML_hu9447518532780869997.webp&#34;
               width=&#34;760&#34;
               height=&#34;522&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Sin embargo, dentro del panorama general, es útil diferenciar algunos conceptos clave:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data Science (Ciencia de Datos)&lt;/strong&gt; se centra en el &lt;strong&gt;análisis de datos&lt;/strong&gt; para &lt;strong&gt;extraer conocimiento&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Machine Learning (Aprendizaje Automático)&lt;/strong&gt; utiliza &lt;strong&gt;algoritmos&lt;/strong&gt; para &lt;strong&gt;predecir&lt;/strong&gt; y tomar decisiones basadas en los datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Artificial Intelligence (Inteligencia Artificial)&lt;/strong&gt; va un paso más allá y busca &lt;strong&gt;sistemas que puedan realizar tareas “inteligentes” de manera autónoma&lt;/strong&gt;, a veces usando ML como herramienta fundamental.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;De forma simplificada:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Data mining genera entendimiento&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Machine learning genera predicciones&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Artificial intelligence genera acciones&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;material-necesario&#34;&gt;Material Necesario&lt;/h2&gt;
&lt;h3 id=&#34;python-y-anaconda&#34;&gt;Python y Anaconda&lt;/h3&gt;
&lt;p&gt;Para trabajar con análisis de datos y Machine Learning, se recomienda utilizar:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Computadora&lt;/strong&gt; con Python instalado.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Anaconda&lt;/strong&gt; (versión con Python 3.x)
&lt;ul&gt;
&lt;li&gt;Descarga desde &lt;a href=&#34;https://www.anaconda.com/download&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.anaconda.com/download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Incluye la distribución de Python y diversas bibliotecas útiles.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jupyter Notebook&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Un entorno interactivo para escribir y ejecutar código Python en celdas, visualizar gráficos, explicar y anotar pasos.&lt;/li&gt;
&lt;li&gt;Permite prototipar y analizar datos de forma ordenada.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;pandas&#34;&gt;Pandas&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://pandas.pydata.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pandas&lt;/a&gt; es una &lt;strong&gt;biblioteca de Python&lt;/strong&gt; especializada en la &lt;strong&gt;manipulación y el análisis de datos&lt;/strong&gt;. Ofrece estructuras de datos como:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DataFrame&lt;/strong&gt;: tablas con filas y columnas, parecidas a las hojas de cálculo.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Series&lt;/strong&gt;: columnas o vectores unidimensionales.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Con pandas podemos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Leer&lt;/strong&gt; datos (csv, Excel, bases de datos SQL).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Filtrar, agrupar y transformar&lt;/strong&gt; datos rápidamente.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Crear&lt;/strong&gt; resúmenes estadísticos y visualizaciones sencillas.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En muchas tareas de minería de datos, &lt;code&gt;pandas&lt;/code&gt; es la base para cargar y preprocesar el dataset antes de aplicar modelos de Machine Learning.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-pandas-biblioteca-de-análisis-de-datos-en-python&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pandas library&#34; srcset=&#34;
               /minerias/1_intro/figures/pandas_hu6045762415544197018.webp 400w,
               /minerias/1_intro/figures/pandas_hu7643437430166501985.webp 760w,
               /minerias/1_intro/figures/pandas_hu888891917289806406.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/pandas_hu6045762415544197018.webp&#34;
               width=&#34;760&#34;
               height=&#34;475&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      pandas: biblioteca de análisis de datos en Python
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;cheatsheets&#34;&gt;Cheatsheets&lt;/h3&gt;
&lt;p&gt;Además, existen &lt;strong&gt;cheatsheets&lt;/strong&gt; muy útiles para repasar rápidamente las funciones principales:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat NumPy&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_np_hu14375244523488473349.webp 400w,
               /minerias/1_intro/figures/cheat_np_hu14411272965934784444.webp 760w,
               /minerias/1_intro/figures/cheat_np_hu13597904967969990868.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_np_hu14375244523488473349.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat Matplotlib&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_matplot_hu15331046240580983923.webp 400w,
               /minerias/1_intro/figures/cheat_matplot_hu3135365546132595272.webp 760w,
               /minerias/1_intro/figures/cheat_matplot_hu10236542872121609322.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_matplot_hu15331046240580983923.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat Scikit-learn&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_skl_hu13780008353465452812.webp 400w,
               /minerias/1_intro/figures/cheat_skl_hu7231920706300985347.webp 760w,
               /minerias/1_intro/figures/cheat_skl_hu10880287153828955388.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_skl_hu13780008353465452812.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat pandas&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_pd_hu10999684890599352937.webp 400w,
               /minerias/1_intro/figures/cheat_pd_hu17601242950209789534.webp 760w,
               /minerias/1_intro/figures/cheat_pd_hu4889890984785326674.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_pd_hu10999684890599352937.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat Jupyter&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_jup_hu13542443862476004036.webp 400w,
               /minerias/1_intro/figures/cheat_jup_hu1785265908805913062.webp 760w,
               /minerias/1_intro/figures/cheat_jup_hu2839386195936346783.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_jup_hu13542443862476004036.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat Keras&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_keras_hu15372201235457536347.webp 400w,
               /minerias/1_intro/figures/cheat_keras_hu5611213694181866590.webp 760w,
               /minerias/1_intro/figures/cheat_keras_hu787666906409877520.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_keras_hu15372201235457536347.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Les pueden encontrar &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/tree/main/CheatSheets/Code&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aca&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;diferentes-métodos-en-minería-de-datos--machine-learning&#34;&gt;Diferentes Métodos en Minería de Datos / Machine Learning&lt;/h2&gt;
&lt;p&gt;Hay varias tareas principales dentro del &lt;strong&gt;aprendizaje a partir de datos&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Clasificación&lt;/strong&gt;: predecir &lt;strong&gt;etiquetas&lt;/strong&gt; (clases discretas).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Regresión&lt;/strong&gt;: predecir un &lt;strong&gt;valor&lt;/strong&gt; (continuo).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering&lt;/strong&gt;: &lt;strong&gt;agrupar&lt;/strong&gt; elementos según su similitud (sin etiquetas dadas).&lt;/li&gt;
&lt;li&gt;(Otros) Reducción de dimensión, detección de anomalías, etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;visión-general&#34;&gt;Visión general&lt;/h3&gt;
&lt;p&gt;Un diagrama popular de &lt;a href=&#34;https://scikit-learn.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scikit-learn&lt;/a&gt; muestra el &lt;strong&gt;mapa&lt;/strong&gt; de estos métodos:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-diferentes-áreas-y-algoritmos-de-aprendizaje&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Mapa de ML de scikit-learn&#34; srcset=&#34;
               /minerias/1_intro/figures/ml_map_hu3659606064345962454.webp 400w,
               /minerias/1_intro/figures/ml_map_hu16404596823941526495.webp 760w,
               /minerias/1_intro/figures/ml_map_hu9329016589100192170.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/ml_map_hu3659606064345962454.webp&#34;
               width=&#34;760&#34;
               height=&#34;474&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Diferentes áreas y algoritmos de aprendizaje
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;A continuación, describimos algunos ejemplos de clasificaciones, regresiones y clusterings comunes.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;clasificación&#34;&gt;Clasificación&lt;/h3&gt;
&lt;p&gt;La &lt;strong&gt;clasificación&lt;/strong&gt; consiste en asignar una etiqueta a cada dato de un conjunto de posibles clases. Ejemplos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reconocimiento de emociones en el habla&lt;/strong&gt;: determinar si alguien está enojado, feliz, triste, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clasificación de especies de animales&lt;/strong&gt;: a partir de características de la imagen, decidir si es un gato, un puma, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Detección de tumores en imágenes médicas&lt;/strong&gt;: clasificar entre “tumor presente” vs “sin tumor”.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplo-de-clasificación-con-múltiples-etiquetas&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo multi-label classification&#34; srcset=&#34;
               /minerias/1_intro/figures/multi_label_classif_hu9756133175341905838.webp 400w,
               /minerias/1_intro/figures/multi_label_classif_hu3882038718077223937.webp 760w,
               /minerias/1_intro/figures/multi_label_classif_hu12748719311531710440.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/multi_label_classif_hu9756133175341905838.webp&#34;
               width=&#34;760&#34;
               height=&#34;262&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo de clasificación con múltiples etiquetas
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;regresión&#34;&gt;Regresión&lt;/h3&gt;
&lt;p&gt;La &lt;strong&gt;regresión&lt;/strong&gt; busca predecir un valor numérico continuo. Ejemplos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reconocer la intensidad de una emoción&lt;/strong&gt;: ¿cuánto enojo muestra la persona?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evaluar daños tras un terremoto&lt;/strong&gt;: estimar la severidad de daños en una escala cuantitativa.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Medir la severidad de Alzheimer&lt;/strong&gt; en la voz: ¿qué tan avanzada está la enfermedad?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-de-un-valor-continuo-a-una-clasificación-basada-en-umbrales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de pasar de regresión a clasificación de edades&#34; srcset=&#34;
               /minerias/1_intro/figures/age_reg_to_classif_hu17690873109572084870.webp 400w,
               /minerias/1_intro/figures/age_reg_to_classif_hu5798053001599690990.webp 760w,
               /minerias/1_intro/figures/age_reg_to_classif_hu7439249746381267252.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/age_reg_to_classif_hu17690873109572084870.webp&#34;
               width=&#34;760&#34;
               height=&#34;649&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      De un valor continuo a una clasificación basada en umbrales
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;clustering&#34;&gt;Clustering&lt;/h3&gt;
&lt;p&gt;El &lt;strong&gt;clustering&lt;/strong&gt; (agrupamiento) agrupa automáticamente los datos según su semejanza, sin etiquetas previas. Ejemplos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Topic mining&lt;/strong&gt; en foros políticos: descubrir de qué hablan los ciudadanos (temas más discutidos).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Detección de desinformación&lt;/strong&gt; en redes sociales: agrupar noticias sospechosas.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Segmentación de clientes&lt;/strong&gt;: agrupar usuarios según sus preferencias para campañas de marketing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-puntos-se-agrupan-en-clusters-similares-se-puede-descartar-puntos-como-ruido&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Clustering de datos bidimensionales&#34; srcset=&#34;
               /minerias/1_intro/figures/clustering_hu7521456035374489175.webp 400w,
               /minerias/1_intro/figures/clustering_hu4875518410358034455.webp 760w,
               /minerias/1_intro/figures/clustering_hu10503044972186760370.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/clustering_hu7521456035374489175.webp&#34;
               width=&#34;760&#34;
               height=&#34;412&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los puntos se agrupan en clusters similares. Se puede descartar puntos como ruido.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;laboratorio-exploración-de-datos-con-movielens&#34;&gt;Laboratorio: Exploración de Datos con MovieLens&lt;/h2&gt;
&lt;p&gt;Como primer enfoque, estudiaremos un &lt;strong&gt;conjunto de datos de críticas de películas&lt;/strong&gt; (MovieLens):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consta de ~3 millones de puntuaciones (“ratings”).&lt;/li&gt;
&lt;li&gt;Incluye &lt;strong&gt;descriptores sociales&lt;/strong&gt;: edad, sexo, etc.&lt;/li&gt;
&lt;li&gt;Permite aplicar un &lt;strong&gt;análisis básico&lt;/strong&gt; de minería de datos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;MovieLens logo&#34; srcset=&#34;
               /minerias/1_intro/figures/movielens-logo-white_hu5994885034689636590.webp 400w,
               /minerias/1_intro/figures/movielens-logo-white_hu9162017677084157356.webp 760w,
               /minerias/1_intro/figures/movielens-logo-white_hu9786150572690709253.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/movielens-logo-white_hu5994885034689636590.webp&#34;
               width=&#34;760&#34;
               height=&#34;267&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En este lab, aprenderemos a:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cargar los datos en &lt;code&gt;pandas&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Explorar variables (estadísticas descriptivas).&lt;/li&gt;
&lt;li&gt;Cruzar información de películas y usuarios.&lt;/li&gt;
&lt;li&gt;Visualizar distribuciones y relaciones simples.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Datos I</title>
      <link>http://localhost:1313/minerias/2_datos/</link>
      <pubDate>Fri, 29 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/2_datos/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_datospdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Datos.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;Esta clase se centra en el concepto de &lt;strong&gt;Datos&lt;/strong&gt; dentro del contexto de Machine Learning y minería de datos. Veremos de manera general cómo se representan, qué tipos de datos existen, cómo es la calidad de estos datos y finalmente cómo podemos realizar pasos de preprocesamiento para preparar los datos antes de aplicar algoritmos de aprendizaje.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;generalidades&#34;&gt;Generalidades&lt;/h2&gt;
&lt;h3 id=&#34;scikit-learn-biblioteca-de-ml-en-python&#34;&gt;Scikit-learn: biblioteca de ML en Python&lt;/h3&gt;
&lt;p&gt;Para manejar datos y entrenar modelos, &lt;strong&gt;scikit-learn&lt;/strong&gt; proporciona multitud de herramientas:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-scikit-learn&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Logo scikit-learn&#34; srcset=&#34;
               /minerias/2_datos/figures/Scikit_learn_logo_small_svg_hu6327989177387202692.webp 400w,
               /minerias/2_datos/figures/Scikit_learn_logo_small_svg_hu8563963018684445495.webp 760w,
               /minerias/2_datos/figures/Scikit_learn_logo_small_svg_hu1265031393500101177.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/Scikit_learn_logo_small_svg_hu6327989177387202692.webp&#34;
               width=&#34;260&#34;
               height=&#34;140&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Scikit-learn
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sitio oficial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/user_guide.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;User guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El &lt;strong&gt;workflow general&lt;/strong&gt; involucra la carga de datos, preprocesamiento, extracción de características, entrenamiento y evaluación, con metodos normalizadas entre las clases:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-etapas-de-un-pipeline-en-scikit-learn&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Flujo de trabajo en scikit-learn&#34; srcset=&#34;
               /minerias/2_datos/figures/supervised_scikit_learn_hu17372726708710164390.webp 400w,
               /minerias/2_datos/figures/supervised_scikit_learn_hu13489451897173136613.webp 760w,
               /minerias/2_datos/figures/supervised_scikit_learn_hu5671300666085423450.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/supervised_scikit_learn_hu17372726708710164390.webp&#34;
               width=&#34;659&#34;
               height=&#34;484&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Etapas de un pipeline en Scikit-learn
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;patrones-en-los-datos-y-vectorización&#34;&gt;Patrones en los datos y vectorización&lt;/h3&gt;
&lt;p&gt;El objetivo de muchos métodos de Machine Learning es &lt;strong&gt;detectar estructuras&lt;/strong&gt; o &lt;strong&gt;patrones&lt;/strong&gt; en los datos. Para ello, generalmente necesitamos que la información esté en forma de &lt;strong&gt;vectores&lt;/strong&gt; numéricos, de modo que cada ejemplo (documento, imagen, usuario, transacción, etc.) esté representado como un conjunto de variables numéricas (una por dimensión).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-here-is-the-content-of-this-class-in-the-global-framwork-of-scikit-learn&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Scikit&#34; srcset=&#34;
               /minerias/2_datos/figures/supervised_scikit_learn_FExt_hu4892075279246747440.webp 400w,
               /minerias/2_datos/figures/supervised_scikit_learn_FExt_hu14889019013373788.webp 760w,
               /minerias/2_datos/figures/supervised_scikit_learn_FExt_hu3437252132674115788.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/supervised_scikit_learn_FExt_hu4892075279246747440.webp&#34;
               width=&#34;659&#34;
               height=&#34;484&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Here is the content of this class, in the global framwork of scikit-learn
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En la práctica, tendremos que &lt;strong&gt;extraer representaciones cifradas&lt;/strong&gt; (features) que describan lo más relevante posible de cada ejemplo. Por ejemplo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformar un texto en un vector que represente la frecuencia de ciertas palabras.&lt;/li&gt;
&lt;li&gt;Medir el histograma de colores de una imagen.&lt;/li&gt;
&lt;li&gt;Recopilar atributos de una tabla (edad, sexo, país&amp;hellip;) para un usuario.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-un-ejemplo-de-vectorizacion-de-razas-de-animales-el-objetivo-aca-es-de-encontrar-un-modelo-que-puede-reconocer-las-partes-del-espacio-caracteristicas-de-una-clase&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Reconnaissance&#34; srcset=&#34;
               /minerias/2_datos/figures/reconnaissance_dans_espace_petit_hu17874801778558254842.webp 400w,
               /minerias/2_datos/figures/reconnaissance_dans_espace_petit_hu15134139039843177786.webp 760w,
               /minerias/2_datos/figures/reconnaissance_dans_espace_petit_hu5122108817378378540.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/reconnaissance_dans_espace_petit_hu17874801778558254842.webp&#34;
               width=&#34;363&#34;
               height=&#34;365&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un ejemplo de vectorizacion de razas de animales. El objetivo aca es de encontrar un modelo que puede reconocer las partes del espacio caracteristicas de una clase.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;features-y-etiquetas&#34;&gt;Features y etiquetas&lt;/h3&gt;
&lt;p&gt;Cuando hacemos aprendizaje &lt;strong&gt;supervisado&lt;/strong&gt;, además de la representación vectorial (features), necesitamos una &lt;strong&gt;etiqueta&lt;/strong&gt; o valor de salida asociado a cada ejemplo:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-proceso-global-de-un-sistema-supervisado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Esquema de aprendizaje supervisado&#34; srcset=&#34;
               /minerias/2_datos/figures/classif_hu9702192758643128410.webp 400w,
               /minerias/2_datos/figures/classif_hu1940178425719737447.webp 760w,
               /minerias/2_datos/figures/classif_hu1255634141064509397.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/classif_hu9702192758643128410.webp&#34;
               width=&#34;760&#34;
               height=&#34;476&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Proceso global de un sistema supervisado
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Features&lt;/strong&gt;: Lo que describe al ejemplo.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Etiqueta (label)&lt;/strong&gt;: Variable objetivo que se quiere predecir.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modelo&lt;/strong&gt;: Aprenderá parámetros para predecir la etiqueta a partir de las features.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;tipos-de-datos&#34;&gt;Tipos de datos&lt;/h2&gt;
&lt;h3 id=&#34;cualitativos-vs-cuantitativos&#34;&gt;Cualitativos vs. cuantitativos&lt;/h3&gt;
&lt;p&gt;Los datos pueden ser de tipo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cuantitativos&lt;/strong&gt;: numéricos, mediciones, contajes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cualitativos&lt;/strong&gt;: categóricos, nominales o incluso ordinales (pero no lineales).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-diferentes-tipos-de-características-cantidad-marca-sabor-etc&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de café con datos cuantitativos y cualitativos&#34; srcset=&#34;
               /minerias/2_datos/figures/coffee_hu12238997880869042543.webp 400w,
               /minerias/2_datos/figures/coffee_hu3514629794022085907.webp 760w,
               /minerias/2_datos/figures/coffee_hu5031277750654754841.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/coffee_hu12238997880869042543.webp&#34;
               width=&#34;760&#34;
               height=&#34;333&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Diferentes tipos de características (cantidad, marca, sabor, etc.)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Los datos cualitativos pueden ser más interpretables, pero a veces pierden detalle.&lt;/li&gt;
&lt;li&gt;Los datos cuantitativos dan más precisión, pero pueden ser más difíciles de interpretar.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;datos-estructurados-vs-no-estructurados&#34;&gt;Datos estructurados vs. no estructurados&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Estructurados&lt;/strong&gt;: Se presentan en tablas con filas y columnas, es decir, cada ejemplo/instancia y sus atributos (p. ej., dataset de Titanic).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No estructurados&lt;/strong&gt;: Texto, imágenes, audio, etc. Suelen requerir más trabajo de &lt;strong&gt;vectorización&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-comparación-entre-datos-en-tabla-y-datos-en-bruto&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplos de datos estructurados vs. no estructurados&#34; srcset=&#34;
               /minerias/2_datos/figures/str_vs_unstr_hu16312124660273804279.webp 400w,
               /minerias/2_datos/figures/str_vs_unstr_hu7267090381556476155.webp 760w,
               /minerias/2_datos/figures/str_vs_unstr_hu5542194265417987857.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/str_vs_unstr_hu16312124660273804279.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Comparación entre datos en tabla y datos en bruto
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En muchos problemas, tendremos que convertir datos no estructurados a forma vectorial o tabular para poder aplicar algoritmos de ML.&lt;/p&gt;
&lt;h3 id=&#34;distancia-entre-vectores&#34;&gt;Distancia entre vectores&lt;/h3&gt;
&lt;p&gt;Cuando representamos datos como vectores, podemos comparar su &lt;strong&gt;similitud&lt;/strong&gt; o &lt;strong&gt;diferencia&lt;/strong&gt; con métricas como la distancia euclidiana o el &lt;strong&gt;coseno&lt;/strong&gt; (similaridad de coseno):&lt;/p&gt;
\[
\cos(\mathbf{X}, \mathbf{X}&#39;) \;=\; 
\frac{\langle \mathbf{X}, \mathbf{X}&#39;\rangle}{\|\mathbf{X}\|\;\|\mathbf{X}&#39;\|}.
\]&lt;p&gt;















&lt;figure  id=&#34;figure-la-distancia-entre-vectores-se-puede-calcular-de-varias-maneras&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;distance_vectors&#34; srcset=&#34;
               /minerias/2_datos/figures/distance_vectors_hu9643923070251790051.webp 400w,
               /minerias/2_datos/figures/distance_vectors_hu922159784453930484.webp 760w,
               /minerias/2_datos/figures/distance_vectors_hu10091620246869096621.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/distance_vectors_hu9643923070251790051.webp&#34;
               width=&#34;760&#34;
               height=&#34;364&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La distancia entre vectores se puede calcular de varias maneras
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Esto se usa en muchas aplicaciones de clustering, recomendación y clasificación.&lt;/p&gt;
&lt;h3 id=&#34;extraccion-con-sklearn&#34;&gt;Extraccion con sklearn&lt;/h3&gt;
&lt;p&gt;Un ejemplo simple de one-hot encoding con scikit-learn:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;genders&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;locations&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;from Africa&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Asia&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Europe&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from US&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;browsers&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Chrome&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Firefox&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses IE&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Safari&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;enc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;preprocessing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OneHotEncoder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;genders&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;locations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;browsers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Note that for there are missing categorical values for the 2nd and 3rd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# feature&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from US&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Safari&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Europe&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Firefox&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;enc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;OneHotEncoder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;from Africa&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Asia&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Europe&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           &lt;span class=&#34;s1&#34;&gt;&amp;#39;from US&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Chrome&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Firefox&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses IE&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Safari&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;enc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Asia&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Chrome&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toarray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;calidad-de-los-datos&#34;&gt;Calidad de los datos&lt;/h2&gt;
&lt;p&gt;Los datos reales suelen estar lejos de ser perfectos.&lt;/p&gt;
&lt;h3 id=&#34;ruido&#34;&gt;Ruido&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Ruido&lt;/strong&gt;: irregularidad aleatoria en los datos, diferencias no explicadas por el modelo. No tienen ningún patrón. Estos errores suelen ser &lt;strong&gt;inevitables e imprevisibles&lt;/strong&gt;. Puede provenir de:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Errores&lt;/strong&gt;: Errores de medición o muestreo que pueden distorsionar los datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Residuos&lt;/strong&gt;: Variación intrínseca no capturada en nuestras features. Incluso aunque no haya errores de medición, un modelo no suele capturar el 100% de la variabilidad, por lo que siempre existirán residuos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ruido-blanco-en-una-imagen-las-perturbaciones-que-habia-en-la-television-cuando-habia-mala-señal-el-sonido-de-fondo-cuando-capta-mal-el-telefono&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ruido blanco&#34; srcset=&#34;
               /minerias/2_datos/figures/white_noise_hu579348812110497967.webp 400w,
               /minerias/2_datos/figures/white_noise_hu10361843702748057629.webp 760w,
               /minerias/2_datos/figures/white_noise_hu15236131570812366011.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/white_noise_hu579348812110497967.webp&#34;
               width=&#34;760&#34;
               height=&#34;284&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ruido blanco en una imagen, las perturbaciones que habia en la television, cuando habia mala señal, el sonido de fondo cuando capta mal el telefono&amp;hellip;
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Es difícil (o imposible) de representar toda la realidad con un ensamble finito de observaciones&lt;/li&gt;
&lt;li&gt;Vamos a representar una cosa con un vector de tamaño finito, lo que puede ser reductible al fenómeno inicial, es una aproximación de la realidad&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Se va a quedar un componente de ruido que no se puede modelizar&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Si queremos modelizar \(Y = 3*X_1 - 2*X^2_2 + \epsilon\) con \(X_1\) y \(X_2\), no lo vamos a lograr.
















&lt;figure  id=&#34;figure-modelo-que-intenta-ajustar-datos-con-ruido&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ruido en el ajuste de una función&#34; srcset=&#34;
               /minerias/2_datos/figures/ex_over-underfitting_noise_hu7160750459805610265.webp 400w,
               /minerias/2_datos/figures/ex_over-underfitting_noise_hu1258070293613913168.webp 760w,
               /minerias/2_datos/figures/ex_over-underfitting_noise_hu16428299825422072936.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/ex_over-underfitting_noise_hu7160750459805610265.webp&#34;
               width=&#34;728&#34;
               height=&#34;255&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Modelo que intenta ajustar datos con ruido
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;outliers&#34;&gt;Outliers&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplo-de-outliers-en-2-dimensiones&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Outliers en diferentes distribuciones&#34; srcset=&#34;
               /minerias/2_datos/figures/outlier_gaussians_hu18089628100723988662.webp 400w,
               /minerias/2_datos/figures/outlier_gaussians_hu11729765782774009637.webp 760w,
               /minerias/2_datos/figures/outlier_gaussians_hu4176910214133138174.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/outlier_gaussians_hu18089628100723988662.webp&#34;
               width=&#34;440&#34;
               height=&#34;310&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo de outliers en 2 dimensiones
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Un &lt;strong&gt;outlier&lt;/strong&gt; o valor atípico es un punto de datos que difiere significativamente de la mayoría. Pueden ser:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Outliers ruidosos&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Son datos erróneos (fallos de medición, errores tipográficos, etc.) o extremos por variabilidad natural que no nos interesan.&lt;/li&gt;
&lt;li&gt;Suelen distorsionar estimaciones estadísticas (e.g. la media).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Outliers “útiles”&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Responden a eventos raros o anómalos que sí queremos detectar (fraude, crisis, rarezas de inventario).&lt;/li&gt;
&lt;li&gt;Pueden ser el foco de ciertos análisis (detección de anomalías).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplos-del-mvtec-anomaly-detection-dataset&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Outliers en diferentes distribuciones&#34; srcset=&#34;
               /minerias/2_datos/figures/dataset_overview_anomaly_hu12222639050208223478.webp 400w,
               /minerias/2_datos/figures/dataset_overview_anomaly_hu14348380986165943337.webp 760w,
               /minerias/2_datos/figures/dataset_overview_anomaly_hu7518922898301784344.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/dataset_overview_anomaly_hu12222639050208223478.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplos del MVTEC Anomaly Detection Dataset
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Para identificarlos, se pueden usar:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Visualización (boxplots, scatter plots).&lt;/li&gt;
&lt;li&gt;Métodos estadísticos (rango intercuartílico, z-score).&lt;/li&gt;
&lt;li&gt;Algoritmos de ML (Isolation Forest, Local Outlier Factor).&lt;/li&gt;
&lt;li&gt;Validación de dominio (comprobar en la realidad si ese punto es auténtico o no).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-outlier-label-detection-cleanlabhttpsgithubcomcleanlabcleanlab-allowed-to-detect-many-of-the-label-error-in-the-imagenet-dataset&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Outliers en diferentes distribuciones&#34; srcset=&#34;
               /minerias/2_datos/figures/CleanLab_hu10917344694898179941.webp 400w,
               /minerias/2_datos/figures/CleanLab_hu1141749507235822239.webp 760w,
               /minerias/2_datos/figures/CleanLab_hu413918498232524429.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/CleanLab_hu10917344694898179941.webp&#34;
               width=&#34;760&#34;
               height=&#34;447&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Outlier Label detection. &lt;a href=&#34;https://github.com/cleanlab/cleanlab&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CleanLab&lt;/a&gt; allowed to detect many of the label error in the Imagenet dataset.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;valores-faltantes&#34;&gt;Valores faltantes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Missing values&lt;/strong&gt;: Es frecuente tener celdas vacías o desconocidas, por ejemplo:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.impute&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SimpleImputer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imp_mean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SimpleImputer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mean&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imp_mean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Podemos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Eliminar las filas&lt;/strong&gt; (si son pocas y su ausencia no afecta demasiado).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Imputar valores&lt;/strong&gt; usando la media, mediana o algoritmos como &lt;code&gt;KNNImputer&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modelos que los manejen directamente&lt;/strong&gt;: algunos estimadores permiten tratar valores faltantes sin preprocesamiento adicional.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-existen-modelos-que-pueden-manejar-los-missing-values-en-scikit&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Modelos que aceptan valores faltantes&#34; srcset=&#34;
               /minerias/2_datos/figures/estimators_missing_values_hu5552150127740906947.webp 400w,
               /minerias/2_datos/figures/estimators_missing_values_hu2966550281670234438.webp 760w,
               /minerias/2_datos/figures/estimators_missing_values_hu1414166785689099899.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/estimators_missing_values_hu5552150127740906947.webp&#34;
               width=&#34;760&#34;
               height=&#34;419&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Existen modelos que pueden manejar los missing values en scikit
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;duplicados&#34;&gt;Duplicados&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Datos duplicados&lt;/strong&gt;: aparecen al combinar fuentes o por errores de recolección. Puede generar &lt;em&gt;sobrerepresentación&lt;/em&gt; de ciertos ejemplos y perjudicar el entrenamiento.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Errores en la concatenación o carga de datos desde fuentes múltiples.&lt;/li&gt;
&lt;li&gt;Recolección repetida de la misma observación.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Los duplicados suelen &lt;strong&gt;sobrerepresentar&lt;/strong&gt; determinados ejemplos, generando un sesgo en el entrenamiento. En casos masivos (p.ej., entrenamiento de grandes modelos de lenguaje), se ha demostrado que duplicar documentos puede perjudicar significativamente la calidad del modelo.&lt;/p&gt;
&lt;p&gt;Para mitigarlos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Comparar hashes o firmas&lt;/strong&gt; de los ejemplos (si hablamos de texto, imágenes, etc.).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering de similitud&lt;/strong&gt; de ejemplos para detectar duplicaciones leves o parciales.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Herramientas de deduplicación&lt;/strong&gt; específicas (ej.: para nombres de usuarios, direcciones de correo, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Es crucial deduplicar en datasets grandes (por ejemplo, para entrenar grandes modelos de lenguaje).&lt;/p&gt;
&lt;p&gt;En caso simple de datos tabulares, se puede utilizar metodos como &lt;code&gt;pandas.DataFrames.drop_duplicates()&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;use-case-llm&#34;&gt;Use-case: LLM&lt;/h3&gt;
&lt;p&gt;Para entrenar un LLM desde zero, es necesario de colectar una grande cantidad de datos! Colectando datos del web, es imposible de tener datos limpios!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Los datos extraídos de la web tienen mucho ruido y hay que limpiarlos.&lt;/li&gt;
&lt;li&gt;Marcas, roturas de sintaxis, etc&amp;hellip; todo lo que da texto no NL es perjudicial, ¡y puede impedir la convergencia!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Se ha determinado que la deduplicación desempeña un papel importante&lt;/strong&gt; en la mejora de los modelos lingüísticos (&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3359591.3359735?casa_token=AT3LybXtoLQAAAAA:LJLGtclf0beYhmJBuxCxUpAgDe4KspLeZYN2LWG9A3ePEl3Lkh21hsjczzjyyMiSx6dg7MQUbmtlLw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Allamanis, 2019&lt;/a&gt;; &lt;a href=&#34;https://arxiv.org/abs/2107.06499&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lee et al., 2022&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Se ha demostrado que la repetición de datos es cada vez más perjudicial para la calidad del modelo a medida que aumenta el número de parámetros (&lt;a href=&#34;https://arxiv.org/abs/2205.10487&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hernandez et al., 2022&lt;/a&gt;):
&lt;ul&gt;
&lt;li&gt;para un modelo de 1B parámetros, cien duplicados son perjudiciales;&lt;/li&gt;
&lt;li&gt;a 175B, &lt;strong&gt;incluso unos pocos duplicados&lt;/strong&gt; podrían tener un efecto desproporcionado.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;limpieza-y-preprocesamiento&#34;&gt;Limpieza y preprocesamiento&lt;/h2&gt;
&lt;h3 id=&#34;estandarización-y-normalización&#34;&gt;Estandarización y normalización&lt;/h3&gt;
&lt;p&gt;Muchos algoritmos de ML (especialmente basados en distancias o gradientes) funcionan mejor cuando las &lt;strong&gt;features&lt;/strong&gt; tienen escalas comparables.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Estandarización&lt;/strong&gt; (StandardScaler):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Convierten cada feature a media cero y varianza uno:&lt;/p&gt;
\[
     X_{\mathrm{std}} = \frac{X - \mu_X}{\sigma_X}.
     \]&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Afecta cada atributo de forma que su distribución resulte centrada en 0 y con desviación estándar 1.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Normalización&lt;/strong&gt; (Normalizer):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ajusta cada &lt;strong&gt;vector&lt;/strong&gt; para que su norma sea 1.&lt;/li&gt;
&lt;li&gt;Se suele usar en tareas donde la dirección del vector importa más que su magnitud (p.ej. coseno de similaridad).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scaling&lt;/strong&gt; a un rango \([0, 1]\) (MinMaxScaler):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Se “comprime” cada atributo dentro de \([0..1]\):&lt;/p&gt;
\[
     X_{\mathrm{scaled}} = \frac{X - X_{\min}}{X_{\max} - X_{\min}}.
     \]&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Útil cuando no se desea asumir forma gaussiana y se quiere mantener la escala finita.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;¿Por qué es importante?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evitar que los atributos con rangos muy grandes dominen sobre otros.&lt;/li&gt;
&lt;li&gt;Favorecer la convergencia de algoritmos de optimización que basan sus pasos en gradientes (como Redes Neuronales).&lt;/li&gt;
&lt;li&gt;Mejorar la calidad de métodos de distancia (k-NN, SVM, clustering) que asumen escalas comparables en las coordenadas.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mas info &lt;a href=&#34;https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aca&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;discretización&#34;&gt;Discretización&lt;/h3&gt;
&lt;p&gt;Dividir atributos continuos en bins (categorías).&lt;/p&gt;
&lt;p&gt;La discretizacion (tambien conocida como cuantizacion o binning) permite dividir las caracterısticas continuas en valores discretos (clases). Las caracterısticas discretizadas codificadas de una sola vez pueden &lt;strong&gt;hacer que un modelo sea mas expresivo, manteniendo la interpretabilidad.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-transformar-la-variable-continua-edad-en-clases-discretas&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de discretización&#34; srcset=&#34;
               /minerias/2_datos/figures/age_reg_to_classif_hu17690873109572084870.webp 400w,
               /minerias/2_datos/figures/age_reg_to_classif_hu5798053001599690990.webp 760w,
               /minerias/2_datos/figures/age_reg_to_classif_hu7439249746381267252.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/age_reg_to_classif_hu17690873109572084870.webp&#34;
               width=&#34;760&#34;
               height=&#34;649&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Transformar la variable continua &amp;rsquo;edad&amp;rsquo; en clases discretas
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;polynomial-features&#34;&gt;Polynomial Features&lt;/h3&gt;
&lt;p&gt;Añadir términos polinómicos (no lineales) para incrementar la complejidad de un modelo lineal.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-polynomial-helps-fitiing-more-complex-functions&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de discretización&#34; srcset=&#34;
               /minerias/2_datos/figures/ex_over-underfitting_polynomial_hu12296047467455913660.webp 400w,
               /minerias/2_datos/figures/ex_over-underfitting_polynomial_hu3603271985052957351.webp 760w,
               /minerias/2_datos/figures/ex_over-underfitting_polynomial_hu12325601955647240871.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/ex_over-underfitting_polynomial_hu12296047467455913660.webp&#34;
               width=&#34;732&#34;
               height=&#34;274&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Polynomial helps fitiing more complex functions
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Mas informaciones &lt;a href=&#34;https://scikit-learn.org/stable/modules/preprocessing.html%5c#generating-polynomial-features&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aca&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;interés-del-sampling-muestreo&#34;&gt;Interés del sampling (muestreo)&lt;/h3&gt;
&lt;p&gt;Un mal muestreo puede generar sesgos en nuestros datos y conclusiones. Existen diversas estrategias:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Muestreo estratificado&lt;/strong&gt;: Mantiene proporciones de clases o grupos.&lt;br&gt;
















&lt;figure  id=&#34;figure-muestreo-estratificado-mantiene-proporciones-en-subgrupos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de muestreo estratificado&#34; srcset=&#34;
               /minerias/2_datos/figures/stratified_sampling_hu3739506566429986846.webp 400w,
               /minerias/2_datos/figures/stratified_sampling_hu12963448647892023621.webp 760w,
               /minerias/2_datos/figures/stratified_sampling_hu9627835439692744135.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/stratified_sampling_hu3739506566429986846.webp&#34;
               width=&#34;486&#34;
               height=&#34;440&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Muestreo estratificado: mantiene proporciones en subgrupos
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Muestreo aleatorio simple&lt;/strong&gt;: Elegir instancias al azar.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Muestreo sistemático&lt;/strong&gt;: Tomar cada k-ésimo elemento desde un punto inicial aleatorio.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-systematic-random-sampling-selecciona-elementos-de-una-población-a-intervalos-regulares-desde-un-punto-de-partida-aleatorio&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de muestreo estratificado&#34; srcset=&#34;
               /minerias/2_datos/figures/systematic_random_sampling_hu11080984733742039593.webp 400w,
               /minerias/2_datos/figures/systematic_random_sampling_hu15285761124891998038.webp 760w,
               /minerias/2_datos/figures/systematic_random_sampling_hu15458938320889412188.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/systematic_random_sampling_hu11080984733742039593.webp&#34;
               width=&#34;760&#34;
               height=&#34;353&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Systematic Random Sampling: Selecciona elementos de una población a intervalos regulares desde un punto de partida aleatorio
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;agregaciones-de-datos&#34;&gt;Agregaciones de datos&lt;/h3&gt;
&lt;p&gt;Combinar varios valores en uno solo (por ejemplo, la media diaria) puede:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reducir ruido&lt;/strong&gt; y variabilidad.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simplificar&lt;/strong&gt; el conjunto de datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resumir&lt;/strong&gt; grandes volúmenes de información.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-agregación-en-un-día-para-medir-la-opinión-general&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Agregación diaria de tweets positivos&#34; srcset=&#34;
               /minerias/2_datos/figures/hapiness_twitter_hu869437225968806113.webp 400w,
               /minerias/2_datos/figures/hapiness_twitter_hu9597793583217252604.webp 760w,
               /minerias/2_datos/figures/hapiness_twitter_hu9500706212212640228.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/hapiness_twitter_hu869437225968806113.webp&#34;
               width=&#34;760&#34;
               height=&#34;398&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Agregación en un día para medir la opinión general
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;dimensión-cursa-y-reducción&#34;&gt;Dimensión: &lt;em&gt;Cursa&lt;/em&gt; y reducción&lt;/h3&gt;
&lt;p&gt;En altas dimensiones, los datos se dispersan y pierden significado las distancias (curse of dimensionality). Para mitigar esto:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reducción de dimensión&lt;/strong&gt; (p. ej. PCA, selección de atributos).&lt;/li&gt;
&lt;li&gt;Eliminar o fusionar atributos irrelevantes.&lt;/li&gt;
&lt;li&gt;Acelerar el procesamiento y mejorar la interpretabilidad.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-en-dimensiones-muy-altas-los-datos-se-distribuyen-uniformemente&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ilustración del curse of dimensionality&#34; srcset=&#34;
               /minerias/2_datos/figures/curse_of_dimensionality_hu13015040265525298778.webp 400w,
               /minerias/2_datos/figures/curse_of_dimensionality_hu17025575749590265977.webp 760w,
               /minerias/2_datos/figures/curse_of_dimensionality_hu17010720842900593354.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/curse_of_dimensionality_hu13015040265525298778.webp&#34;
               width=&#34;433&#34;
               height=&#34;347&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      En dimensiones muy altas, los datos se distribuyen uniformemente
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>(TODO) Datos II</title>
      <link>http://localhost:1313/minerias/3_datos_exp/</link>
      <pubDate>Thu, 28 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/3_datos_exp/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-not-available-heretodopdf&#34;&gt;The slides are not available &lt;a href=&#34;todo.pdf&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Intro Aprendizaje Supervisado</title>
      <link>http://localhost:1313/minerias-en/1_intro/</link>
      <pubDate>Wed, 27 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias-en/1_intro/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-heredm_intro_slpdf&#34;&gt;The slides are available &lt;a href=&#34;DM_Intro_SL.pdf&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;This class is pretty cool as you will discover the basics of the knowledge used to build Machine Learning, Deep Learning and Artifical Intelligence in general: Supervised Learning! This is a simple setting where a &lt;strong&gt;model will learn its own parameters using examples and associated labels&lt;/strong&gt;. We will revise all the important concepts of supervised learning, which are very useful for anybody who wants to become data scientist.&lt;/p&gt;
&lt;p&gt;Esta clase es bastante bacan ya que descubriran las bases del conocimiento utilizado para construir Machine Learning, Deep Learning e Inteligencia Artificial en general: Aprendizaje Supervisado! Se trata de un entorno sencillo en el que un &lt;strong&gt;modelo aprenderá sus propios parámetros utilizando ejemplos y etiquetas asociadas&lt;/strong&gt;. Revisaremos todos los conceptos importantes del aprendizaje supervisado, que son muy útiles para cualquiera que quiera trabajar como data scientist.&lt;/p&gt;
&lt;h2 id=&#34;generalidades&#34;&gt;Generalidades&lt;/h2&gt;
&lt;p&gt;El aprendizaje supervisado utiliza datos y etiquetas para aprender a un modelo a reconocer padrones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Es necesario de transformar los documentos en vectores, para poder hacer la optimizacion&lt;/li&gt;
&lt;li&gt;El modelo va a apprender sus parametros sobre un conjunto de entrenamiento&lt;/li&gt;
&lt;li&gt;El modelo entrenado puede ser usado para predicir la etiquetas de nuevos datos que nunca ha visto antes&lt;/li&gt;
&lt;li&gt;El documento puede ser cualquier dato: audio, texto, imagen, video, usuario, red,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/predictive_modeling_data_flow.png&#34; alt=&#34;predictive_modeling_data_flow&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;features-y-etiquetas&#34;&gt;Features y etiquetas&lt;/h3&gt;
&lt;p&gt;Se puede representar en un espacio los documentos como vectores. Aca cada punto es una cancion, que esta representando con su intensidad y tempo promedios. La etiqueta es la color del punto. Aca tenemos una tarea de &lt;strong&gt;clasificacion binaria de musica&lt;/strong&gt;, sengundo las preferencias de un usuario.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/classif.jpg&#34; alt=&#34;classif&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El objetivo del juego, va a ser de encontrar &lt;strong&gt;una funcion que separa el espacio en dos partes&lt;/strong&gt;. Una donde hay las canciones que le gustan a la persona, y la otra parte que no le gustan. De este manera, cuando vamos a tener un nuevo punto en este espacio, podemos decir si la persona va a gustar o no esta cancion, lo que sea &lt;strong&gt;predicir su etiqueta&lt;/strong&gt;!&lt;/p&gt;
&lt;h3 id=&#34;en-resumen&#34;&gt;En resumen&lt;/h3&gt;
&lt;p&gt;Se necesitan varias cosas para un entrenamiento&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Tener datos etiquetados&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Conjunto de datos de tamaño $n$
, $\mathcal{D}_n = \{(\text{Doc}_i, Y_i), i=1..n\}$
&lt;/li&gt;
&lt;li&gt;$\text{Doc}$ es una muestra (por ejemplo: una persona)&lt;/li&gt;
&lt;li&gt;$Y$ son las etiquetas (por ejemplo: monto del préstamo concedido)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Extraer los descriptores&lt;/strong&gt; = transformar documentos en vectores&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;$\mathbf{X}$ es un vector de observaciones (por ejemplo: edad, sexo, salario)&lt;/li&gt;
&lt;li&gt;$Y$ son las etiquetas (por ejemplo: monto del préstamo concedido)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Crear un modelo matemático $f_\theta$&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Modelo $f_\theta$ tal que  $f_\theta(\mathbf{X})$
 esté cerca de $Y$ (para regresión)&lt;/li&gt;
&lt;li&gt;$\theta$ es el conjunto de parámetros del modelo matemático&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Implementar una función de costo (error) $\ell$
 a minimizar&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Cuanto más se equivoque el modelo, mayor será el costo&lt;/li&gt;
&lt;li&gt;En general, se desea tener un costo pequeño&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;Encontrar los parámetros  $\theta^*$ 
 de manera que  $\ell(f_{\theta^*}(\mathbf{X}_i), Y_i)$ 
 sea pequeño&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
$$\theta^* = \underset{\theta}{\arg\min}\sum_{i}\ell(f_{\theta}(\mathbf{X}_i), Y_i)$$&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;&lt;strong&gt;Probar $f_{\theta^*}$
 en nuevos datos con una métrica de evaluación adecuada&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;aprendizaje&#34;&gt;Aprendizaje&lt;/h2&gt;
&lt;p&gt;Hay varios conceptos en el aprendizaje:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Datos etiquetados&lt;/strong&gt;: Regresión o Clasificación&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Extracción de características&lt;/strong&gt;: Tono, Intensidad, Tempo o Edad, Salario, Género, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modelo $f_\theta$&lt;/strong&gt;: SVM, Regresión Logística, Bosque Aleatorio, CNN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Función de costo&lt;/strong&gt; a optimizar: Pérdida de Bisagra, Pérdida de Entropía Cruzada, Pérdida Logística, Pérdida Cuadrada, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Algoritmo de optimización&lt;/strong&gt;: Adam, SGD, BFGS, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Métrica de evaluación&lt;/strong&gt;: Recall, Precisión, Mínimos Cuadrados, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;funcion-de-costo&#34;&gt;Funcion de costo&lt;/h3&gt;
&lt;p&gt;Para cuantificar las errores del modelo en la optimizacion, se necesita una funcion de costo que llamamos  $\ell$ 
. Ella representa si el modelo esta dando las buenas respuestas $y$
 segundo una entrada $X$
. Este funcion penaliza el modelo cuando comete errores, y lo que queremos hacer es optimizar los pesos del modelo, para obtener una valor minimum de este costo, lo que significaria menos errores, entonces mejor modelo.&lt;/p&gt;
&lt;p&gt;Hay que minimizar esta función sobre el conjunto de entrenamiento (riesgo empírico) para encontrar parámetros del modelo satisfactorios:&lt;/p&gt;
$$ f_{\hat{\theta}} =\underset{f_\theta, \theta \in \Theta}{\arg\min} \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$$&lt;p&gt;Los parametros van a cambiar para tener un valor minimum de costo:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/convergence_algo_optim.png&#34; alt=&#34;convergence_algo_optim&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;La funcion de costo expresa el error desde una perspectiva &lt;strong&gt;numérica&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Transmite al algoritmo de aprendizaje lo que es importante y tiene sentido para la tarea&lt;/li&gt;
&lt;li&gt;Debe ser una función que se pueda optimizar eficientemente (convexa). &lt;strong&gt;La función  $\ell^{0/1} = \mathds{1}_{f(\mathbf{X}) = Y}$ 
 no es utilizable&lt;/strong&gt; (ni siquiera continua).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;complejidad-de-los-modelos-y-sobresoto-aprendizaje&#34;&gt;Complejidad de los modelos y sobre/soto-aprendizaje&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt; $\mathcal{F} = \{ f: \text{ funciones medibles } \mathcal{X} \text{&amp;rarr;} \mathcal{Y}\}$ 
&lt;/li&gt;
&lt;li&gt;Mejor solución  $f^* = \arg\min_{f \in \mathcal{F}}\mathcal{R}(f)$ 
&lt;/li&gt;
&lt;li&gt;Clase de funciones  $\mathcal{S} \subset \mathcal{F}$ 
 utilizadas como modelos&lt;/li&gt;
&lt;li&gt;Objetivo ideal en $\mathcal{S}$:  $f^*_\mathcal{S} = \arg\min_{f \in \mathcal{S}}\mathcal{R}(f)$ 
&lt;/li&gt;
&lt;li&gt;Estimación obtenida en  $\mathcal{S}$ 
: se obtiene  $f_\mathcal{S}$ 
 tras un entrenamiento&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se pueden encontrar dos maneras de no tener el riesgo minimum optimum:&lt;/p&gt;
$$ \mathcal{R}(\hat{f_\mathcal{S}}) - \mathcal{R}(f^*) = \textcolor{red}{\underbrace{ \mathcal{R}(f_\mathcal{S}^*) - \mathcal{R}(f^*) }_{\text{error de aproximacion}}} +  \textcolor{blue}{\underbrace{ \mathcal{R}(\hat{f_\mathcal{S}}) - \mathcal{R}(f_\mathcal{S}^*) }_{\text{error de estimacion}}}$$&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/approx_estim_errors.png&#34; alt=&#34;approx_estim_errors&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El error de aproximación puede ser grande si el modelo $\mathcal{S}$ no es adaptado, y el error de estimación puede ser grande si el modelo es complejo.&lt;/p&gt;
&lt;p&gt;Un ejemplo simple seria un polinomio de grado P que quiere estimar un polinomio de grado N con ruido:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/ex_over-underfitting.png&#34; alt=&#34;underfitting&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Soto-aprentizaje&lt;/strong&gt;: Si no hay demasiado parametros, es imposible de estimar bien la curva,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sobre-aprentizaje&lt;/strong&gt;: Si hay demasiado parametros va a enfocar en memorizar el ruido del ensemble de entrenamiento&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;regularizacion-y-parsimonia&#34;&gt;Regularizacion y parsimonia&lt;/h3&gt;
&lt;p&gt;Una solucion para combatir el problema de no generalizacion es la regularizacion, que permite de agregar una penalización en relación con la complejidad del modelo:&lt;/p&gt;

$$\arg\min_{f_\theta, \theta \in \Theta} \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) ) + pen(\theta)$$


&lt;p&gt;Hay varias posibilidades de penalizacion, generalmente se usa la norma de los pesos del modelo. La intuicion detras de eso es que disminuir la norma del modelo o su número de coeficientes, número de ramas del grafo (poda).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AIC:

$pen(\theta) = \lambda ||\theta||_0$


&lt;em&gt;(no convexa, parsimoniosa, poco utilizada)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Ridge:

$pen(\theta) = \lambda ||\theta||_2$ 


&lt;em&gt;(convexa, no parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Lasso:

$pen(\theta) = \lambda ||\theta||_1$ 


&lt;em&gt;(convexa, parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Elastic Net:

$pen(\theta) = \lambda_1 ||\theta||_1 + \lambda_2 ||\theta||_2$


&lt;em&gt;(convexa, parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El  $\lambda$ 
 es un nuevo hiperparametro del modelo.&lt;/p&gt;
&lt;p&gt;El lasso induce la parcimonia. Aca se pueden ver para  $n=\{0,1,2\}$ 
, las bolas  $$\mathcal{B}^n = \{x / x \in \mathbb{R}^d \text{ and } ||x||_n &lt; 1\}$$ 
:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/norms.png&#34; alt=&#34;norms&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En dimensiones grandes, la mayoría de  $\mathcal{B}^1$ 
 se concentra en los ejes: &lt;strong&gt;esto equivale a tener valores nulos para otros ejes&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/Sparsityl1.png&#34; alt=&#34;Sparsityl1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;optimizacion-loss-landscape&#34;&gt;Optimizacion, &lt;em&gt;loss landscape&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;La optimizacion de la funcion de costo sobre el ensemble de entrenamiento ( $ \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$ 
) se puede hacer de manera analitica en casos simples, o de manera iterativa. La fase de optimizacion va a &lt;strong&gt;hacer converger los parametros&lt;/strong&gt; para encontrar los que van a dar un &lt;strong&gt;costo minimum en el conjunto de datos de entrenamiento&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/convergence_algo_optim.png&#34; alt=&#34;convergence_algo_optim&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En este ejemplo se puede ver los parametros $a,b$
 del modelo  $y = a\mathbf{X}+b$ 
 cambiar por cada iteracion, para tener un valor del error (sse; suma residual de cuadrados) que esta diminuando:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/regression_gif.gif&#34; alt=&#34;regression_gif&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Porque la valor del costo empirico  $ \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$ 
 es un nombre real positivo, podemos representarlo en un eje, y los parametros con unos otros ejes. Eso se llama el &lt;em&gt;loss landscape&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/LossAlps.png&#34; alt=&#34;LossAlps&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El objetivo del algoritmo de optimizacion es de encontrar la &amp;ldquo;ruta&amp;rdquo; para conducir en una &amp;ldquo;valle&amp;rdquo;, que representa un minimum local o global. Este ollo significa que los parametros sean los que dan un error pequeña.&lt;/p&gt;
&lt;h3 id=&#34;gradiente-deciendente&#34;&gt;Gradiente deciendente&lt;/h3&gt;
&lt;p&gt;El gradiente El gradiente de una función  $\nabla_xf(x)=(\frac{\partial f}{\partial\x_i})_{i=1..n}$ 
 es su derivativa según cada dimensión. Es una &lt;strong&gt;aproximación lineal de la función al nivel local&lt;/strong&gt;. Este indica la direccion donde aumenta una funcion:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/gradient_curve1D.png&#34; alt=&#34;gradient_curve1D&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Por eso, se puede utilizar el gradiente de la funccion de costo para minimizar el costo. Después de cada cálculo de la función de costo  $\ell(Y_i, f_\theta(\mathbf{X}_i) ; \theta)$ 
, se calcula el gradiente de esta función para actualizar los parámetros $\theta$
:&lt;/p&gt;
$$	\theta \leftarrow \theta - \alpha*\nabla_\theta \ell(Y_i, f_\theta(\mathbf{X}_i) ; \theta)$$&lt;p&gt;La tasa de aprendizaje  $\alpha$ 
 en la ecuacion precedente representa la cantidad de acutalizacion de los parametros. Es importante porque va a influir sobre la convergencia.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/learningrates.jpeg&#34; alt=&#34;learningrates&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En en &lt;em&gt;loss landscape&lt;/em&gt;, se puede representar el modelo durante la optimizacion como un vector moviendo en cada iteracion. Con este vision, la tasa de aprendizaje define mas o menos la &amp;ldquo;velocidad&amp;rdquo; de como se mueve este punto. Por eso, es simple de entender que a veces tiene que ser mas grande y otra veces mas pequeño, por ejemplo para pasar topografias particular del &lt;em&gt;landscape&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Hay varios algoritmos de tipo gradiente decendiente para converger, con una mejora aproximacion de la tasa de aprendizaje, o la utilizacion de un momentum para ayudar el modelo
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/OtherOptimizers.gif&#34; alt=&#34;OtherOptimizers&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;metricas&#34;&gt;Metricas&lt;/h2&gt;
&lt;h3 id=&#34;tipos-de-errores&#34;&gt;Tipos de errores&lt;/h3&gt;
&lt;p&gt;Un clasificador binario debe detectar un evento. A cada prediccion puede tener una prediciccion verdadera o falsa: eso son los True/False Positives/Negatives: True Positive (TP), False Postiive (FP), False Negative (FN), True Negative (TN). Se pueden encontrar dos tipos de errores:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/error_types.jpg&#34; alt=&#34;error&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Con eso se puede crear una matriz de confusion.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/confusion_matrix.png&#34; alt=&#34;confusion_matrix&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Las matrices de confusion pueden abarcar mas de 2 clases:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;confusion_matrix&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Se puede cada vez volver a una binaria:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/conf_mat_multi.png&#34; alt=&#34;conf_mat_multi&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tipos-de-metricas-y-costo&#34;&gt;Tipos de metricas y costo&lt;/h3&gt;
&lt;p&gt;Usando los True/False Positives/Negatives, se puede calcular varias metricas segundo el tipo de applicacion. Tenemos: el accuracy al nivel general, y el recall, la precision y el F-score al nivel de las clases. Mas informacion &lt;a href=&#34;https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;por alla&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Cada tipo de error puede tener un costo differente segundo si es importante o no en la applicacion del sistema. Por eso se puede utilizar un matriz de costo, y calcular un costo global del sistema.&lt;/p&gt;
&lt;h3 id=&#34;aggregacion&#34;&gt;Aggregacion&lt;/h3&gt;
&lt;p&gt;Se puede agregar las metricas que son al nivel de clase para obtener un valor general:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Macro-averaging&lt;/strong&gt;: computar métrica para cada clase y luego promediar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Micro-averaging&lt;/strong&gt;: crear matriz de confusion binaria para cada clase, combinar las matrices y luego evaluar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weighted-averaging&lt;/strong&gt;: computar métrica para cada clase y luego promediar usando pesos segun el importancia de la clase (nombre de ejemplos)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a simple example in python obtained by the &lt;code&gt;sklearn.metrics.classification_report&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;class 0&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;class 1&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;class 2&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;              precision    recall  f1-score   support

     class 0       0.50      1.00      0.67         1
     class 1       0.00      0.00      0.00         1
     class 2       1.00      0.67      0.80         3

    accuracy                           0.60         5
   macro avg       0.50      0.56      0.49         5
weighted avg       0.70      0.60      0.61         5
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;roc--auc&#34;&gt;ROC &amp;amp; AUC&lt;/h3&gt;
&lt;p&gt;Al momento de la inferencia, nuestro clasificador binario va a dar una probabilidad que un ejemplo sea de la clase positiva. Generalmente, si es superior a $\tau = 0.5$
, significa que el ejemplo es de la clase positiva. Sin embargo, se puede jugar con este umbral $\tau$
.&lt;/p&gt;
&lt;p&gt;El ROC (Receiver Operating Characteristic) es une curva representando la performancia de un clasificador en varias situaciones y que se crea variando el umbral. Para varios valores de el umbra, se calcula la fraccion de verdaderos positivos de los positivos frente a la fraccion de falsos positivos de los negativos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/ROC.png&#34; alt=&#34;ROC&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El Area Under Curve (AUC) permite de obtener una unica valor representando la calidad de la curve. Mas grande significa mejor.&lt;/p&gt;
&lt;h3 id=&#34;regresion&#34;&gt;Regresion&lt;/h3&gt;
&lt;p&gt;Para una regresion, se utilizan metricas que que evaluan las distancias, y si el modelo representa bien la varianza de los datos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Varios calculos de errores&lt;/li&gt;
&lt;li&gt;Coeficiente de determinacion $R^2$
 representa la proporcion de la varianza explicada&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tecnicas-de-evaluacion&#34;&gt;Tecnicas de evaluacion&lt;/h2&gt;
&lt;h3 id=&#34;validacion-cruzada-cross-validation&#34;&gt;Validacion Cruzada (Cross-Validation)&lt;/h3&gt;
&lt;p&gt;Para obtener una mejora estimacion de las performancias del modelo. Para estar seguro de testear sobre cada datos, se puede hacer $V$
 experiencias, cortando el dataset en $V$
 partes, entrenar sobre $V-1$
 y testear sobre $1$
. Es un tipo de bootstrapping con los datos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/cross-val_final.png&#34; alt=&#34;cross-val_final&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Eso sirve para obtener los hiperparametros optimum, antes de entrenar el model final sobre todos los datos, y estimar las performancias sobre el ensemble de test.&lt;/p&gt;
&lt;h3 id=&#34;conjuntos-de-validacion-y-prueba-holdout&#34;&gt;Conjuntos de validacion y prueba (Holdout)&lt;/h3&gt;
&lt;p&gt;Si es imposible de hacer una validacion cruzada (porque el entrenaimento es largo), se puede crear un set de entrenamiento, de validacion, y de test.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/train_val_test.png&#34; alt=&#34;train_val_test&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tamaño-de-la-particion&#34;&gt;Tamaño de la particion&lt;/h3&gt;
&lt;p&gt;Un modelo que es buena usando pocos datos es interesante porque a veces obtener etiquetas puede ser costozo. Generalmente las &lt;strong&gt;perfomancias son mas variables y mas bajas con pocos datos de entrenamiento&lt;/strong&gt;, pero la &lt;strong&gt;evaluacion es mas confiable con mas datos de test&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/learning_curve.png&#34; alt=&#34;learning_curve&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Intro Aprendizaje Supervisado</title>
      <link>http://localhost:1313/minerias/4_intro_sl/</link>
      <pubDate>Wed, 27 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/4_intro_sl/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_intro_slpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Intro_SL.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;Esta clase es bastante interesante ya que descubriran las bases del conocimiento utilizado para construir Machine Learning, Deep Learning e Inteligencia Artificial en general: Aprendizaje Supervisado!&lt;/p&gt;
&lt;p&gt;Se trata de un entorno sencillo en el que un &lt;strong&gt;modelo aprenderá sus propios parámetros utilizando ejemplos y etiquetas asociadas&lt;/strong&gt;. Revisaremos todos los conceptos importantes del aprendizaje supervisado, que son muy útiles para cualquiera que quiera trabajar como data scientist.&lt;/p&gt;
&lt;h2 id=&#34;generalidades&#34;&gt;Generalidades&lt;/h2&gt;
&lt;p&gt;El aprendizaje supervisado utiliza datos y etiquetas para aprender a un modelo a reconocer padrones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Es necesario de transformar los documentos en vectores, para poder hacer la optimizacion&lt;/li&gt;
&lt;li&gt;El modelo va a apprender sus parametros sobre un conjunto de entrenamiento&lt;/li&gt;
&lt;li&gt;El modelo entrenado puede ser usado para predicir la etiquetas de nuevos datos que nunca ha visto antes&lt;/li&gt;
&lt;li&gt;El documento puede ser cualquier dato: audio, texto, imagen, video, usuario, red,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-aprendizaje-de-maquinas-predictivo-supervisado-sigue-eso&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;predictive_modeling_data_flow&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/predictive_modeling_data_flow_hu12315308385899460389.webp 400w,
               /minerias/4_intro_sl/figures/predictive_modeling_data_flow_hu9011300678791282958.webp 760w,
               /minerias/4_intro_sl/figures/predictive_modeling_data_flow_hu8943212305677280315.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/predictive_modeling_data_flow_hu12315308385899460389.webp&#34;
               width=&#34;760&#34;
               height=&#34;549&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El aprendizaje de maquinas predictivo supervisado sigue eso
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;features-y-etiquetas&#34;&gt;Features y etiquetas&lt;/h3&gt;
&lt;p&gt;Se puede representar en un espacio los documentos como vectores. Aca cada punto es una cancion, que esta representando con su intensidad y tempo promedios. La etiqueta es la color del punto. Aca tenemos una tarea de &lt;strong&gt;clasificacion binaria de musica&lt;/strong&gt;, segundo las preferencias de un usuario.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-para-las-tareas-de-clasificaciones-los-ejemplos-se-representan-como-puntos-en-un-espacio-de-dimension-de-las-observaciones-y-una-color-o-forma-para-representar-las-diferentes-clases&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;classif&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/classif_hu9702192758643128410.webp 400w,
               /minerias/4_intro_sl/figures/classif_hu1940178425719737447.webp 760w,
               /minerias/4_intro_sl/figures/classif_hu1255634141064509397.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/classif_hu9702192758643128410.webp&#34;
               width=&#34;760&#34;
               height=&#34;476&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Para las tareas de clasificaciones, los ejemplos se representan como puntos en un espacio de dimension de las observaciones, y una color o forma para representar las diferentes clases
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El objetivo del juego, va a ser de encontrar &lt;strong&gt;una funcion que separa el espacio en dos partes&lt;/strong&gt;. Una donde hay las canciones que le gustan a la persona, y la otra parte que no le gustan. De este manera, cuando vamos a tener un nuevo punto en este espacio, podemos decir si la persona va a gustar o no esta cancion, lo que sea &lt;strong&gt;predicir su etiqueta&lt;/strong&gt;!&lt;/p&gt;
&lt;h3 id=&#34;en-resumen&#34;&gt;En resumen&lt;/h3&gt;
&lt;p&gt;Se necesitan varias cosas para un entrenamiento&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Tener datos etiquetados&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Conjunto de datos de tamaño $n$
, $\mathcal{D}_n = \{(\text{Doc}_i, Y_i), i=1..n\}$
&lt;/li&gt;
&lt;li&gt;$\text{Doc}$ es una muestra (por ejemplo: una persona)&lt;/li&gt;
&lt;li&gt;$Y$ son las etiquetas (por ejemplo: monto del préstamo concedido)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Extraer los descriptores&lt;/strong&gt; = transformar documentos en vectores&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;$\mathbf{X}$ es un vector de observaciones (por ejemplo: edad, sexo, salario)&lt;/li&gt;
&lt;li&gt;$Y$ son las etiquetas (por ejemplo: monto del préstamo concedido)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Crear un modelo matemático $f_\theta$&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Modelo $f_\theta$ tal que  $f_\theta(\mathbf{X})$
 esté cerca de $Y$ (para regresión)&lt;/li&gt;
&lt;li&gt;$\theta$ es el conjunto de parámetros del modelo matemático&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Implementar una función de costo (error) $\ell$
 a minimizar&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Cuanto más se equivoque el modelo, mayor será el costo&lt;/li&gt;
&lt;li&gt;En general, se desea tener un costo pequeño&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;Encontrar los parámetros  $\theta^*$ 
 de manera que  $\ell(f_{\theta^*}(\mathbf{X}_i), Y_i)$ 
 sea pequeño&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
$$\theta^* = \underset{\theta}{\arg\min}\sum_{i}\ell(f_{\theta}(\mathbf{X}_i), Y_i)$$&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;&lt;strong&gt;Probar $f_{\theta^*}$
 en nuevos datos con una métrica de evaluación adecuada&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;aprendizaje&#34;&gt;Aprendizaje&lt;/h2&gt;
&lt;p&gt;Hay varios conceptos en el aprendizaje:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Datos etiquetados&lt;/strong&gt;: Regresión o Clasificación&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Extracción de características&lt;/strong&gt;: Tono, Intensidad, Tempo o Edad, Salario, Género, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modelo $f_\theta$&lt;/strong&gt;: SVM, Regresión Logística, Bosque Aleatorio, CNN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Función de costo&lt;/strong&gt; a optimizar: Pérdida de Bisagra, Pérdida de Entropía Cruzada, Pérdida Logística, Pérdida Cuadrada, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Algoritmo de optimización&lt;/strong&gt;: Adam, SGD, BFGS, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Métrica de evaluación&lt;/strong&gt;: Recall, Precisión, Mínimos Cuadrados, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;funcion-de-costo&#34;&gt;Funcion de costo&lt;/h3&gt;
&lt;p&gt;Para cuantificar las errores del modelo en la optimizacion, se necesita una funcion de costo que llamamos  $\ell$ 
. Ella representa si el modelo esta dando las buenas respuestas $y$
 segundo una entrada $X$
. Este funcion penaliza el modelo cuando comete errores, y lo que queremos hacer es optimizar los pesos del modelo, para obtener una valor minimum de este costo, lo que significaria menos errores, entonces mejor modelo.&lt;/p&gt;
&lt;p&gt;Hay que minimizar esta función sobre el conjunto de entrenamiento (riesgo empírico) para encontrar parámetros del modelo satisfactorios:&lt;/p&gt;
$$ f_{\hat{\theta}} =\underset{f_\theta, \theta \in \Theta}{\arg\min} \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$$&lt;p&gt;Los parametros van a cambiar para tener un valor minimum de costo:
















&lt;figure  id=&#34;figure-los-pesos-cambian-poco-a-poco-para-llegar-a-los-que-van-a-dar-un-valor-de-costo-minimum-sobre-el-ensemble-de-entrenamiento&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;convergence_algo_optim&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu3361748985186866440.webp 400w,
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu3884812293168319734.webp 760w,
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu2615079541688126126.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/convergence_algo_optim_hu3361748985186866440.webp&#34;
               width=&#34;566&#34;
               height=&#34;572&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los pesos cambian poco a poco para llegar a los que van a dar un valor de costo minimum sobre el ensemble de entrenamiento
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;La funcion de costo expresa el error desde una perspectiva &lt;strong&gt;numérica&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Transmite al algoritmo de aprendizaje lo que es importante y tiene sentido para la tarea&lt;/li&gt;
&lt;li&gt;Debe ser una función que se pueda optimizar eficientemente (convexa). &lt;strong&gt;La función  $\ell^{0/1} = \mathbf{1}_{f(\mathbf{X}) = Y}$ 
 no es utilizable&lt;/strong&gt; (ni siquiera continua).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;complejidad-de-los-modelos-y-sobresoto-aprendizaje&#34;&gt;Complejidad de los modelos y sobre/soto-aprendizaje&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt; $\mathcal{F} = \{ f: \text{ funciones medibles } \mathcal{X} \text{&amp;rarr;} \mathcal{Y}\}$ 
&lt;/li&gt;
&lt;li&gt;Mejor solución  $f^* = \arg\min_{f \in \mathcal{F}}\mathcal{R}(f)$ 
&lt;/li&gt;
&lt;li&gt;Clase de funciones  $\mathcal{S} \subset \mathcal{F}$ 
 utilizadas como modelos&lt;/li&gt;
&lt;li&gt;Objetivo ideal en $\mathcal{S}$:  $f^*_\mathcal{S} = \arg\min_{f \in \mathcal{S}}\mathcal{R}(f)$ 
&lt;/li&gt;
&lt;li&gt;Estimación obtenida en  $\mathcal{S}$ 
: se obtiene  $f_\mathcal{S}$ 
 tras un entrenamiento&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se pueden encontrar dos maneras de no tener el riesgo minimum optimum:&lt;/p&gt;
$$ \mathcal{R}(\hat{f_\mathcal{S}}) - \mathcal{R}(f^*) = \textcolor{red}{\underbrace{ \mathcal{R}(f_\mathcal{S}^*) - \mathcal{R}(f^*) }_{\text{error de aproximacion}}} +  \textcolor{blue}{\underbrace{ \mathcal{R}(\hat{f_\mathcal{S}}) - \mathcal{R}(f_\mathcal{S}^*) }_{\text{error de estimacion}}}$$&lt;p&gt;















&lt;figure  id=&#34;figure-los-2-tipos-de-errores-el-error-de-aproximacion-viene-de-la-eleccion-de-los-modelos-que-se-utilizan-y-el-error-de-estimacion-viene-de-un-mal-entrenamiento-del-modelo&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;approx_estim_errors&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/approx_estim_errors_hu1287908794753332032.webp 400w,
               /minerias/4_intro_sl/figures/approx_estim_errors_hu13343448165022106133.webp 760w,
               /minerias/4_intro_sl/figures/approx_estim_errors_hu4804674474612499519.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/approx_estim_errors_hu1287908794753332032.webp&#34;
               width=&#34;508&#34;
               height=&#34;435&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los 2 tipos de errores: el error de aproximacion viene de la eleccion de los modelos que se utilizan, y el error de estimacion viene de un mal entrenamiento del modelo
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El error de aproximación puede ser grande si el modelo $\mathcal{S}$ no es adaptado, y el error de estimación puede ser grande si el modelo es complejo.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-un-ejemplo-simple-seria-un-polinomio-de-grado-p-que-quiere-estimar-un-polinomio-de-grado-n-con-ruido-si-p-es-mas-grande-o-mas-pequeno-que-n-no-es-adaptado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;underfitting&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/ex_over-underfitting_hu10525897534329112004.webp 400w,
               /minerias/4_intro_sl/figures/ex_over-underfitting_hu2460076892096630892.webp 760w,
               /minerias/4_intro_sl/figures/ex_over-underfitting_hu9118631690023105709.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/ex_over-underfitting_hu10525897534329112004.webp&#34;
               width=&#34;760&#34;
               height=&#34;264&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un ejemplo simple seria un polinomio de grado P que quiere estimar un polinomio de grado N con ruido. Si P es mas grande o mas pequeno que N, no es adaptado.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Soto-aprentizaje&lt;/strong&gt;: Si no hay demasiado parametros, es imposible de estimar bien la curva,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sobre-aprentizaje&lt;/strong&gt;: Si hay demasiado parametros va a enfocar en memorizar el ruido del ensemble de entrenamiento&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;regularizacion-y-parsimonia&#34;&gt;Regularizacion y parsimonia&lt;/h3&gt;
&lt;p&gt;Una solucion para combatir el problema de no generalizacion es la regularizacion, que permite de agregar una penalización en relación con la complejidad del modelo:&lt;/p&gt;

$$\arg\min_{f_\theta, \theta \in \Theta} \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) ) + pen(\theta)$$


&lt;p&gt;Hay varias posibilidades de penalizacion, generalmente se usa la norma de los pesos del modelo. La intuicion detras de eso es que disminuir la norma del modelo o su número de coeficientes, número de ramas del grafo (poda).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AIC:

$pen(\theta) = \lambda ||\theta||_0$


&lt;em&gt;(no convexa, parsimoniosa, poco utilizada)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Ridge:

$pen(\theta) = \lambda ||\theta||_2$ 


&lt;em&gt;(convexa, no parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Lasso:

$pen(\theta) = \lambda ||\theta||_1$ 


&lt;em&gt;(convexa, parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Elastic Net:

$pen(\theta) = \lambda_1 ||\theta||_1 + \lambda_2 ||\theta||_2$


&lt;em&gt;(convexa, parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El  $\lambda$ 
 es un nuevo hiperparametro del modelo.&lt;/p&gt;
&lt;p&gt;El lasso induce la parcimonia. Aca se pueden ver para  $n=\{0,1,2\}$ 
, las bolas  $$\mathcal{B}^n = \{x / x \in \mathbb{R}^d \text{ and } ||x||_n &lt; 1\}$$ 
:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;norms&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/norms_hu13040269207447033896.webp 400w,
               /minerias/4_intro_sl/figures/norms_hu2484826675081491891.webp 760w,
               /minerias/4_intro_sl/figures/norms_hu549636321832970956.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/norms_hu13040269207447033896.webp&#34;
               width=&#34;760&#34;
               height=&#34;319&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En dimensiones grandes, la mayoría de  $\mathcal{B}^1$ 
 se concentra en los ejes: &lt;strong&gt;esto equivale a tener valores nulos para otros ejes&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Sparsityl1&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/Sparsityl1_hu15118340912051855990.webp 400w,
               /minerias/4_intro_sl/figures/Sparsityl1_hu2311885472990105800.webp 760w,
               /minerias/4_intro_sl/figures/Sparsityl1_hu6053000379869258004.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/Sparsityl1_hu15118340912051855990.webp&#34;
               width=&#34;760&#34;
               height=&#34;308&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;optimizacion-loss-landscape&#34;&gt;Optimizacion, &lt;em&gt;loss landscape&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;La optimizacion de la funcion de costo sobre el ensemble de entrenamiento ( $ \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$ 
) se puede hacer de manera analitica en casos simples, o de manera iterativa. La fase de optimizacion va a &lt;strong&gt;hacer converger los parametros&lt;/strong&gt; para encontrar los que van a dar un &lt;strong&gt;costo minimum en el conjunto de datos de entrenamiento&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;convergence_algo_optim&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu3361748985186866440.webp 400w,
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu3884812293168319734.webp 760w,
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu2615079541688126126.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/convergence_algo_optim_hu3361748985186866440.webp&#34;
               width=&#34;566&#34;
               height=&#34;572&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En este ejemplo se puede ver los parametros $a,b$
 del modelo  $y = a\mathbf{X}+b$ 
 cambiar por cada iteracion, para tener un valor del error (sse; suma residual de cuadrados) que esta diminuando:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;regression_gif&#34;
           src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/regression_gif.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Porque la valor del costo empirico  $ \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$ 
 es un nombre real positivo, podemos representarlo en un eje, y los parametros con unos otros ejes. Eso se llama el &lt;em&gt;loss landscape&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-loss-landscape-parece-a-un-paisaje-con-desnivel-con-el-objetivo-de-encontrar-el-lugar-con-menos-altura&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;LossAlps&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/LossAlps_hu15806339177112344745.webp 400w,
               /minerias/4_intro_sl/figures/LossAlps_hu9473298813042643160.webp 760w,
               /minerias/4_intro_sl/figures/LossAlps_hu7762387643821809596.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/LossAlps_hu15806339177112344745.webp&#34;
               width=&#34;760&#34;
               height=&#34;498&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La &lt;em&gt;loss landscape&lt;/em&gt; parece a un paisaje con desnivel, con el objetivo de encontrar el lugar con menos altura.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El objetivo del algoritmo de optimizacion es de encontrar la &amp;ldquo;ruta&amp;rdquo; para conducir en una &amp;ldquo;valle&amp;rdquo;, que representa un minimum local o global. Este ollo significa que los parametros sean los que dan un error pequeña.&lt;/p&gt;
&lt;h3 id=&#34;gradiente-descendiente&#34;&gt;Gradiente descendiente&lt;/h3&gt;
&lt;p&gt;El gradiente de una función  $\nabla_xf(x)=(\frac{\partial f}{\partial x_i})_{i=1..n}$ 
 es su derivativa según cada dimensión. Es una &lt;strong&gt;aproximación lineal de la función al nivel local&lt;/strong&gt;. Este indica la direccion donde aumenta una funcion:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;gradient_curve1D&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/gradient_curve1D_hu10032121186573210922.webp 400w,
               /minerias/4_intro_sl/figures/gradient_curve1D_hu12987032236723031820.webp 760w,
               /minerias/4_intro_sl/figures/gradient_curve1D_hu8038234561045909677.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/gradient_curve1D_hu10032121186573210922.webp&#34;
               width=&#34;760&#34;
               height=&#34;415&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Por eso, se puede utilizar el gradiente de la funccion de costo para minimizar el costo. Después de cada cálculo de la función de costo  $\ell(Y_i, f_\theta(\mathbf{X}_i) ; \theta)$ 
, se calcula el gradiente de esta función para actualizar los parámetros $\theta$
:&lt;/p&gt;
$$	\theta \leftarrow \theta - \alpha*\nabla_\theta \ell(Y_i, f_\theta(\mathbf{X}_i) ; \theta)$$&lt;p&gt;La tasa de aprendizaje  $\alpha$ 
 en la ecuacion precedente representa la cantidad de acutalizacion de los parametros. Es importante porque va a influir sobre la convergencia.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-tasa-de-aprendizaje-es-crucial-para-el-exito-de-la-fase-de-entrenamiento&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;learningrates&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/learningrates_hu14981630448780851733.webp 400w,
               /minerias/4_intro_sl/figures/learningrates_hu5823504888508698054.webp 760w,
               /minerias/4_intro_sl/figures/learningrates_hu11541866586040789986.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/learningrates_hu14981630448780851733.webp&#34;
               width=&#34;459&#34;
               height=&#34;414&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La tasa de aprendizaje es crucial para el exito de la fase de entrenamiento.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En en &lt;em&gt;loss landscape&lt;/em&gt;, se puede representar el modelo durante la optimizacion como un vector moviendo en cada iteracion. Con este vision, la tasa de aprendizaje define mas o menos la &amp;ldquo;velocidad&amp;rdquo; de como se mueve este punto. Por eso, es simple de entender que a veces tiene que ser mas grande y otra veces mas pequeño, por ejemplo para pasar topografias particular del &lt;em&gt;landscape&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Hay varios algoritmos de tipo gradiente descendiente para converger, con una mejora aproximacion de la tasa de aprendizaje, o la utilizacion de un momentum para ayudar el modelo
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;OtherOptimizers&#34;
           src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/OtherOptimizers.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;metricas&#34;&gt;Metricas&lt;/h2&gt;
&lt;h3 id=&#34;tipos-de-errores&#34;&gt;Tipos de errores&lt;/h3&gt;
&lt;p&gt;Un clasificador binario debe detectar un evento. A cada prediccion puede tener una prediciccion verdadera o falsa: eso son los True/False Positives/Negatives: True Positive (TP), False Postiive (FP), False Negative (FN), True Negative (TN). Se pueden encontrar dos tipos de errores:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;error&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/error_types_hu818360641458426582.webp 400w,
               /minerias/4_intro_sl/figures/error_types_hu1763655108969077203.webp 760w,
               /minerias/4_intro_sl/figures/error_types_hu8812666687817491822.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/error_types_hu818360641458426582.webp&#34;
               width=&#34;760&#34;
               height=&#34;573&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Con eso se puede crear una matriz de confusion.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-matriz-de-confusion-tiene-las-etiquetas-en-un-eje-y-las-predicciones-en-el-otro-se-puede-representar-los-truefalse-postivenegative&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;confusion_matrix&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/confusion_matrix_hu17666632291397020102.webp 400w,
               /minerias/4_intro_sl/figures/confusion_matrix_hu6029062098124639712.webp 760w,
               /minerias/4_intro_sl/figures/confusion_matrix_hu4969514950180408067.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/confusion_matrix_hu17666632291397020102.webp&#34;
               width=&#34;596&#34;
               height=&#34;415&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La matriz de confusion tiene las etiquetas en un eje, y las predicciones en el otro. Se puede representar los True/False Postive/Negative.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Las matrices de confusion pueden abarcar mas de 2 clases:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;confusion_matrix&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Se puede cada vez volver a una binaria:
















&lt;figure  id=&#34;figure-la-matriz-de-confusion-tiene-las-etiquetas-en-un-eje-y-las-predicciones-en-el-otro-una-matriz-diagonal-significa-predicciones-perfectas&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;conf_mat_multi&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/conf_mat_multi_hu1455269705468184231.webp 400w,
               /minerias/4_intro_sl/figures/conf_mat_multi_hu7808360544726272494.webp 760w,
               /minerias/4_intro_sl/figures/conf_mat_multi_hu8975441635701126753.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/conf_mat_multi_hu1455269705468184231.webp&#34;
               width=&#34;474&#34;
               height=&#34;250&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La matriz de confusion tiene las etiquetas en un eje, y las predicciones en el otro. Una matriz diagonal significa predicciones perfectas.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tipos-de-metricas-y-costo&#34;&gt;Tipos de metricas y costo&lt;/h3&gt;
&lt;p&gt;Usando los True/False Positives/Negatives, se puede calcular varias metricas segundo el tipo de applicacion. Tenemos: el accuracy al nivel general, y el recall, la precision y el F-score al nivel de las clases. Mas informacion &lt;a href=&#34;https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;por alla&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Cada tipo de error puede tener un costo differente segundo si es importante o no en la applicacion del sistema. Por eso se puede utilizar un matriz de costo, y calcular un costo global del sistema.&lt;/p&gt;
&lt;h3 id=&#34;aggregacion&#34;&gt;Aggregacion&lt;/h3&gt;
&lt;p&gt;Se puede agregar las metricas que son al nivel de clase para obtener un valor general:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Macro-averaging&lt;/strong&gt;: computar métrica para cada clase y luego promediar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Micro-averaging&lt;/strong&gt;: crear matriz de confusion binaria para cada clase, combinar las matrices y luego evaluar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weighted-averaging&lt;/strong&gt;: computar métrica para cada clase y luego promediar usando pesos segun el importancia de la clase (nombre de ejemplos)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a simple example in python obtained by the &lt;code&gt;sklearn.metrics.classification_report&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;class 0&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;class 1&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;class 2&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;              precision    recall  f1-score   support

     class 0       0.50      1.00      0.67         1
     class 1       0.00      0.00      0.00         1
     class 2       1.00      0.67      0.80         3

    accuracy                           0.60         5
   macro avg       0.50      0.56      0.49         5
weighted avg       0.70      0.60      0.61         5
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;roc--auc&#34;&gt;ROC &amp;amp; AUC&lt;/h3&gt;
&lt;p&gt;Al momento de la inferencia, nuestro clasificador binario va a dar una probabilidad que un ejemplo sea de la clase positiva. Generalmente, si es superior a $\tau = 0.5$
, significa que el ejemplo es de la clase positiva. Sin embargo, se puede jugar con este umbral $\tau$
.&lt;/p&gt;
&lt;p&gt;El ROC (Receiver Operating Characteristic) es une curva representando la performancia de un clasificador en varias situaciones y que se crea variando el umbral. Para varios valores de el umbra, se calcula la fraccion de verdaderos positivos de los positivos frente a la fraccion de falsos positivos de los negativos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;ROC&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/ROC_hu10607619452381477277.webp 400w,
               /minerias/4_intro_sl/figures/ROC_hu3908369485916332207.webp 760w,
               /minerias/4_intro_sl/figures/ROC_hu7705981326579221202.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/ROC_hu10607619452381477277.webp&#34;
               width=&#34;760&#34;
               height=&#34;491&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El Area Under Curve (AUC) permite de obtener una unica valor representando la calidad de la curve. Mas grande significa mejor.&lt;/p&gt;
&lt;h3 id=&#34;regresion&#34;&gt;Regresion&lt;/h3&gt;
&lt;p&gt;Para una regresion, se utilizan metricas que que evaluan las distancias, y si el modelo representa bien la varianza de los datos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Varios calculos de errores&lt;/li&gt;
&lt;li&gt;Coeficiente de determinacion $R^2$
 representa la proporcion de la varianza explicada&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tecnicas-de-evaluacion&#34;&gt;Tecnicas de evaluacion&lt;/h2&gt;
&lt;h3 id=&#34;validacion-cruzada-cross-validation&#34;&gt;Validacion Cruzada (Cross-Validation)&lt;/h3&gt;
&lt;p&gt;Para obtener una mejora estimacion de las performancias del modelo. Para estar seguro de testear sobre cada datos, se puede hacer $V$
 experiencias, cortando el dataset en $V$
 partes, entrenar sobre $V-1$
 y testear sobre $1$
. Es un tipo de bootstrapping con los datos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-separar-en-3-parte-y-hacer-3-entrenamiento-permite-de-hacer-el-test-sobre-todo-el-ensemble-y-tener-una-mejora-estimacion-de-las-performancias-del-modelo&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;cross-val_final&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/cross-val_final_hu16748371362900430386.webp 400w,
               /minerias/4_intro_sl/figures/cross-val_final_hu11491613420033986625.webp 760w,
               /minerias/4_intro_sl/figures/cross-val_final_hu4516641686194685870.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/cross-val_final_hu16748371362900430386.webp&#34;
               width=&#34;760&#34;
               height=&#34;212&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Separar en 3 parte, y hacer 3 entrenamiento permite de hacer el test sobre todo el ensemble y tener una mejora estimacion de las performancias del modelo.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Eso sirve para obtener los hiperparametros optimum, antes de entrenar el model final sobre todos los datos, y estimar las performancias sobre el ensemble de test.&lt;/p&gt;
&lt;h3 id=&#34;conjuntos-de-validacion-y-prueba-holdout&#34;&gt;Conjuntos de validacion y prueba (Holdout)&lt;/h3&gt;
&lt;p&gt;Si es imposible de hacer una validacion cruzada (porque el entrenaimento es largo), se puede crear un set de entrenamiento, de validacion, y de test.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-usar-un-ensemble-de-validacion-permite-de-encontrar-los-hiperparametros-sin-usar-el-test-y-sin-usar-de-validacion-cruzada&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;train_val_test&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/train_val_test_hu13319893936448070572.webp 400w,
               /minerias/4_intro_sl/figures/train_val_test_hu11490916923281978634.webp 760w,
               /minerias/4_intro_sl/figures/train_val_test_hu7094084863204531350.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/train_val_test_hu13319893936448070572.webp&#34;
               width=&#34;760&#34;
               height=&#34;279&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Usar un ensemble de validacion permite de encontrar los hiperparametros sin usar el test, y sin usar de validacion cruzada.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tamaño-de-la-particion&#34;&gt;Tamaño de la particion&lt;/h3&gt;
&lt;p&gt;Un modelo que es buena usando pocos datos es interesante porque a veces obtener etiquetas puede ser costozo. Generalmente las &lt;strong&gt;perfomancias son mas variables y mas bajas con pocos datos de entrenamiento&lt;/strong&gt;, pero la &lt;strong&gt;evaluacion es mas confiable con mas datos de test&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;learning_curve&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/learning_curve_hu14578813128231917822.webp 400w,
               /minerias/4_intro_sl/figures/learning_curve_hu7895650233809507061.webp 760w,
               /minerias/4_intro_sl/figures/learning_curve_hu16581810329368848848.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/learning_curve_hu14578813128231917822.webp&#34;
               width=&#34;760&#34;
               height=&#34;637&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Biases and Fairness</title>
      <link>http://localhost:1313/minerias/5_biases/</link>
      <pubDate>Tue, 26 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/5_biases/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_biasespdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Biases.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Modelos Lineales</title>
      <link>http://localhost:1313/minerias/6_modelos_lin/</link>
      <pubDate>Mon, 25 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/6_modelos_lin/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_modelos_linpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Modelos_Lin.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;Esta clase profundiza en los &lt;strong&gt;modelos de clasificación lineal&lt;/strong&gt;, mostrando cómo un &lt;strong&gt;hiperplano&lt;/strong&gt; puede separar ejemplos en un espacio de características. Además, se introduce la &lt;strong&gt;regresión lineal&lt;/strong&gt; como un caso particular de modelos lineales (cuando la variable a predecir es continua) y la regresión logística (para valores binarios o multi-clase). Finalmente, veremos una &lt;strong&gt;introducción al uso de scikit-learn&lt;/strong&gt;, la librería de Python muy popular para Machine Learning.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Puedes enfatizar en las propiedades de la linealidad, la noción de hiperplano, la forma de pasar a modelos más complejos con un truco de aumento del espacio, y rematar con ejemplos en scikit-learn. Invita a la discusión de por qué a veces preferimos estos modelos lineales frente a otros más complejos.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;modelos-de-clasificación&#34;&gt;Modelos de Clasificación&lt;/h2&gt;
&lt;h3 id=&#34;clasificador-lineal&#34;&gt;Clasificador lineal&lt;/h3&gt;
&lt;p&gt;El objetivo de un &lt;strong&gt;clasificador lineal&lt;/strong&gt; es separar el espacio de atributos con un &lt;strong&gt;hiperplano&lt;/strong&gt; de manera que queden los ejemplos de una clase a un lado y los de la(s) otra(s) clase(s) al otro lado.&lt;/p&gt;
&lt;h4 id=&#34;problemas-lineales-vs-no-lineales&#34;&gt;Problemas lineales vs. no lineales&lt;/h4&gt;
&lt;p&gt;En la práctica, muchas fronteras de decisión no son lineales. Sin embargo, &lt;strong&gt;aún podemos aplicar modelos lineales&lt;/strong&gt; si creamos características más elaboradas o hacemos transformaciones adecuadas.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplos-de-problemas-lineales-y-no-lineales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Clasificación lineal y no lineal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/linear_vs_nonlinear_problems_hu7353041200993864283.webp 400w,
               /minerias/6_modelos_lin/figures/linear_vs_nonlinear_problems_hu17403413559867806974.webp 760w,
               /minerias/6_modelos_lin/figures/linear_vs_nonlinear_problems_hu18016639814542214630.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/linear_vs_nonlinear_problems_hu7353041200993864283.webp&#34;
               width=&#34;709&#34;
               height=&#34;297&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplos de problemas lineales y no lineales
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Una función $f : \mathcal{X}\rightarrow \mathcal{Y}$
 es lineal si $f(\lambda \mathbf{x} + \mathbf{x}&#39;) = \lambda\,f(\mathbf{x}) + f(\mathbf{x}&#39;)$
.&lt;/li&gt;
&lt;li&gt;Un caso típico es $f(\mathbf{x}) = \theta^T \mathbf{x} = \sum_i \theta_i\,x_i$
.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;hiperplano-geometría&#34;&gt;Hiperplano (geometría)&lt;/h4&gt;
$$
w_1\,x_1 \;+\; w_2\,x_2 \;+\;\dots\;+\; w_d\,x_d \;+\; w_0 \;=\; 0.
$$&lt;p&gt;&lt;strong&gt;Interpretación&lt;/strong&gt;: el signo de $w_1 x_1 + \dots + w_d x_d + w_0$
 indica de qué lado del hiperplano se encuentra $\mathbf{x}$
.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-en-2d-es-una-recta-en-3d-es-un-plano&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representación de un hiperplano en 2D y 3D&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/affine_hu14528710492767468521.webp 400w,
               /minerias/6_modelos_lin/figures/affine_hu15839829693383708641.webp 760w,
               /minerias/6_modelos_lin/figures/affine_hu14583323748885349885.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/affine_hu14528710492767468521.webp&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      En 2D es una recta, en 3D es un plano
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Recordar que, en 2D, se llama recta; en 3D, se llama plano; y en más dimensiones, se sigue llamando hiperplano.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-normal-define-la-orientación-del-hiperplano&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representación del plano mediante la normal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/plan_normale_hu15260604472700012555.webp 400w,
               /minerias/6_modelos_lin/figures/plan_normale_hu6943290207337226051.webp 760w,
               /minerias/6_modelos_lin/figures/plan_normale_hu9804219792372522524.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/plan_normale_hu15260604472700012555.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La normal define la orientación del hiperplano
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En este diagrama vemos cómo la &lt;strong&gt;normal&lt;/strong&gt; ($\vec{n}$
) al hiperplano define su orientación. El término $w_0$
 (o sesgo) desplaza el plano.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;producto-escalar-y-parte-afín&#34;&gt;Producto escalar y parte afín&lt;/h4&gt;
&lt;p&gt;Si &lt;strong&gt;aumentamos el espacio&lt;/strong&gt; añadiendo un 1 a nuestro vector de características:
$
\mathbf{x} \;=\;
\begin{pmatrix}
x_1\\
\vdots\\
x_d\\
1
\end{pmatrix},\quad
\theta \;=\;
\begin{pmatrix}
\theta_1\\
\vdots\\
\theta_d\\
\theta_0
\end{pmatrix},
$

entonces $\theta^T \mathbf{x} = w_0 + \sum_i w_i\,x_i$
. Esto permite manejar en un mismo marco la parte “afín” del hiperplano.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representación general de un hiperplano afín&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/geom2D-plan_hu3378174178292732278.webp 400w,
               /minerias/6_modelos_lin/figures/geom2D-plan_hu1534089568248987208.webp 760w,
               /minerias/6_modelos_lin/figures/geom2D-plan_hu17731144349146713873.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/geom2D-plan_hu3378174178292732278.webp&#34;
               width=&#34;482&#34;
               height=&#34;243&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;resumen&#34;&gt;Resumen&lt;/h4&gt;
&lt;p&gt;El &lt;strong&gt;clasificador lineal&lt;/strong&gt; más sencillo se define como:&lt;/p&gt;
$$
f_{\mathbf{W}, b}(\mathbf{x}) \;=\;
\begin{cases}
+1, &amp; \text{si } (\mathbf{W}^T\,\mathbf{x} + b)\;\ge\;0, \\
-1, &amp; \text{en caso contrario}.
\end{cases}
$$&lt;p&gt;O, en problemas multiclase, usamos la misma idea (hiperplano para cada clase) y elegimos la que tenga la salida más alta (argmax).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-podemos-ver-la-separación-con-una-superficie-lineal-en-el-espacio-transformado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de separación lineal en 3D (SVM no lineal)&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/SVM_non_lin_3D_hu16934183206793690649.webp 400w,
               /minerias/6_modelos_lin/figures/SVM_non_lin_3D_hu12349553245862043253.webp 760w,
               /minerias/6_modelos_lin/figures/SVM_non_lin_3D_hu15825121860496258888.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/SVM_non_lin_3D_hu16934183206793690649.webp&#34;
               width=&#34;760&#34;
               height=&#34;703&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Podemos ver la separación con una superficie lineal en el espacio transformado.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Recalca cómo, si no es separable linealmente, podemos usar un truco de “features” que nos lleven a un espacio donde sí lo sea.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-aquí-el-hiperplano-es-una-simple-recta-2d&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Separando puntos con un hiperplano en 2D&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/linsep_new_hu14997818569280874164.webp 400w,
               /minerias/6_modelos_lin/figures/linsep_new_hu11636099713454292706.webp 760w,
               /minerias/6_modelos_lin/figures/linsep_new_hu16742827150983731599.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/linsep_new_hu14997818569280874164.webp&#34;
               width=&#34;760&#34;
               height=&#34;364&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Aquí el hiperplano es una simple recta 2D
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-un-hiperplano-en-d-dimensiones&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representación más genérica en un espacio N-dimensional&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/Linear_Classifier_space_hu15836063779108037436.webp 400w,
               /minerias/6_modelos_lin/figures/Linear_Classifier_space_hu7924874973121578882.webp 760w,
               /minerias/6_modelos_lin/figures/Linear_Classifier_space_hu4361361228696633468.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/Linear_Classifier_space_hu15836063779108037436.webp&#34;
               width=&#34;706&#34;
               height=&#34;518&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un hiperplano en d dimensiones
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;clasificador-lineal-multinomial&#34;&gt;Clasificador lineal multinomial&lt;/h3&gt;
&lt;p&gt;Para más de 2 clases, podemos tener una matriz $\mathbf{W}$
, donde cada fila corresponde a un posible “hiperplano” que da una puntuación a la clase. Luego:&lt;/p&gt;
$$
\hat{c}(\mathbf{x})
\;=\;
\arg\max_{c}\;\bigl(\mathbf{W}_c^T\,\mathbf{x} + b_c\bigr).
$$&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Clasificador lineal multiclase como operación matricial&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/Linear_Classification_hu12810854765152666704.webp 400w,
               /minerias/6_modelos_lin/figures/Linear_Classification_hu8176628540058915532.webp 760w,
               /minerias/6_modelos_lin/figures/Linear_Classification_hu11231406798243868969.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/Linear_Classification_hu12810854765152666704.webp&#34;
               width=&#34;760&#34;
               height=&#34;641&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: destacar que es una operación muy rápida, pues es un producto matriz-vector.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;integración-del-sesgo&#34;&gt;Integración del sesgo&lt;/h3&gt;
&lt;p&gt;En vez de $\mathbf{W}^T\mathbf{x} + b$
, se pasa a un producto escalar extendido:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-se-añade-el-1-al-vector-de-descriptores-y-el-bias-a-los-pesos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Bias Trick&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/Bias_Trick_hu7434524410363380459.webp 400w,
               /minerias/6_modelos_lin/figures/Bias_Trick_hu14795603539966083441.webp 760w,
               /minerias/6_modelos_lin/figures/Bias_Trick_hu3757125100915727117.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/Bias_Trick_hu7434524410363380459.webp&#34;
               width=&#34;760&#34;
               height=&#34;277&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Se añade el 1 al vector de descriptores y el bias a los pesos
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;aumento-del-espacio-para-no-linealidad&#34;&gt;Aumento del espacio para no linealidad&lt;/h3&gt;
&lt;p&gt;Se puede &lt;strong&gt;agregar variables no lineales&lt;/strong&gt; (por ejemplo $z = x^2 + y^2$
) para separar datos no linealmente separables en la dimensión original. La separación sigue siendo &lt;em&gt;lineal&lt;/em&gt; en el espacio de mayor dimensión.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;De 2D a 3D para volver lineal lo no lineal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/data_2d_to_3d_hu6940047956663229860.webp 400w,
               /minerias/6_modelos_lin/figures/data_2d_to_3d_hu8538703031235704932.webp 760w,
               /minerias/6_modelos_lin/figures/data_2d_to_3d_hu13469008302112689616.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/data_2d_to_3d_hu6940047956663229860.webp&#34;
               width=&#34;760&#34;
               height=&#34;355&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;regresión-lineal&#34;&gt;Regresión Lineal&lt;/h2&gt;
&lt;p&gt;La &lt;strong&gt;Regresión Lineal&lt;/strong&gt; es un modelo lineal para predecir una variable continua $y$
. En su forma más simple en 1D:&lt;/p&gt;
$$
\hat{y} \;=\; w\,x \;+\; b.
$$&lt;p&gt;O en multidimensional:&lt;/p&gt;
$$
\hat{y} \;=\; \mathbf{W}^T\,\mathbf{x} \;+\; b.
$$&lt;p&gt;















&lt;figure  id=&#34;figure-en-lugar-de-clasificar-en-un-lado-u-otro-medimos-distancias-a-la-línea&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Regresión lineal vs. clasificación lineal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/reg_lin_hu2428590659555122744.webp 400w,
               /minerias/6_modelos_lin/figures/reg_lin_hu1609359113409240423.webp 760w,
               /minerias/6_modelos_lin/figures/reg_lin_hu16163012276799070061.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/reg_lin_hu2428590659555122744.webp&#34;
               width=&#34;386&#34;
               height=&#34;266&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      En lugar de clasificar en un lado u otro, medimos distancias a la línea
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;métricas-en-regresión&#34;&gt;Métricas en regresión&lt;/h3&gt;
&lt;p&gt;Para estimar la calidad de la predicción:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Error Medio Absoluto: $\frac{1}{n}\sum \bigl|Y_i - f(\mathbf{X}_i)\bigr|$
&lt;/li&gt;
&lt;li&gt;Error Cuadrático Medio: $\frac{1}{n}\sum \bigl(Y_i - f(\mathbf{X}_i)\bigr)^2$
&lt;/li&gt;
&lt;li&gt;Coeficiente de determinación $R^2$
, que mide cuánta varianza de $Y$
 explica el modelo.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de error cuadrático para la regresión lineal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/reg_lineaire_loss_hu13269445812579728799.webp 400w,
               /minerias/6_modelos_lin/figures/reg_lineaire_loss_hu2278288848151013165.webp 760w,
               /minerias/6_modelos_lin/figures/reg_lineaire_loss_hu18217655019017418819.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/reg_lineaire_loss_hu13269445812579728799.webp&#34;
               width=&#34;640&#34;
               height=&#34;480&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Explica la interpretación de $R^2$
 como fracción de varianza explicada.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;regresión-de-un-plano-en-3d&#34;&gt;Regresión de un plano en 3D&lt;/h3&gt;
&lt;p&gt;Para dos atributos $x_1, x_2$
 y una salida $y$
:&lt;/p&gt;
$$
\hat{y} \;=\; w_1\,x_1 \;+\; w_2\,x_2 \;+\; b.
$$&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Un plano que ajusta los datos en 3D&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/reg_plane_hu11375769634492767005.webp 400w,
               /minerias/6_modelos_lin/figures/reg_plane_hu13355732907300323387.webp 760w,
               /minerias/6_modelos_lin/figures/reg_plane_hu17520921710119118135.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/reg_plane_hu11375769634492767005.webp&#34;
               width=&#34;697&#34;
               height=&#34;399&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;regresión-logística&#34;&gt;Regresión Logística&lt;/h2&gt;
&lt;p&gt;La &lt;strong&gt;regresión logística&lt;/strong&gt; (en su forma binaria) se utiliza para convertir una &lt;strong&gt;salida lineal&lt;/strong&gt; (o “distancia” en el espacio de características) en una &lt;strong&gt;probabilidad&lt;/strong&gt; entre 0 y 1. Además, en el caso &lt;strong&gt;multiclase&lt;/strong&gt;, se generaliza a la llamada &lt;strong&gt;función softmax&lt;/strong&gt;, la cual asigna una probabilidad a cada clase, de modo que la suma de todas las probabilidades es igual a 1.&lt;/p&gt;
&lt;h3 id=&#34;caso-binario&#34;&gt;Caso Binario&lt;/h3&gt;
&lt;p&gt;ara problemas de clasificación binaria, la &lt;strong&gt;regresión logística&lt;/strong&gt; aplica la función sigmoide o &lt;em&gt;softmax&lt;/em&gt; sobre la salida lineal. La idea principal es definir una &lt;strong&gt;función sigmoide&lt;/strong&gt; que proyecte cualquier valor real (la salida lineal $\mathbf{W}^T \mathbf{x} + b$
) a un rango de $]0, 1[$
:&lt;/p&gt;
$$
\sigma(z) \;=\;
\frac{1}{1 + e^{-z}}
$$&lt;ul&gt;
&lt;li&gt;Cuando $z \rightarrow +\infty$
, la sigmoide se acerca a 1.&lt;/li&gt;
&lt;li&gt;Cuando $z \rightarrow -\infty$
, la sigmoide se acerca a 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Función sigmoide&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/sigmo_hu14640827423314996410.webp 400w,
               /minerias/6_modelos_lin/figures/sigmo_hu14976402490176052729.webp 760w,
               /minerias/6_modelos_lin/figures/sigmo_hu4385362737546358557.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/sigmo_hu14640827423314996410.webp&#34;
               width=&#34;760&#34;
               height=&#34;497&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En &lt;strong&gt;regresión logística binaria&lt;/strong&gt; (dos clases), llamemos “1” a la clase positiva y “0” (o “-1”) a la negativa. Entonces la probabilidad de que un ejemplo $\mathbf{x}$
 sea de la clase positiva es:&lt;/p&gt;
$$
P(Y = 1 \;|\; \mathbf{x})
\;=\;
\sigma\bigl(\mathbf{W}^T\mathbf{x} + b\bigr)
\;=\;
\frac{1}{1 + e^{-(\mathbf{W}^T\mathbf{x} + b)}}.
$$&lt;p&gt;Por ende, $P(Y=0 \;|\; \mathbf{x}) = 1 - P(Y=1 \;|\; \mathbf{x})$
. Esto nos da una probabilidad. Para la clase final, elegimos la etiqueta según $P(Y=1) &gt; 0.5$
 (u otro umbral). En el caso binario equivale a comparar si la salida lineal es mayor o menor que 0:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Si $\mathbf{W}^T\mathbf{x} + b &gt; 0$
, predice “1”.&lt;/li&gt;
&lt;li&gt;Si $\mathbf{W}^T\mathbf{x} + b &lt; 0$
, predice “0” (o “-1”).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;conexión-distancia-probabilidad&#34;&gt;Conexión distancia-probabilidad&lt;/h4&gt;
&lt;p&gt;En modelos lineales clásicos (p.e., SVM), la salida $\mathbf{W}^T\mathbf{x} + b$
 indica una &lt;strong&gt;distancia&lt;/strong&gt; (o margen) respecto al hiperplano. Para convertir dicha cantidad en una &lt;strong&gt;probabilidad&lt;/strong&gt;, aplicamos la función sigmoide, que comprime valores reales (infinitos en ambos extremos) a un rango de 0 a 1.&lt;/p&gt;
&lt;h3 id=&#34;caso-multiclase-softmax&#34;&gt;Caso Multiclase: Softmax&lt;/h3&gt;
&lt;p&gt;Para &lt;strong&gt;$C$
 clases&lt;/strong&gt;, generalizamos la función logística a &lt;strong&gt;softmax&lt;/strong&gt;, asignando parámetros $\theta^{(1)}, \dots, \theta^{(C)}$
 (un vector por clase) y obteniendo probabilidades que suman 1:&lt;/p&gt;
$$
P(Y = c)
\;=\;
\frac{\exp^{&lt;\theta^{(c)} \mid \mathbf{X}&gt;}}
{\sum_{j=1}^{C}
\exp^{&lt;\theta^{(j)} \mid \mathbf{X}&gt;}}
\quad,\quad
c=1,\dots,C.
$$&lt;p&gt;donde:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\theta^{(c)}$
 son los parámetros asociados a la clase $c$
.&lt;/li&gt;
&lt;li&gt;La &lt;strong&gt;suma de probabilidades&lt;/strong&gt; sobre las $C$
 clases es igual a 1 (gracias al denominador).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La clase final se predice con la regla:&lt;/p&gt;
$$
\hat{c}(\mathbf{X})
\;=\;
\arg\max_{1 \le c \le C} 
\,P(Y=c).
$$&lt;p&gt;Es habitual agrupar todos los vectores $\theta^{(c)}$
 en una misma matriz:&lt;/p&gt;
$$
\theta \;=\;
\begin{pmatrix}
\vertbar &amp; \vertbar &amp; \cdots &amp; \vertbar \\
\theta^{(1)} &amp; \theta^{(2)} &amp; \dots &amp; \theta^{(C)} \\
\vertbar &amp; \vertbar &amp; \cdots &amp; \vertbar
\end{pmatrix}.
$$&lt;p&gt;&lt;em&gt;(Cada columna es un vector de parámetros para la clase correspondiente.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;uso-de-scikit-learn&#34;&gt;Uso de Scikit-learn&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;scikit-learn&lt;/strong&gt; (&lt;code&gt;sklearn&lt;/code&gt;) es una biblioteca de Python que nos permite entrenar y probar modelos de Machine Learning con funciones normalizadas.&lt;/p&gt;
&lt;h3 id=&#34;funciones-generales&#34;&gt;Funciones generales&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-se-separan-datos-se-entrena-y-se-valida&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Flujo típico de aprendizaje supervisado con sklearn&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/supervised_scikit_learn_hu17372726708710164390.webp 400w,
               /minerias/6_modelos_lin/figures/supervised_scikit_learn_hu13489451897173136613.webp 760w,
               /minerias/6_modelos_lin/figures/supervised_scikit_learn_hu5671300666085423450.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/supervised_scikit_learn_hu17372726708710164390.webp&#34;
               width=&#34;659&#34;
               height=&#34;484&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Se separan datos, se entrena y se valida
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En &lt;code&gt;sklearn&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;load_iris&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SGDClassifier&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;load_iris&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;n&#34;&gt;test_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SGDClassifier&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tol&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1e-3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;(Para el orador: Subraya la facilidad de implementación y las funciones de utilidad para preprocesar, hacer feature extraction, validación cruzada, etc.)&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;conjuntos-de-datos-extracción-de-características-y-preprocesamiento&#34;&gt;Conjuntos de datos, extracción de características y preprocesamiento&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Múltiples datasets de juguete: Iris, Digits, Wine, etc.&lt;/li&gt;
&lt;li&gt;Conjuntos más grandes: RCV1 (texto), Faces (imágenes), etc.&lt;/li&gt;
&lt;li&gt;Módulos como &lt;code&gt;feature_extraction&lt;/code&gt;, &lt;code&gt;feature_selection&lt;/code&gt;, &lt;code&gt;preprocessing&lt;/code&gt; para:&lt;/li&gt;
&lt;li&gt;Vectorizar texto
&lt;ul&gt;
&lt;li&gt;Seleccionar atributos relevantes&lt;/li&gt;
&lt;li&gt;Normalizar los datos&lt;/li&gt;
&lt;li&gt;Rellenar valores faltantes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Invita a explorar la documentación sklearn.org y mostrar un ejemplo interactivo si hay tiempo.)&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;validación-cruzada-y-búsqueda-de-hiperparámetros&#34;&gt;Validación cruzada y búsqueda de hiperparámetros&lt;/h3&gt;
&lt;p&gt;Incluye herramientas como:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;KFold&lt;/code&gt;, &lt;code&gt;StratifiedKFold&lt;/code&gt; para dividir los datos&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cross_val_score&lt;/code&gt; para evaluar un modelo en K particiones&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GridSearchCV&lt;/code&gt; o &lt;code&gt;RandomizedSearchCV&lt;/code&gt; para probar múltiples parámetros y hacer validación cruzada&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GridSearchCV&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parameters&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;kernel&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;rbf&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;C&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;svc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;svm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SVC&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gamma&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scale&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;svc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;(Para el orador: Resaltar la importancia de la validación cruzada para evitar sobreajustes y encontrar buenos hiperparámetros.)&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;conclusión&#34;&gt;Conclusión&lt;/h3&gt;
&lt;p&gt;En esta clase hemos visto:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cómo un clasificador lineal separa el espacio con un hiperplano.&lt;/li&gt;
&lt;li&gt;La regresión lineal como caso de modelo lineal para predicción de variables continuas.&lt;/li&gt;
&lt;li&gt;Cómo extender la linealidad introduciendo variables polinómicas o el truco del Bias.&lt;/li&gt;
&lt;li&gt;Un breve vistazo a la regresión logística, esencial para clasificación binaria y multi-clase con softmax.&lt;/li&gt;
&lt;li&gt;scikit-learn y sus funcionalidades para datasets, entrenamiento, validación y selección de hiperparámetros.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: concluye enfatizando que, aunque hay modelos más complejos como redes neuronales o ensembles, entender los modelos lineales es clave para la práctica de Machine Learning y la interpretación de resultados.)&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Mineria de Datos</title>
      <link>http://localhost:1313/teaching/minerias/</link>
      <pubDate>Sun, 24 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teaching/minerias/</guid>
      <description>&lt;h3 id=&#34;all-the-different-classes-can-be-found-hereminerias&#34;&gt;All the different classes can be found &lt;a href=&#34;../../minerias&#34;&gt;here&lt;/a&gt;!&lt;/h3&gt;
&lt;p&gt;This is the CC5205 course from the Universidad de Chile. I restructured it so that it is more adapted to nowadays techniques and more machine learning oriented, it is heavily based on &lt;a href=&#34;https://scikit-learn.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scikit&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a summary:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;General introduction&lt;/strong&gt;: Definitions of Data Mining, Data Science, and content of the class&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data I&lt;/strong&gt;: (Un)structured data, Representation, Normalization, Noise removal, &amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Data II&lt;/strong&gt;: Basic statistics for data exploration.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Intro to Supervised Learning&lt;/strong&gt;: Basics of Machine Learning and supervised learning.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Intro to Fairness and Biases&lt;/strong&gt;: How to avoid making bad models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linear Models&lt;/strong&gt;: A very simple model, which is the base of deep neural networks!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Classifiers&lt;/strong&gt;: KNN, Naive Bayes, Decision Tree, Boosting, Bagging, Random Forests.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Dimensionality Reduction&lt;/strong&gt;: Principal Component Analysis, Independant Component Analysis, t-SNE, UMAP,&amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Clustering methods&lt;/strong&gt;: Clustering methods and associated metrics&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SVM, SVR&lt;/strong&gt;: Hinge loss, Lagrangian, KKT conditions, non-linear SVM, Kernel trick, SV Regressor&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Introduction to Neural Nets&lt;/strong&gt;: Basics of Deep Learning&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Introduction to NLP&lt;/strong&gt; (Invited Speaker: Juan Jose Alegria): How to deal with natural language.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Regularization</title>
      <link>http://localhost:1313/deep/6_regularization/</link>
      <pubDate>Sun, 24 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/6_regularization/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides6_regularizationpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/6_Regularization.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Clasificadores</title>
      <link>http://localhost:1313/minerias/7_clasificadores/</link>
      <pubDate>Sat, 23 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/7_clasificadores/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_modelos_slpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Modelos_SL.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>SVM</title>
      <link>http://localhost:1313/minerias/8_svm/</link>
      <pubDate>Fri, 22 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/8_svm/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_svmpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_SVM.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;h2 id=&#34;máquinas-de-vectores-de-soporte-svm&#34;&gt;Máquinas de Vectores de Soporte (SVM)&lt;/h2&gt;
&lt;p&gt;Las &lt;strong&gt;Máquinas de Vectores de Soporte&lt;/strong&gt; son modelos de clasificación (o regresión) que buscan encontrar un &lt;strong&gt;hiperplano&lt;/strong&gt; o frontera de decisión que &lt;strong&gt;maximice el margen&lt;/strong&gt; entre las clases. A continuación, veremos sus conceptos clave, la formulación lineal, el uso de kernels y, finalmente, la extensión a la regresión (SVR).&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;separadores-de-gran-margen&#34;&gt;Separadores de Gran Margen&lt;/h3&gt;
&lt;p&gt;El objetivo de las SVM es encontrar un &lt;strong&gt;separador&lt;/strong&gt; (en dimensión \(d\), un hiperplano) que no solo divida correctamente las clases, sino que lo haga maximizando la distancia mínima con cualquier punto de entrenamiento.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-svm-que-logra-una-separación-no-lineal&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de frontera no lineal buscada por SVM&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_nonlin_hu10766200129307954814.webp 400w,
               /minerias/8_svm/figures/SVM_nonlin_hu940999748329515222.webp 760w,
               /minerias/8_svm/figures/SVM_nonlin_hu10800116435089468750.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_nonlin_hu10766200129307954814.webp&#34;
               width=&#34;760&#34;
               height=&#34;307&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      SVM que logra una separación no lineal
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En casos lineales y perfectamente separables, puede haber varios hiperplanos que distingan las clases. La pregunta es: &lt;strong&gt;¿Cuál elegir?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-dos-posibles-hiperplanos-separadores&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Distintos hiperplanos posibles&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_which_hyperplan2_hu6991979370543567446.webp 400w,
               /minerias/8_svm/figures/svm_which_hyperplan2_hu671267611003501627.webp 760w,
               /minerias/8_svm/figures/svm_which_hyperplan2_hu14002891887294419535.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_which_hyperplan2_hu6991979370543567446.webp&#34;
               width=&#34;478&#34;
               height=&#34;410&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Dos posibles hiperplanos separadores
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;La SVM opta por el que maximiza el margen, buscando así una mejor &lt;strong&gt;capacidad de generalización&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;clasificador-lineal-recordatorio&#34;&gt;Clasificador lineal: recordatorio&lt;/h3&gt;
&lt;p&gt;Un clasificador lineal en \(\mathbb{R}^d\) se define por:&lt;/p&gt;
\[
f(\mathbf{X}) = \mathrm{signo}(\mathbf{W}^\top \mathbf{X} + b).
\]&lt;p&gt;En la siguiente figura se ilustra una separación lineal (en 3D) que se proyecta a una separación curva al volver al espacio 2D:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-vista-en-3d-de-datos-originalmente-no-separables-linealmente&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Espacio 3D para separar datos no lineales&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_non_lin_3D_hu2697375277477187509.webp 400w,
               /minerias/8_svm/figures/SVM_non_lin_3D_hu14481105654133733525.webp 760w,
               /minerias/8_svm/figures/SVM_non_lin_3D_hu17332218457834828460.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_non_lin_3D_hu2697375277477187509.webp&#34;
               width=&#34;760&#34;
               height=&#34;703&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Vista en 3D de datos originalmente no separables linealmente
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;svm-lineal-márgenes-y-restricción-de-separabilidad&#34;&gt;SVM lineal: márgenes y restricción de separabilidad&lt;/h3&gt;
&lt;p&gt;El hiperplano \(\mathbf{W}^\top \mathbf{X} + b = 0\) y los planos paralelos \(\mathbf{W}^\top \mathbf{X} + b = \pm 1\) marcan el &lt;strong&gt;margen&lt;/strong&gt;. Cuanto mayor sea la distancia entre esos planos, mayor será la robustez.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-hiperplano-central-y-márgenes-en-1&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Márgenes alrededor del hiperplano&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_hu17965602084783293788.webp 400w,
               /minerias/8_svm/figures/SVM_hu114460994655993461.webp 760w,
               /minerias/8_svm/figures/SVM_hu14476676033574681305.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_hu17965602084783293788.webp&#34;
               width=&#34;760&#34;
               height=&#34;534&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Hiperplano central y márgenes en ±1
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Margen geométrico&lt;/strong&gt;:
Consideremos los planos de decisión \(\mathbf{W}^\top \mathbf{X} + b = \pm 1\). La distancia entre esos dos planos es:&lt;/p&gt;
\[
     \frac{2}{\|\mathbf{W}\|}.
   \]&lt;p&gt;Por ello, &lt;strong&gt;maximizar&lt;/strong&gt; esa distancia es &lt;strong&gt;equivalente&lt;/strong&gt; a &lt;strong&gt;minimizar&lt;/strong&gt; \(\|\mathbf{W}\|\).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Forma habitual en SVM&lt;/strong&gt;:&lt;br&gt;
Para comodidad numérica, se minimiza \(\tfrac{1}{2}\|\mathbf{W}\|^2\) en lugar de \(\|\mathbf{W}\|\), pero el criterio es el mismo.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Para datos &lt;strong&gt;(casi) separables&lt;/strong&gt;, la SVM busca:&lt;/p&gt;
\[
\begin{aligned}
&amp; \min_{\mathbf{W}, b} \quad \frac{1}{2}\|\mathbf{W}\|^2 \\
&amp; \text{sujeto a } \quad 
Y_i \, (\mathbf{W}^\top \mathbf{X}_i + b)\; \ge 1,\quad \forall i.
\end{aligned}
\]&lt;p&gt;En suma, la restricción \(Y_i(\mathbf{W}^\top \mathbf{X}_i + b)\ge 1\) asegura que cada punto esté al menos a distancia \(1/\|\mathbf{W}\|\) del hiperplano, y al reducir \(\|\mathbf{W}\|\) aumentamos este margen.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;formulación-primal-y-dual&#34;&gt;Formulación primal y dual&lt;/h3&gt;
&lt;p&gt;Los problemas primal y dual son equivalentes en entornos convexos.&lt;/p&gt;
&lt;p&gt;El problema Primal:&lt;/p&gt;
\[
\begin{aligned}
&amp;\min \quad z = c^t x, \\
&amp;\text{subject to} \quad A x \ge b, \\
&amp;\qquad\quad\;\; x \ge 0.
\end{aligned}
\]&lt;p&gt;El problema Dual:&lt;/p&gt;
\[
\begin{aligned}
&amp;\max \quad z = b^t y, \\
&amp;\text{subject to} \quad A^t y \le c, \\
&amp;\qquad\quad\;\; y \ge 0,
\end{aligned}
\]&lt;p&gt;En la práctica se implementan algoritmos para el &lt;strong&gt;problema dual&lt;/strong&gt;, sobre todo cuando se utilizan kernels.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-un-problema-primal&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Interpretación visual primal-dual (izq/primal, der/dual)&#34; srcset=&#34;
               /minerias/8_svm/figures/primal_hu5214921791707174292.webp 400w,
               /minerias/8_svm/figures/primal_hu6218951539569108450.webp 760w,
               /minerias/8_svm/figures/primal_hu6179495431827664383.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/primal_hu5214921791707174292.webp&#34;
               width=&#34;581&#34;
               height=&#34;480&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un problema Primal
    &lt;/figcaption&gt;&lt;/figure&gt;
 















&lt;figure  id=&#34;figure-un-problema-dual&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Interpretación visual primal-dual (izq/primal, der/dual)&#34; srcset=&#34;
               /minerias/8_svm/figures/dual_hu9024437098989026950.webp 400w,
               /minerias/8_svm/figures/dual_hu11370458516146254517.webp 760w,
               /minerias/8_svm/figures/dual_hu15067324994502624637.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/dual_hu9024437098989026950.webp&#34;
               width=&#34;581&#34;
               height=&#34;480&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un problema Dual
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Para resolverlo, se introduce el &lt;strong&gt;Lagrangiano&lt;/strong&gt; y se pasa a la &lt;strong&gt;formulación dual&lt;/strong&gt;. De este modo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Primal&lt;/strong&gt;: parámetros \(\mathbf{W}, b\).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dual&lt;/strong&gt;: multiplicadores \(\alpha_i\).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;introducción-del-lagrangiano-y-condiciones-kkt&#34;&gt;Introducción del Lagrangiano y condiciones KKT&lt;/h3&gt;
\[
\min_{\mathbf{W},b} \quad \frac{1}{2}\|\mathbf{W}\|^2 
\quad\text{sujeto a}\quad Y_i(\mathbf{W}^\top\mathbf{X}_i + b)\;\ge\;1,
\]&lt;p&gt;
se introduce el &lt;strong&gt;Lagrangiano&lt;/strong&gt;:&lt;/p&gt;
\[
\mathcal{L}(\mathbf{W}, b, \boldsymbol{\alpha}) 
\;=\; \tfrac{1}{2}\|\mathbf{W}\|^2 
\;-\; \sum_{i=1}^n \alpha_i \,\bigl(Y_i(\mathbf{W}^\top \mathbf{X}_i + b) - 1\bigr),
\]&lt;p&gt;
donde \(\alpha_i \ge 0\) son los &lt;strong&gt;multiplicadores de Lagrange&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Las &lt;strong&gt;Condiciones de Karush-Kuhn-Tucker (KKT)&lt;/strong&gt; aplicadas a este problema especifican, entre otras, que:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\(\nabla_{\mathbf{W}} \,\mathcal{L} = 0\) y \(\nabla_b \,\mathcal{L} = 0\) (estacionaridad).&lt;/li&gt;
&lt;li&gt;\(\alpha_i \ge 0\).&lt;/li&gt;
&lt;li&gt;\(\alpha_i \,\bigl[Y_i(\mathbf{W}^\top \mathbf{X}_i + b)-1\bigr] = 0\) (complementariedad):&lt;br&gt;
esto implica que para cada \(i\), o bien la restricción se cumple con margen (estricto) o \(\alpha_i=0\).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;resolviendo-el-problema-dual-y-aparición-de-alpha_i&#34;&gt;Resolviendo el problema Dual y aparición de \(\alpha_i\)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Construcción del Dual&lt;/strong&gt;:&lt;br&gt;
Se reemplaza \(\|\mathbf{W}\|^2\) y se resuelve en función de \(\boldsymbol{\alpha}\). El &lt;strong&gt;problema dual&lt;/strong&gt; pasa a ser:
\[
   \begin{aligned}
   &amp;\max_{\boldsymbol{\alpha}} \quad 
     \sum_{i=1}^n \alpha_i \;-\; \tfrac{1}{2}\sum_{i,j} \alpha_i \alpha_j \,Y_i Y_j \,\langle \mathbf{X}_i,\mathbf{X}_j\rangle,\\
   &amp;\text{sujeto a}\quad \alpha_i \ge 0,\;\; \sum_{i=1}^n \alpha_i Y_i = 0.
   \end{aligned}
   \]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Solución para \(\mathbf{W}\)&lt;/strong&gt;:&lt;br&gt;
De las KKT, se deduce que
\[
     \mathbf{W} \;=\; \sum_{i=1}^n \alpha_i \,Y_i \,\mathbf{X}_i.
   \]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clasificador&lt;/strong&gt;:&lt;br&gt;
\[
     f(\mathbf{X}) \;=\; \mathrm{signo}\!\Bigl(\sum_{i=1}^n \alpha_i\,Y_i\,\langle\mathbf{X}_i,\mathbf{X}\rangle + b \Bigr).
   \]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Notar que en este punto aún &lt;strong&gt;no&lt;/strong&gt; hemos introducido el concepto de &lt;strong&gt;soft margin&lt;/strong&gt;. Cuando todos los datos son separables y no hay ruido, cada punto cumple la restricción sin violarla. Una vez introducidos errores o ruido, pasaremos a la versión &lt;em&gt;soft margin&lt;/em&gt;.
mal-dual (izq/primal, der/dual)](figures/dual.png &amp;ldquo;Un problema Dual&amp;rdquo;)&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;vectores-de-soporte&#34;&gt;Vectores de Soporte&lt;/h3&gt;
\[
\mathbf{W} = \sum_{i=1}^{n} \alpha_i \, Y_i \, \mathbf{X}_i
\]\[
f(\mathbf{X}) = \mathrm{signo}\!\Big(\sum_{i=1}^{n} \alpha_i \,Y_i\;\langle \mathbf{X}_i,\mathbf{X}\rangle + b\Big).
\]&lt;p&gt;Solo los puntos con \(\alpha_i \neq 0\) se llaman &lt;strong&gt;vectores de soporte&lt;/strong&gt;, aquellos que “soportan” el margen.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-vectores-de-soporte-definen-el-hiperplano-final&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Puntos soportando el margen&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_support_hu9573517152434623081.webp 400w,
               /minerias/8_svm/figures/svm_support_hu3030785379930506308.webp 760w,
               /minerias/8_svm/figures/svm_support_hu13275145611349553827.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_support_hu9573517152434623081.webp&#34;
               width=&#34;760&#34;
               height=&#34;667&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los vectores de soporte definen el hiperplano final
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;soft-margin-y-ruido&#34;&gt;Soft margin y ruido&lt;/h3&gt;
&lt;p&gt;Cuando hay ruido, el plan optimal no es necesariamente el mejor:
















&lt;figure  id=&#34;figure-ejemplo-de-hiperplanos-con-ruido-y-errores&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo con ruido; margen distinto según C&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_bruit_hu15490994747521239547.webp 400w,
               /minerias/8_svm/figures/SVM_bruit_hu9950590124400274101.webp 760w,
               /minerias/8_svm/figures/SVM_bruit_hu4310381433717407342.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_bruit_hu15490994747521239547.webp&#34;
               width=&#34;760&#34;
               height=&#34;641&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo de hiperplanos con ruido y errores
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Cuando los datos no son perfectamente separables (o hay ruido), se permiten &lt;strong&gt;variables de holgura&lt;/strong&gt; \(\xi_i \ge 0\). Esto penaliza los errores o los puntos dentro del margen:&lt;/p&gt;
\[
\begin{aligned}
&amp; \min_{\mathbf{W},b} \quad \frac{1}{2}\|\mathbf{W}\|^2 + C \sum_{i}\xi_i \\
&amp; \text{sujeto a} \quad Y_i(\mathbf{W}^\top \mathbf{X}_i + b) \ge 1 - \xi_i,\quad \xi_i \ge 0.
\end{aligned}
\]&lt;p&gt;















&lt;figure  id=&#34;figure-las-variables-de-holgura-permiten-el-ruido-en-los-datos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Epsilon&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_non_lin_hu8821990965519421223.webp 400w,
               /minerias/8_svm/figures/SVM_non_lin_hu13426229250700642069.webp 760w,
               /minerias/8_svm/figures/SVM_non_lin_hu5029092690650428657.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_non_lin_hu8821990965519421223.webp&#34;
               width=&#34;356&#34;
               height=&#34;335&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Las variables de holgura permiten el ruido en los datos.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El parámetro \(C\) balancea la &lt;strong&gt;complejidad&lt;/strong&gt; vs. el &lt;strong&gt;número de errores&lt;/strong&gt;, y es un parametro de regularizacion.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;resolución-dual-con-kkt&#34;&gt;Resolución Dual con KKT&lt;/h4&gt;
&lt;p&gt;Tras introducir variables de holgura \(\xi_i \ge 0\), la &lt;strong&gt;formulación primal&lt;/strong&gt; se convierte en:&lt;/p&gt;
\[
\begin{aligned}
&amp; \min_{\mathbf{W}, b, \{\xi_i\}} \quad 
   \frac{1}{2}\|\mathbf{W}\|^2 + C\sum_{i=1}^n \xi_i, \\
&amp; \text{sujeto a} \quad
   Y_i(\mathbf{W}^\top\mathbf{X}_i + b)\;\ge\;1 - \xi_i,\quad \xi_i \ge 0.
\end{aligned}
\]&lt;p&gt;En el &lt;strong&gt;Lagrangiano&lt;/strong&gt;, aparecen ahora multiplicadores \(\alpha_i\) y \(\mu_i\) para manejar las restricciones asociadas a \(\xi_i\). Se obtienen condiciones KKT adicionales, incluyendo&lt;/p&gt;
\[
\alpha_i \,\bigl[Y_i(\mathbf{W}^\top\mathbf{X}_i + b)-1+\xi_i\bigr] \;=\; 0,\quad
\mu_i\,\xi_i \;=\; 0,\quad 
0 \;\le\;\alpha_i \;\le\; C.
\]&lt;p&gt;El problema &lt;strong&gt;dual&lt;/strong&gt; final para la SVM con soft margin vuelve a ser:&lt;/p&gt;
\[
\begin{aligned}
&amp; \max_{\boldsymbol{\alpha}} \quad 
   \sum_{i=1}^n \alpha_i \;-\; \tfrac{1}{2}\sum_{i,j} \alpha_i \alpha_j \,Y_i Y_j \,\langle \mathbf{X}_i,\mathbf{X}_j\rangle,\\
&amp; \text{sujeto a} \quad 0 \;\le\;\alpha_i \;\le\; C,\quad \sum_{i=1}^n \alpha_i Y_i = 0.
\end{aligned}
\]&lt;p&gt;Aquí, los puntos para los que \(\alpha_i\) está en el rango \((0, C)\) se convierten en los &lt;strong&gt;vectores de soporte&lt;/strong&gt;, y la resolución sigue análoga al caso separable.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;equivalente-de-regularización-hinge-loss&#34;&gt;Equivalente de regularización (Hinge loss)&lt;/h4&gt;
&lt;p&gt;Otra forma de ver la &lt;strong&gt;SVM lineal&lt;/strong&gt; es como un caso especial de &lt;strong&gt;pérdida bisagra (hinge loss)&lt;/strong&gt; con regularización en la norma de \(\mathbf{W}\).&lt;br&gt;
En el &lt;strong&gt;espacio primal&lt;/strong&gt;, la minimización se puede escribir como:&lt;/p&gt;
\[
\underset{\mathbf{W}, b}{\min} \;\; \sum_{i=1}^{n} \max\bigl(0,\,1 - Y_i\bigl(\mathbf{W}^\top \mathbf{X}_i + b\bigr)\bigr) \;+\; \lambda \,\|\mathbf{W}\|^2,
\]&lt;p&gt;donde \(\lambda\) es un parámetro de regularización relacionado inversamente con \(C\).&lt;/p&gt;
&lt;p&gt;La pérdida (bisagra) \(\max(0,\,1 - Y_i(\mathbf{W}^\top \mathbf{X}_i + b))\) fuerza cada ejemplo a estar, idealmente, al menos a 1 de distancia del hiperplano, y penaliza las violaciones a ese margen. Así, minimizar la norma de \(\mathbf{W}\) y el costo bisagra conduce al mismo criterio de “gran margen” que describimos antes.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;kernel-trick-y-espacio-aumentado&#34;&gt;Kernel Trick y espacio aumentado&lt;/h3&gt;
&lt;p&gt;La separación lineal puede no ser posible en el espacio original, pero sí en una &lt;strong&gt;dimensión mayor&lt;/strong&gt;. Aun así, no es necesario calcular explícitamente dicha transformación \(\varphi(\mathbf{X})\). El &lt;strong&gt;truco del kernel&lt;/strong&gt; nos dice que:&lt;/p&gt;
\[
k(\mathbf{X},\mathbf{X}&#39;) = \langle \varphi(\mathbf{X}), \,\varphi(\mathbf{X}&#39;) \rangle.
\]&lt;h4 id=&#34;aumento-del-espacio-idea&#34;&gt;Aumento del espacio (idea)&lt;/h4&gt;
&lt;p&gt;En el nuevo espacio, la separación lineal puede existir aunque en el original no:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-aumento-de-dimensión-para-separar-datos-no-lineales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Otra vista del aumento de dimensión&#34; srcset=&#34;
               /minerias/8_svm/figures/data_2d_to_3d_2_hu15601119294237896571.webp 400w,
               /minerias/8_svm/figures/data_2d_to_3d_2_hu12492001661735803246.webp 760w,
               /minerias/8_svm/figures/data_2d_to_3d_2_hu7038276523966741848.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/data_2d_to_3d_2_hu15601119294237896571.webp&#34;
               width=&#34;760&#34;
               height=&#34;369&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Aumento de dimensión para separar datos no lineales
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Cuidado con la alta dimensionalidad si \(d\) es muy grande.)&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;ejemplo-de-kernel-trick&#34;&gt;Ejemplo de Kernel Trick&lt;/h4&gt;
&lt;p&gt;Supongamos que queremos clasificar datos en \(\mathbb{R}^2\) usando un &lt;strong&gt;núcleo polinomial de grado 2&lt;/strong&gt;. Podemos definir una transformación explícita:&lt;/p&gt;
\[
\varphi: (x_1,x_2) \;\mapsto\; (\,x_1^2,\;\sqrt{2}\,x_1x_2,\;x_2^2,\;\sqrt{2}\,x_1,\;\sqrt{2}\,x_2,\;1\,).
\]&lt;p&gt;Al calcular el producto punto en este espacio, se observa que:&lt;/p&gt;
\[
\langle \varphi(\mathbf{X}),\varphi(\mathbf{X}&#39;)\rangle 
\;=\; \bigl(\langle \mathbf{X},\mathbf{X}&#39;\rangle + 1\bigr)^2
\]&lt;p&gt;De modo que el &lt;strong&gt;kernel&lt;/strong&gt; asociado es:&lt;/p&gt;
\[
k(\mathbf{X},\mathbf{X}&#39;) 
\;=\; \bigl( \mathbf{X}\cdot\mathbf{X}&#39; + 1 \bigr)^2.
\]&lt;p&gt;Esto permite a la SVM trabajar implícitamente con una dimensión más alta sin calcular \(\varphi(\mathbf{X})\) ni \(\varphi(\mathbf{X}&#39;)\) de forma explícita.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-truco-del-kernel-permite-separar-datos-no-lineales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Otra vista del aumento de dimensión&#34; srcset=&#34;
               /minerias/8_svm/figures/kernel_SVM_hu6299395877450182764.webp 400w,
               /minerias/8_svm/figures/kernel_SVM_hu11090577963053166792.webp 760w,
               /minerias/8_svm/figures/kernel_SVM_hu7485170395093064274.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/kernel_SVM_hu6299395877450182764.webp&#34;
               width=&#34;760&#34;
               height=&#34;472&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El truco del kernel permite separar datos no lineales.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;tipos-de-kernel-comunes&#34;&gt;Tipos de kernel comunes&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
\[
  k(\mathbf{X},\mathbf{X}&#39;) \;=\; \langle \mathbf{X},\;\mathbf{X}&#39; \rangle
  \]&lt;/li&gt;
&lt;li&gt;
\[
  k(\mathbf{X},\mathbf{X}&#39;) \;=\; \bigl(\langle \mathbf{X}, \mathbf{X}&#39; \rangle + c\bigr)^{d}
  \]&lt;/li&gt;
&lt;li&gt;
\[
  k(\mathbf{X},\mathbf{X}&#39;) \;=\; \exp\!\bigl(-\gamma\,\|\mathbf{X}-\mathbf{X}&#39;\|^2\bigr)
  \]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Lineal&lt;/strong&gt;&lt;br&gt;
















&lt;figure  id=&#34;figure-separación-lineal-con-kernel-lineal&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kernel lineal&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_kernel_lin_hu15985672093414640765.webp 400w,
               /minerias/8_svm/figures/svm_kernel_lin_hu5215183063117229496.webp 760w,
               /minerias/8_svm/figures/svm_kernel_lin_hu13743402759049042516.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_kernel_lin_hu15985672093414640765.webp&#34;
               width=&#34;760&#34;
               height=&#34;576&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Separación lineal con kernel lineal
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Polinomial&lt;/strong&gt;&lt;br&gt;
















&lt;figure  id=&#34;figure-separación-con-kernel-polinomial&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kernel polinomial&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_kernel_poly_hu2205477111260707794.webp 400w,
               /minerias/8_svm/figures/svm_kernel_poly_hu14329925200945324446.webp 760w,
               /minerias/8_svm/figures/svm_kernel_poly_hu12127295301654093412.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_kernel_poly_hu2205477111260707794.webp&#34;
               width=&#34;760&#34;
               height=&#34;576&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Separación con kernel polinomial
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gaussiano&lt;/strong&gt;&lt;br&gt;
















&lt;figure  id=&#34;figure-separación-con-kernel-gaussiano&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kernel RBF&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_kernel_gauss_hu2637743137941300484.webp 400w,
               /minerias/8_svm/figures/svm_kernel_gauss_hu2121526416713396169.webp 760w,
               /minerias/8_svm/figures/svm_kernel_gauss_hu5837164105067530359.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_kernel_gauss_hu2637743137941300484.webp&#34;
               width=&#34;760&#34;
               height=&#34;576&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Separación con kernel gaussiano
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;conclusión-de-svm&#34;&gt;Conclusión de SVM&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Se basa en &lt;strong&gt;maximizar el margen&lt;/strong&gt; (reduce sobreajuste).&lt;/li&gt;
&lt;li&gt;La solución surge de un problema de &lt;strong&gt;optimización convexa&lt;/strong&gt; que se puede abordar en su versión dual.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Los vectores de soporte&lt;/strong&gt; son los únicos puntos relevantes para la frontera de decisión.&lt;/li&gt;
&lt;li&gt;Permite &lt;strong&gt;kernels&lt;/strong&gt; para manejar no linealidades.&lt;/li&gt;
&lt;li&gt;Ajustar hiperparámetros (ej. \(C\), grado del polinomio, \(\gamma\) en el gaussiano) puede ser costoso.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;support-vector-regressor-svr&#34;&gt;Support Vector Regressor (SVR)&lt;/h2&gt;
&lt;p&gt;La SVM también puede adaptarse a &lt;strong&gt;tareas de regresión&lt;/strong&gt;. En vez de separar puntos en clases, se busca que la predicción \(\hat{y}\) caiga en un &lt;strong&gt;tubo de ancho \(\epsilon\)&lt;/strong&gt; en torno al valor real \(y\). A esto se lo denomina &lt;strong&gt;pérdida \(\epsilon\)-insensible&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;principio&#34;&gt;Principio&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-svr-con-zona-sin-penalización-si-el-error--ε&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Tubo ε-insensible en SVR&#34; srcset=&#34;
               /minerias/8_svm/figures/svr_hu8880163900142633628.webp 400w,
               /minerias/8_svm/figures/svr_hu4001860459484953900.webp 760w,
               /minerias/8_svm/figures/svr_hu17612073410467756993.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svr_hu8880163900142633628.webp&#34;
               width=&#34;760&#34;
               height=&#34;306&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      SVR con zona sin penalización si el error &amp;lt; ε
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Si \(|\hat{y} - y| \leq \epsilon\), no se incurre en penalización. Caso contrario, se agregan variables \(\xi_i, \xi_i^*\) que miden el exceso del error respecto de \(\epsilon\).&lt;/p&gt;
&lt;h3 id=&#34;formulación&#34;&gt;Formulación&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
\[
  \min_{\mathbf{W},b} \;\; \tfrac{1}{2}\|\mathbf{W}\|^2 + C\sum_i (\xi_i + \xi_i^*)
  \]\[
  \begin{cases}
  y_i - f(\mathbf{X}_i) \;\le\; \epsilon + \xi_i, \\
  f(\mathbf{X}_i) - y_i \;\le\; \epsilon + \xi_i^*, \\
  \xi_i,\xi_i^*\ge0.
  \end{cases}
  \]&lt;/li&gt;
&lt;li&gt;
\[
  f(\mathbf{X}) \;=\; \sum_{i=1}^{n} (\alpha_i - \alpha_i^*)\,k(\mathbf{X}_i,\mathbf{X})\;+\;b.
  \]&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ejemplo&#34;&gt;Ejemplo&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-svr-ajustando-una-curva-y-mostrando-el-tubo-ε&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de ajuste con SVR&#34; srcset=&#34;
               /minerias/8_svm/figures/svr_ex_hu6641046939284454635.webp 400w,
               /minerias/8_svm/figures/svr_ex_hu10964327218363507417.webp 760w,
               /minerias/8_svm/figures/svr_ex_hu9191617817313677244.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svr_ex_hu6641046939284454635.webp&#34;
               width=&#34;760&#34;
               height=&#34;563&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      SVR ajustando una curva y mostrando el tubo ±ε
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Solo los puntos que quedan fuera del tubo (por encima de \(\epsilon\)) se convierten en vectores de soporte.&lt;/p&gt;
&lt;h4 id=&#34;resumen-svr&#34;&gt;Resumen SVR&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Extiende la SVM a &lt;strong&gt;regresión&lt;/strong&gt;, usando la idea de &lt;em&gt;máximo margen&lt;/em&gt; alrededor de la curva aprendida.&lt;/li&gt;
&lt;li&gt;El &lt;strong&gt;parámetro \(\epsilon\)&lt;/strong&gt; controla el ancho de la zona “sin costo”; \(\xi_i,\xi_i^*\) miden el exceso.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;\(C\)&lt;/strong&gt; regula la penalización por exceder \(\epsilon\).&lt;/li&gt;
&lt;li&gt;Se pueden usar &lt;strong&gt;kernels&lt;/strong&gt; para la parte no lineal, igual que en la clasificación.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;¡Eso es todo sobre &lt;strong&gt;SVM&lt;/strong&gt; y &lt;strong&gt;SVR&lt;/strong&gt;! Son métodos muy potentes y ampliamente utilizados en Machine Learning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SVM&lt;/strong&gt; para clasificación binaria (y extensiones a multiclase).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SVR&lt;/strong&gt; para regresión con márgenes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kernels&lt;/strong&gt; para no linealidad en ambos casos.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Clustering</title>
      <link>http://localhost:1313/minerias/9_clustering/</link>
      <pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/9_clustering/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_clusteringpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Clustering.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;En &lt;strong&gt;aprendizaje no supervisado&lt;/strong&gt;, no hay una variable objetivo \(Y\) etiquetada que queramos predecir. El objetivo es &lt;strong&gt;descubrir estructuras&lt;/strong&gt; en los datos, como &lt;strong&gt;grupos (clusters)&lt;/strong&gt;, &lt;strong&gt;patrones&lt;/strong&gt; o &lt;strong&gt;regularidades&lt;/strong&gt;. Esto difiere del &lt;strong&gt;aprendizaje supervisado&lt;/strong&gt;, donde sí conocemos las etiquetas \((\mathbf{X}_i, Y_i)\) y buscamos una función \(f\) que prediga \(Y\) a partir de \(\mathbf{X}\).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-aprendizaje-non-supervisado-es-mas-complejo-y-menos-performante-que-el-supervisado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Aprendizaje supervisado vs. no supervisado&#34; srcset=&#34;
               /minerias/9_clustering/figures/tweet_socher_unsupervised_hu5197646474298531310.webp 400w,
               /minerias/9_clustering/figures/tweet_socher_unsupervised_hu4366812009784522218.webp 760w,
               /minerias/9_clustering/figures/tweet_socher_unsupervised_hu11863700504794312954.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/tweet_socher_unsupervised_hu5197646474298531310.webp&#34;
               width=&#34;760&#34;
               height=&#34;219&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El aprendizaje non supervisado es mas complejo y menos performante que el supervisado.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;clustering-principio&#34;&gt;Clustering: Principio&lt;/h2&gt;
&lt;h3 id=&#34;por-qué-clústeres&#34;&gt;¿Por qué clústeres?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Topic modeling&lt;/strong&gt;: agrupar documentos o comentarios según su tema.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Análisis de sentimientos&lt;/strong&gt;: reagrupar comentarios de usuarios para descubrir críticas comunes o elogios.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Segmentación de clientes&lt;/strong&gt;: en marketing, agrupar clientes con comportamientos similares.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eficiencia&lt;/strong&gt;: entrenar submodelos especializados en cada clúster de datos.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ambigüedad&#34;&gt;Ambigüedad&lt;/h3&gt;
&lt;p&gt;Distintas particiones pueden ser igualmente válidas:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-distintas-clusterizaciones-posibles-por-una-misma&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Distintas clusterizaciones posibles&#34; srcset=&#34;
               /minerias/9_clustering/figures/different_clusterizations_2_hu15775732108812300988.webp 400w,
               /minerias/9_clustering/figures/different_clusterizations_2_hu12295819656352621145.webp 760w,
               /minerias/9_clustering/figures/different_clusterizations_2_hu15640061247686310699.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/different_clusterizations_2_hu15775732108812300988.webp&#34;
               width=&#34;760&#34;
               height=&#34;424&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Distintas clusterizaciones posibles por una misma
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;No siempre hay una sola respuesta a “cómo” agrupar.&lt;/p&gt;
&lt;h3 id=&#34;objetivo-intuitivo&#34;&gt;Objetivo intuitivo&lt;/h3&gt;
&lt;p&gt;Disminuir la &lt;strong&gt;distancia intra-cluster&lt;/strong&gt; (los puntos de un mismo grupo están juntos)
y aumentar la &lt;strong&gt;distancia inter-cluster&lt;/strong&gt; (grupos lejos entre sí):&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-buscamos-que-los-puntos-de-un-mismo-clúster-estén-cerca-y-los-distintos-clústeres-lejos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Inter/intra distancias&#34; srcset=&#34;
               /minerias/9_clustering/figures/cluster_inter_intra_hu7865371396031803691.webp 400w,
               /minerias/9_clustering/figures/cluster_inter_intra_hu2172439649587475770.webp 760w,
               /minerias/9_clustering/figures/cluster_inter_intra_hu17635859847885416538.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/cluster_inter_intra_hu7865371396031803691.webp&#34;
               width=&#34;760&#34;
               height=&#34;637&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Buscamos que los puntos de un mismo clúster estén cerca, y los distintos clústeres lejos.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;k-means&#34;&gt;K-means&lt;/h2&gt;
&lt;h3 id=&#34;idea-general&#34;&gt;Idea general&lt;/h3&gt;
&lt;p&gt;Separar los datos en \(K\) grupos usando “centroides” (medias de cada clúster):&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-centroides-se-ajustan-iterando-la-asignación-de-puntos-y-recálculo-de-medias&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;K-means ejemplo simple&#34; srcset=&#34;
               /minerias/9_clustering/figures/k_means_ex1_hu2736599721081469354.webp 400w,
               /minerias/9_clustering/figures/k_means_ex1_hu6532534073349502683.webp 760w,
               /minerias/9_clustering/figures/k_means_ex1_hu11178902821246344841.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/k_means_ex1_hu2736599721081469354.webp&#34;
               width=&#34;760&#34;
               height=&#34;505&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los centroides se ajustan iterando la asignación de puntos y recálculo de medias.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;minimizar-la-sse-sum-of-squared-errors&#34;&gt;Minimizar la SSE (Sum of Squared Errors)&lt;/h3&gt;
&lt;p&gt;K-means particiona los datos \(\Xb_i\) en \(K\) clústeres \(\{\mathcal{C}_1,\dots,\mathcal{C}_K\}\) para &lt;strong&gt;minimizar&lt;/strong&gt;:&lt;/p&gt;
\[
G(\mathcal{C}_1,\dots,\mathcal{C}_K)
= \sum_{k=1}^K 
  \sum_{i\in\mathcal{C}_k} \|\Xb_i - \mu_k\|^2,
\]&lt;p&gt;donde \(\mu_k\) es el &lt;strong&gt;centroide&lt;/strong&gt; del clúster \(k\). Cada punto se asigna al \(\mu_k\) más cercano en norma Euclídea.&lt;/p&gt;
&lt;h3 id=&#34;algoritmo-iterativo&#34;&gt;Algoritmo iterativo&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Asignación&lt;/strong&gt;: Conociendo los centroides \(\mu_k\), cada punto se asigna al más cercano.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Actualización&lt;/strong&gt;: Conociendo la asignación, se recalculan los centroides \(\mu_k\)
como la media de los puntos en cada clúster.&lt;/li&gt;
&lt;li&gt;Se repite hasta que la inercia (SSE) deje de disminuir significativamente.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Paso de asignación y actualización&#34; srcset=&#34;
               /minerias/9_clustering/figures/steps-of-kmeans_hu6095530476482662818.webp 400w,
               /minerias/9_clustering/figures/steps-of-kmeans_hu14495224545641776934.webp 760w,
               /minerias/9_clustering/figures/steps-of-kmeans_hu16240963076215426502.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/steps-of-kmeans_hu6095530476482662818.webp&#34;
               width=&#34;760&#34;
               height=&#34;246&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;dependencia-de-la-inicialización&#34;&gt;Dependencia de la inicialización&lt;/h3&gt;
&lt;p&gt;Es un problema no convexo, por lo que su solución depende de la semilla inicial:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-una-primera-inicializacion-da-un-primer-resultado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Distintas inicializaciones llevan a diferentes soluciones&#34; srcset=&#34;
               /minerias/9_clustering/figures/K_mean_conv_ex_1_hu13723184752837687416.webp 400w,
               /minerias/9_clustering/figures/K_mean_conv_ex_1_hu18197821088450864026.webp 760w,
               /minerias/9_clustering/figures/K_mean_conv_ex_1_hu381108850359093404.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/K_mean_conv_ex_1_hu13723184752837687416.webp&#34;
               width=&#34;760&#34;
               height=&#34;661&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Una primera inicializacion da un primer resultado.
    &lt;/figcaption&gt;&lt;/figure&gt;

















&lt;figure  id=&#34;figure-una-otra-inicializacion-da-un-otro-resultado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Otra inicialización distinta&#34; srcset=&#34;
               /minerias/9_clustering/figures/K_mean_conv_ex_2_hu2276176246617213499.webp 400w,
               /minerias/9_clustering/figures/K_mean_conv_ex_2_hu17439637570382563269.webp 760w,
               /minerias/9_clustering/figures/K_mean_conv_ex_2_hu4315955420995951315.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/K_mean_conv_ex_2_hu2276176246617213499.webp&#34;
               width=&#34;760&#34;
               height=&#34;661&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Una otra inicializacion da un otro resultado
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solución&lt;/strong&gt;: ejecutar K-means varias veces y elegir la partición con menor SSE.&lt;/p&gt;
&lt;h3 id=&#34;elección-de-k&#34;&gt;Elección de \(K\)&lt;/h3&gt;
&lt;p&gt;El número de clústeres debe fijarse antes. Se puede explorar varios valores y usar el
&lt;strong&gt;método del codo (elbow method)&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-codo-indica-un-buen-trade-off-no-reduce-mucho-más-la-varianza-al-aumentar-k&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Elbow method en K-means&#34; srcset=&#34;
               /minerias/9_clustering/figures/kmeans_elbow_hu14641282044619962302.webp 400w,
               /minerias/9_clustering/figures/kmeans_elbow_hu13047655996396632350.webp 760w,
               /minerias/9_clustering/figures/kmeans_elbow_hu7513878213620665158.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/kmeans_elbow_hu14641282044619962302.webp&#34;
               width=&#34;389&#34;
               height=&#34;278&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El codo indica un buen trade-off: no reduce mucho más la varianza al aumentar K.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dbscan&#34;&gt;DBSCAN&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;DBSCAN (Density-Based Spatial Clustering of Applications with Noise)&lt;/strong&gt; busca regiones densas y marca los puntos dispersos como ruido.&lt;/p&gt;
&lt;h3 id=&#34;ejemplo&#34;&gt;Ejemplo&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-dbscan-puede-reconocer-clusters-y-eliminar-ruido-al-mismo-tiempo&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;DBSCAN puede eliminar ruido&#34;
           src=&#34;http://localhost:1313/minerias/9_clustering/figures/DBSCAN.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      DBSCAN puede reconocer clusters y eliminar ruido al mismo tiempo.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;principios&#34;&gt;Principios&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Parámetros:
&lt;ul&gt;
&lt;li&gt;\(\texttt{eps} (\varepsilon)\): radio de vecindad.&lt;/li&gt;
&lt;li&gt;\(\texttt{min\_samples}\): mínimo de puntos para que un punto sea núcleo (core).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clasifica en &lt;strong&gt;core&lt;/strong&gt;, &lt;strong&gt;border&lt;/strong&gt;, &lt;strong&gt;noise&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Core&lt;/strong&gt;: al menos \(\texttt{min\_samples}\) puntos en su vecindad.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Border&lt;/strong&gt;: no llega a ese umbral, pero está dentro del vecindario de un core.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Noise&lt;/strong&gt;: no pertenece a core ni al vecindario de un core.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-principio-de-dbscan-puntos-core-border-noise&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Puntos Core, Border, Noise&#34; srcset=&#34;
               /minerias/9_clustering/figures/dbscan-principle_hu181525653378491942.webp 400w,
               /minerias/9_clustering/figures/dbscan-principle_hu2428826805354743809.webp 760w,
               /minerias/9_clustering/figures/dbscan-principle_hu8842561263444215320.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/dbscan-principle_hu181525653378491942.webp&#34;
               width=&#34;358&#34;
               height=&#34;168&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Principio de DBSCAN: Puntos Core, Border, Noise
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;ventajas-y-desventajas&#34;&gt;Ventajas y Desventajas&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Ventajas&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detecta formas arbitrarias (no sólo esferas).&lt;/li&gt;
&lt;li&gt;Identifica outliers (ruido).&lt;/li&gt;
&lt;li&gt;Menos parámetros que métodos jerárquicos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Desventajas&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sensible a \(\texttt{eps}\) y \(\texttt{min\_samples}\).&lt;/li&gt;
&lt;li&gt;Si la densidad varía drásticamente, un único \(\texttt{eps}\) no es apropiado.&lt;/li&gt;
&lt;li&gt;Difícil en alta dimensionalidad.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-mal-ajuste-con-eps-grandepequeño&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/dbscan_disvantages_2.png&#34; alt=&#34;Mal ajuste con eps grande/pequeño&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Mal ajuste con eps grande/pequeño
    &lt;/figcaption&gt;&lt;/figure&gt;

















&lt;figure  id=&#34;figure-ruido-o-clusters&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/dbscan_disvantages_1.png&#34; alt=&#34;Ruido o clusters?&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ruido o clusters?
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;elección-de-textttminpts-y-varepsilon&#34;&gt;Elección de \(\texttt{minPts}\) y \(\varepsilon\)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;\(\texttt{minPts}\)&lt;/strong&gt;: regla de pulgar \(\texttt{minPts}\ge D+1\) (donde \(D\) = dimensión).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;\(\varepsilon\)&lt;/strong&gt;: usar gráfico de k-dist y buscar el “codo”.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;OPTICS&lt;/em&gt; es una alternativa más avanzada que ajusta la densidad de forma variable.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;clustering-jerárquico&#34;&gt;Clustering Jerárquico&lt;/h2&gt;
&lt;h3 id=&#34;bisecting-k-means&#34;&gt;Bisecting K-means&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Bisecting K-means&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Arranca con todos los puntos como un clúster.&lt;/li&gt;
&lt;li&gt;Aplica K-means con \(k=2\) (bisect) para dividirlo en 2.&lt;/li&gt;
&lt;li&gt;Escoge el clúster con mayor SSE y lo subdivide.&lt;/li&gt;
&lt;li&gt;Repite hasta lograr \(K\) clústeres.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Bisecting K-means diagrama&#34; srcset=&#34;
               /minerias/9_clustering/figures/bisecting_kmeans_hu3410477381541693384.webp 400w,
               /minerias/9_clustering/figures/bisecting_kmeans_hu4900784332573473429.webp 760w,
               /minerias/9_clustering/figures/bisecting_kmeans_hu3758992962579795936.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/bisecting_kmeans_hu3410477381541693384.webp&#34;
               width=&#34;760&#34;
               height=&#34;234&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ventajas&lt;/strong&gt;: combinan jerarquía y rapidez de K-means.&lt;br&gt;
&lt;strong&gt;Algoritmo&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Pseudocódigo de Bisecting K-means&#34; srcset=&#34;
               /minerias/9_clustering/figures/Bissected_KMEANS_algo_hu5885889109457301429.webp 400w,
               /minerias/9_clustering/figures/Bissected_KMEANS_algo_hu15649835566660434353.webp 760w,
               /minerias/9_clustering/figures/Bissected_KMEANS_algo_hu9289569499455429687.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/Bissected_KMEANS_algo_hu5885889109457301429.webp&#34;
               width=&#34;401&#34;
               height=&#34;705&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;jerárquico-aglomerativo-hac&#34;&gt;Jerárquico Aglomerativo (HAC)&lt;/h3&gt;
&lt;p&gt;Otro enfoque jerárquico:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cada punto inicia como un clúster propio.&lt;/li&gt;
&lt;li&gt;Se fusionan iterativamente los 2 clústeres más cercanos.&lt;/li&gt;
&lt;li&gt;Se actualiza la distancia con el nuevo clúster.&lt;/li&gt;
&lt;li&gt;Hasta que quede un solo clúster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-fusión-jerárquica-paso-a-paso&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fusión jerárquica paso a paso&#34;
           src=&#34;http://localhost:1313/minerias/9_clustering/figures/Merging_Clusters.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fusión jerárquica paso a paso
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Distancia entre clústeres (Linkage):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-como-cuantificar-la-similitud-entre-2-clusters&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Criterios de linkage&#34; srcset=&#34;
               /minerias/9_clustering/figures/Cluster_sim_1_hu14647459013340444117.webp 400w,
               /minerias/9_clustering/figures/Cluster_sim_1_hu11785271453636633236.webp 760w,
               /minerias/9_clustering/figures/Cluster_sim_1_hu15281884628367069891.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/Cluster_sim_1_hu14647459013340444117.webp&#34;
               width=&#34;760&#34;
               height=&#34;329&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Como cuantificar la similitud entre 2 clusters?
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Se define la “distancia” entre dos grupos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Single linkage&lt;/strong&gt;: menor distancia entre pares de puntos (sensibilidad al ruido).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Complete linkage&lt;/strong&gt;: mayor distancia entre pares de puntos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Average linkage&lt;/strong&gt;: promedio de distancias entre pares (compromiso).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Centroid&lt;/strong&gt; linkage: distancia entre centroides.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;hdbscan&#34;&gt;HDBSCAN&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;HDBSCAN&lt;/strong&gt;: extensión jerárquica de DBSCAN&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Explora múltiples densidades.&lt;/li&gt;
&lt;li&gt;No fija un único \(\varepsilon\).&lt;/li&gt;
&lt;li&gt;Elige subconjuntos estables dentro de la jerarquía de densidad.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://hdbscan.readthedocs.io/en/latest&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentación HDBSCAN&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;métricas-de-validación&#34;&gt;Métricas de Validación&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;A diferencia del aprendizaje supervisado&lt;/strong&gt;, muchas veces no hay etiquetas para evaluar la calidad de un clustering. Dos enfoques:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Métricas externas&lt;/strong&gt; (hay etiquetas reales):
&lt;ul&gt;
&lt;li&gt;Homogeneidad, Completeness, V-measure.&lt;/li&gt;
&lt;li&gt;Rand Index, Fowlkes–Mallows.&lt;/li&gt;
&lt;li&gt;Mutual Information (MI).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Métricas internas&lt;/strong&gt; (sólo datos y clústeres):
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Silhouette&lt;/strong&gt; (valores entre -1 y 1).&lt;/li&gt;
&lt;li&gt;SSE (inercia en K-means).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;resumen-rápido&#34;&gt;Resumen rápido&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Homogeneidad&lt;/strong&gt;: cada clúster contiene sólo puntos de una clase.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Completeness&lt;/strong&gt;: cada clase está contenida en un único clúster.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;V-measure&lt;/strong&gt;: media armónica de las dos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fowlkes–Mallows&lt;/strong&gt;: ve pares de puntos coincidentes en la etiqueta y en el cluster.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Silhouette&lt;/strong&gt;: cohesión y separación sin usar clases reales.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;otros-métodos-de-clustering&#34;&gt;Otros métodos de clustering&lt;/h2&gt;
&lt;p&gt;Existen varias alternativas según forma de los clústeres, ruido, densidad variable, etc.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;clustering_examples.png&#34; alt=&#34;Galería de métodos de clustering&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Tabla de referencia (Scikit-learn):&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Method Name&lt;/th&gt;
          &lt;th&gt;Parameters&lt;/th&gt;
          &lt;th&gt;Scalability&lt;/th&gt;
          &lt;th&gt;Use Case&lt;/th&gt;
          &lt;th&gt;Geometry (Metric Used)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#k-means&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;K-Means&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters&lt;/td&gt;
          &lt;td&gt;Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt; with MiniBatch code&lt;/td&gt;
          &lt;td&gt;General-purpose, even cluster size, flat geometry, not too many clusters, inductive&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#affinity-propagation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Affinity Propagation&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Damping, sample preference&lt;/td&gt;
          &lt;td&gt;Not scalable with &lt;code&gt;n_samples&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Many clusters, uneven cluster size, non-flat geometry, inductive&lt;/td&gt;
          &lt;td&gt;Graph distance (e.g., nearest-neighbor graph)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#mean-shift&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Mean-Shift&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Bandwidth&lt;/td&gt;
          &lt;td&gt;Not scalable with &lt;code&gt;n_samples&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Many clusters, uneven cluster size, non-flat geometry, inductive&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#spectral-clustering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Spectral Clustering&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters&lt;/td&gt;
          &lt;td&gt;Medium &lt;code&gt;n_samples&lt;/code&gt;, small &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Few clusters, even cluster size, non-flat geometry, transductive&lt;/td&gt;
          &lt;td&gt;Graph distance (e.g., nearest-neighbor graph)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Ward Hierarchical Clustering&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters or distance threshold&lt;/td&gt;
          &lt;td&gt;Large &lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Many clusters, possibly connectivity constraints, transductive&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Agglomerative Clustering&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters or distance threshold, linkage type, distance&lt;/td&gt;
          &lt;td&gt;Large &lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Many clusters, possibly connectivity constraints, non-Euclidean distances, transductive&lt;/td&gt;
          &lt;td&gt;Any pairwise distance&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#dbscan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;DBSCAN&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Neighborhood size&lt;/td&gt;
          &lt;td&gt;Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Non-flat geometry, uneven cluster sizes, outlier removal, transductive&lt;/td&gt;
          &lt;td&gt;Distances between nearest points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#hdbscan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;HDBSCAN&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Minimum cluster membership, minimum point neighbors&lt;/td&gt;
          &lt;td&gt;Large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Non-flat geometry, uneven cluster sizes, outlier removal, transductive, hierarchical, variable cluster density&lt;/td&gt;
          &lt;td&gt;Distances between nearest points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#optics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;OPTICS&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Minimum cluster membership&lt;/td&gt;
          &lt;td&gt;Very large &lt;code&gt;n_samples&lt;/code&gt;, large &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Non-flat geometry, uneven cluster sizes, variable cluster density, outlier removal, transductive&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#gaussian-mixture&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Gaussian Mixtures&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Many&lt;/td&gt;
          &lt;td&gt;Not scalable&lt;/td&gt;
          &lt;td&gt;Flat geometry, good for density estimation, inductive&lt;/td&gt;
          &lt;td&gt;Mahalanobis distances to centers&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#birch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;BIRCH&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Branching factor, threshold, optional global clusterer&lt;/td&gt;
          &lt;td&gt;Large &lt;code&gt;n_clusters&lt;/code&gt; and &lt;code&gt;n_samples&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Large dataset, outlier removal, data reduction, inductive&lt;/td&gt;
          &lt;td&gt;Euclidean distance between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#bisecting-k-means&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Bisecting K-Means&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters&lt;/td&gt;
          &lt;td&gt;Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;General-purpose, even cluster size, flat geometry, no empty clusters, inductive, hierarchical&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Más info en: &lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;clustering scikit-learn docs&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;use-case-bertopic&#34;&gt;Use-case: BERTopic&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;BERTopic&lt;/strong&gt; es una librería que combina embeddings (BERT) + clustering para &lt;strong&gt;topic modeling&lt;/strong&gt; sobre textos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;BERTopic Ejemplo&#34; srcset=&#34;
               /minerias/9_clustering/figures/BERTopic_pres_hu16487685084505827816.webp 400w,
               /minerias/9_clustering/figures/BERTopic_pres_hu4264554082630846410.webp 760w,
               /minerias/9_clustering/figures/BERTopic_pres_hu2358273787969741926.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/BERTopic_pres_hu16487685084505827816.webp&#34;
               width=&#34;760&#34;
               height=&#34;429&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Puede:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Agrupar oraciones/documentos en “temas” usando embeddings.&lt;/li&gt;
&lt;li&gt;Visualizar la &lt;strong&gt;evolución&lt;/strong&gt; de temas en el tiempo (dynamic topic modeling).&lt;/li&gt;
&lt;li&gt;Hacer &lt;strong&gt;clustering jerárquico&lt;/strong&gt; en temas descubiertos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://maartengr.github.io/BERTopic/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BERTopic docs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-permite-un-tracking-dinámico-de-la-evolución-de-topics-ademas-se-puede-ver-que-las-palabras-las-mas-importante-para-cada-topic-evoluan-en-el-tiempo&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Visualización de temas en el tiempo&#34;
           src=&#34;http://localhost:1313/minerias/9_clustering/figures/BERTopic_time.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Permite un tracking dinámico de la evolución de topics. Ademas se puede ver que las palabras las mas importante para cada topic evoluan en el tiempo.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Computer Vision Architectures</title>
      <link>http://localhost:1313/deep/9_cnn_architectures/</link>
      <pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/9_cnn_architectures/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides9_cnn_architecturespdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/9_CNN_Architectures.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Dimensionality Reduction</title>
      <link>http://localhost:1313/minerias/10_reduccion_atributos/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/10_reduccion_atributos/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_disminucion_dimensionespdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Disminucion_Dimensiones.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;Las &lt;strong&gt;técnicas de reducción de dimensión&lt;/strong&gt; buscan simplificar la representación de los datos, sea eliminando atributos innecesarios (selección de características) o encontrando una proyección más compacta que mantenga la mayor parte de la información. A continuación, veremos métodos tanto &lt;strong&gt;supervisados&lt;/strong&gt; (wrappers, filters) como &lt;strong&gt;no supervisados&lt;/strong&gt; (PCA, entre otros).&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;motivaciones-para-una-dimensión-más-baja&#34;&gt;Motivaciones para una Dimensión más Baja&lt;/h2&gt;
&lt;h3 id=&#34;selección-y-reducción-de-atributos&#34;&gt;Selección y Reducción de Atributos&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Motivación General&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;En muchos problemas de aprendizaje, hay &lt;strong&gt;atributos irrelevantes&lt;/strong&gt; o &lt;strong&gt;redundantes&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Pueden perjudicar el desempeño de un clasificador o incrementar el costo de entrenamiento.&lt;/li&gt;
&lt;li&gt;Dos enfoques principales:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Selección de atributos (supervisado)&lt;/strong&gt;: escoger un &lt;strong&gt;subconjunto&lt;/strong&gt; relevante para la tarea (clasificación, regresión&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reducción de dimensionalidad (no supervisado)&lt;/strong&gt;: encontrar una &lt;strong&gt;proyección&lt;/strong&gt; de menor dimensión que concentre la información de los datos.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;razones-para-seleccionar-atributos&#34;&gt;Razones para Seleccionar Atributos&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Árboles de decisión&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Aunque tratan de escoger atributos relevantes, si hay muchos atributos basura, puede aparecer sobreajuste (“aprender” ruido con árboles muy profundos).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;KNN&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Se ve muy afectado por atributos irrelevantes, pues todas las dimensiones contribuyen igual al &lt;strong&gt;cálculo de distancias&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Naïve Bayes&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Robusto a atributos irrelevantes (los ignora en la probabilidad a posteriori), pero sufre con atributos muy &lt;strong&gt;correlacionados&lt;/strong&gt; (redundantes).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;En general, se quiere &lt;strong&gt;mitigar la curse of dimensionality&lt;/strong&gt; (maldición de la dimensionalidad).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;selección-de-atributos&#34;&gt;Selección de Atributos&lt;/h2&gt;
&lt;h3 id=&#34;filtros-vs-envoltura&#34;&gt;Filtros vs. Envoltura&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Feature-based (Filtros)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evalúan atributos por &lt;strong&gt;propiedades de los datos&lt;/strong&gt; (p.ej. varianza, correlación, información mutua).&lt;/li&gt;
&lt;li&gt;Independientes del clasificador.&lt;/li&gt;
&lt;li&gt;Más rápidos y con menos riesgo de sobreajuste, pero &lt;strong&gt;no captan&lt;/strong&gt; interacciones complejas con la tarea predictiva.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Model-based (Wrappers)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Entrenan un &lt;strong&gt;clasificador&lt;/strong&gt; sobre cada subconjunto para medir qué tan bueno es.&lt;/li&gt;
&lt;li&gt;Objetivo: maximizar la capacidad predictiva del modelo específico.&lt;/li&gt;
&lt;li&gt;Pueden ser computacionalmente costosos y propensos a sobreajuste, pero suelen encontrar subconjuntos de atributos &lt;strong&gt;más específicos a la tarea&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;métodos-feature-based-univariate&#34;&gt;Métodos Feature-based (Univariate)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Independientes de un modelo&lt;/strong&gt; (univariate feature selection).&lt;/li&gt;
&lt;li&gt;Usan &lt;strong&gt;métricas&lt;/strong&gt; generales (entropía, Information Gain, correlación, \(\chi^2\)&amp;hellip;).&lt;/li&gt;
&lt;li&gt;Ejemplos:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Information Gain&lt;/strong&gt; (basado en entropía).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mutual Information&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Correlation-based Feature Selection (CFS)&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Low variance&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Son rápidos y simples, pero &lt;strong&gt;no consideran&lt;/strong&gt; cómo cada atributo interactúa con un clasificador concreto.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Mutual Information y \(\chi^2\) son útiles cuando los datos son dispersos (sparse).&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h4 id=&#34;correlation-based-feature-selection-cfs&#34;&gt;Correlation-based Feature Selection (CFS)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Se evalúa un subconjunto de atributos según correlaciones en los datos:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Alta correlación&lt;/strong&gt; con la clase.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Baja correlación&lt;/strong&gt; entre atributos (evitar redundancia).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Se suele usar &lt;em&gt;symmetric uncertainty&lt;/em&gt; para medir correlaciones entre atributos categóricos:&lt;/li&gt;
&lt;/ul&gt;
\[
\text{SymmUnc}(A,B) 
= \frac{2 \times (H(A) - H(A|B))}{H(A)+H(B)} 
= \frac{2 \times IG(A,B)}{H(A)+H(B)},
\]&lt;p&gt;
donde \(H(\cdot)\) es la entropía, e \(IG(A,B)\) la ganancia de información.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Búsqueda de subconjuntos&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;El total de subconjuntos es \(\mathcal{O}(2^n)\).&lt;/li&gt;
&lt;li&gt;Se aplican heurísticas &lt;strong&gt;greedy&lt;/strong&gt; (Forward selection, Backward elimination) o más avanzadas (Best-first search, Beam search, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;model-based-scheme-specific&#34;&gt;Model-based (Scheme-Specific)&lt;/h3&gt;
&lt;h4 id=&#34;selección-basada-en-importancia-de-atributos&#34;&gt;Selección basada en importancia de atributos&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Tras entrenar un &lt;strong&gt;modelo&lt;/strong&gt; (ej. árbol, regresión lineal, random forest), se obtiene la &lt;strong&gt;importancia&lt;/strong&gt; de cada atributo (coeficientes o feature importances).&lt;/li&gt;
&lt;li&gt;Se descartan los que &lt;strong&gt;no&lt;/strong&gt; superan cierto umbral.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SelectFromModel de scikit-learn&lt;/a&gt; permite automatizarlo.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Regularización \(\ell_1\) (Lasso)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Induce &lt;strong&gt;parcimonia&lt;/strong&gt;: algunos coeficientes se anulan.&lt;/li&gt;
&lt;li&gt;Ideal para selección en modelos lineales (regresión, logística).&lt;/li&gt;
&lt;li&gt;Penaliza \(\sum |w_j|\), forzando algunos \(w_j\) a 0.&lt;/li&gt;
&lt;li&gt;Integra fácilmente con &lt;code&gt;SelectFromModel&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;selección-por-wrapper-performance-based&#34;&gt;Selección por Wrapper (Performance-based)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Se prueban subconjuntos entrenando un modelo y midiendo su &lt;strong&gt;performance&lt;/strong&gt; (accuracy, F1, AUC&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Muy costoso&lt;/strong&gt;: reentrenar el modelo para cada subconjunto potencial.&lt;/li&gt;
&lt;li&gt;A menudo se hace &lt;strong&gt;greedy&lt;/strong&gt; (Forward o Backward).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recursive Feature Elimination (RFE)&lt;/strong&gt;:
&lt;ol&gt;
&lt;li&gt;Entrena estimador, extrae la &lt;strong&gt;importancia&lt;/strong&gt; de atributos,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Descarta&lt;/strong&gt; los menos importantes,&lt;/li&gt;
&lt;li&gt;Repite con el subconjunto reducido hasta lograr la cantidad de atributos deseada.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reducción-de-dimensión&#34;&gt;Reducción de Dimensión&lt;/h2&gt;
&lt;p&gt;Más allá de “quitar” atributos, a veces &lt;strong&gt;transformamos&lt;/strong&gt; los datos a una dimensión menor con un método no supervisado.&lt;/p&gt;
&lt;h3 id=&#34;intereses-de-la-reducción-de-dimensión&#34;&gt;Intereses de la Reducción de Dimensión&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Simplificar los datos&lt;/strong&gt;: Menos ruido, mejor generalización.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reducir costo computacional&lt;/strong&gt;: Entrenar y predecir con menos dimensiones es más rápido.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualización&lt;/strong&gt;: Proyecciones 2D o 3D para entender la estructura de los datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evitar la curse of dimensionality&lt;/strong&gt;: Métodos basados en distancia sufren en alta dimensión.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compresión&lt;/strong&gt;: Reducir espacio de almacenamiento.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;análisis-de-componentes-principales-pca&#34;&gt;Análisis de Componentes Principales (PCA)&lt;/h2&gt;
&lt;p&gt;PCA es un método &lt;strong&gt;lineal&lt;/strong&gt; que halla vectores propios de la matriz de &lt;strong&gt;covarianza&lt;/strong&gt;. Permitten de representar la mayor parte de los datos, con menos vectores en la base del espacio.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-cada-dato-se-representa-como-una-suma-ponderada-de-vectores-de-una-nueva-base-que-permite-de-representar-bien-la-mayor-parte-de-los-datos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de eigenfaces (PCA en imágenes)&#34; srcset=&#34;
               /minerias/10_reduccion_atributos/figures/pca_matrices_val_hu2261646820185605856.webp 400w,
               /minerias/10_reduccion_atributos/figures/pca_matrices_val_hu4505522404744315614.webp 760w,
               /minerias/10_reduccion_atributos/figures/pca_matrices_val_hu4178062851371759896.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/pca_matrices_val_hu2261646820185605856.webp&#34;
               width=&#34;760&#34;
               height=&#34;417&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cada dato se representa como una suma ponderada de vectores de una nueva base, que permite de representar bien la mayor parte de los datos.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-eigenfaces-como-vectores-base-de-pca-obtenidos-con-pca-en-un-dataset-de-rostros&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Eigenfaces obtenidos con PCA en un dataset de rostros&#34; srcset=&#34;
               /minerias/10_reduccion_atributos/figures/eigenfaces2_hu6363039486458666921.webp 400w,
               /minerias/10_reduccion_atributos/figures/eigenfaces2_hu8512282051007263862.webp 760w,
               /minerias/10_reduccion_atributos/figures/eigenfaces2_hu15806552021475915375.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/eigenfaces2_hu6363039486458666921.webp&#34;
               width=&#34;576&#34;
               height=&#34;237&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Eigenfaces como vectores base de PCA obtenidos con PCA en un dataset de rostros.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;por-qué-pca&#34;&gt;¿Por qué PCA?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reduce dimensión&lt;/strong&gt; para análisis, visualización o compresión.&lt;/li&gt;
&lt;li&gt;Encuentra un &lt;strong&gt;sistema de coordenadas&lt;/strong&gt; donde los ejes (componentes principales) corresponden a las direcciones de &lt;strong&gt;mayor varianza&lt;/strong&gt; en los datos.&lt;/li&gt;
&lt;li&gt;Base calculada con las &lt;strong&gt;autovectores&lt;/strong&gt; de la covarianza.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ejemplo-e-ilustración&#34;&gt;Ejemplo e Ilustración&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PCA ve la redundancia (varias variables correlacionadas) y la condensa en &lt;strong&gt;componentes&lt;/strong&gt; que explican la mayor parte de la varianza.&lt;/li&gt;
&lt;li&gt;Datos \(\mathbf{X}_0\) &lt;strong&gt;centrados&lt;/strong&gt; (o estandarizados) se proyectan en el subespacio donde la &lt;strong&gt;varianza&lt;/strong&gt; proyectada es máxima.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplo-pca-de-2d-a-1d&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo PCA 2D -&amp;gt; 1D&#34;
           src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/EX_PCA.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo PCA de 2D a 1D.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Se pueden visualizar transformaciones o la reconstrucción aproximada:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-data-inicial-normalizada-transformada-y-reconstruida&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Data normalized transformed reconstructed&#34;
           src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/PCA_data_original_normalized_transformed_reconstructed.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La data inicial, normalizada, transformada y reconstruida
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;fundamento-matemático&#34;&gt;Fundamento Matemático&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Normalizamos \(\mathbf{X}\) a \(\mathbf{X}_0\) (restando la media, opcionalmente dividiendo por la desviación estándar).&lt;/li&gt;
&lt;li&gt;Calculamos \(\Sigma = \mathbf{X}_0^\top \mathbf{X}_0\) (matriz de covarianza).&lt;/li&gt;
&lt;li&gt;Hallamos &lt;strong&gt;vectores propios&lt;/strong&gt; \(u_k\) y valores propios \(\lambda_k\) de \(\Sigma\).&lt;/li&gt;
&lt;li&gt;Elegimos los \(L\) vectores con mayores \(\lambda_k\) para capturar, p. ej., 99% de la varianza.&lt;/li&gt;
&lt;li&gt;Proyectamos los datos en esos vectores: se obtiene la &lt;strong&gt;representación&lt;/strong&gt; de \(\mathbf{X}_0\) en dimensión \(L\).&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;PCA&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pasos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Centrar&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datos&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Calcular&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;covarianza&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Eigen&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;decomposition&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Elegir&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;top&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;L&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;componentes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Proyectar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Reconstruir&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;ejemplos-visuales&#34;&gt;Ejemplos Visuales&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Ejemplo con 32 imágenes y Reconstrucción con 4 componentes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplo-de-datos-originales-y-reconstrucción-con-solo-4-componentes-principales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;32 imágenes antes de la reducción de dimensión (PCA)&#34;
           src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/pca_raw.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo de datos originales, y reconstrucción con solo 4 componentes principales.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
\[
    0,078 \mathbf{u}_1 + 0,062 \mathbf{u}_2 - 0,182 \mathbf{u}_3 + 0,179\mathbf{u}_4
\]&lt;p&gt;















&lt;figure  id=&#34;figure-reconstruccion&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pca_ex.png&#34; srcset=&#34;
               /minerias/10_reduccion_atributos/figures/pca_ex_hu15294993851617418670.webp 400w,
               /minerias/10_reduccion_atributos/figures/pca_ex_hu26270393708423628.webp 760w,
               /minerias/10_reduccion_atributos/figures/pca_ex_hu942683097186566598.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/pca_ex_hu15294993851617418670.webp&#34;
               width=&#34;760&#34;
               height=&#34;151&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Reconstruccion
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;En imágenes de caras (eigenfaces):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-vectores-base-se-llaman-eigenfaces-en-este-caso&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de eigenfaces (PCA en imágenes)&#34; srcset=&#34;
               /minerias/10_reduccion_atributos/figures/eigenfaces_hu4547894862833859281.webp 400w,
               /minerias/10_reduccion_atributos/figures/eigenfaces_hu9446926744243638575.webp 760w,
               /minerias/10_reduccion_atributos/figures/eigenfaces_hu2553934778585337579.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/eigenfaces_hu4547894862833859281.webp&#34;
               width=&#34;760&#34;
               height=&#34;475&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los vectores base se llaman eigenfaces en este caso.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;vectores-propios-y-covarianza&#34;&gt;Vectores Propios y Covarianza&lt;/h3&gt;
&lt;p&gt;Para &lt;strong&gt;reducir la dimensión&lt;/strong&gt; con PCA, se calcula la \textbf{matriz de covarianza} de los datos centrados y se obtienen sus \textbf{valores y vectores propios}. Recordemos:&lt;/p&gt;
\[
\text{cov}(X,Y) \;=\; \mathbb{E}\bigl[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])\bigr].
\]&lt;ul&gt;
&lt;li&gt;\(\text{cov}(X,Y) &gt; 0\) indica relación lineal directa (si \(X\) aumenta, \(Y\) también).&lt;/li&gt;
&lt;li&gt;\(\text{cov}(X,Y) &lt; 0\) indica relación lineal inversa.&lt;/li&gt;
&lt;li&gt;\(\text{cov}(X,Y) = 0\) sugiere ausencia de relación lineal aparente.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En \textbf{matriz de covarianza} \(\mathbf{\Sigma}\) (dimensión \(d\times d\)), cada entrada \(\Sigma_{ij}\) es la covarianza entre el atributo \(i\) y el atributo \(j\). Si tenemos datos centrados \(\mathbf{X}_0\), se define:&lt;/p&gt;
\[
\mathbf{\Sigma} 
\;=\; \mathbf{X}_0^\top \,\mathbf{X}_0 
\quad (\text{o bien } \tfrac{1}{n}\mathbf{X}_0^\top \mathbf{X}_0 \,\text{dependiendo de la convención de normalización}).
\]&lt;p&gt;Los \textbf{valores propios} \(\lambda\) y \textbf{vectores propios} \(\mathbf{u}\) de \(\mathbf{\Sigma}\) satisfacen&lt;/p&gt;
\[
\mathbf{\Sigma}\,\mathbf{u} 
\;=\; \lambda \,\mathbf{u}.
\]&lt;p&gt;Los \(\lambda\) más grandes corresponderán a las \textbf{direcciones de mayor varianza} en los datos.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;pca-aproximación-de-los-datos&#34;&gt;PCA: Aproximación de los Datos&lt;/h3&gt;
&lt;p&gt;En PCA, se busca aproximar el conjunto de datos \(\mathbf{X}\) con un subespacio de dimensión \(L\). Sean \(\{\mathbf{b}_i\}_{i=1..L}\) vectores ortonormales que generan ese subespacio (los ejes principales). El error de proyección se minimiza cuando:&lt;/p&gt;
\[
(\mathbf{b}_i)_{i=1..L} 
\;=\;
\underset{(\mathbf{b}_i)_{i=1..L}}{\arg\max}\;
\sum_{i=1}^{L}\,
\mathbf{b}_i^\top \,\mathrm{cov}(\mathbf{X})\,\mathbf{b}_i.
\]&lt;ul&gt;
&lt;li&gt;\(\mathrm{cov}(\mathbf{X})\) denota la matriz de covarianza de los datos centrados.&lt;/li&gt;
&lt;li&gt;La mejor base \(\{\mathbf{b}_1, \dots, \mathbf{b}_L\}\) corresponde, en la práctica, a los \(\mathbf{u}_1,\dots,\mathbf{u}_L\) vectores propios de \(\mathrm{cov}(\mathbf{X})\) asociados a los \(\lambda\) más grandes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En notación concreta:&lt;/p&gt;
\[
\mathrm{cov}(\mathbf{X})
\;=\;
(\mathbf{X} - \mu_\mathbf{X})^\top (\mathbf{X} - \mu_\mathbf{X}),
\]&lt;p&gt;
donde \(\mu_\mathbf{X}\) es la media de \(\mathbf{X}\).&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;pca-normalización-centrado-de-los-datos&#34;&gt;PCA: Normalización (Centrado) de los Datos&lt;/h3&gt;
&lt;p&gt;Sea \(\mathbf{X}\) una matriz \(d \times n\) (d: número de atributos, n: número de ejemplos). Para construir \(\mathbf{X}_0\) centrada:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Calcule la media de cada columna (atributo):
\[
   \mu_i = \tfrac{1}{d}\,\sum_{k=1}^d \mathbf{X}_i^{(k)} 
   \quad\bigl(\text{o a veces} \tfrac{1}{n}\,\sum_{k=1}^n \text{depende de filas/columnas}\bigr).
   \]&lt;/li&gt;
&lt;li&gt;Reste esa media a la columna:
\[
   \mathbf{X}_0 = 
   \mathbf{X} - \mu.
   \]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;En cada columna, la suma (o media) pasa a ser 0, eliminando el \textbf{sesgo}. Opcionalmente, se divide además por la desviación estándar para escalarlos. Así, evitamos que atributos con escalas grandes dominen la varianza total.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Xb -&amp;gt; (Xb - media_col)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   -&amp;gt; (opcional) / desviacion_col
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;pca-principio-y-método&#34;&gt;PCA: Principio y Método&lt;/h3&gt;
&lt;p&gt;Dado un dataset \(\mathbf{X}\), el algoritmo PCA se realiza típicamente así:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Crear&lt;/strong&gt; la matriz de datos \(\mathbf{X}\) (dimensión \(d \times n\)), donde cada columna representa un ejemplo (o cada fila, según convención).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
\[
   \mathbf{X}_0 = \mathbf{X} - \mu
   \]&lt;p&gt;
\(\mu\) es la media por atributo (o por componente), de modo que la media de cada columna quede en 0.&lt;br&gt;
&lt;em&gt;(Opcionalmente, se puede escalar además por la desviación estándar para igualar las escalas.)&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
\[
   \mathbf{\Sigma} = \mathbf{X}_0^\top \,\mathbf{X}_0 
   \]&lt;p&gt;
(o a veces dividido por \(n\), según la convención estadística).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Obtener&lt;/strong&gt; los vectores propios \(\mathbf{u}_k\) y valores propios \(\lambda_k\) de \(\mathbf{\Sigma}\):&lt;/p&gt;
\[
   \mathbf{\Sigma} \mathbf{u}_k = \lambda_k \mathbf{u}_k.
   \]&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ordenar&lt;/strong&gt; los vectores propios en orden decreciente de \(\lambda_k\).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Elegir&lt;/strong&gt; los \(L\) vectores con valores propios más grandes, cumpliendo por ejemplo que&lt;/p&gt;
\[ 
   \frac{\sum_{k=1}^{L}\,\lambda_k}{\sum_{k=1}^{n}\,\lambda_k} &gt; 0.95  \quad (\text{o el umbral deseado de varianza explicada}).
  \]&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Proyectar&lt;/strong&gt; los datos sobre esos \(L\) vectores para obtener una &lt;strong&gt;representación de dimensión menor&lt;/strong&gt; (\(\mathbb{R}^L\)). Cada ejemplo se convierte en \(\mathbf{u}_1^\top \mathbf{X}_0, \dots, \mathbf{u}_L^\top \mathbf{X}_0\).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Opcional) &lt;strong&gt;Reconstruir&lt;/strong&gt; los datos en la dimensión original si se desea una aproximación de \(\mathbf{X}\), sabiendo que hay una pérdida de información si \(L &lt; d\).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h4 id=&#34;intuición-máxima-varianza&#34;&gt;Intuición: Máxima Varianza&lt;/h4&gt;
&lt;p&gt;La idea fundamental de PCA es buscar direcciones (vectores) que &lt;strong&gt;maximicen&lt;/strong&gt; la varianza de la proyección. En particular, la primera componente principal es:&lt;/p&gt;
\[
\max_{\|\mathbf{u}\|=1}
\ 
\mathbf{u}^\top 
\bigl(\mathbf{X}_0^\top\,\mathbf{X}_0\bigr)\,
\mathbf{u},
\]&lt;p&gt;
y la \(\mathbf{u}\) que soluciona esto es el &lt;strong&gt;vector propio&lt;/strong&gt; de \(\mathbf{\Sigma} = \mathbf{X}_0^\top \mathbf{X}_0\) con &lt;strong&gt;mayor&lt;/strong&gt; valor propio \(\lambda\). Después, la segunda componente es la dirección ortogonal a la primera que maximiza la varianza restante, y así sucesivamente.&lt;/p&gt;
&lt;p&gt;La proyección en los primeros \(L\) vectores propios captura &lt;strong&gt;buena parte&lt;/strong&gt; de la varianza total, reduciendo la dimensión mientras preserva la mayor información posible.&lt;/p&gt;
&lt;h2 id=&#34;otros-algoritmos&#34;&gt;Otros Algoritmos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multidimensional Scaling (MDS)&lt;/strong&gt;: Preserva distancias entre puntos en la proyección.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;t-SNE&lt;/strong&gt;: Modela la cercanía de puntos en alta dimensión a una proyección 2D:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=NEaUSP4YerM&#34; title=&#34;Video sobre t-SNE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video explicativo t-SNE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ICA (Independent Component Analysis)&lt;/strong&gt;: Busca componentes estadísticamente independientes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;UMAP&lt;/strong&gt;: Se basa en geometría riemanniana y topología algebraica:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nq6iPZVUxZU&#34; title=&#34;Video sobre UMAP&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Más detalles en video UMAP&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autoencoder&lt;/strong&gt;: Red neuronal no supervisada para comprimir (encoder) y reconstruir (decoder), usando la capa latente como reducción de dimensión.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusiones&#34;&gt;Conclusiones&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Selección de atributos&lt;/strong&gt; (filtrada o basada en un modelo) reduce complejidad y puede mejorar rendimiento, sobre todo en métodos sensibles a ruido y correlaciones.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reducción de dimensionalidad&lt;/strong&gt; (PCA, t-SNE, UMAP, etc.) proyecta los datos a un espacio de menor dimensión, lo que facilita la visualización, disminuye ruido y puede acelerar el entrenamiento.&lt;/li&gt;
&lt;li&gt;Hay que equilibrar la &lt;strong&gt;simplicidad&lt;/strong&gt; lograda y la &lt;strong&gt;pérdida de información&lt;/strong&gt; al desechar o proyectar atributos.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Transfer Learning</title>
      <link>http://localhost:1313/deep/10_transferlearning/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/10_transferlearning/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides10_transferlearningpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/10_TransferLearning.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Object Detection</title>
      <link>http://localhost:1313/deep/11_computervision/</link>
      <pubDate>Tue, 19 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/11_computervision/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides11_computervisionpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/11_ComputerVision.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Redes Neuronales</title>
      <link>http://localhost:1313/minerias/11_nn/</link>
      <pubDate>Tue, 19 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/11_nn/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_nnetpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_NNet.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;hr&gt;
&lt;h2 id=&#34;perceptrón&#34;&gt;Perceptrón&lt;/h2&gt;
&lt;p&gt;Las &lt;strong&gt;Redes Neuronales&lt;/strong&gt; se inspiran ligeramente en la biología de las neuronas, tratando de simular cómo la señal fluye entre capas de neuronas. El &lt;strong&gt;Perceptrón&lt;/strong&gt; es la unidad básica que originó muchos avances en este campo.&lt;/p&gt;
&lt;h3 id=&#34;por-qué-este-nombre&#34;&gt;¿Por qué este nombre?&lt;/h3&gt;
&lt;p&gt;En biología, una neurona:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Recibe&lt;/strong&gt; neurotransmisores por las dendritas, provenientes de sinapsis de otras neuronas.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Se activa&lt;/strong&gt; al superar un cierto umbral de estimulación.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Emite&lt;/strong&gt; a su vez señal eléctrica por el axón, y libera neurotransmisores en sus sinapsis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-las-dendritas-reciben-información-si-supera-un-umbral-la-neurona-dispara-por-el-axón&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Esquema de neurona biológica&#34; srcset=&#34;
               /minerias/11_nn/figures/neurone_bio_hu5042147682634696871.webp 400w,
               /minerias/11_nn/figures/neurone_bio_hu8780734665714482128.webp 760w,
               /minerias/11_nn/figures/neurone_bio_hu11577556031772479973.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/neurone_bio_hu5042147682634696871.webp&#34;
               width=&#34;760&#34;
               height=&#34;560&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Las dendritas reciben información; si supera un umbral, la neurona dispara por el axón.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En un &lt;strong&gt;perceptrón&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Las entradas (análogo de dendritas) se combinan con ciertos pesos (\(w_i\)) y pasan por una función de activación que decide si hay salida (dispara) o no.&lt;/li&gt;
&lt;li&gt;Si supera un &lt;strong&gt;umbral&lt;/strong&gt;, la “neurona” artificial se activa.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;perceptrón-presentación&#34;&gt;Perceptrón: Presentación&lt;/h3&gt;
&lt;p&gt;El perceptrón más simple (con dos entradas \(x_1\) y \(x_2\)) se representa como:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Un &lt;strong&gt;suma ponderada&lt;/strong&gt; \(\sum_j x_j w_j - b\)&lt;/li&gt;
&lt;li&gt;Una &lt;strong&gt;función de activación&lt;/strong&gt; &lt;code&gt;f&lt;/code&gt; que decide la salida \(y\).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;En la versión binaria más elemental:&lt;/p&gt;
\[
y = f\bigl(x_1 w_1 + x_2 w_2 - b\bigr) = f\bigl(W^TX- b\bigr)
\]&lt;p&gt;Donde \(f\) es (en teoría) la función &lt;strong&gt;Heaviside&lt;/strong&gt;:&lt;/p&gt;
\[
f(z) = 
\begin{cases}
1, &amp; z \ge 0\\
0, &amp; z &lt; 0
\end{cases}
\]&lt;p&gt;Si \(x_1 w_1 + x_2 w_2 \) supera el umbral \(b\), la salida es \(1\).&lt;/p&gt;
&lt;p&gt;Algunas representaciones gráficas:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-perceptron-con-la-capa-de-entrada-x-la-funcion-de-activacion-f-la-salida-y&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Perceptrón con umbral binario&#34;
           src=&#34;http://localhost:1313/minerias/11_nn/figures/Binary_valued_threshold.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El perceptron, con la capa de entrada \(X\), la funcion de activacion \(f\), la salida \(y\)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;perceptrón-multicapa-mlp&#34;&gt;Perceptrón Multicapa (MLP)&lt;/h2&gt;
&lt;p&gt;Para resolver tareas más complejas, se agregan &lt;strong&gt;capas&lt;/strong&gt; de neuronas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Capa de entrada&lt;/strong&gt;: Recibe las características (\(x\) o \(\mathbf{a}^{(1)}\)).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Capas ocultas&lt;/strong&gt;: Transforman la información de forma intermedia.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Capa de salida&lt;/strong&gt;: Emite la predicción final (clase, valor, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ejemplo-de-un-mlp&#34;&gt;Ejemplo de un MLP&lt;/h3&gt;
&lt;p&gt;La señal va propagándose hacia adelante, capa por capa (“feed-forward”):
















&lt;figure  id=&#34;figure-propagación-en-un-mlp-con-2-capas-de-neuronas-intermedias&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;MLP de 2 capas ocultas&#34;
           src=&#34;http://localhost:1313/minerias/11_nn/figures/MLP2_L.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Propagación en un MLP, con 2 capas de neuronas intermedias
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ecuaciones-y-composición&#34;&gt;Ecuaciones y Composición&lt;/h3&gt;
&lt;h4 id=&#34;principio-de-una-capa&#34;&gt;Principio de una capa&lt;/h4&gt;
&lt;p&gt;Si la capa \(\ell\) tiene \(n_\ell\) neuronas, y recibimos como entrada \(\mathbf{a}^{(\ell)}\), la salida \(\mathbf{a}^{(\ell+1)}\) se obtiene aplicando:&lt;/p&gt;
\[
\mathbf{a}^{(\ell+1)} 
= f\bigl( \mathbf{W}^{(\ell,\ell+1)} \; \mathbf{a}^{(\ell)} \bigr)
\]&lt;p&gt;donde \(f\) es la función de activación elemento a elemento, y \(\mathbf{W}^{(\ell,\ell+1)}\) es la matriz de pesos entre la capa \(\ell\) y la capa \(\ell+1\).&lt;/p&gt;
&lt;p&gt;Por ejemplo, para una sola neurona \(j\) en la capa \(\ell+1\):&lt;/p&gt;
\[
a_j^{(\ell+1)} 
= f\Bigl(\sum_i w_{ji}^{(\ell,\ell+1)} \; a_i^{(\ell)}\Bigr)
\]&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de una capa con 4 neuronas de salida&#34; srcset=&#34;
               /minerias/11_nn/figures/MLP2_L0_hu9982466221484515949.webp 400w,
               /minerias/11_nn/figures/MLP2_L0_hu13782756864887087107.webp 760w,
               /minerias/11_nn/figures/MLP2_L0_hu17769283940668246020.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/MLP2_L0_hu9982466221484515949.webp&#34;
               width=&#34;544&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;mlp-composición-de-capas&#34;&gt;MLP: composición de capas&lt;/h4&gt;
&lt;p&gt;Un MLP con \(L\) capas puede verse como una &lt;strong&gt;composición de funciones&lt;/strong&gt;:&lt;/p&gt;
\[
\mathbf{a}^{(2)} = h^{(1,2)}(\mathbf{a}^{(1)}), 
\quad
\mathbf{a}^{(3)} = h^{(2,3)}(\mathbf{a}^{(2)}) 
\quad \ldots \quad
\mathbf{a}^{(L)} = h^{(L-1,L)}(\mathbf{a}^{(L-1)}).
\]&lt;p&gt;Por tanto:&lt;/p&gt;
\[
\mathbf{a}^{(L)} 
= h^{(L-1,L)} \circ \cdots \circ h^{(1,2)}\;(\mathbf{a}^{(1)}).
\]&lt;p&gt;Esta \(\mathbf{a}^{(L)}\) es la &lt;strong&gt;salida final&lt;/strong&gt; del MLP.&lt;/p&gt;
&lt;p&gt;Se puede escribir una funcion del MLP:&lt;/p&gt;
\[
MLP = h^{(L-1, L)} \circ h^{(L-2, L-1)} \circ ... \circ h^{(1,2)} \text{ \textbf{tal que} } MLP(\mathbf{a}^{(1)}) = \mathbf{a}^{(L)}
\]&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Conclusión&lt;/strong&gt;: un MLP es una &lt;strong&gt;función no lineal&lt;/strong&gt; compuesta. A mayor número de capas (profundidad), mayor &lt;strong&gt;capacidad&lt;/strong&gt; de representar funciones complejas.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;funciones-de-activación&#34;&gt;Funciones de Activación&lt;/h2&gt;
&lt;p&gt;La función de activación en cada neurona &lt;strong&gt;rompe la linealidad&lt;/strong&gt;. Sin ella, el modelo sería solo una combinación lineal de los datos. Algunas funciones típicas:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;strong&gt;Nombre&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Gráfico&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Ecuación&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Valores en&lt;/strong&gt; \(\pm\infty\)&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Valores derivada en&lt;/strong&gt; \(\pm\infty\)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Heaviside&lt;/strong&gt; (teórica)&lt;/td&gt;
          &lt;td&gt;[No derivable]&lt;/td&gt;
          &lt;td&gt;\(f(z)=\mathbf{1}_{z\ge0}\)&lt;/td&gt;
          &lt;td&gt;0,1&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Sigmoide&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;sigmoide&#34; srcset=&#34;
               /minerias/11_nn/figures/sigmoide_hu2258526441697663153.webp 400w,
               /minerias/11_nn/figures/sigmoide_hu11249631941563051249.webp 760w,
               /minerias/11_nn/figures/sigmoide_hu6025699800413662374.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/sigmoide_hu2258526441697663153.webp&#34;
               width=&#34;250&#34;
               height=&#34;106&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;\(f(z)=\frac{1}{1+e^{-z}}\)&lt;/td&gt;
          &lt;td&gt;0; 1&lt;/td&gt;
          &lt;td&gt;0; 0&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Tanh&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;tanh&#34; srcset=&#34;
               /minerias/11_nn/figures/tanh_hu2161236630147589151.webp 400w,
               /minerias/11_nn/figures/tanh_hu13683484027632460599.webp 760w,
               /minerias/11_nn/figures/tanh_hu7537390151399161997.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/tanh_hu2161236630147589151.webp&#34;
               width=&#34;250&#34;
               height=&#34;106&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;\(f(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}\)&lt;/td&gt;
          &lt;td&gt;-1; 1&lt;/td&gt;
          &lt;td&gt;0; 0&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;ReLU&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;relu&#34; srcset=&#34;
               /minerias/11_nn/figures/relu_hu14682383464111917821.webp 400w,
               /minerias/11_nn/figures/relu_hu247199606108359105.webp 760w,
               /minerias/11_nn/figures/relu_hu1501887440186754615.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/relu_hu14682383464111917821.webp&#34;
               width=&#34;250&#34;
               height=&#34;106&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;\(f(z)=\max(0,z)\)&lt;/td&gt;
          &lt;td&gt;0; \(z\)&lt;/td&gt;
          &lt;td&gt;0; 1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;ELU&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;elu&#34; srcset=&#34;
               /minerias/11_nn/figures/elu_hu3293995043550659080.webp 400w,
               /minerias/11_nn/figures/elu_hu16152205053403592329.webp 760w,
               /minerias/11_nn/figures/elu_hu15040008162705597673.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/elu_hu3293995043550659080.webp&#34;
               width=&#34;250&#34;
               height=&#34;100&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;\(f(z)=\begin{cases}\alpha(e^z-1)&amp;z&lt;0\\ z&amp;z\ge0\end{cases}\)&lt;/td&gt;
          &lt;td&gt;\(-\alpha\); \(z\)&lt;/td&gt;
          &lt;td&gt;0; 1&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Heaviside&lt;/strong&gt; (original) no es derivable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sigmoide / Tanh&lt;/strong&gt;: buenas para salidas en [0,1] o [-1,1], pero pueden saturarse.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReLU&lt;/strong&gt;: muy popular en redes profundas.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ELU&lt;/strong&gt;: variante suavizada por debajo de 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;recuerdos-de-optimización-y-entrenamiento&#34;&gt;Recuerdos de Optimización y Entrenamiento&lt;/h2&gt;
&lt;p&gt;Para entrenar la red, definimos una &lt;strong&gt;función de costo&lt;/strong&gt; (\(\ell\)), por ejemplo el error entre salidas reales y predichas. Queremos &lt;strong&gt;minimizar&lt;/strong&gt; esa función respecto de los &lt;strong&gt;pesos&lt;/strong&gt; de la red.&lt;/p&gt;
&lt;h3 id=&#34;descenso-del-gradiente&#34;&gt;Descenso del Gradiente&lt;/h3&gt;
&lt;p&gt;Si \(\theta\) representa todos los pesos:&lt;/p&gt;
\[
\theta \leftarrow \theta - \alpha \; \nabla_\theta \ell(\theta)
\]&lt;p&gt;donde \(\alpha\) es la &lt;strong&gt;tasa de aprendizaje&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-visualización-conceptual&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Convergencia en un valle del “paisaje de costos”&#34; srcset=&#34;
               /minerias/11_nn/figures/LossAlps_hu15806339177112344745.webp 400w,
               /minerias/11_nn/figures/LossAlps_hu9473298813042643160.webp 760w,
               /minerias/11_nn/figures/LossAlps_hu7762387643821809596.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/LossAlps_hu15806339177112344745.webp&#34;
               width=&#34;760&#34;
               height=&#34;498&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Visualización conceptual
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Se pueden usar mini-batches (stochastic gradient descent - SGD) para computar gradientes parciales y hacer actualizaciones más frecuentes.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;backpropagation-el-núcleo-del-entrenamiento&#34;&gt;Backpropagation: el núcleo del entrenamiento&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Backpropagation&lt;/strong&gt; (o retropropagación del error) es el algoritmo que:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Calcula&lt;/strong&gt; la salida de la red (forward pass).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evalúa&lt;/strong&gt; el error (función de costo).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Propaga&lt;/strong&gt; gradientes hacia atrás (desde la salida a cada capa) usando la &lt;strong&gt;regla de la cadena&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Actualiza&lt;/strong&gt; cada peso según su gradiente parcial.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Explicación más detallada:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tras un &lt;strong&gt;forward pass&lt;/strong&gt;, conocemos la salida \(\mathbf{a}^{(L)}\).&lt;/li&gt;
&lt;li&gt;Comparamos con la etiqueta real y obtenemos el &lt;strong&gt;error&lt;/strong&gt; \(\ell\).&lt;/li&gt;
&lt;li&gt;Para cada capa \(\ell\), la &lt;strong&gt;derivada&lt;/strong&gt; de \(\ell\) respecto a \(\mathbf{W}^{(\ell,\ell+1)}\) se computa recursivamente, empezando por la capa de salida y yendo hacia la capa de entrada.&lt;/li&gt;
&lt;li&gt;Esto es posible gracias a que
\[
  \frac{\partial \ell}{\partial \mathbf{W}^{(\ell,\ell+1)}} 
  = \frac{\partial \ell}{\partial \mathbf{a}^{(\ell+1)}} 
  \cdot \frac{\partial \mathbf{a}^{(\ell+1)}}{\partial \mathbf{z}^{(\ell+1)}} 
  \cdot \frac{\partial \mathbf{z}^{(\ell+1)}}{\partial \mathbf{W}^{(\ell,\ell+1)}}.
  \]&lt;/li&gt;
&lt;li&gt;Se multiplican derivadas (regla de la cadena) y se obtiene la dirección de ajuste de cada peso.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-error-fluye-hacia-atrás-para-ajustar-cada-capa&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representación esquemática de backpropagation (imagen ilustrativa)&#34; srcset=&#34;
               /minerias/11_nn/figures/backprop_hu5437070840985716372.webp 400w,
               /minerias/11_nn/figures/backprop_hu525999881374688638.webp 760w,
               /minerias/11_nn/figures/backprop_hu15532578210586162933.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/backprop_hu5437070840985716372.webp&#34;
               width=&#34;760&#34;
               height=&#34;543&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El error fluye hacia atrás para ajustar cada capa
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En la práctica, librerías como &lt;strong&gt;PyTorch&lt;/strong&gt; o &lt;strong&gt;TensorFlow&lt;/strong&gt; hacen esto automáticamente mediante &lt;strong&gt;autograd&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;representaciones&#34;&gt;Representaciones&lt;/h2&gt;
&lt;p&gt;En un MLP, cada capa oculta \(\mathbf{a}^{(\ell)}\) forma una &lt;strong&gt;representación&lt;/strong&gt; distinta de los datos. Al componer varias capas, se construyen representaciones de nivel creciente de abstracción.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-cada-capa-genera-un-nuevo-vector-de-características-activaciones&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;MLP con 2 capas ocultas y salidas intermedias (activaciones)&#34; srcset=&#34;
               /minerias/11_nn/figures/MLP2_L6_hu2654510542182663165.webp 400w,
               /minerias/11_nn/figures/MLP2_L6_hu9619913887787023670.webp 760w,
               /minerias/11_nn/figures/MLP2_L6_hu6647341152618120042.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/MLP2_L6_hu2654510542182663165.webp&#34;
               width=&#34;760&#34;
               height=&#34;594&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cada capa genera un nuevo vector de características (activaciones)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;En imágenes: capas iniciales detectan contornos, capas intermedias detectan partes (nariz, ojo&amp;hellip;), capas finales reconocen objetos concretos.&lt;/li&gt;
&lt;li&gt;En texto: capas iniciales identifican gramática, capas intermedias reconocen entidades, capas profundas comprenden significados complejos (sentimientos, intenciones…).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;composicionalidad-de-las-representaciones&#34;&gt;Composicionalidad de las representaciones&lt;/h3&gt;
&lt;p&gt;En CNN u otras redes, se pueden visualizar “filtros” que activan sobre patrones (bordes, texturas, etc.).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-se-compone-con-los-filtros-mas-basicos-los-filtros-mas-complejos-una-cara-se-compone-de-2-ojos-una-nariz-y-una-boca&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Visualización de filtros (composición de características)&#34; srcset=&#34;
               /minerias/11_nn/figures/filters_visualization_hu17234472207453702754.webp 400w,
               /minerias/11_nn/figures/filters_visualization_hu9084227478072464886.webp 760w,
               /minerias/11_nn/figures/filters_visualization_hu7053406489742120465.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/filters_visualization_hu17234472207453702754.webp&#34;
               width=&#34;679&#34;
               height=&#34;672&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Se compone con los filtros mas basicos los filtros mas complejos: una cara se compone de 2 ojos una nariz y una boca.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;visibilidad-de-filtros&#34;&gt;Visibilidad de filtros&lt;/h3&gt;
&lt;p&gt;Una video muy interesante de la &lt;a href=&#34;https://www.youtube.com/watch?v=AgkfIQ4IGaM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Visualization Toolbox&lt;/a&gt; para ver en tiempo real lo que activa los diferentes neuronas, las imagenes del dataset que les activan lo mas, y imagenes artificiales optimizada para activar los filtros.&lt;/p&gt;
&lt;p&gt;La visualizacion de las imagenes que activan el mas los filtros de un AlexNet en &lt;a href=&#34;https://distill.pub/2017/feature-visualization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Distill.pub: Feature Visualization&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-primeros-filtros-son-lo-mas-simple-como-detecor-de-edge-y-se-van-complejando-tipo-texturas-y-despues-objetos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Visualización de filtros (composición de características)&#34; srcset=&#34;
               /minerias/11_nn/figures/feature_vis_hu12627367647364061408.webp 400w,
               /minerias/11_nn/figures/feature_vis_hu3957077363820538824.webp 760w,
               /minerias/11_nn/figures/feature_vis_hu7687384663625210479.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/feature_vis_hu12627367647364061408.webp&#34;
               width=&#34;760&#34;
               height=&#34;284&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los primeros filtros son lo mas simple como detecor de edge, y se van complejando tipo texturas y despues objetos.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;representation-learning-for-transfer&#34;&gt;Representation Learning for Transfer&lt;/h2&gt;
&lt;h3 id=&#34;aprendizaje-de-representaciones&#34;&gt;Aprendizaje de Representaciones&lt;/h3&gt;
&lt;p&gt;El &lt;strong&gt;aprendizaje de representaciones&lt;/strong&gt; (Representation Learning) se basa en que la red neuronal aprende, de forma automática, &lt;strong&gt;características&lt;/strong&gt; o &lt;strong&gt;features&lt;/strong&gt; útiles directamente desde los datos brutos (imágenes, texto, etc.). Estas capas ocultas (o &lt;em&gt;embeddings&lt;/em&gt;) pueden:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Generalizar&lt;/strong&gt; mejor que las características diseñadas a mano (hand-crafted features).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Adaptarse&lt;/strong&gt; a distintas tareas si se transfieren.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Los intereses son varios, por ejemplo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cada capa proporciona una representación de los datos de entrada con dimensiones más bajas.&lt;/li&gt;
&lt;li&gt;Esas representaciones provenientes únicamente de los datos brutos a veces superan conjuntos de descriptores clásicos \(\rightarrow\) &lt;a href=&#34;https://arxiv.org/pdf/1609.08675&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube-8M&lt;/a&gt;: Representaciones con LogReg superaban a todos los clasificadores de vanguardia en muchas tareas.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-las-representaciones-en-altas-dimensiones-se-proyectan-a-2d-y-muestran-agrupaciones-naturales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;t-SNE de representaciones de AlexNet&#34; srcset=&#34;
               /minerias/11_nn/figures/tsne_hu6012296096494109504.webp 400w,
               /minerias/11_nn/figures/tsne_hu6407126937998179609.webp 760w,
               /minerias/11_nn/figures/tsne_hu17633236819676664136.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/tsne_hu6012296096494109504.webp&#34;
               width=&#34;760&#34;
               height=&#34;283&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Las representaciones en altas dimensiones se proyectan a 2D y muestran agrupaciones naturales.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Ejemplo: después de entrenar en ImageNet, las capas profundas “entienden” rasgos básicos de las imágenes. Si queremos clasificar perros vs. gatos, basta con re-entrenar poco.)&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;transferencia&#34;&gt;Transferencia&lt;/h3&gt;
&lt;p&gt;Una red entrenada en una tarea (p. ej. reconocimiento de objetos en imágenes) puede servir como base para otras tareas (p. ej. detectar nuevos tipos de objetos). Se aprovecha el &lt;strong&gt;transfer learning&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Entrenamos una red (p. ej. CNN) en una gran base (ImageNet).&lt;/li&gt;
&lt;li&gt;Se “toman” sus capas iniciales como &lt;strong&gt;extractor de características&lt;/strong&gt; (al estar entrenadas en millones de imágenes, captan contornos y patrones generales).&lt;/li&gt;
&lt;li&gt;Para una nueva tarea con pocos datos, se conectan la capa final (llamado head) nueva o se re-entrena ligeramente (fine-tuning).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;De este modo, la &lt;strong&gt;representación&lt;/strong&gt; (las activaciones intermedias) es &lt;strong&gt;reutilizada&lt;/strong&gt;. Esto ahorra tiempo y datos:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;El MLP o CNN grande provee features genéricas.&lt;/li&gt;
&lt;li&gt;Sólo ajustamos parcialmente la red (o las últimas capas) a la tarea específica.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;frameworks-populares&#34;&gt;Frameworks Populares&lt;/h2&gt;
&lt;h3 id=&#34;keras&#34;&gt;Keras&lt;/h3&gt;
&lt;p&gt;Biblioteca de Python de alto nivel para Redes Neuronales, sobre TensorFlow u otros backends.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Keras logo&#34; srcset=&#34;
               /minerias/11_nn/figures/keras_hu1035629169656843260.webp 400w,
               /minerias/11_nn/figures/keras_hu8780139607811972134.webp 760w,
               /minerias/11_nn/figures/keras_hu15459690173681857519.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/keras_hu1035629169656843260.webp&#34;
               width=&#34;760&#34;
               height=&#34;220&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ejemplo CNN preentrenada (VGG16)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorial RNN-LSTM seq2seq&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Embeddings de palabras preentrenados&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pytorch&#34;&gt;PyTorch&lt;/h3&gt;
&lt;p&gt;Biblioteca de Python centrada en el cálculo automático de gradientes y en el aprendizaje profundo.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;PyTorch logo&#34; srcset=&#34;
               /minerias/11_nn/figures/pytorch_hu8893412317164389539.webp 400w,
               /minerias/11_nn/figures/pytorch_hu16231463881976280037.webp 760w,
               /minerias/11_nn/figures/pytorch_hu894001013880019535.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/pytorch_hu8893412317164389539.webp&#34;
               width=&#34;512&#34;
               height=&#34;256&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorial Transfer Learning con ResNet18&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pytorch.org/audio/stable/tutorials/speech_recognition_pipeline_tutorial.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Speech recognition con Wav2Vec2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RNN-GRU seq2seq para traducción&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;huggingface-transformers&#34;&gt;HuggingFace Transformers&lt;/h3&gt;
&lt;p&gt;Biblioteca en Python para modelos tipo &lt;strong&gt;Transformers&lt;/strong&gt; (BERT, GPT, etc.).&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;HuggingFace logo&#34; srcset=&#34;
               /minerias/11_nn/figures/hf_logo_hu4463973729321469342.webp 400w,
               /minerias/11_nn/figures/hf_logo_hu16750015608575083964.webp 760w,
               /minerias/11_nn/figures/hf_logo_hu855115890972270235.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/hf_logo_hu4463973729321469342.webp&#34;
               width=&#34;760&#34;
               height=&#34;175&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Soporta modelos &lt;strong&gt;preentrenados&lt;/strong&gt; en texto, visión, audio&amp;hellip;&lt;/li&gt;
&lt;li&gt;Otras librerías: &lt;code&gt;Diffusers&lt;/code&gt; (imágenes generativas), &lt;code&gt;Datasets&lt;/code&gt;, &lt;code&gt;Accelerate&lt;/code&gt;, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Intro a la NLP</title>
      <link>http://localhost:1313/minerias/12_nlp/</link>
      <pubDate>Mon, 18 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/12_nlp/</guid>
      <description>&lt;p&gt;This is a class from an invited speaker, &lt;a href=&#34;https://cl.linkedin.com/in/juanjo-alegria&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Juan Jose Alegria&lt;/a&gt;!&lt;/p&gt;
&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esc12_introduccion_nlppdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/c12_introduccio%cc%81n_nlp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Generative LLMs</title>
      <link>http://localhost:1313/deep/n_generative_llms/</link>
      <pubDate>Mon, 11 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/n_generative_llms/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslidesn_generative_llmspdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/N_Generative_LLMs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Large Multimodal Models</title>
      <link>http://localhost:1313/deep/n_multimodal_models/</link>
      <pubDate>Sun, 10 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/n_multimodal_models/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslidesn_multimodal_modelspdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/N_Multimodal_Models.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>http://localhost:1313/teaching/deep/</link>
      <pubDate>Sat, 24 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teaching/deep/</guid>
      <description>&lt;h3 id=&#34;all-the-different-classes-can-be-found-heredeep-index&#34;&gt;All the different classes can be found &lt;a href=&#34;../../deep-index&#34;&gt;here&lt;/a&gt;!&lt;/h3&gt;
&lt;p&gt;This is the CC66204 course from the Universidad de Chile. Based on the class of &lt;a href=&#34;https://github.com/ivansipiran&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ivan Sipiran&lt;/a&gt;, I added details in each of the classes, allowing to understand on how we get to the recent large multimodal models. The github is &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;br&gt;
Here&amp;rsquo;s a summary:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;General introduction&lt;/strong&gt;: Overview of the class, reminders from Machine Learning,&amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Basics&lt;/strong&gt;: Perceptron, Vanilla Gradient Descent, MLP, Backprop,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Losses and Activations&lt;/strong&gt;: General losses, Softmax, CE, Activation functions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Initialization and Optimization&lt;/strong&gt;: Weights initialization, Complex gradient descents&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Penalization, Dropout, Data augmentation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Convolutional Layer&lt;/strong&gt;: Convolution, Padding, Pooling, LeNet&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Computer Vision Architectures&lt;/strong&gt;: ImageNet, Revolution of depth, Classical classifiers architectures&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transfer Learning&lt;/strong&gt;: Motivation, Principle, Types of TL, Weights unfreezing, Pre-training datasets, SoTA&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Object Detection&lt;/strong&gt;: Principle, IoU and mAP, Classical Object Detection, Segmentation and Mask-RCNN, SoTA&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Recurrent Layer&lt;/strong&gt;: Sequential Modeling, RNN, LSTM, GRU,&amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Attention&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Transformers&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generative Large Language Models&lt;/strong&gt;: Language Modeling and Temperature, Abilities and In-Context-Learning, Tokenization, Instructions, Alignments, Reasonings, Training and Evaluating in Practice, LLMs as Agents&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Large Multimodal Models&lt;/strong&gt;: Multimodality, Fusion, Original tasks and datasets, Early multimodal transformers, CLIP and text2image Diffusion, Frozen encoders, BLIP 1/2/3 and LMM Assistants, Open-source training datasets, LMM evaluation, Video, Multimodal Tokenization&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Deep Natural Language Feature Learning for Interpretable Prediction</title>
      <link>http://localhost:1313/publication/emnlp23-nllf/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/emnlp23-nllf/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Targeted Image Data Augmentation Increases Basic Skills Captioning Robustness</title>
      <link>http://localhost:1313/publication/gem23-tida/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/gem23-tida/</guid>
      <description></description>
    </item>
    
    <item>
      <title>🎉 Easily create your own simple yet highly customizable blog</title>
      <link>http://localhost:1313/not_used/post/get-started/</link>
      <pubDate>Fri, 27 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/get-started/</guid>
      <description>&lt;p&gt;Welcome 👋&lt;/p&gt;



&lt;details class=&#34;print:hidden xl:hidden&#34; open&gt;
  &lt;summary&gt;Table of Contents&lt;/summary&gt;
  &lt;div class=&#34;text-sm&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#get-started&#34;&gt;Get Started&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#-click-here-to-become-a-sponsor-and-help-support-hugo-bloxs-future-httpshugobloxcomsponsor&#34;&gt;&lt;a href=&#34;https://hugoblox.com/sponsor/&#34;&gt;❤️ Click here to become a sponsor and help support Hugo Blox&amp;rsquo;s future ❤️&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#ecosystem&#34;&gt;Ecosystem&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#inspiration&#34;&gt;Inspiration&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#themes&#34;&gt;Themes&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
  &lt;/div&gt;
&lt;/details&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The Hugo Blox website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site&lt;/li&gt;
&lt;li&gt;The template can be modified and customised to suit your needs. It&amp;rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a &lt;strong&gt;no-code solution (write in Markdown and customize with YAML parameters)&lt;/strong&gt; and having &lt;strong&gt;flexibility to later add even deeper personalization with HTML and CSS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;get-started&#34;&gt;Get Started&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;👉 &lt;a href=&#34;https://hugoblox.com/templates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Create a new site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;📚 &lt;a href=&#34;https://docs.hugoblox.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Personalize your site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;💬 &lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chat with the &lt;strong&gt;Hugo Blox community&lt;/strong&gt;&lt;/a&gt; or &lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Hugo community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;🐦 Twitter: &lt;a href=&#34;https://twitter.com/GetResearchDev&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@GetResearchDev&lt;/a&gt; &lt;a href=&#34;https://twitter.com/GeorgeCushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@GeorgeCushen&lt;/a&gt; #MadeWithHugoBlox&lt;/li&gt;
&lt;li&gt;💡 &lt;a href=&#34;https://github.com/HugoBlox/hugo-blox-builder/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Request a &lt;strong&gt;feature&lt;/strong&gt; or report a &lt;strong&gt;bug&lt;/strong&gt; for &lt;em&gt;Hugo Blox&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;⬆️ &lt;strong&gt;Updating Hugo Blox?&lt;/strong&gt; View the &lt;a href=&#34;https://docs.hugoblox.com/reference/update/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Update Guide&lt;/a&gt; and &lt;a href=&#34;https://github.com/HugoBlox/hugo-blox-builder/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/h2&gt;
&lt;p&gt;To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.&lt;/p&gt;
&lt;h3 id=&#34;-click-here-to-become-a-sponsor-and-help-support-hugo-bloxs-future-httpshugobloxcomsponsor&#34;&gt;&lt;a href=&#34;https://hugoblox.com/sponsor/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;❤️ Click here to become a sponsor and help support Hugo Blox&amp;rsquo;s future ❤️&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As a token of appreciation for sponsoring, you can &lt;strong&gt;unlock &lt;a href=&#34;https://hugoblox.com/sponsor/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;these&lt;/a&gt; awesome rewards and extra features 🦄✨&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;ecosystem&#34;&gt;Ecosystem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/GetRD/academic-file-converter&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bibtex To Markdown&lt;/a&gt;:&lt;/strong&gt; Automatically import publications from BibTeX&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;inspiration&#34;&gt;Inspiration&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://hugoblox.com/creators/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learn what other &lt;strong&gt;creators&lt;/strong&gt;&lt;/a&gt; are building with this template.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page builder&lt;/strong&gt; - Create &lt;em&gt;anything&lt;/em&gt; with no-code &lt;a href=&#34;https://hugoblox.com/blocks/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;blocks&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;elements&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit any type of content&lt;/strong&gt; - Blog posts, publications, talks, slides, projects, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create content&lt;/strong&gt; in &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.hugoblox.com/getting-started/cms/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&lt;/a&gt;, or &lt;a href=&#34;https://docs.hugoblox.com/getting-started/cms/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt; - Fully customizable &lt;a href=&#34;https://docs.hugoblox.com/getting-started/customize/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;color&lt;/strong&gt; and &lt;strong&gt;font themes&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Code and Math&lt;/strong&gt; - Code syntax highlighting and LaTeX math supported&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrations&lt;/strong&gt; - &lt;a href=&#34;https://analytics.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Analytics&lt;/a&gt;, &lt;a href=&#34;https://disqus.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disqus commenting&lt;/a&gt;, Maps, Contact Forms, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beautiful Site&lt;/strong&gt; - Simple and refreshing one-page design&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry-Leading SEO&lt;/strong&gt; - Help get your website found on search engines and social media&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Media Galleries&lt;/strong&gt; - Display your images and videos with captions in a customizable gallery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile Friendly&lt;/strong&gt; - Look amazing on every screen with a mobile friendly version of your site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-language&lt;/strong&gt; - 35+ language packs including English, 中文, and Português&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt; - Each author gets their own profile page&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privacy Pack&lt;/strong&gt; - Assists with GDPR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stand Out&lt;/strong&gt; - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-Click Deployment&lt;/strong&gt; - No servers. No databases. Only files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;p&gt;Hugo Blox and its templates come with &lt;strong&gt;automatic day (light) and night (dark) mode&lt;/strong&gt; built-in. Visitors can choose their preferred mode by clicking the sun/moon icon in the header.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.hugoblox.com/getting-started/customize/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Choose a stunning &lt;strong&gt;theme&lt;/strong&gt; and &lt;strong&gt;font&lt;/strong&gt;&lt;/a&gt; for your site. Themes are fully customizable.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2016-present &lt;a href=&#34;https://georgecushen.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;George Cushen&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Released under the &lt;a href=&#34;https://github.com/HugoBlox/hugo-blox-builder/blob/main/LICENSE.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>🧠 Sharpen your thinking with a second brain</title>
      <link>http://localhost:1313/not_used/post/second-brain/</link>
      <pubDate>Thu, 26 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/second-brain/</guid>
      <description>&lt;p&gt;Create a personal knowledge base and share your knowledge with your peers.&lt;/p&gt;
&lt;p&gt;Hugo Blox web framework empowers you with one of the most flexible note-taking capabilities out there.&lt;/p&gt;
&lt;p&gt;Create a powerful knowledge base that works on top of a local folder of plain text Markdown files.&lt;/p&gt;
&lt;p&gt;Use it as your second brain, either publicly sharing your knowledge with your peers via your website, or via a private GitHub repository and password-protected site just for yourself.&lt;/p&gt;
&lt;h2 id=&#34;mindmaps&#34;&gt;Mindmaps&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports a Markdown extension for mindmaps.&lt;/p&gt;
&lt;p&gt;With this open format, can even edit your mindmaps in other popular tools such as Obsidian.&lt;/p&gt;
&lt;p&gt;Simply insert a Markdown code block labelled as &lt;code&gt;markmap&lt;/code&gt; and optionally set the height of the mindmap as shown in the example below.&lt;/p&gt;
&lt;p&gt;Mindmaps can be created by simply writing the items as a Markdown list within the &lt;code&gt;markmap&lt;/code&gt; code block, indenting each item to create as many sub-levels as you need:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap {height=&#34;200px&#34;}
- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Anh here&amp;rsquo;s a more advanced mindmap with formatting, code blocks, and math:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap
- Mindmaps
  - Links
    - [Hugo Blox Docs](https://docs.hugoblox.com/)
    - [Discord Community](https://discord.gg/z8wNYzb)
    - [GitHub](https://github.com/HugoBlox/hugo-blox-builder)
  - Features
    - Markdown formatting
    - **inline** ~~text~~ *styles*
    - multiline
      text
    - `inline code`
    -
      ```js
      console.log(&#39;hello&#39;);
      console.log(&#39;code block&#39;);
      ```
    - Math: $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 500px;&#34;&gt;

&lt;pre&gt;- Mindmaps
  - Links
    - [Hugo Blox Docs](https://docs.hugoblox.com/)
    - [Discord Community](https://discord.gg/z8wNYzb)
    - [GitHub](https://github.com/HugoBlox/hugo-blox-builder)
  - Features
    - Markdown formatting
    - **inline** ~~text~~ *styles*
    - multiline
      text
    - `inline code`
    -
      ```js
      console.log(&#39;hello&#39;);
      console.log(&#39;code block&#39;);
      ```
    - Math: $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&#34;highlighting&#34;&gt;Highlighting&lt;/h2&gt;
&lt;p&gt;&lt;mark&gt;Highlight&lt;/mark&gt; important text with &lt;code&gt;mark&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;Highlighted text&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;callouts&#34;&gt;Callouts&lt;/h2&gt;
&lt;p&gt;Use &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/#callouts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;callouts&lt;/a&gt; (aka &lt;em&gt;asides&lt;/em&gt;, &lt;em&gt;hints&lt;/em&gt;, or &lt;em&gt;alerts&lt;/em&gt;) to draw attention to notes, tips, and warnings.&lt;/p&gt;
&lt;p&gt;By wrapping a paragraph in &lt;code&gt;{{% callout note %}} ... {{% /callout %}}&lt;/code&gt;, it will render as an aside.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% callout note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% /callout %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Or use the &lt;code&gt;warning&lt;/code&gt; callout type so your readers don&amp;rsquo;t miss critical details:&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-yellow-100 dark:bg-yellow-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-red-400&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.&lt;/span&gt;
&lt;/div&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>📈 Communicate your results effectively with the best data visualizations</title>
      <link>http://localhost:1313/not_used/post/data-visualization/</link>
      <pubDate>Wed, 25 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/data-visualization/</guid>
      <description>&lt;p&gt;Hugo Blox is designed to give technical content creators a seamless experience. You can focus on the content and Hugo Blox handles the rest.&lt;/p&gt;
&lt;p&gt;Use popular tools such as Plotly, Mermaid, and data frames.&lt;/p&gt;
&lt;h2 id=&#34;charts&#34;&gt;Charts&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the popular &lt;a href=&#34;https://plot.ly/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Plotly&lt;/a&gt; format for interactive data visualizations. With Plotly, you can design almost any kind of visualization you can imagine!&lt;/p&gt;
&lt;p&gt;Save your Plotly JSON in your page folder, for example &lt;code&gt;line-chart.json&lt;/code&gt;, and then add the &lt;code&gt;{{&amp;lt; chart data=&amp;quot;line-chart&amp;quot; &amp;gt;}}&lt;/code&gt; shortcode where you would like the chart to appear.&lt;/p&gt;
&lt;p&gt;Demo:&lt;/p&gt;




&lt;div id=&#34;chart-217684953&#34; class=&#34;chart&#34;&gt;&lt;/div&gt;
&lt;script&gt;
  async function fetchChartJSON() {
    console.debug(&#39;Hugo Blox fetching chart JSON...&#39;)
    const response = await fetch(&#39;.\/line-chart.json&#39;);
    return await response.json();
  }

  (function() {
    let a = setInterval( function() {
      if ( typeof window.Plotly === &#39;undefined&#39; ) {
        console.debug(&#39;Plotly not loaded yet...&#39;)
        return;
      }
      clearInterval( a );

      fetchChartJSON().then(chart =&gt; {
        console.debug(&#39;Plotting chart...&#39;)
        window.Plotly.newPlot(&#39;chart-217684953&#39;, chart.data, chart.layout, {responsive: true});
      });
    }, 500 );
  })();
&lt;/script&gt;

&lt;p&gt;You might also find the &lt;a href=&#34;http://plotly-json-editor.getforge.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Plotly JSON Editor&lt;/a&gt; useful.&lt;/p&gt;
&lt;h2 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the &lt;em&gt;Mermaid&lt;/em&gt; Markdown extension for diagrams.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;flowchart&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;graph TD
A[Hard] --&gt;|Text| B(Round)
B --&gt; C{Decision}
C --&gt;|One| D[Result 1]
C --&gt;|Two| E[Result 2]
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;sequence diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;sequenceDiagram
Alice-&gt;&gt;John: Hello John, how are you?
loop Healthcheck
    John-&gt;&gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&gt;&gt;Alice: Great!
John-&gt;&gt;Bob: How about you?
Bob--&gt;&gt;John: Jolly good!
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;class diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
Class03 *-- Class04
Class05 o-- Class06
Class07 .. Class08
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
Class08 &amp;lt;--&amp;gt; C2: Cool label
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;classDiagram
Class01 &lt;|-- AveryLongClass : Cool
Class03 *-- Class04
Class05 o-- Class06
Class07 .. Class08
Class09 --&gt; C2 : Where am i?
Class09 --* C3
Class09 --|&gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
Class08 &lt;--&gt; C2: Cool label
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;state diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;stateDiagram
[*] --&gt; Still
Still --&gt; [*]
Still --&gt; Moving
Moving --&gt; Still
Moving --&gt; Crash
Crash --&gt; [*]
&lt;/div&gt;
&lt;h2 id=&#34;data-frames&#34;&gt;Data Frames&lt;/h2&gt;
&lt;p&gt;Save your spreadsheet as a CSV file in your page&amp;rsquo;s folder and then render it by adding the &lt;em&gt;Table&lt;/em&gt; shortcode to your page:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;results.csv&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;header&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;caption&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Table 1: My results&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;














&lt;table class=&#34;table-auto w-full&#34;&gt;
  
    
    
    &lt;thead&gt;
      &lt;tr&gt;  &lt;th class=&#34;border-b dark:border-slate-600 font-medium p-4 pt-0 pb-3 text-slate-400 dark:text-slate-200 text-left&#34;&gt;customer_id&lt;/th&gt;  &lt;th class=&#34;border-b dark:border-slate-600 font-medium p-4 pt-0 pb-3 text-slate-400 dark:text-slate-200 text-left&#34;&gt;score&lt;/th&gt;  &lt;/tr&gt;
    &lt;/thead&gt;
  
  &lt;tbody&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;1&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;0&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;2&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;text&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;0.5&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;3&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;1&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
  &lt;/tbody&gt;
  
    &lt;caption class=&#34;table-caption&#34;&gt;Table 1: My results&lt;/caption&gt;
  
&lt;/table&gt;

&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>👩🏼‍🏫 Teach academic courses</title>
      <link>http://localhost:1313/not_used/post/teach-courses/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/teach-courses/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube D2vj0WcvH5c &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili BV1WV4y1r7DF &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;w-full h-auto aspect-video relative&#34;&gt;
  &lt;iframe src=&#34;//player.bilibili.com/player.html?bvid=BV1WV4y1r7DF&amp;page=1&#34;
  allow=&#34;accelerometer; clipboard-write; encrypted-media; gyroscope; fullscreen; picture-in-picture;&#34;
  class=&#34;w-full h-full&#34;
  &gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;http://localhost:1313/not_used/post/teach-courses/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;👉 Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;👉 Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me 🎉
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. Enable math by setting the &lt;code&gt;math: true&lt;/code&gt; option in your page&amp;rsquo;s front matter, or enable math for your entire site by toggling math in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;$...$&lt;/code&gt; or &lt;code&gt;$$...$$&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;$\nabla F(\mathbf{x}_{n})$&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Learn JavaScript</title>
      <link>http://localhost:1313/teachingini/js/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teachingini/js/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube w7Ft2ymGmfc &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili id=&amp;quot;BV1WV4y1r7DF&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;http://localhost:1313/teachingini/js/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;👉 Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;👉 Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me 🎉
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;{{&amp;lt; math &amp;gt;}}$...${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; or &lt;code&gt;{{&amp;lt; math &amp;gt;}}$$...$${{&amp;lt; /math &amp;gt;}}&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;We wrap the LaTeX math in the Hugo Blox &lt;em&gt;math&lt;/em&gt; shortcode to prevent Hugo rendering our math as Markdown.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;

$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$


&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;{{&amp;lt; math &amp;gt;}}$\nabla F(\mathbf{x}_{n})${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$
.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;


$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$



&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Learn Python</title>
      <link>http://localhost:1313/teachingini/python/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teachingini/python/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube w7Ft2ymGmfc &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili id=&amp;quot;BV1WV4y1r7DF&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;http://localhost:1313/teachingini/python/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;👉 Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;👉 Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me 🎉
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;{{&amp;lt; math &amp;gt;}}$...${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; or &lt;code&gt;{{&amp;lt; math &amp;gt;}}$$...$${{&amp;lt; /math &amp;gt;}}&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;We wrap the LaTeX math in the Hugo Blox &lt;em&gt;math&lt;/em&gt; shortcode to prevent Hugo rendering our math as Markdown.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;

$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$


&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;{{&amp;lt; math &amp;gt;}}$\nabla F(\mathbf{x}_{n})${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$
.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;


$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$



&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Test Python</title>
      <link>http://localhost:1313/minerias/python/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/python/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube w7Ft2ymGmfc &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili id=&amp;quot;BV1WV4y1r7DF&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;http://localhost:1313/minerias/python/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;👉 Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;👉 Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me 🎉
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;{{&amp;lt; math &amp;gt;}}$...${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; or &lt;code&gt;{{&amp;lt; math &amp;gt;}}$$...$${{&amp;lt; /math &amp;gt;}}&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;We wrap the LaTeX math in the Hugo Blox &lt;em&gt;math&lt;/em&gt; shortcode to prevent Hugo rendering our math as Markdown.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;

$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$


&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;{{&amp;lt; math &amp;gt;}}$\nabla F(\mathbf{x}_{n})${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$
.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;


$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$



&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>✅ Manage your projects</title>
      <link>http://localhost:1313/not_used/post/project-management/</link>
      <pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/project-management/</guid>
      <description>&lt;p&gt;Easily manage your projects - create ideation mind maps, Gantt charts, todo lists, and more!&lt;/p&gt;
&lt;h2 id=&#34;ideation&#34;&gt;Ideation&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports a Markdown extension for mindmaps.&lt;/p&gt;
&lt;p&gt;Simply insert a Markdown code block labelled as &lt;code&gt;markmap&lt;/code&gt; and optionally set the height of the mindmap as shown in the example below.&lt;/p&gt;
&lt;p&gt;Mindmaps can be created by simply writing the items as a Markdown list within the &lt;code&gt;markmap&lt;/code&gt; code block, indenting each item to create as many sub-levels as you need:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap {height=&#34;200px&#34;}
- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the &lt;em&gt;Mermaid&lt;/em&gt; Markdown extension for diagrams.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;Gantt diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
&lt;/div&gt;
&lt;h2 id=&#34;todo-lists&#34;&gt;Todo lists&lt;/h2&gt;
&lt;p&gt;You can even write your todo lists in Markdown too:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write math example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write diagram example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [ ]&lt;/span&gt; Do something else
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write math example
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write diagram example&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Do something else&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it 🙌&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>WASSA Workshop @ ACL 23</title>
      <link>http://localhost:1313/event/wassa23/</link>
      <pubDate>Fri, 14 Jul 2023 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/wassa23/</guid>
      <description>&lt;p&gt;We are orgnizing the 13th edition of the WASSA workshop this year at &lt;a href=&#34;https://2023.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL23&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Our keynote speakers will be David Jurgens and Emily Öhman&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-david-jurgens&#34;&gt;Invited Talk: David Jurgens&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://wassa-workshop.github.io/assets/images/david_jurgens.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;the-social-dimensions-of-communication-how-context-shapes-language-use-and-interpretation&#34;&gt;The Social Dimensions of Communication: How Context Shapes Language Use and Interpretation&lt;/h4&gt;
&lt;p&gt;NLP studies of communication often focus on the individual: What we say, when we say it, and how we say it. Yet, the larger social context beyond the individual also plays an important role in our communication — just think of things you can say to your friends but not your parents. How does the social context influence our communication style and content? In this talk, I will describe recent work from my group studying the influence of this context by examining how we choose who to communicate with, how we interpret messages, and how we phrase messages. Across these studies, I will motivate a causal approach for NLP when studying communication behavior to move beyond descriptive analyses to more precise estimates of the effects of social context.&lt;/p&gt;
&lt;h4 id=&#34;bio&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;David Jurgens is an assistant professor at the University of Michigan School of Information where he leads the Blablablab. He holds a PhD in Computer Science from the University of California, Los Angeles. His research focuses on the intersection between NLP and computational social science venues and has won the Cozzarelli Prize, Cialdini Prize, best paper at ICWSM and W-NUT, and best paper nomination at ACL and Web Science.&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-emily-öhman&#34;&gt;Invited Talk: Emily Öhman&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://wassa-workshop.github.io/assets/images/emilyohman.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;affective-datafication-of-narratives-measuring-affect-emotion-and-mood-in-literary-texts&#34;&gt;Affective Datafication of Narratives: measuring affect, emotion, and mood in literary texts&lt;/h4&gt;
&lt;p&gt;Our understanding of affect, emotion, and mood - despite the distinct nuances each term holds - often becomes blurred, leading to a usage that is almost interchangeable, particularly within sentiment analysis and NLP. In contrast, traditional fields such as literary studies hold on to more rigid definitions of these terms and how they are understood both in theory and practice. This can easily foster a disconnect between emerging fields such as computational literary studies and the more established qualitative counterparts. This disconnect unfortunately hinders the free exchange of innovative research ideas and methodologies. This talk aims to bridge this gap, highlighting the unique roles of affect, emotion, and mood in narratives and how we can attempt to robustly measure them. We will delve into the interplay of these terms, exploring how they shape and are shaped by authors, readers, and researchers focusing on the operationalization and translation involved in the analysis of emotion-laden phenomena. This exploration will underscore the need for a more comprehensive and nuanced understanding, encouraging synergy between tradition and innovation in emotion detection in general and literary research in particular.&lt;/p&gt;
&lt;h4 id=&#34;bio-1&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;Emily Öhman is currently a tenure-track Assistant professor of Digital Humanities at Waseda University. She received her PhD in Language Technology from the University of Helsinki, where her work centered on building multilingual emotion detection resources for downstream tasks.&lt;/p&gt;
&lt;p&gt;Her research interests lie within digital humanities and NLP, more specifically sentiment analysis and emotion detection, often doing collaborations with various disciplines such as history, literature, and political science. Her recent projects have focused on negative emotions in literature using affect as a proxy for the literary concept of mood and most recently contrasting the semantic spaces of shame and guilt in Japanese and English social media posts.&lt;/p&gt;
&lt;h2 id=&#34;about-wassa&#34;&gt;About WASSA&lt;/h2&gt;
&lt;p&gt;The aim of WASSA 2023 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text. For this edition, we encourage the submission of long and short research and demo papers including, but not restricted to the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resources for subjectivity, sentiment, emotion and social media analysis&lt;/li&gt;
&lt;li&gt;Opinion retrieval, extraction, categorization, aggregation and summarization&lt;/li&gt;
&lt;li&gt;Humor, Irony and Sarcasm detection&lt;/li&gt;
&lt;li&gt;Mis- and disinformation analysis and the role of affective attributes&lt;/li&gt;
&lt;li&gt;Aspect and topic-based sentiment and emotion analysis&lt;/li&gt;
&lt;li&gt;Analysis of stable traits of social media users, incl. personality analysis and profiling&lt;/li&gt;
&lt;li&gt;Transfer learning for domain, language and genre portability of sentiment analysis&lt;/li&gt;
&lt;li&gt;Modelling commonsense knowledge for subjectivity, sentiment or emotion analysis&lt;/li&gt;
&lt;li&gt;Improvement of NLP tasks using subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;Intrinsic and extrinsic evaluation of subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;The role of emotions in argument mining&lt;/li&gt;
&lt;li&gt;Application of theories from related fields to subjectivity and sentiment analysis&lt;/li&gt;
&lt;li&gt;Multimodal emotion detection and classification&lt;/li&gt;
&lt;li&gt;Applications of sentiment and emotion mining&lt;/li&gt;
&lt;li&gt;Public sentiments and communication patterns of public health emergencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We furthermore encourage submissions to the special theme Ethics in Affective Computing, including opinion papers, as well as experimental papers. This includes the following topics, but is not limited to them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Which properties of a model render a automatic analysis task unethical?&lt;/li&gt;
&lt;li&gt;Which characteristics of an annotation task are to be considered in ethical considerations?&lt;/li&gt;
&lt;li&gt;What are appropriate methods to analyze data and models from an ethical perspective?&lt;/li&gt;
&lt;li&gt;What aspects are particular important for affective analysis tasks, in contrast to other NLP settings?&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Findings of WASSA 2023 Shared Task on Empathy, Emotion and Personality Detection in Conversation and Reactions to News Articles</title>
      <link>http://localhost:1313/publication/wassa23-task/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wassa23-task/</guid>
      <description>&lt;p&gt;Third shared task related to Empathy we organized at WASSA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multilingual Multi-Target Stance Recognition in Online Public Consultations</title>
      <link>http://localhost:1313/publication/mdpi23-participatory/</link>
      <pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/mdpi23-participatory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CoFE: A New Dataset of Intra-Multilingual Multi-target Stance Classification from an Online European Participatory Democracy Platform</title>
      <link>http://localhost:1313/publication/aacl22-cofe/</link>
      <pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/aacl22-cofe/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Debating Europe: A Multilingual Multi-Target Stance Classification Dataset of Online Debates</title>
      <link>http://localhost:1313/publication/lrec22-deurope/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec22-deurope/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Opinions in Interactions : New Annotations of the SEMAINE Database</title>
      <link>http://localhost:1313/publication/lrec22-opinions/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec22-opinions/</guid>
      <description></description>
    </item>
    
    <item>
      <title>WASSA 2022 Shared Task: Predicting Empathy, Emotion and Personality in Reaction to News Stories</title>
      <link>http://localhost:1313/publication/wassa22-task/</link>
      <pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wassa22-task/</guid>
      <description>&lt;p&gt;Second shared task related to Empathy we organized at WASSA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How does a Pre-Trained Transformer Integrate Contextual Keywords? Application to Humanitarian Computing</title>
      <link>http://localhost:1313/publication/iscram21-meta/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/iscram21-meta/</guid>
      <description>&lt;p&gt;It is possible to integrate textual metadata into transformers in order to help the model improve its performances. We show the model uses the semantics of the keyword metadata analyzing the attention interaction between the metadata and the text to classify. We applied this to a humanitarian classification task over tweets, using the disaster event type as context, and finally show this method is also useful to caracterize a new event like a hurricane in a data-driven way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving Sentiment Analysis over non-English Tweets using Multilingual Transformers and Automatic Translation for Data-Augmentation</title>
      <link>http://localhost:1313/publication/coling20-mling/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/coling20-mling/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Apprentissage Machine</title>
      <link>http://localhost:1313/teaching/fouilledonnees/</link>
      <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teaching/fouilledonnees/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Valentin Barriere</title>
      <link></link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid></guid>
      <description>&lt;h2 id=&#34;about-me&#34;&gt;About Me&lt;/h2&gt;
&lt;p&gt;Valentin Barriere is an AI profesor in the CS department of the University of Chile, specialized in multimodal machine learning for social interactions studies, with a focus on natural language processing. He also work on multilingual debates analysis, social biases detection, explainable IA, and also multimodal satellite data processing. Before this, he worked for public institutions such as the Supreme Court (Cour de Cassation) and the European Commission&amp;rsquo;s Joint Research Center.&lt;/p&gt;
&lt;p&gt;He is director of several projects focused on the use of Machine Learning for social good with public Chilean institutions, and involved as IA advisor of the CopernicusLAC program in Chile with the aim to develop general multi-modal and multi-resolution models for satellite data processing.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
