<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Valentin Barriere</title>
    <link>http://localhost:1313/</link>
      <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <description>Valentin Barriere</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu6033596820838205990.png</url>
      <title>Valentin Barriere</title>
      <link>http://localhost:1313/</link>
    </image>
    
    <item>
      <title>[Tesis postgrado] [Pagada] Deteccion de Fuego en la naturaleza usando IA</title>
      <link>http://localhost:1313/job_offers/thesis-fairefighter/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-fairefighter/</guid>
      <description>&lt;p&gt;Early wildfire detection is of the utmost importance to enable rapid response efforts, and thus minimize the negative impacts of wildfire spreads. To this extent, we propose to install a networks of stations composed of cameras connected to Raspberry Pi that process the images in real time in order to automatically detect smoke plumes using Computer Vision algorithms. We scrapped the web in order to create &lt;a href=&#34;https://arxiv.org/abs/2402.05349&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a new database&lt;/a&gt; of smoke plumes&amp;rsquo; sequence of images (videos).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-overview-of-the-fairefighter-solution-using-object-detection-models-to-detect-smoke-plumes-in-the-wild&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overview_EWD&#34; srcset=&#34;
               /job_offers/thesis-fairefighter/overview_EWD_hu9830338541403336544.webp 400w,
               /job_offers/thesis-fairefighter/overview_EWD_hu2557711783386077624.webp 760w,
               /job_offers/thesis-fairefighter/overview_EWD_hu7278080974264488546.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-fairefighter/overview_EWD_hu9830338541403336544.webp&#34;
               width=&#34;760&#34;
               height=&#34;427&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Overview of the fAIrefighter solution, using object detection models to detect smoke plumes in the wild
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The challenges are various:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The detection is currently tackled using a classical state-of-the-art object detection model (Yolov8) that do not take into account the sequentiality&lt;/li&gt;
&lt;li&gt;The images are processed on a light computer, this makes space to work more frugal models&lt;/li&gt;
&lt;li&gt;A benchmark of the SOTA models is needed&lt;/li&gt;
&lt;li&gt;How to improve the quality of the dataset by using bigger models offline (even though they cannot be used online)&lt;/li&gt;
&lt;li&gt;Improve the model for early detection (&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S092427162200332X&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;an exemple&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a project in collaboration with the non-profit association PyroNear and the Corporacion Nacional Forestal.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Aprender a aprender -- IA y Meta-learning para datos Satelitales</title>
      <link>http://localhost:1313/job_offers/thesis-meta-deepcrop/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-meta-deepcrop/</guid>
      <description>&lt;p&gt;Recent trend in Deep Learning is to train in a self-supervised way models that create high-quality dense vector representation to be fine-tuned on downstream tasks, allowing to reach high results in text [1], computer vision [2] but also in speech [3]. This trend is also true when processing Remote Sensing data [4], [5], [6]. These models are pre-trained on a huge quantity of data without labels using techniques such as Masked Image Modeling  of the U-BARN [7]. They have been shown to reach higher results than the state-of-the-art approach for crop classification. Moreover, recent work [8] showed that they can also be pre-train using meta-learning methods, with available labeled data in order to adapt easily to a new unseen task with only a few training examples.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-meteor-model-learned-using-meta-learning-and-various-tasks-from-8&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;metalearning&#34; srcset=&#34;
               /job_offers/thesis-meta-deepcrop/metalearning_hu8736316492409248854.webp 400w,
               /job_offers/thesis-meta-deepcrop/metalearning_hu5378775358810166572.webp 760w,
               /job_offers/thesis-meta-deepcrop/metalearning_hu11622278346872266028.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-meta-deepcrop/metalearning_hu8736316492409248854.webp&#34;
               width=&#34;760&#34;
               height=&#34;505&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      METEOR model learned using Meta learning and various tasks from [8]
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Therefore, the development of state-of-the-art classification and estimation models, as well as technologies to collect necessary in-situ (ground truth) data, are crucially lacking in Chile. Importantly, given the violent climate changes and drought episodes Chile is currently facing, this technology is becoming imperative. In the project we describe below we propose an innovative way of developing such a technology, based on state-of-the-art deep learning models and remote sensing, that can efficiently, quickly and accurately generate estimates of field areas, crop types and yield estimations.&lt;/p&gt;
&lt;h3 id=&#34;task&#34;&gt;Task&lt;/h3&gt;
&lt;p&gt;Intensive pre-training of models of billions of parameters will be implemented, and we will further fine-tune them over several task using labels from chilean landsape delivered from our project partner the Centro de Informaci√≥n de Recursos Naturales (CIREN).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collect a huge dataset of open-source Sentinel2 data at the level of the whole country and for several years&lt;/li&gt;
&lt;li&gt;Train a foundational model in an auto-supervised way using the various spectrum of data from Chile (climate, vegetation, soil is very different)&lt;/li&gt;
&lt;li&gt;Use meta-learning algorithm in order to fine-tune the model for a broad set of different tasks using annotated dataset from Chile and from abroad&lt;/li&gt;
&lt;li&gt;Deliver the model as an open-source tool for the community&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bibliography&#34;&gt;Bibliography&lt;/h3&gt;
&lt;p&gt;[1]  J. Devlin, M. Chang, K. Lee, and K. Toutanova, ‚ÄòBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding‚Äô, 2018.
[2]  A. Dosovitskiy et al., ‚ÄòAn image is worth 16x16 words: Transformers for image recognition at scale‚Äô, arXiv preprint arXiv:2010.11929, 2020. ‚Ä®
[3]  V. Pratap et al., ‚ÄòScaling speech technology to 1,000+ languages‚Äô, arXiv preprint arXiv:2305.13516, 2023. ‚Ä®
[4]  M. J. Smith, L. Fleming, and J. E. Geach, ‚ÄòEarthPT: a foundation model for Earth Observation‚Äô, arXiv preprint arXiv:2309.07207, 2023. ‚Ä®
[5]  A. Lacoste et al., ‚ÄòGeo-bench: Toward foundation models for earth monitoring‚Äô, Adv Neural Inf Process Syst, vol. 36, 2024. ‚Ä®
[6]  Z. Xiong, Y. Wang, F. Zhang, and X. X. Zhu, ‚ÄòOne for All: Toward Unified Foundation Models for Earth Vision‚Äô, arXiv preprint arXiv:2401.07527, 2024. ‚Ä®
[7]  I. Dumeur, S. Valero, and J. Inglada, ‚ÄòSelf-supervised spatio-temporal representation learning of Satellite Image Time Series‚Äô, IEEE J Sel Top Appl Earth Obs Remote Sens, 2024.
[8]  M. Ru√üwurm, S. Wang, B. Kellenberger, R. Roscher, and D. Tuia, ‚ÄòMeta-learning to address diverse Earth observation problems across resolutions‚Äô, Commun Earth Environ, vol. 5, no. 1, p. 37, 2024. ‚Ä®&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Change my view! -- Analisis de argumentacion multimodal</title>
      <link>http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;‚Ä®Interactions and Multimodality are crucial in the development of intelligent AI models that can understand human-like communication. Human learning occurs through interactions with the environment and other humans, which involves the integration of information from multiple modalities such as vision, language but also touch and hearing that enable us to understand the subtle social meaning behind communication.¬†
Therefore, to create intelligent machines that can understand human communication, it is essential to train them on multimodal interactions that mimic those of humans to ensure that they can understand and respond appropriately to complex social phenomena.¬†
The research objective is to design adaptive models that take as a starting point the specificities of the multimodal interaction: the media used to communicate, the way the users are socially linked together, and the modalities used by them to transfer information.¬†
For this reason, we aim to study multimodal argumentation mining as a starting point. Dialog systems helps to improve the quality of a debate [1,2,3,4]. But phenomena related to argumentation relies on multimodal communication and are related to persuasion, or communication skills [5,6,7,8]. For this, we are focusing on multimodal argument mining [9,10,11,12].¬†&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig_tesis_proposicion&#34; srcset=&#34;
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu700631809574394399.webp 400w,
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu1221762742450276794.webp 760w,
               /job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu4398504731950838957.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-postgrado-mmodaleca/fig_tesis_proposicion_hu700631809574394399.webp&#34;
               width=&#34;760&#34;
               height=&#34;241&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;The student will engage in the construction of multimodal machine learning models that take as input video and are able to detect complex social phenomena such as empathy, persuasion and emotion but also text-based argumentation models. During the thesis, we will also focus on the construction of a debate dataset in Chilean Spanish (and hopefully ¬†in French), on political hot topics that are seen as polarizing in both countries.¬†
s
In a few bullet-points, different research axis will be explored regarding the available time (w.r.t. the type of tesis/memoria):¬†&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creation of mutlimodal models aiming to detect social phenomena in discourse and also in a dyadic or group interaction&lt;/li&gt;
&lt;li&gt;Adaptation or creation of an text-based argumentation annotation scheme for multimodal data&lt;/li&gt;
&lt;li&gt;Creation of the chilean part of a multicultural database of debates on polarizing topics ¬†&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Funds will be available to support the research of the student.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;‚Ä®### Bibliography&lt;/p&gt;
&lt;p&gt;[1] V. Petukhova, T. Mayer, A. Malchanau, and H. Bunt, ‚ÄúVirtual debate coach design: Assessing multimodal argumentation performance,‚Äù ICMI 2017 - Proc. 19th ACM Int. Conf. Multimodal Interact., vol. 2017-Janua, no. 1, pp. 41‚Äì50, 2017.‚Ä®&lt;/p&gt;
&lt;p&gt;[2] N. Rach, E. Andr√©, K. Weber, W. Minker, L. Pragst, and S. Ultes, ‚ÄúEVA: A multimodal argumentative dialogue system,‚Äù ICMI 2018 - Proc. 2018 Int. Conf. Multimodal Interact., no. October, pp. 551‚Äì552, 2018.‚Ä®&lt;/p&gt;
&lt;p&gt;[3] A. Khan, J. Hughes, D. Valentine, L. Ruis, K. Sachan, and A. Radhakrishnan, ‚ÄúDebating with More Persuasive LLMs Leads to More Truthful Answers,‚Äù 2024.‚Ä®&lt;/p&gt;
&lt;p&gt;[4] L. P. Argyle et al., ‚ÄúAI Chat Assistants can Improve Conversations about Divisive Topics,‚Äù ArXiv, 2023.‚Ä®&lt;/p&gt;
&lt;p&gt;[5] T. Ohba, C. O. Mawalim, S. Katada, H. Kuroki, and S. Okada, ‚ÄúMultimodal Analysis for Communication Skill and Self-Efficacy Level Estimation in Job Interview Scenario,‚Äù ACM Int. Conf. Proceeding Ser., pp. 110‚Äì120, 2022.‚Ä®&lt;/p&gt;
&lt;p&gt;[6] S. Park, H. S. Shim, M. Chatterjee, K. Sagae, and L.-P. Morency, ‚ÄúComputational Analysis of Persuasiveness in Social Multimedia: A Novel Dataset and Multimodal Prediction Approach,‚Äù Proc. 16th Int. Conf. Multimodal Interact. - ICMI ‚Äô14, pp. 50‚Äì57, 2014.‚Ä®&lt;/p&gt;
&lt;p&gt;[7] B. Siddiquie, D. Chisholm, and A. Divakaran, ‚ÄúExploiting multimodal affect and semantics to identify politically persuasive web videos,‚Äù in ICMI 2015 - Proceedings of the 2015 ACM International Conference on Multimodal Interaction, 2015, pp. 203‚Äì210.‚Ä®&lt;/p&gt;
&lt;p&gt;[8] B. Nojavanasghari, D. Gopinath, J. Koushik, T. Baltru≈°aitis, and L.-P. Morency, ‚ÄúDeep Multimodal Fusion for Persuasiveness Prediction,‚Äù in ICMI 2016 - Proceedings of the 2016 ACM International Conference on Multimodal Interaction, 2016, pp. 1‚Äì5.‚Ä®&lt;/p&gt;
&lt;p&gt;[9] R. Mestre, R. Milicin, S. E. Middleton, M. Ryan, J. Zhu, and T. J. Norman, ‚ÄúM-Arg: Multimodal Argument Mining Dataset for Political Debates with Audio and Transcripts,‚Äù 8th Work. Argument Mining, ArgMining 2021 - Proc., no. 2014, pp. 78‚Äì88, 2021.‚Ä®&lt;/p&gt;
&lt;p&gt;[10] M. Brilman and S. Scherer, ‚ÄúA Multimodal Predictive Model of Successful Debaters or How I Learned to Sway Votes,‚Äù Proc. 23rd ACM Int. Conf. Multimed., pp. 149‚Äì158, 2015.‚Ä®&lt;/p&gt;
&lt;p&gt;[11] E. Mancini, F. Ruggeri, A. Galassi, and P. Torroni, ‚ÄúMultimodal Argument Mining: A Case Study in Political Debates,‚Äù Proc. 9th Work. Argument Min., pp. 158‚Äì170, 2022.‚Ä®&lt;/p&gt;
&lt;p&gt;[12] T. Shiota and K. Shimada, ‚ÄúThe Discussion Corpus toward Argumentation Quality Assessment in Multi-Party Conversation,‚Äù Proc. - 2020 9th Int. Congr. Adv. Appl. Informatics, IIAI-AAI 2020, pp. 280‚Äì283, 2020.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Tesis pre/postgrado] [Pagada] Xenophobias -- Deteccion y reduccion de sesgos etnicos en LLM</title>
      <link>http://localhost:1313/job_offers/thesis-postgrado-bias/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-postgrado-bias/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;Classical bias detection methods used in Machine Learning are themselves biased because of the different confounding variables implied in the assessment of the initial biases. First they are using templates that are syntactically simple and distant from the target data on which the model will be applied. Second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms.
We propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. The idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-non-causal-changes-such-as-in-names-can-cause-differences-in-the-model-outputs-which-should-not-happen&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;figure_v5&#34; srcset=&#34;
               /job_offers/thesis-postgrado-bias/figure_v5_hu4101750334257282784.webp 400w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu12014982446003253994.webp 760w,
               /job_offers/thesis-postgrado-bias/figure_v5_hu11181646692821307121.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-postgrado-bias/figure_v5_hu4101750334257282784.webp&#34;
               width=&#34;760&#34;
               height=&#34;267&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Non-causal changes such as in names can cause differences in the model outputs, which should not happen.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Our work offers a fine-grained analysis of the interactions between names and languages, revealing significant biases in multilingual models, but also strong biases towards some countries&amp;rsquo; names. We linked this with the pre-training data used to pre-train the LLM, by the mean of the Language Model&amp;rsquo;s (pseudo-)likelihood and found out very socially interesting resuts. For example, a sentence containing a Moroccan name will be more likely to be tagged as positive, and less likely to be tagged as hate speech.&lt;/p&gt;
&lt;p&gt;In other words we want to answer the questions: (i) are LLM xenophobic? (ii) how to quantify it? (iii) how to remove this bias?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Funds will be available to support the research of the student.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;We started to answer these questions in two papers (one published at COLING24 and one published at EMNLP24), and would like to continue the adventure with you! We plan to submit our future work at another international NLP/ML/AI conference.&lt;/p&gt;
&lt;p&gt;We have several possibilities regarding the works that can be tackled in this tesis:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLM to generate data fitting to production data distribution (KL‚Äî&amp;gt;0)&lt;/li&gt;
&lt;li&gt;Generate more target-groups attributes (more fine-grained, since not relying on template; how to validate them)&lt;/li&gt;
&lt;li&gt;Method to reduce the bias of the trained model&lt;/li&gt;
&lt;li&gt;Test current method on bigger LLM classifiers&lt;/li&gt;
&lt;li&gt;Our method is quantitative and require classes that can manually be seen as positives and negatives. How to extend this to any classification, how to check this bias qualitatively using an algorithm on the distribution (Optimal Transport distance or others‚Ä¶)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Fondecyt de Iniciacionüó£Ô∏èüí¨ü§ñ</title>
      <link>http://localhost:1313/project/mmodal_eca/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/mmodal_eca/</guid>
      <description>&lt;p&gt;Multimodal Argumentation Mining in Groups Assisted by an Embodied Conversational Agent&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Principal Investigator of this project&lt;/strong&gt;. This is a 3 years &lt;a href=&#34;https://anid.cl/concursos/concurso-de-proyectos-fondecyt-de-iniciacion-en-investigacion-2025/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fondecyt&lt;/a&gt; grant of of 90.000.000,00 CLP&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; from the Chilean National Research Agency. This is a colaboration with the Universit√© Paris Saclay, the European Commission&amp;rsquo;s DGIT, Sorbonne Universit√© and Bamberg University.&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;Interactions and Multimodality are crucial in the development of intelligent AI models that can understand human-like communication. Human learning occurs through interactions with the environment and other humans, which involves the integration of information from multiple modalities such as vision, language but also touch and hearing that enable us to understand the subtle social meanings behind communication.&lt;/p&gt;
&lt;p&gt;Therefore, to create intelligent machines that can understand human non-verbal communication, it is essential to train them on &lt;strong&gt;multimodal interactions that mimic those of humans to ensure that they can understand and respond appropriately to complex social phenomena&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The recent computational boom has seen the emergence of seminal studies focusing on Multimodal data (Cho, Lu, Schwenk, Hajishirzi, &amp;amp; Kembhavi, 2020; Hasan et al., 2019; Jaegle et al., 2021; J. Li, Li, Xiong, &amp;amp; Hoi, 2022; J. Wang et al., 2022; Zadeh, Chan, Liang, Tong, &amp;amp; Morency, 2019)‚Å† and Interactions, whether these ones are textual like OpenIA&amp;rsquo;s InstructGPT or Anthropic&amp;rsquo;s Claude  (Bai et al., 2022; Ouyang et al., 2022; Schulman et al., 2022)‚Å†, or multimodal like Google&amp;rsquo;s PaLM (Chowdhery et al., n.d.; Chung et al., 2022; Schick, Lomeli, Dwivedi-yu, &amp;amp; Dess√¨, 2022)‚Å† or GPT-4 (Bubeck et al., 2023; OpenAI, 2023; Wu et al., 2023)‚Å†.&lt;/p&gt;
&lt;p&gt;These advancements show the potential for machines to learn from multimodal interactions and understand human communication, which could revolutionize the way humans socially interact with machines in the future. &lt;strong&gt;Nevertheless, nowadays generative agents are restraint to unimodal data or not using the full time-series of every modality of a real human-machine social interaction&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Interaction and multimodality are vital contexts in many social situations. They are also mandatory to make a machine understand the world and get commonsense knowledge, which is essential when tackling human-related complex tasks. Indeed, &lt;strong&gt;humans are social animals&lt;/strong&gt; and they interact with one another. In a general way, the integration of more context is the key to a deep understanding of many phenomena, in order to disambiguate a situation or to reinforce the current estimation: interaction is a crucial context in many social situations. Multimodal interactions allow understanding in a deeper way human behavior. In this particular setting, it is possible to understand a broader part of the multimodal natural language (see Figure 1). Studying the affective and &lt;strong&gt;social phenomena like Opinions, Emotions, Empathy, Distress, Stances, Persuasiveness or speaker traits allows to greatly improves the response from the machine&lt;/strong&gt; (Pelachaud, Busso, &amp;amp; Heylen, 2021; Zhao, Sinha, Black, &amp;amp; Cassell, 2016)‚Å†, but this task is difficult even using multimodal data. My research focuses on designing and developing methods that integrate the multimodal context and how humans influence each other in discussion situations. The research goals of this project fall into this general research area: &lt;strong&gt;how to use interactions and multimodality of non-verbal language to enhance social AI systems&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-examples-of-non-verbal-language-involved-in-a-social-interaction-from-vinciarelli-2009&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;interaction&#34; srcset=&#34;
               /project/mmodal_eca/interaction_hu15794327103315274671.webp 400w,
               /project/mmodal_eca/interaction_hu15612226579774470620.webp 760w,
               /project/mmodal_eca/interaction_hu8198735632516945012.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/mmodal_eca/interaction_hu15794327103315274671.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Examples of non-verbal language involved in a social interaction from Vinciarelli (2009)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;multimodality&#34;&gt;Multimodality:&lt;/h4&gt;
&lt;p&gt;Communication is not just limited to language, and it is essential to consider other modalities such as vision or audio when building natural language processing (NLP) systems (Baltru≈°aitis, Ahuja, &amp;amp; Morency, 2017; Liang, Zadeh, &amp;amp; Morency, 2022)‚Å†. &lt;strong&gt;Incorporating multiple modalities, or multimodality, is critical in creating more human-like interactions between humans and machines&lt;/strong&gt;. For instance, while language is the primary means of communication for humans, it is often supplemented by visual and auditory cues such as facial expressions, tone of voice, and gestures. Therefore, it is important building multimodal machine learning systems that can interpret and respond to these cues in a human-like manner.&lt;/p&gt;
&lt;p&gt;According to (Fr√∂hlich, Sievers, Townsend, Gruber, &amp;amp; van Schaik, 2019)‚Å†, both human and non-human primate communication is inherently multimodal. As an example, (Mehrabian, 1971)‚Å† even states that 55% of the emotional content is in the visual signal (facial expressions and body language), 38% in the vocal signal (intonation and sound of the voice) and 7% in the verbal signal (through the meaning of the words and the arrangement of the sentence).&lt;/p&gt;
&lt;h4 id=&#34;interactions-dynamics&#34;&gt;Interactions dynamics:&lt;/h4&gt;
&lt;p&gt;It is essential to consider the interactive nature of human communication and incorporate it into natural language processing (NLP) systems. By allowing the machine to understand the context and flow of the conversation, it can provide a more natural and seamless interaction with users (Sutskever, Vinyals, &amp;amp; Le, 2014)‚Å†. (Z. Li, Wallace, Shen, &amp;amp; Lin, 2020)‚Å† suggested that these systems can provide tailored content and services based on the user&amp;rsquo;s interests and preferences, leading to more engaging and personalized interactions with the user. &lt;strong&gt;As humans, we are not learnig by looking at or enviroment, but by interacting with it and with our peers&lt;/strong&gt;. By considering the interactive nature of human communication and incorporating it into NLP systems, machines can learn to communicate in a way that is more similar to humans, making interactions more engaging and effective.&lt;/p&gt;
&lt;h4 id=&#34;proposed-research-project&#34;&gt;Proposed research project:&lt;/h4&gt;
&lt;p&gt;This research project aims at studying the complex phenomena characterizing social interactions between humans using different media, implying different modalities and data domains. My research objective is to design adaptive models that take as a starting point the specificities of the multimodal interaction: the media used to communicate, the interactants&amp;rsquo; social relationship, and the communication modalities used to transfer the information. &lt;strong&gt;The general goals stand to: understand what the users are trying to achieve as a group, what is the output of this interaction, how a social agent helps reaching it&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-beatrice-bianccardihttpsbeatricebiancardigitlabio-interacting-with-the-virtual-agent-greta&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;beatrice_eca&#34; srcset=&#34;
               /project/mmodal_eca/beatrice_eca_hu9343440991652273668.webp 400w,
               /project/mmodal_eca/beatrice_eca_hu1100368193974869717.webp 760w,
               /project/mmodal_eca/beatrice_eca_hu13291684369485421113.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/mmodal_eca/beatrice_eca_hu9343440991652273668.webp&#34;
               width=&#34;430&#34;
               height=&#34;279&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;a href=&#34;https://beatricebiancardi.gitlab.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Beatrice Bianccardi&lt;/a&gt; interacting with the virtual agent Greta
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In particlar, this project aims to explore the dynamics of how a group of individuals with polarized opinions can reach a consensus. In this work, within groups of individuals debating hot societal topics and issues, the aim will be to automatically detect and retrieve stances and arguments towards the debate question and to ultimately moderate the debate using a human-computer interface that would be specific to such an interaction. To this aim, we think that an &lt;strong&gt;Embodied Conversational Agent&lt;/strong&gt; (Cassell, 2001; Pelachaud, 2005)‚Å† like the one illustrated in Figure 2, would be the most relevant. Indeed bodily representations structure the way humans perceive the world and the way they perceive other people. Cognitive sciences and social sciences altogether have stressed &lt;strong&gt;the importance of embodiment in social interaction, highlighting how interacting with others influences how we behave, perceive and think&lt;/strong&gt; (Smith &amp;amp; Neff, 2018; Tieri, Morone, Paolucci, &amp;amp; Iosa, 2018)‚Å†, including our social behaviors with embodied intelligent agents such as virtual humans and robots (Holz, Dragone, &amp;amp; O‚ÄôHare, 2009)‚Å†.&lt;/p&gt;
&lt;p&gt;Another goal is to explore the polarization of society&amp;rsquo;s attitudes towards hot political topics and study the &lt;strong&gt;difference in terms of the difficulty of finding a consensus&lt;/strong&gt; regarding the type of topics, and the human values involved in classical argumentation (Kiesel, Weimar, Handke, &amp;amp; Weimar, 2022; Mirzakhmedova et al., 2023)‚Å†. In today&amp;rsquo;s society, the polarization of opinions on political topics is a common phenomenon that can be observed in many different areas. Debates about societal topics and issues can be especially polarizing and lead to a lack of understanding and cooperation between groups with different perspectives (Livingstone, Fern√°ndez Rodriguez, &amp;amp; Rothers, 2020)‚Å†. Therefore, &lt;strong&gt;it is crucial to understand how individuals with polarized opinions can reach a consensus&lt;/strong&gt;, and this is the aim of this research project. To achieve it, this project plans to develop an automatic approach to &lt;strong&gt;detect and retrieve the stance and arguments&lt;/strong&gt; of individuals involved in real-time multimodal debates about hot societal topics.&lt;/p&gt;
&lt;p&gt;This research aims to delve into the complexities of group dynamics in polarized debates on societal issues. To achieve this, we will not only automatically detect and retrieve stances and their arguments toward the debate question, but also take into account the multimodal aspects of the debate, such as &lt;strong&gt;body language, facial expressions and acoustics&lt;/strong&gt;, which are shown to be important for persuasion in a Vlog (Nojavanasghari, Gopinath, Koushik, Baltru≈°aitis, &amp;amp; Morency, 2016; S. Park, Shim, Chatterjee, Sagae, &amp;amp; Morency, 2014; Siddiquie, Chisholm, &amp;amp; Divakaran, 2015)‚Å† or within a debate (Brilman &amp;amp; Scherer, 2015; Mestre et al., 2021)‚Å†. Real-time interaction within the group will be analyzed to understand &lt;strong&gt;how individuals respond to each other and how the group as whole moves toward a consensus&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 100k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Large Multimodal Models @ CENIAMODAL</title>
      <link>http://localhost:1313/event/ceniamodal/</link>
      <pubDate>Tue, 17 Dec 2024 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/ceniamodal/</guid>
      <description>&lt;p&gt;We are organizing the first edition of the Chilean Workshop on Multimodal Machine Learning in the Universidad Catolica del Norte in Coquimbo!&lt;/p&gt;
&lt;p&gt;Our keynote speakers will be Mohammad Soleymani and Paul Liang&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-mohammad-soleymani&#34;&gt;Invited Talk: Mohammad Soleymani&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image&#34; srcset=&#34;
               /event/ceniamodal/mohammad_hu16140766223214765226.webp 400w,
               /event/ceniamodal/mohammad_hu6648946481130016374.webp 760w,
               /event/ceniamodal/mohammad_hu17490119621469978857.webp 1200w&#34;
               src=&#34;http://localhost:1313/event/ceniamodal/mohammad_hu16140766223214765226.webp&#34;
               width=&#34;256&#34;
               height=&#34;318&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;multimodal-emotion-recognition&#34;&gt;Multimodal Emotion Recognition&lt;/h4&gt;
&lt;p&gt;Mohammad Soleymani is a research associate professor with the USC Institute for Creative Technologies. He received his PhD in computer science from the University of Geneva in 2011. From 2012 to 2014, he was a Marie Curie fellow at Imperial College London. Prior to joining ICT, he was a research scientist at the Swiss Center for Affective Sciences, University of Geneva. His main line of research involves machine learning for emotion recognition and behavior understanding. He is a recipient of the Swiss National Science Foundation Ambizione grant and the EU Marie Curie fellowship. He has served on multiple conference organization committees and editorial roles, most notably as associate editor for the IEEE Transactions on Affective Computing (2015-2021), general chair for ICMI 2024 and ACII 2021 and technical program chair for ACM ICMI 2018 and ACII 2017. He was the president of the Association for the Advancement of Affective Computing (AAAC) (2019-2021).&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-paul-liang&#34;&gt;Invited Talk: Paul Liang&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image&#34; srcset=&#34;
               /event/ceniamodal/paul-liang-headshot-small_hu7254305025386846404.webp 400w,
               /event/ceniamodal/paul-liang-headshot-small_hu7504278872317812574.webp 760w,
               /event/ceniamodal/paul-liang-headshot-small_hu11974117804273599440.webp 1200w&#34;
               src=&#34;http://localhost:1313/event/ceniamodal/paul-liang-headshot-small_hu7254305025386846404.webp&#34;
               width=&#34;290&#34;
               height=&#34;303&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;fundamentals-of-multimodal-representation-learning&#34;&gt;Fundamentals of Multimodal Representation Learning&lt;/h4&gt;
&lt;p&gt;Paul Liang is an Assistant Professor at the MIT Media Lab and MIT EECS. His research advances the foundations of multisensory artificial
intelligence to enhance the human experience. He is a recipient of the Siebel Scholars Award, Waibel Presidential Fellowship, Facebook
PhD Fellowship, Center for ML and Health Fellowship, Rising Stars in Data Science, and 3 best paper awards. Outside of research, he
received the Alan J. Perlis Graduate Student Teaching Award for developing new courses on multimodal machine learning.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Experience</title>
      <link>http://localhost:1313/experience/</link>
      <pubDate>Sat, 14 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/experience/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tackling Biases In or Using Generative AI @ JSIC&#39;24</title>
      <link>http://localhost:1313/event/jsic/</link>
      <pubDate>Wed, 04 Dec 2024 08:30:00 +0000</pubDate>
      <guid>http://localhost:1313/event/jsic/</guid>
      <description>&lt;p&gt;In this talk, I am focusing on several methods based on data perturbation to detect biases in Large Language Models (LLMs) and Large Multimodal Models (LMMs). We have observed cases where these systems leverage gender, race, or even socioeconomic class information inappropriately for task resolution. Instead of employing real causal reasoning, they often rely on spurious correlations‚Äîa phenomenon commonly referred to as bias.&lt;/p&gt;
&lt;p&gt;We will demystify the concept of bias, explaining why biases are ubiquitous, why they can sometimes be useful, and proposing a method to detect harmful biases.&lt;/p&gt;
&lt;p&gt;First, we will introduce a method we developed to detect biases in LLMs toward different countries using the most common names as proxies. Our findings reveal very negative biases toward certain countries, using widely utilized open-source classifiers for social media analysis. Furthermore, we demonstrate that the same multilingual model tends to favor names from countries that speak the language of the sentence‚Äîa phenomenon we call AI Xenophobia. This phenomenon has significant social implications. Our study, which examined the perplexity of language models and classifier outputs, shows that the model reacts differently to completely unknown languages compared to familiar ones and exhibits similar behavior toward names as it does with unfamiliar languages.&lt;/p&gt;
&lt;p&gt;Second, we present a method to mitigate biases in Vision-Language Models, particularly in image captioning models. By perturbing the training data through data augmentation with a Text-to-Image generative model, we enhance variability in the dataset. This approach not only reduces gender bias but also improves the model&amp;rsquo;s performance in tasks such as counting objects and detecting colors.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] Data Engineer for Geographic and Remote Sensing data</title>
      <link>http://localhost:1313/job_offers/data-eng-deepcrop/</link>
      <pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/data-eng-deepcrop/</guid>
      <description>&lt;p&gt;CIREN, in collaboration with CENIA, is looking for a Data Engineer to be part of the FONDEF Advanced Technologies project team: an ai system for nation-wide agricultural production monitoring based on crowd-sourced and remote-sensing data.&lt;/p&gt;
&lt;h3 id=&#34;what-are-we-looking-for&#34;&gt;What are we looking for?&lt;/h3&gt;
&lt;p&gt;We are looking for a professional with strong technical competencies and interpersonal skills that include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Professionals in the areas of Computer Engineering, Mathematics, Statistics, Physics, Industrial Engineering or related disciplines, preferably with a Master&amp;rsquo;s degree.&lt;/li&gt;
&lt;li&gt;1 to 3 years of professional or project experience.&lt;/li&gt;
&lt;li&gt;Experience in Python, R or SQL&lt;/li&gt;
&lt;li&gt;Knowledge in Machine Learning libraries (scikit-learn, TensorFlow, PyTorch).&lt;/li&gt;
&lt;li&gt;Knowledge in tools to manage geographic data: geopandas, postGIS, geoSQL.&lt;/li&gt;
&lt;li&gt;Knowledge in spatial data processing: Sentinel2, LANDSAT, etc.&lt;/li&gt;
&lt;li&gt;Familiarity with data visualization tools (Power BI, Tableau, Matplotlib, Seaborn).&lt;/li&gt;
&lt;li&gt;Experience in data cleansing and data management in large volumes.&lt;/li&gt;
&lt;li&gt;Knowledge in statistics and advanced probability.&lt;/li&gt;
&lt;li&gt;Familiarity with relational and non-relational databases (PostgreSQL, MongoDB).&lt;/li&gt;
&lt;li&gt;Intermediate or advanced technical English (desirable).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-will-you-do&#34;&gt;What will you do?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Design, implement and optimize Machine Learning and predictive analytics models.&lt;/li&gt;
&lt;li&gt;Collect, clean and structure large volumes of data for analysis.&lt;/li&gt;
&lt;li&gt;Generate actionable insights to support strategic decision making.&lt;/li&gt;
&lt;li&gt;Collaborate with cross-functional teams (developers, analysts, business leaders).&lt;/li&gt;
&lt;li&gt;Visualize data using tools such as Power BI, Tableau or similar.&lt;/li&gt;
&lt;li&gt;Document processes, methodologies and key findings of the projects.&lt;/li&gt;
&lt;li&gt;Ensure the quality and security of the data handled.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-do-we-offer&#34;&gt;What do we offer?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Total gross remuneration of &lt;strong&gt;$2.500.000&lt;/strong&gt;. 2 year fixed term project contract with CIREN.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Offer in the CENIA website &lt;a href=&#34;https://cenia.cl/2024/12/07/buscamos-ingenieroa-de-datos/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] Machine Learning Engineer for Geographic and Remote Sensing data</title>
      <link>http://localhost:1313/job_offers/ml-eng-deepcrop/</link>
      <pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/ml-eng-deepcrop/</guid>
      <description>&lt;p&gt;We are looking for a Machine Learning / Deep Learning research engineer to work on large multi-modal and multi-resolution representation parsing models with satellite data (image sequences).&lt;/p&gt;
&lt;h3 id=&#34;what-will-you-do&#34;&gt;What will you do?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Participate in FONDEF Advanced Technologies project: an ai system for nation-wide agricultural production monitoring based on crowd-sourced and remote-sensing data.&lt;/li&gt;
&lt;li&gt;Develop end-to-end AI solutions.&lt;/li&gt;
&lt;li&gt;Collection of relevant information and design of solutions focused on the optimization of industrial processes.&lt;/li&gt;
&lt;li&gt;Industrial data processing and analysis.&lt;/li&gt;
&lt;li&gt;Development and implementation of advanced predictive models to model subsections of the process.&lt;/li&gt;
&lt;li&gt;Integration and deployment of solutions in production environments.&lt;/li&gt;
&lt;li&gt;Design and build machine learning pipelines focused on optimization and prediction.&lt;/li&gt;
&lt;li&gt;Collaborate on projects within asset-intensive industries such as mining, energy, pulp and paper, among others, applying ML techniques to improve efficiency and productivity.&lt;/li&gt;
&lt;li&gt;Utilize cloud and high performance computing technologies.&lt;/li&gt;
&lt;li&gt;Continuously improve ML solutions through experimentation and iteration.&lt;/li&gt;
&lt;li&gt;Keep up to date with the latest trends and developments in ML and optimization technologies.&lt;/li&gt;
&lt;li&gt;Work closely with the CopernicusLAC team, the European Space Agency&amp;rsquo;s satellite constellation data hub.&lt;/li&gt;
&lt;li&gt;Work on the creation of a satellite data dataset (Sentinel2, Sentinel3, Sentinel5) throughout Latin America and the Caribbean.&lt;/li&gt;
&lt;li&gt;Design and create foundational models for satellite data processing in conjunction with researchers from CENIA and profe from the University of Chile:&lt;/li&gt;
&lt;li&gt;Use multi-scale self-supervised learning techniques on satellite data.&lt;/li&gt;
&lt;li&gt;Use meta-learning algorithms to learn the model to learn new tasks: crop-land mapping, land-use mapping, drought detection, illegal deforestation, etc.&lt;/li&gt;
&lt;li&gt;Participate in writing scientific papers on data creation and modeling, participate in presentation at appropriate conferences: CVPR, ICCV, ECCV, WACAV, NeurIPS, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-are-we-looking-for&#34;&gt;What are we looking for?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Bachelor&amp;rsquo;s degree in Computer Science, Mathematics, Statistics, Engineering or a related field.&lt;/li&gt;
&lt;li&gt;1 to 3 years of professional or ML project experience.&lt;/li&gt;
&lt;li&gt;Verifiable experience in software and/or software development based on machine learning, computer vision and satellite data management.&lt;/li&gt;
&lt;li&gt;Knowledge and previous experience with Python and some of the following libraries: PyTorch, Huggingface, TensorFlow, Scikit-Learn or other related libraries (Excluded)&lt;/li&gt;
&lt;li&gt;Knowledge in tools to manage geographic data: geopandas, postGIS, geoSQL, etc&amp;hellip;&lt;/li&gt;
&lt;li&gt;Knowledge in spatial data processing: Sentinel2 data, LANDSAT, GEE, etc&amp;hellip;&lt;/li&gt;
&lt;li&gt;Demonstrated experience in the design and construction of machine learning pipelines (Excluded).&lt;/li&gt;
&lt;li&gt;Demonstrated experience in the use and development of vision projects (Excluding)&lt;/li&gt;
&lt;li&gt;Familiarity with Machine Learning Operations (MLOps) development practices (Required).&lt;/li&gt;
&lt;li&gt;Experience in consulting projects (Desirable).&lt;/li&gt;
&lt;li&gt;Development experience in Cloud platforms (Desirable).&lt;/li&gt;
&lt;li&gt;Experience with cloud computing platforms, in particular GCP. (Desirable)&lt;/li&gt;
&lt;li&gt;Knowledge of deploying ML models in production environments (Desirable).&lt;/li&gt;
&lt;li&gt;Development experience with code versioning in Git (Desirable).&lt;/li&gt;
&lt;li&gt;Experience with Docker (desirable).&lt;/li&gt;
&lt;li&gt;Experience with Python packages and environments (desirable).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-do-we-offer&#34;&gt;What do we offer?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Total gross remuneration of &lt;strong&gt;$2.500.000&lt;/strong&gt;. Fixed term project contract 2 years.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of our benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;üè°Hybrid work system: Home office combined with face-to-face workday.&lt;/li&gt;
&lt;li&gt;üë£Comfortable offices close to San Joaqu√≠n subway station.&lt;/li&gt;
&lt;li&gt;üö≤Access to bike rack and dressing rooms.&lt;/li&gt;
&lt;li&gt;Parking at preferential price.&lt;/li&gt;
&lt;li&gt;Casual Dress Code.&lt;/li&gt;
&lt;li&gt;üéÅBirthday free day.&lt;/li&gt;
&lt;li&gt;üéÑAdvance disconnection for the holidays.&lt;/li&gt;
&lt;li&gt;‚úâÔ∏è Day off for Vocal de mesa.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CENIA site offer &lt;a href=&#34;https://cenia.cl/2024/12/06/buscamos-igenieroa-en-machine-learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aca&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CEDS 24 Conferencia Internacional del Espacio y Desarollo Sostenible</title>
      <link>http://localhost:1313/not_used/ceds24/</link>
      <pubDate>Wed, 27 Nov 2024 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/ceds24/</guid>
      <description>&lt;p&gt;&lt;strong&gt;La Conferencia Internacional Espacio y Desarrollo Sostenible (CEDS2024)&lt;/strong&gt; ha sido concebida como un espacio de conocimiento e intercambio de experiencias e ideas en torno a los desaf√≠os y oportunidades que se presentan en los temas del espacio y a la b√∫squeda de estrategias y alternativas de acci√≥n que posibiliten su uso de manera sostenible. Con este objetivo se abordar√°n los √°mbitos cient√≠fico-tecnol√≥gicos, el desarrollo industrial y las estrategias nacionales incluyendo los marcos jur√≠dicos y de colaboraci√≥n necesarios para su uso en un mundo globalizado, √∫nico posible cuando de espacio se trata.&lt;/p&gt;
&lt;h2 id=&#34;ceds-y-la-universidad-de-chile&#34;&gt;CEDS y la Universidad de Chile&lt;/h2&gt;
&lt;p&gt;La Universidad de Chile, ha estado estrechamente vinculada a estos temas, desde que firmara el acuerdo en 1958 para apoyar los programas de la NASA y crear el Centro de Estudios Espaciales, o en 2017 cuando, a trav√©s del Programa SUCHAI de nano-sat√©lites lanzara el primer nano-sat√©lite chileno, base de la actual constelaci√≥n de nano-sat√©lites de Chile y, actualmente llevando cabo el proyecto &lt;a href=&#34;https://www.copernicuslac-chile.eu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Centro Regional Copernicus para Am√©rica Latina y el Caribe: CopernicusLAC Chile&lt;/a&gt;, en el marco del acuerdo firmado con la Uni√≥n Europea, el que est√° desplegando una poderosa infraestructura para el almacenamiento y procesamiento de datos, entregando servicios a la regi√≥n que beneficiar√°n la toma de decisiones en diversos √°mbitos que afectan hoy a la sociedad. Por estas y otras razones, junto a instituciones nacionales e internacionales, tanto p√∫blicas como privadas, han decidido organizar la Conferencia Internacional Espacio y Desarrollo Sostenible (CEDS2024).&lt;/p&gt;
&lt;h2 id=&#34;ejes-tem√°ticos&#34;&gt;Ejes tem√°ticos&lt;/h2&gt;
&lt;p&gt;CEDS2024 es un espacio donde se analizar√° y discutir√° acerca de:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Oportunidades y Desaf√≠os en el desarrollo espacial&lt;/li&gt;
&lt;li&gt;Promoci√≥n del desarrollo de la Ciencia y Tecnolog√≠a Espacial&lt;/li&gt;
&lt;li&gt;Promover la Innovaci√≥n y el Desarrollo industrial en materia Espacial&lt;/li&gt;
&lt;li&gt;El Espacio en los Grandes Desaf√≠os Globales&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>[FOUND] [Tesis pre/postgrado] JAJAJJJJJ -- Deteccion de humor en videos de stand-up comedy</title>
      <link>http://localhost:1313/job_offers/thesis-jajaja/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/job_offers/thesis-jajaja/</guid>
      <description>&lt;h3 id=&#34;content&#34;&gt;Content&lt;/h3&gt;
&lt;p&gt;Humour is a key dimension in human-human communication and is used constantly, in a wide variety of contexts. It is used for its pleasing effect as it can help explain complex ideas during important presentations or it can serve as pure entertainment like in movies or stand up comedy. Sometimes, it can also be used in a less deliberate manner, unconsciously, as a way to regulate the inherent stress and tension arising in conversations, by presenting one‚Äôs ideas and intentions in an alternate way.&lt;/p&gt;
&lt;p&gt;While Human-Agent interactions are growing in popularity due to the recent thrive of Large Language Models, the resulting conversations still remain frustrating for the users when they start to use subtle conversational strategies and skills such as irony, euphemism, hyperbolism and humour.&lt;/p&gt;
&lt;p&gt;Today, when a human is using humour during a human-agent interaction, this tends to interrupt the flow of the interaction. Agents interpret quite literally what a human is saying and as the agent does not react as the human would expect from a fellow conversational partner this leads to rephrasing, repeating and eventually frustration.&lt;/p&gt;
&lt;p&gt;Our vision for the future of conversational agents is that agents should be able at least to detect humorous attempts and to redirect the flow of the conversation accordingly. In this project, our main objective is to endow conversational agents with the ability to recognize when humour is being used by a human during human-agent interactions. Towards this goal, we will be relying on a multimodal approach and we will investigate how multimodal computational models can achieve this.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-example-taken-from-the-ur-funny-dataset-6&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;UR_FUNNY&#34; srcset=&#34;
               /job_offers/thesis-jajaja/UR_FUNNY_hu10620972935419908973.webp 400w,
               /job_offers/thesis-jajaja/UR_FUNNY_hu12261418939102111829.webp 760w,
               /job_offers/thesis-jajaja/UR_FUNNY_hu2094234890411483346.webp 1200w&#34;
               src=&#34;http://localhost:1313/job_offers/thesis-jajaja/UR_FUNNY_hu10620972935419908973.webp&#34;
               width=&#34;760&#34;
               height=&#34;296&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Example taken from the UR-FUNNY dataset [6]
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;On this project, we will focus on the use of multimodal models with or without interactions [1,2] that can be also multilingual [3]. We would focus on multimodal but also multicultural specific social context [4], showing that multimodal is essential to detect complex human cultural and social phenonema such as sarcasm [5] or humour detection [6]. For group interactions, modelization of the speakers will be done using special architecture such as DialogueRNN [7].&lt;/p&gt;
&lt;h3 id=&#34;tasks&#34;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;Here, we will focus on the first brick of this amazing human-machine project, which is the characterization and detection of humor using verbal and non-verbal language. First, we will study this complex phenomena in various languages using stand-up comedy videos. Second, if time allows it, we would focus on dyad or group interactions, such as TV-shows or better, naturalistic interactions.&lt;/p&gt;
&lt;p&gt;The student will have to work on the several tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collection of a dataset of stand-up comedy videos on youtube&lt;/li&gt;
&lt;li&gt;Cleaning and analysis of the dataset&lt;/li&gt;
&lt;li&gt;Multimodal modelization of human verbal and non-verbal language using binary classification&lt;/li&gt;
&lt;li&gt;Possibility to think about a more fine-grained humour taxonomy (more than just binary, how to propagate laugh, etc‚Ä¶)&lt;/li&gt;
&lt;li&gt;Collection of a dataset of humor in interactions&lt;/li&gt;
&lt;li&gt;Modelization more complex of multi-party interactions&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bibliography&#34;&gt;Bibliography&lt;/h3&gt;
&lt;p&gt;[1] P. P. Liang, Y. Cheng, R. Salakhutdinov, and L. P. Morency, ‚ÄúMultimodal Fusion Interactions: A Study of Human and Automatic Quantification,‚Äù ACM Int. Conf. Proceeding Ser., pp. 425‚Äì435, 2023.&lt;/p&gt;
&lt;p&gt;[2] A. Zadeh, P. P. Liang, N. Mazumder, S. Poria, E. Cambria, and L.-P. Morency, ‚ÄúMemory Fusion Network for Multi-view Sequential Learning,‚Äù in AAAI, 2018.&lt;/p&gt;
&lt;p&gt;[3] A. Zadeh, Y. S. Cao, S. Hessner, P. P. Liang, S. Poria, and L. Morency, ‚ÄúCMU-MOSEAS‚ÄØ: A Multimodal Language Dataset for Spanish , Portuguese , German and French,‚Äù in EMNLP, 2020, vol. 1, no. 1, pp. 1801‚Äì1812.&lt;/p&gt;
&lt;p&gt;[4] M. Sap, S. Gabriel, L. Qin, D. Jurafsky, N. A. Smith, and Y. Choi, ‚ÄúSocial Bias Frames: Reasoning about Social and Power Implications of Language,‚Äù Proc. ofthe 58th Annu. Meet. ofthe Assoc. Comput. Linguist., pp. 5477‚Äì5490, 2020.&lt;/p&gt;
&lt;p&gt;[5] P. Desai, T. Chakraborty, and M. S. Akhtar, ‚ÄúNice perfume. How long did you marinate in it? Multimodal Sarcasm Explanation,‚Äù in AAAI, 2022.&lt;/p&gt;
&lt;p&gt;[6] M. K. Hasan et al., ‚ÄúUR-FUNNY: A Multimodal Language Dataset for Understanding Humor,‚Äù 2019.&lt;/p&gt;
&lt;p&gt;[7] N. Majumder, S. Poria, D. Hazarika, R. Mihalcea, A. Gelbukh, and E. Cambria, ‚ÄúDialogueRNN: An Attentive RNN for Emotion Detection in Conversations,‚Äù in AAAI, 2019.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers</title>
      <link>http://localhost:1313/publication/emnlp24-ppl/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/emnlp24-ppl/</guid>
      <description>&lt;p&gt;This work is driven by the results of a &lt;a href=&#34;http://localhost:1313/publication/LREC24-XENOPHOBIA/&#34;&gt;previous paper&lt;/a&gt; on country-level bias detection in LLMs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>XenophoBiasüè≥Ô∏è‚Äçüåà</title>
      <link>http://localhost:1313/project/xenophobias/</link>
      <pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/xenophobias/</guid>
      <description>&lt;p&gt;Multicultural Bias Recognition to Detect and Mitigate Racism, Xenophobia and Geographic Inequalities in Multilingual Large Language Models.&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Principal Investigator of this project&lt;/strong&gt;. This is a 2 years &lt;a href=&#34;https://uchile.cl/convocatorias/216327/concurso-u-inicia-2024&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;U-inicia&lt;/a&gt; grant from the University with a total budget of 8,000,000 CLP.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;Classical bias detection methods used in Machine Learning and Natural Language Processing (NLP) are themselves biased because of the different confounding variables implied in the assessment of the initial biases. First they are using templates that are syntactically simple and distant from the target data on which the model will be applied. Second, current methods are assessing biases in pre-trained language models or in dataset, but not directly on the fine-tuned classifier that can actually produce harms.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;counfounding&#34; srcset=&#34;
               /project/xenophobias/featured_hu4709178623435340922.webp 400w,
               /project/xenophobias/featured_hu2414093935314123718.webp 760w,
               /project/xenophobias/featured_hu9909048982336450453.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/featured_hu4709178623435340922.webp&#34;
               width=&#34;449&#34;
               height=&#34;587&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We propose a simple method to detect the biases of a specific fine-tuned classifier on any type of unlabeled data. The idea is to study the classifier behavior by creating counterfactual examples directly on the target data distribution and quantify the amount of changes. We focus on named entity perturbations by applying a &lt;strong&gt;Named Entity Recognition&lt;/strong&gt; (NER) on target-domain data and modifying them accordingly to most common names or location of a target group (gender and/or country), and this for several morphosynctactically different languages spoken in relation with the countries of the target groups. &lt;strong&gt;The idea is that perturbing the input data with a non-causal change should not impact the output distribution of a model&lt;/strong&gt;, but it actually does with respect to the languages and the country of provenance of the added entity perturbing the sentence. An analysis of the changes helps practitioners getting a deeper understanding of how a model can react to different target groups.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-we-use-the-target-domain-data-to-create-templates&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overall&#34; srcset=&#34;
               /project/xenophobias/figure_v9_1_hu1431973182623297372.webp 400w,
               /project/xenophobias/figure_v9_1_hu5426821930535034716.webp 760w,
               /project/xenophobias/figure_v9_1_hu13032372178332810117.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/figure_v9_1_hu1431973182623297372.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      We use the target-domain data to create templates.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Here is an example with two sentences, $S^n$
 being ambiguous and $S^1$
 obvious hate speech. The model output of the perturbated versions is highly variable for the multilingual variations of &lt;em&gt;Alexander&lt;/em&gt;. With some name variations, such as the Turkish or Indian, the models classify the sentences as more negative or detect less hate speech. Meaning it will not moderate the content of an insult toward this person (see below):
















&lt;figure  id=&#34;figure-the-templates-obtained-from-target-domain-data-are-filled-with-common-names-from-various-countries-the-difference-in-the-models-output-is-significative-of-a-bias-regarding-the-names&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;overall&#34; srcset=&#34;
               /project/xenophobias/figure_v9_2_hu5969773204992941524.webp 400w,
               /project/xenophobias/figure_v9_2_hu408390470316705406.webp 760w,
               /project/xenophobias/figure_v9_2_hu4458702702344355493.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/figure_v9_2_hu5969773204992941524.webp&#34;
               width=&#34;760&#34;
               height=&#34;334&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The templates obtained from target-domain data are filled with common names from various countries. The difference in the model&amp;rsquo;s output is significative of a bias regarding the names.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We will then focus on &lt;strong&gt;how to leverage LLM in order to create sentences from the target-domain data distribution&lt;/strong&gt;, with entites, then with more fine-grained named concepts related to the countries, such as local meals, celebrations, or regional slang.
We want first to use our method on models available in open-source that are likely to be deployed by industry, i.e., widely used classifiers for subjectivity analysis, including sentiment, emotion, hate speech, and offensive text using Twitter data. &lt;strong&gt;We will assess the bias of a variety of models&lt;/strong&gt; such as an open-source multilingual sentiment analysis model trained over multiple-languages tweets, a multilingual stance recognition model trained over several languages and assessed over English language, an English hate speech classifier, an English large language model, and a multilingual large language model such as Llama-3.
Our work offers a fine-grained analysis of the interactions between names and languages, aiming to reveal significant biases in multilingual models, but also strong biases towards some countries‚Äô names. &lt;strong&gt;We want to link this with the pre-training data used to pre-train the LLM, by the mean of the Language Model‚Äôs (pseudo-)likelihood&lt;/strong&gt;. We hope to find out very socially interesting/impacting results such as a sentence containing a name from an arabic or slavic country will more likely to be tagged as negative, and less likely to be tagged as hate speech.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;In other words we want to answer the questions:&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Are LLM xenophobic?&lt;/li&gt;
&lt;li&gt;How to quantify it?&lt;/li&gt;
&lt;li&gt;How to remove this bias?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;schedule&#34;&gt;Schedule&lt;/h3&gt;
&lt;p&gt;Milestones will follow the project objectives and milestones are defined as a group of objectives with a publication at an A(*)-ranked conference or in a journal to complete the milestone.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Milestone 1&lt;/strong&gt; consists of objectives 1 and 2 as well as the publication of a paper at an A(*) conference. The method developed above will be applied to different types of classifiers and generative models. A perplexity analysis will be performed to try to quantify the visible bias of the internal states of neural networks. I plan 5 months to adapt the method that already exists for LLM and use perplexity to find lassos between frequencies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Milestone 2&lt;/strong&gt; consists of objectives 3 and 4, as well as the publication of a paper in a conference A. I plan 4 months for the artificial data generation because it is not so straightforward and we will have to work on the generation in the target distribution per se, and also on the collection and how to add in the generation the socio-cultural attributes of the different countries (2 months + 2 months).&lt;/p&gt;
&lt;p&gt;The last &lt;strong&gt;Milestone 3&lt;/strong&gt; contains the final objective concerning the reduction of bias, with the aggregation of all previous results in a journal publication.  Working on bias reduction based on our method will be quite straightforward. The writing of a journal paper where we will have all the results of the project will be longer than the previous conference papers, which will have more specific and limited contents. For that I plan 4 months for the reduction and 3 months for the writing, with 2 overlapping months.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;gantt&#34; srcset=&#34;
               /project/xenophobias/gantt_hu3088727843124199660.webp 400w,
               /project/xenophobias/gantt_hu11767512201186597748.webp 760w,
               /project/xenophobias/gantt_hu16173524106031046137.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/xenophobias/gantt_hu3088727843124199660.webp&#34;
               width=&#34;760&#34;
               height=&#34;272&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 8k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>(Preprint) Scrapping The Web For Early Wildfire Detection: A New Annotated Dataset of Images and Videos of Smoke Plumes In-the-wild</title>
      <link>http://localhost:1313/publication/preprint-scrapping/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/preprint-scrapping/</guid>
      <description>&lt;p&gt;This work goes directly in the context of the &lt;a href=&#34;http://localhost:1313/project/fAIrefighter/&#34;&gt;fAIrefighterüßØ&lt;/a&gt; project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CopernicusLACüõ∞Ô∏èüá™üá∫</title>
      <link>http://localhost:1313/project/copernicus/</link>
      <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/copernicus/</guid>
      <description>&lt;p&gt;Our project is located in Santiago de Chile and operates as a centre dedicated to the storage, processing, and distribution of satellite data of the Copernicus Programme and the provision of services of regional interest for the benefit of all countries in Latin America and the Caribbean (LAC).&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;I act as &lt;strong&gt;Scientific Advisor and Researcher Artificial Intelligence for Earth Observation&lt;/strong&gt; within the CopernicusLAC project, where I aim to be part of the team developing novel, large-scale, and generalizable vision models for remote sensing data processing.&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.copernicuslac-chile.eu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Copernicus Regional Centre for Latin America and the Caribbean&lt;/a&gt; (CopernicusLAC Chile) is a project funded by the European Union and the University of Chile and implemented by the Center for Mathematical Modeling (CMM).&lt;/p&gt;
&lt;p&gt;This project provides Copernicus data storage, processing, and distribution services for the region, as well as developing monitoring services in the areas of land use and land cover, urban areas and oceans and coasts, including the coordination of access to in situ data, i.e. data from land-based meteorological stations, ocean buoys and air quality monitoring networks, among others.&lt;/p&gt;
&lt;p&gt;Our mission is to meet the region‚Äôs needs for the storage, processing, and distribution of advanced Earth observation data for both the specialist community and the public. Our commitment is to offer innovative solutions, promoting collaboration and open access to information to drive socio-economic and environmental progress in Latin America and the Caribbean.&lt;/p&gt;
&lt;p&gt;Our vision is to be recognised as a leader in the Earth observation community for Latin America and the Caribbean. We seek to be a key source of information, contributing significantly to informed decision-making that transforms and promotes meaningful sustainable development for the region.&lt;/p&gt;
&lt;h3 id=&#34;copernicus-eu&#34;&gt;Copernicus EU&lt;/h3&gt;
&lt;p&gt;Copernicus is the European Earth observation system, which offers free and open access data and services through its network of Sentinel satellites, providing images of our planet with valuable information to be applied in areas such as agriculture, mining, urban planning, disaster management, environmental protection, among others.&lt;/p&gt;
&lt;p&gt;The programme is coordinated and managed by the European Commission and implemented in collaboration with the Member States, the European Space Agency (ESA), the European Organisation for the Exploitation of Meteorological Satellites (Eumetsat), the European Centre for Medium-Range Weather Forecasts, EU agencies and Mercator Ocean, among others.&lt;/p&gt;
&lt;p&gt;It uses vast amounts of global data from satellites and measurement systems on land, air and sea to provide information that helps service providers, public administrations and other international organisations to improve the quality of life of Europe‚Äôs citizens. The information services provided are freely and openly accessible to its users.&lt;/p&gt;
&lt;p&gt;(Source and more information: &lt;a href=&#34;https://www.copernicus.eu/en/about-copernicus&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Copernicus EU&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DeepCropüõ∞Ô∏èüåæüåΩ</title>
      <link>http://localhost:1313/project/deepcrop/</link>
      <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/deepcrop/</guid>
      <description>&lt;p&gt;We are creating an AI system for nation-wide agricultural production monitoring based on crowd-sourced and remote-sensing.&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Director of this project&lt;/strong&gt;, which is a collaboration between the University of Chile, (the Centre of Artificial Intelligence)[https://www.cenia.cl], (the Center of Natural Ressources)[https://www.ciren.cl] as principal institutions, and the &lt;a href=&#34;https://www.eurocrops.tum.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Technical University of Munich&lt;/a&gt;, the &lt;a href=&#34;https://www.jrc.eu.todo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;European Commission&amp;rsquo;s Joint Research Center&lt;/a&gt;, and the &lt;a href=&#34;https://www.epfl.ch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;√âcole Polytechnique F√©d√©rale de Lausanne&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is a 4 years &lt;a href=&#34;https://anid.cl/concursos/concurso-idea-id-tecnologias-avanzadas-2024/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Tecnologia Avanzada&lt;/em&gt;&lt;/a&gt; project funded to the tune of 660,000,000 CLP&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; coming as grant from the National Research and Development Agency (ANID).&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;This project aims to develop a crop map (like land-use but for crop i.e., which crop are cultivated where) at the country-level. To this aim we will leverage the capacity of general purpose model that we will trained over Chile. This is quite fun as Chile is a very long country with many different climates, making it the perfect place to test a model claiming to be general.&lt;/p&gt;
&lt;p&gt;The objectives are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gathering existing general crop data at the polygon- and pixel-level from open-source and in-house datasets&lt;/li&gt;
&lt;li&gt;Collecting Chilean crop data at the polygon- and pixel-level, including yield&lt;/li&gt;
&lt;li&gt;Implementing a parcel delineation model, with a polygon-level crop classifier&lt;/li&gt;
&lt;li&gt;Pre-training a large vision model on Worldwide, South American, and Chilean multimodal and multiresolution data&lt;/li&gt;
&lt;li&gt;Train the model to learn to learn various tasks using meta-learning algorithms&lt;/li&gt;
&lt;li&gt;Implement a dashboard using the model&amp;rsquo;s predictions&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 670k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>WASSA Workshop @ ACL 24</title>
      <link>http://localhost:1313/event/wassa24/</link>
      <pubDate>Thu, 15 Aug 2024 09:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/wassa24/</guid>
      <description>&lt;p&gt;We are orgnizing the 14th edition of the WASSA workshop this year at &lt;a href=&#34;https://2024.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL24&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Our keynote speaker will be Debora Nozza&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://workshop-wassa.github.io/assets/images/debora_nozza.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;
&lt;p&gt;The proliferation of hate speech on social media platforms has been rising, with (pseudo-)anonymity allowing individuals to target others without being recognized or easily traced. While this societal issue has garnered significant attention in the NLP community, it presents three major challenges. Hate speech detection models need to be fair, work across all languages, and incorporate personalization while balancing privacy concerns. Addressing these challenges will revolutionize the field of hate speech detection and contribute to the development of a ‚Äúuniversal‚Äù model that can adapt to individual user perspectives. In this talk, I will present my contributions in this area along with my perspectives on future directions.&lt;/p&gt;
&lt;h4 id=&#34;bio&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;Debora Nozza is an Assistant Professor in Computing Sciences at Bocconi University. Her research interests mainly focus on Natural Language Processing, specifically on the detection and counter-acting of hate speech and algorithmic bias on Social Media data in multilingual context&lt;/p&gt;
&lt;h2 id=&#34;about-wassa&#34;&gt;About WASSA&lt;/h2&gt;
&lt;p&gt;The aim of WASSA 2024 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text. For this edition, we encourage the submission of long and short research and demo papers including, but not restricted to the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resources for subjectivity, sentiment, emotion and social media analysis&lt;/li&gt;
&lt;li&gt;Opinion retrieval, extraction, categorization, aggregation and summarization&lt;/li&gt;
&lt;li&gt;Humor, Irony and Sarcasm detection&lt;/li&gt;
&lt;li&gt;Mis- and disinformation analysis and the role of affective attributes&lt;/li&gt;
&lt;li&gt;Aspect and topic-based sentiment and emotion analysis&lt;/li&gt;
&lt;li&gt;Analysis of stable traits of social media users, incl. personality analysis and profiling&lt;/li&gt;
&lt;li&gt;Transfer learning for domain, language and genre portability of sentiment analysis&lt;/li&gt;
&lt;li&gt;Modelling commonsense knowledge for subjectivity, sentiment or emotion analysis&lt;/li&gt;
&lt;li&gt;Improvement of NLP tasks using subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;Intrinsic and extrinsic evaluation of subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;The role of emotions in argument mining&lt;/li&gt;
&lt;li&gt;Application of theories from related fields to subjectivity and sentiment analysis&lt;/li&gt;
&lt;li&gt;Multimodal emotion detection and classification&lt;/li&gt;
&lt;li&gt;Applications of sentiment and emotion mining&lt;/li&gt;
&lt;li&gt;Public sentiments and communication patterns of public health emergencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the past years we have noticed that WASSA offers a platform to researchers investigating sentiment and emotion in lesser-resourced languages. The 2023 edition featured work on no less than 23 different languages and two papers specifically targeted multilingual emotion detection. We wish to continue these efforts as we find it important to consider and publish advances in any language as this helps to underline the wealth of our research community and to diminish the dominance of English-language research. To this purpose we propose a Special track on multilinguality and social bridge between high- and lesser-resourced languages/communities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fantastic Biases (What are They) and Where to Find Them</title>
      <link>http://localhost:1313/publication/bits24-biases/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/bits24-biases/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Findings of WASSA 2024 Shared Task on Empathy and Personality Detection in Interactions</title>
      <link>http://localhost:1313/publication/wassa24-task/</link>
      <pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wassa24-task/</guid>
      <description>&lt;p&gt;Fourth shared task related to Empathy we organized at WASSA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>fAIrefighterüßØ</title>
      <link>http://localhost:1313/project/fairefighter/</link>
      <pubDate>Sun, 09 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/fairefighter/</guid>
      <description>&lt;p&gt;A wildfire early detection and spread prediction AI-driven decision support tool.&lt;/p&gt;
&lt;h4 id=&#34;my-role&#34;&gt;My role&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I am the Director of this project&lt;/strong&gt;, which is a collaboration between the University of Chile, the &lt;a href=&#34;https://www.cenia.cl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Centre of Artificial Intelligence&lt;/a&gt;, the &lt;a href=&#34;https://www.puc.cl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Catholic University&lt;/a&gt;, the &lt;a href=&#34;https://www.conaf.cl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;National Forestry Corporation&lt;/a&gt;, and the Non-Governmental Organization &lt;a href=&#34;https://pyronear.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyroNear&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is a 2 years &lt;a href=&#34;https://anid.cl/concursos/concurso-idea-id-2024/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;IDeA&lt;/em&gt;&lt;/a&gt; project project funded to the tune of 220,000,000 CLP&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; coming as grant from the National Research and Development Agency (ANID).&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The project&lt;/h3&gt;
&lt;p&gt;In Chile, there are no technologies to perform early wildfire detection based on on computer vision. Moreover there is no decision support tool to inform authorities regarding predictive propagation of ongoing wildfires. However, there are huge consequences of not containing wildfires: economical, ecological, and societal.&lt;/p&gt;
&lt;p&gt;We propose a two-level plan to fight wildfire at different levels that are complementary. The first one to tackle the wildfire as soon as possible, the second to get information in order to distribute human, machine and water resources efficiently:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Early Wildfire Prediction (EWD): Perform early wildfire detection using computer vision&lt;/li&gt;
&lt;li&gt;Wildfire Spread Prediction (WSP): If the wildfire is getting out of control, an AI-based tool predict the wildfire spread using remote sensing and physics informed neural networks (PINNs).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A global overview of both the systems and how they are interacting is visible below:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image_all&#34; srcset=&#34;
               /project/fairefighter/fAIrefighter_all_hu1213781944679647980.webp 400w,
               /project/fairefighter/fAIrefighter_all_hu5711198834479959995.webp 760w,
               /project/fairefighter/fAIrefighter_all_hu17062598067408856427.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/fairefighter/fAIrefighter_all_hu1213781944679647980.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: The first part consists in installing stations that detect smoke plumes in the wild. The algorithms are frugal Computer Vision methods such as small neural networks implemented on mini-computers, in order to process the information locally and send flags and data when a wildfire is detected. It is necessary to install stations on the watchtowers, collect data, annotate them, and train the models in order to achieve this.
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image_all&#34; srcset=&#34;
               /project/fairefighter/fAIrefighter_ewd_hu15059260110091567817.webp 400w,
               /project/fairefighter/fAIrefighter_ewd_hu17704182685406066860.webp 760w,
               /project/fairefighter/fAIrefighter_ewd_hu8766366730088195042.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/fairefighter/fAIrefighter_ewd_hu15059260110091567817.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 0.1: Gather training set: Gather smoke plume images from open-source platforms from everywhere in the world, and train a first version on the model.&lt;/li&gt;
&lt;li&gt;Step 0.2: Train a model: Train a first version of the EWD, using a YoloV5.&lt;/li&gt;
&lt;li&gt;Step 1: Putting cameras on the watchtowers. Gather data for detection and annotation purposes.&lt;/li&gt;
&lt;li&gt;Step 2: Process chilean images on the annotation platform. The images where potential
smoke plumes are automatically detected by the model trained on phase 0 will be manually validated by humans, in order to enhance the quality of the dataset by adapting the model to in-domain images and reducing the number of false positives.&lt;/li&gt;
&lt;li&gt;Step 3: Gather in-domain training set: Combine the initial training set with the annotated chilean data in order to adapt the model to the environment.&lt;/li&gt;
&lt;li&gt;Step 4.1: Fine-tune the smoke plume detection model images: First, the model will be trained using available data that we are collecting, then it will be fine-tuned on multimodal Chilean data&lt;/li&gt;
&lt;li&gt;Step 4.2: Apply the model on new images in real time&lt;/li&gt;
&lt;li&gt;Step 5: Visualize the alerts on a web platform: using an interface to see where the watchtower is and where the camera is looking at, but also what are the images from the camera that triggered the alert. The platform will also have an interface allowing for validation or rejection of the smoke plumes detected, in order to enhance the quality of the model.&lt;/li&gt;
&lt;li&gt;Step Final: Resource deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: The second part consists in prediction of wildfire propagation using physics-informed machine learning model. It is necessary to collect a wildfire scar dataset, create a physical model of wildifre propgation based on it, to generate artificial data. On this generated data, a PINN can be trained and then fine-tuned on real chilean wildfires, and compared to reality.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;image_all&#34; srcset=&#34;
               /project/fairefighter/fAIrefighter_wsp_hu13840030640784380258.webp 400w,
               /project/fairefighter/fAIrefighter_wsp_hu10695992529765654606.webp 760w,
               /project/fairefighter/fAIrefighter_wsp_hu13493718214921426331.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/fairefighter/fAIrefighter_wsp_hu13840030640784380258.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 0: Gather data from various sources, like wildfire scars, meteorological data, and more. This data forms the basis for studying wildfire patterns.&lt;/li&gt;
&lt;li&gt;Step 1: Use of the open-source tool called Cell2Fire to simulate how wildfires spread. This helps us understand fire behavior and make predictions.&lt;/li&gt;
&lt;li&gt;Step 2: Creation of artificial training data using simulator. We select specific wildfires and replicate their growth using Cell2Fire. This gives us data to analyze.&lt;/li&gt;
&lt;li&gt;Step3:Combinationofdataandscientificmodels.Byintegratingphysics-basedequations into neural networks we build a strong model for wildfire spread. This blends real data with scientific knowledge.&lt;/li&gt;
&lt;li&gt;Steps 4.1/4.2: Fine-tune the model and apply it on new remote sensing data: first, the model will be trained using available data that we are collecting, then it will be fine-tuned on Chilean data.&lt;/li&gt;
&lt;li&gt;Step 5: Visualize on a web platform.&lt;/li&gt;
&lt;li&gt;Step Final: Resource deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Overall&lt;/strong&gt;: There is no notion of intellectual property in our project. We will base our technology on open-source knowledge like published papers that we will re-implement ourselves or by using available online code without restrictive license. Subsequently, all our models and datasets will be published as open-source resources for the research community.&lt;/p&gt;
&lt;h3 id=&#34;objectives&#34;&gt;Objectives&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Main&lt;/strong&gt;:
Integrated, technology-driven wildfire management system active at two levels: &lt;em&gt;(i)&lt;/em&gt; to proactively detect early wildfire foci, &lt;em&gt;(ii)&lt;/em&gt; accurately predict wildfire spread in order to &lt;em&gt;(iii)&lt;/em&gt; facilitate real-time decision-making by allowing forest guards, firemen and policy-makers to get more information when allocating resources such as manpower, material and water or when planning evacuation&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Specific&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Early Wildfire Detection&lt;/li&gt;
&lt;li&gt;Wildfire Spread Prediction&lt;/li&gt;
&lt;li&gt;Decision Support Tool&lt;/li&gt;
&lt;li&gt;Impact Assessment&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;~ 220k dollars&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>http://localhost:1313/deep-index/</link>
      <pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep-index/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Minerias de Datos</title>
      <link>http://localhost:1313/minerias-index/</link>
      <pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias-index/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>http://localhost:1313/projects/</link>
      <pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Are Text Classifiers Xenophobic? A Country-Oriented Bias Detection Method with Least Confounding Variables</title>
      <link>http://localhost:1313/publication/lrec24-xenophobia/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec24-xenophobia/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Touch√©23-ValueEval Dataset for Identifying Human Values behind Arguments</title>
      <link>http://localhost:1313/publication/lrec24-touche/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec24-touche/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Boosting crop classification by hierarchically fusing satellite, rotational, and contextual data</title>
      <link>http://localhost:1313/publication/rse24-boosting/</link>
      <pubDate>Mon, 01 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/rse24-boosting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Introduccion</title>
      <link>http://localhost:1313/deep/1_introduction/</link>
      <pubDate>Sat, 30 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/1_introduction/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides1_introductionpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/1_Introduction.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Introduccion</title>
      <link>http://localhost:1313/minerias/1_intro/</link>
      <pubDate>Sat, 30 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/1_intro/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_intro_generalpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Intro_general.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;h2 id=&#34;introducci√≥n-a-la-ciencia-de-datos-ia-y-machine-learning&#34;&gt;Introducci√≥n a la Ciencia de Datos, IA y Machine Learning&lt;/h2&gt;
&lt;p&gt;La &lt;strong&gt;Miner√≠a de Datos&lt;/strong&gt; (o Data Mining) es un campo que busca la &lt;strong&gt;extracci√≥n de conocimiento a partir de grandes cantidades de datos&lt;/strong&gt; mediante m√©todos autom√°ticos o semiautom√°ticos. Se nutre de diversas disciplinas ‚Äîcomo estad√≠stica, inteligencia artificial o inform√°tica‚Äî para &lt;strong&gt;encontrar patrones&lt;/strong&gt; y &lt;strong&gt;estructuras relevantes&lt;/strong&gt; en esos datos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Campos&#34; srcset=&#34;
               /minerias/1_intro/figures/DS_AI_ML_hu9447518532780869997.webp 400w,
               /minerias/1_intro/figures/DS_AI_ML_hu3965967255674636004.webp 760w,
               /minerias/1_intro/figures/DS_AI_ML_hu8785539472510587232.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/DS_AI_ML_hu9447518532780869997.webp&#34;
               width=&#34;760&#34;
               height=&#34;522&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Sin embargo, dentro del panorama general, es √∫til diferenciar algunos conceptos clave:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data Science (Ciencia de Datos)&lt;/strong&gt; se centra en el &lt;strong&gt;an√°lisis de datos&lt;/strong&gt; para &lt;strong&gt;extraer conocimiento&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Machine Learning (Aprendizaje Autom√°tico)&lt;/strong&gt; utiliza &lt;strong&gt;algoritmos&lt;/strong&gt; para &lt;strong&gt;predecir&lt;/strong&gt; y tomar decisiones basadas en los datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Artificial Intelligence (Inteligencia Artificial)&lt;/strong&gt; va un paso m√°s all√° y busca &lt;strong&gt;sistemas que puedan realizar tareas ‚Äúinteligentes‚Äù de manera aut√≥noma&lt;/strong&gt;, a veces usando ML como herramienta fundamental.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;De forma simplificada:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Data mining genera entendimiento&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Machine learning genera predicciones&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Artificial intelligence genera acciones&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;material-necesario&#34;&gt;Material Necesario&lt;/h2&gt;
&lt;h3 id=&#34;python-y-anaconda&#34;&gt;Python y Anaconda&lt;/h3&gt;
&lt;p&gt;Para trabajar con an√°lisis de datos y Machine Learning, se recomienda utilizar:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Computadora&lt;/strong&gt; con Python instalado.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Anaconda&lt;/strong&gt; (versi√≥n con Python 3.x)
&lt;ul&gt;
&lt;li&gt;Descarga desde &lt;a href=&#34;https://www.anaconda.com/download&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.anaconda.com/download&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Incluye la distribuci√≥n de Python y diversas bibliotecas √∫tiles.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jupyter Notebook&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Un entorno interactivo para escribir y ejecutar c√≥digo Python en celdas, visualizar gr√°ficos, explicar y anotar pasos.&lt;/li&gt;
&lt;li&gt;Permite prototipar y analizar datos de forma ordenada.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;pandas&#34;&gt;Pandas&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://pandas.pydata.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pandas&lt;/a&gt; es una &lt;strong&gt;biblioteca de Python&lt;/strong&gt; especializada en la &lt;strong&gt;manipulaci√≥n y el an√°lisis de datos&lt;/strong&gt;. Ofrece estructuras de datos como:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DataFrame&lt;/strong&gt;: tablas con filas y columnas, parecidas a las hojas de c√°lculo.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Series&lt;/strong&gt;: columnas o vectores unidimensionales.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Con pandas podemos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Leer&lt;/strong&gt; datos (csv, Excel, bases de datos SQL).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Filtrar, agrupar y transformar&lt;/strong&gt; datos r√°pidamente.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Crear&lt;/strong&gt; res√∫menes estad√≠sticos y visualizaciones sencillas.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En muchas tareas de miner√≠a de datos, &lt;code&gt;pandas&lt;/code&gt; es la base para cargar y preprocesar el dataset antes de aplicar modelos de Machine Learning.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-pandas-biblioteca-de-an√°lisis-de-datos-en-python&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pandas library&#34; srcset=&#34;
               /minerias/1_intro/figures/pandas_hu6045762415544197018.webp 400w,
               /minerias/1_intro/figures/pandas_hu7643437430166501985.webp 760w,
               /minerias/1_intro/figures/pandas_hu888891917289806406.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/pandas_hu6045762415544197018.webp&#34;
               width=&#34;760&#34;
               height=&#34;475&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      pandas: biblioteca de an√°lisis de datos en Python
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;cheatsheets&#34;&gt;Cheatsheets&lt;/h3&gt;
&lt;p&gt;Adem√°s, existen &lt;strong&gt;cheatsheets&lt;/strong&gt; muy √∫tiles para repasar r√°pidamente las funciones principales:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat NumPy&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_np_hu14375244523488473349.webp 400w,
               /minerias/1_intro/figures/cheat_np_hu14411272965934784444.webp 760w,
               /minerias/1_intro/figures/cheat_np_hu13597904967969990868.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_np_hu14375244523488473349.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat Matplotlib&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_matplot_hu15331046240580983923.webp 400w,
               /minerias/1_intro/figures/cheat_matplot_hu3135365546132595272.webp 760w,
               /minerias/1_intro/figures/cheat_matplot_hu10236542872121609322.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_matplot_hu15331046240580983923.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat Scikit-learn&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_skl_hu13780008353465452812.webp 400w,
               /minerias/1_intro/figures/cheat_skl_hu7231920706300985347.webp 760w,
               /minerias/1_intro/figures/cheat_skl_hu10880287153828955388.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_skl_hu13780008353465452812.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat pandas&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_pd_hu10999684890599352937.webp 400w,
               /minerias/1_intro/figures/cheat_pd_hu17601242950209789534.webp 760w,
               /minerias/1_intro/figures/cheat_pd_hu4889890984785326674.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_pd_hu10999684890599352937.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat Jupyter&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_jup_hu13542443862476004036.webp 400w,
               /minerias/1_intro/figures/cheat_jup_hu1785265908805913062.webp 760w,
               /minerias/1_intro/figures/cheat_jup_hu2839386195936346783.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_jup_hu13542443862476004036.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Cheat Keras&#34; srcset=&#34;
               /minerias/1_intro/figures/cheat_keras_hu15372201235457536347.webp 400w,
               /minerias/1_intro/figures/cheat_keras_hu5611213694181866590.webp 760w,
               /minerias/1_intro/figures/cheat_keras_hu787666906409877520.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/cheat_keras_hu15372201235457536347.webp&#34;
               width=&#34;708&#34;
               height=&#34;622&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Les pueden encontrar &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/tree/main/CheatSheets/Code&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aca&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;diferentes-m√©todos-en-miner√≠a-de-datos--machine-learning&#34;&gt;Diferentes M√©todos en Miner√≠a de Datos / Machine Learning&lt;/h2&gt;
&lt;p&gt;Hay varias tareas principales dentro del &lt;strong&gt;aprendizaje a partir de datos&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Clasificaci√≥n&lt;/strong&gt;: predecir &lt;strong&gt;etiquetas&lt;/strong&gt; (clases discretas).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Regresi√≥n&lt;/strong&gt;: predecir un &lt;strong&gt;valor&lt;/strong&gt; (continuo).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering&lt;/strong&gt;: &lt;strong&gt;agrupar&lt;/strong&gt; elementos seg√∫n su similitud (sin etiquetas dadas).&lt;/li&gt;
&lt;li&gt;(Otros) Reducci√≥n de dimensi√≥n, detecci√≥n de anomal√≠as, etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;visi√≥n-general&#34;&gt;Visi√≥n general&lt;/h3&gt;
&lt;p&gt;Un diagrama popular de &lt;a href=&#34;https://scikit-learn.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scikit-learn&lt;/a&gt; muestra el &lt;strong&gt;mapa&lt;/strong&gt; de estos m√©todos:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-diferentes-√°reas-y-algoritmos-de-aprendizaje&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Mapa de ML de scikit-learn&#34; srcset=&#34;
               /minerias/1_intro/figures/ml_map_hu3659606064345962454.webp 400w,
               /minerias/1_intro/figures/ml_map_hu16404596823941526495.webp 760w,
               /minerias/1_intro/figures/ml_map_hu9329016589100192170.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/ml_map_hu3659606064345962454.webp&#34;
               width=&#34;760&#34;
               height=&#34;474&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Diferentes √°reas y algoritmos de aprendizaje
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;A continuaci√≥n, describimos algunos ejemplos de clasificaciones, regresiones y clusterings comunes.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;clasificaci√≥n&#34;&gt;Clasificaci√≥n&lt;/h3&gt;
&lt;p&gt;La &lt;strong&gt;clasificaci√≥n&lt;/strong&gt; consiste en asignar una etiqueta a cada dato de un conjunto de posibles clases. Ejemplos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reconocimiento de emociones en el habla&lt;/strong&gt;: determinar si alguien est√° enojado, feliz, triste, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clasificaci√≥n de especies de animales&lt;/strong&gt;: a partir de caracter√≠sticas de la imagen, decidir si es un gato, un puma, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Detecci√≥n de tumores en im√°genes m√©dicas&lt;/strong&gt;: clasificar entre ‚Äútumor presente‚Äù vs ‚Äúsin tumor‚Äù.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplo-de-clasificaci√≥n-con-m√∫ltiples-etiquetas&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo multi-label classification&#34; srcset=&#34;
               /minerias/1_intro/figures/multi_label_classif_hu9756133175341905838.webp 400w,
               /minerias/1_intro/figures/multi_label_classif_hu3882038718077223937.webp 760w,
               /minerias/1_intro/figures/multi_label_classif_hu12748719311531710440.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/multi_label_classif_hu9756133175341905838.webp&#34;
               width=&#34;760&#34;
               height=&#34;262&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo de clasificaci√≥n con m√∫ltiples etiquetas
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;regresi√≥n&#34;&gt;Regresi√≥n&lt;/h3&gt;
&lt;p&gt;La &lt;strong&gt;regresi√≥n&lt;/strong&gt; busca predecir un valor num√©rico continuo. Ejemplos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reconocer la intensidad de una emoci√≥n&lt;/strong&gt;: ¬øcu√°nto enojo muestra la persona?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evaluar da√±os tras un terremoto&lt;/strong&gt;: estimar la severidad de da√±os en una escala cuantitativa.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Medir la severidad de Alzheimer&lt;/strong&gt; en la voz: ¬øqu√© tan avanzada est√° la enfermedad?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-de-un-valor-continuo-a-una-clasificaci√≥n-basada-en-umbrales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de pasar de regresi√≥n a clasificaci√≥n de edades&#34; srcset=&#34;
               /minerias/1_intro/figures/age_reg_to_classif_hu17690873109572084870.webp 400w,
               /minerias/1_intro/figures/age_reg_to_classif_hu5798053001599690990.webp 760w,
               /minerias/1_intro/figures/age_reg_to_classif_hu7439249746381267252.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/age_reg_to_classif_hu17690873109572084870.webp&#34;
               width=&#34;760&#34;
               height=&#34;649&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      De un valor continuo a una clasificaci√≥n basada en umbrales
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;clustering&#34;&gt;Clustering&lt;/h3&gt;
&lt;p&gt;El &lt;strong&gt;clustering&lt;/strong&gt; (agrupamiento) agrupa autom√°ticamente los datos seg√∫n su semejanza, sin etiquetas previas. Ejemplos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Topic mining&lt;/strong&gt; en foros pol√≠ticos: descubrir de qu√© hablan los ciudadanos (temas m√°s discutidos).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Detecci√≥n de desinformaci√≥n&lt;/strong&gt; en redes sociales: agrupar noticias sospechosas.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Segmentaci√≥n de clientes&lt;/strong&gt;: agrupar usuarios seg√∫n sus preferencias para campa√±as de marketing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-puntos-se-agrupan-en-clusters-similares-se-puede-descartar-puntos-como-ruido&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Clustering de datos bidimensionales&#34; srcset=&#34;
               /minerias/1_intro/figures/clustering_hu7521456035374489175.webp 400w,
               /minerias/1_intro/figures/clustering_hu4875518410358034455.webp 760w,
               /minerias/1_intro/figures/clustering_hu10503044972186760370.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/clustering_hu7521456035374489175.webp&#34;
               width=&#34;760&#34;
               height=&#34;412&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los puntos se agrupan en clusters similares. Se puede descartar puntos como ruido.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;laboratorio-exploraci√≥n-de-datos-con-movielens&#34;&gt;Laboratorio: Exploraci√≥n de Datos con MovieLens&lt;/h2&gt;
&lt;p&gt;Como primer enfoque, estudiaremos un &lt;strong&gt;conjunto de datos de cr√≠ticas de pel√≠culas&lt;/strong&gt; (MovieLens):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consta de ~3 millones de puntuaciones (‚Äúratings‚Äù).&lt;/li&gt;
&lt;li&gt;Incluye &lt;strong&gt;descriptores sociales&lt;/strong&gt;: edad, sexo, etc.&lt;/li&gt;
&lt;li&gt;Permite aplicar un &lt;strong&gt;an√°lisis b√°sico&lt;/strong&gt; de miner√≠a de datos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;MovieLens logo&#34; srcset=&#34;
               /minerias/1_intro/figures/movielens-logo-white_hu5994885034689636590.webp 400w,
               /minerias/1_intro/figures/movielens-logo-white_hu9162017677084157356.webp 760w,
               /minerias/1_intro/figures/movielens-logo-white_hu9786150572690709253.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/1_intro/figures/movielens-logo-white_hu5994885034689636590.webp&#34;
               width=&#34;760&#34;
               height=&#34;267&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En este lab, aprenderemos a:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cargar los datos en &lt;code&gt;pandas&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Explorar variables (estad√≠sticas descriptivas).&lt;/li&gt;
&lt;li&gt;Cruzar informaci√≥n de pel√≠culas y usuarios.&lt;/li&gt;
&lt;li&gt;Visualizar distribuciones y relaciones simples.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Datos I</title>
      <link>http://localhost:1313/minerias/2_datos/</link>
      <pubDate>Fri, 29 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/2_datos/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_datospdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Datos.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;Esta clase se centra en el concepto de &lt;strong&gt;Datos&lt;/strong&gt; dentro del contexto de Machine Learning y miner√≠a de datos. Veremos de manera general c√≥mo se representan, qu√© tipos de datos existen, c√≥mo es la calidad de estos datos y finalmente c√≥mo podemos realizar pasos de preprocesamiento para preparar los datos antes de aplicar algoritmos de aprendizaje.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;generalidades&#34;&gt;Generalidades&lt;/h2&gt;
&lt;h3 id=&#34;scikit-learn-biblioteca-de-ml-en-python&#34;&gt;Scikit-learn: biblioteca de ML en Python&lt;/h3&gt;
&lt;p&gt;Para manejar datos y entrenar modelos, &lt;strong&gt;scikit-learn&lt;/strong&gt; proporciona multitud de herramientas:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-scikit-learn&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Logo scikit-learn&#34; srcset=&#34;
               /minerias/2_datos/figures/Scikit_learn_logo_small_svg_hu6327989177387202692.webp 400w,
               /minerias/2_datos/figures/Scikit_learn_logo_small_svg_hu8563963018684445495.webp 760w,
               /minerias/2_datos/figures/Scikit_learn_logo_small_svg_hu1265031393500101177.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/Scikit_learn_logo_small_svg_hu6327989177387202692.webp&#34;
               width=&#34;260&#34;
               height=&#34;140&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Scikit-learn
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sitio oficial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/user_guide.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;User guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El &lt;strong&gt;workflow general&lt;/strong&gt; involucra la carga de datos, preprocesamiento, extracci√≥n de caracter√≠sticas, entrenamiento y evaluaci√≥n, con metodos normalizadas entre las clases:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-etapas-de-un-pipeline-en-scikit-learn&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Flujo de trabajo en scikit-learn&#34; srcset=&#34;
               /minerias/2_datos/figures/supervised_scikit_learn_hu17372726708710164390.webp 400w,
               /minerias/2_datos/figures/supervised_scikit_learn_hu13489451897173136613.webp 760w,
               /minerias/2_datos/figures/supervised_scikit_learn_hu5671300666085423450.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/supervised_scikit_learn_hu17372726708710164390.webp&#34;
               width=&#34;659&#34;
               height=&#34;484&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Etapas de un pipeline en Scikit-learn
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;patrones-en-los-datos-y-vectorizaci√≥n&#34;&gt;Patrones en los datos y vectorizaci√≥n&lt;/h3&gt;
&lt;p&gt;El objetivo de muchos m√©todos de Machine Learning es &lt;strong&gt;detectar estructuras&lt;/strong&gt; o &lt;strong&gt;patrones&lt;/strong&gt; en los datos. Para ello, generalmente necesitamos que la informaci√≥n est√© en forma de &lt;strong&gt;vectores&lt;/strong&gt; num√©ricos, de modo que cada ejemplo (documento, imagen, usuario, transacci√≥n, etc.) est√© representado como un conjunto de variables num√©ricas (una por dimensi√≥n).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-here-is-the-content-of-this-class-in-the-global-framwork-of-scikit-learn&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Scikit&#34; srcset=&#34;
               /minerias/2_datos/figures/supervised_scikit_learn_FExt_hu4892075279246747440.webp 400w,
               /minerias/2_datos/figures/supervised_scikit_learn_FExt_hu14889019013373788.webp 760w,
               /minerias/2_datos/figures/supervised_scikit_learn_FExt_hu3437252132674115788.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/supervised_scikit_learn_FExt_hu4892075279246747440.webp&#34;
               width=&#34;659&#34;
               height=&#34;484&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Here is the content of this class, in the global framwork of scikit-learn
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En la pr√°ctica, tendremos que &lt;strong&gt;extraer representaciones cifradas&lt;/strong&gt; (features) que describan lo m√°s relevante posible de cada ejemplo. Por ejemplo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformar un texto en un vector que represente la frecuencia de ciertas palabras.&lt;/li&gt;
&lt;li&gt;Medir el histograma de colores de una imagen.&lt;/li&gt;
&lt;li&gt;Recopilar atributos de una tabla (edad, sexo, pa√≠s&amp;hellip;) para un usuario.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-un-ejemplo-de-vectorizacion-de-razas-de-animales-el-objetivo-aca-es-de-encontrar-un-modelo-que-puede-reconocer-las-partes-del-espacio-caracteristicas-de-una-clase&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Reconnaissance&#34; srcset=&#34;
               /minerias/2_datos/figures/reconnaissance_dans_espace_petit_hu17874801778558254842.webp 400w,
               /minerias/2_datos/figures/reconnaissance_dans_espace_petit_hu15134139039843177786.webp 760w,
               /minerias/2_datos/figures/reconnaissance_dans_espace_petit_hu5122108817378378540.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/reconnaissance_dans_espace_petit_hu17874801778558254842.webp&#34;
               width=&#34;363&#34;
               height=&#34;365&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un ejemplo de vectorizacion de razas de animales. El objetivo aca es de encontrar un modelo que puede reconocer las partes del espacio caracteristicas de una clase.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;features-y-etiquetas&#34;&gt;Features y etiquetas&lt;/h3&gt;
&lt;p&gt;Cuando hacemos aprendizaje &lt;strong&gt;supervisado&lt;/strong&gt;, adem√°s de la representaci√≥n vectorial (features), necesitamos una &lt;strong&gt;etiqueta&lt;/strong&gt; o valor de salida asociado a cada ejemplo:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-proceso-global-de-un-sistema-supervisado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Esquema de aprendizaje supervisado&#34; srcset=&#34;
               /minerias/2_datos/figures/classif_hu9702192758643128410.webp 400w,
               /minerias/2_datos/figures/classif_hu1940178425719737447.webp 760w,
               /minerias/2_datos/figures/classif_hu1255634141064509397.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/classif_hu9702192758643128410.webp&#34;
               width=&#34;760&#34;
               height=&#34;476&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Proceso global de un sistema supervisado
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Features&lt;/strong&gt;: Lo que describe al ejemplo.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Etiqueta (label)&lt;/strong&gt;: Variable objetivo que se quiere predecir.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modelo&lt;/strong&gt;: Aprender√° par√°metros para predecir la etiqueta a partir de las features.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;tipos-de-datos&#34;&gt;Tipos de datos&lt;/h2&gt;
&lt;h3 id=&#34;cualitativos-vs-cuantitativos&#34;&gt;Cualitativos vs. cuantitativos&lt;/h3&gt;
&lt;p&gt;Los datos pueden ser de tipo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cuantitativos&lt;/strong&gt;: num√©ricos, mediciones, contajes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cualitativos&lt;/strong&gt;: categ√≥ricos, nominales o incluso ordinales (pero no lineales).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-diferentes-tipos-de-caracter√≠sticas-cantidad-marca-sabor-etc&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de caf√© con datos cuantitativos y cualitativos&#34; srcset=&#34;
               /minerias/2_datos/figures/coffee_hu12238997880869042543.webp 400w,
               /minerias/2_datos/figures/coffee_hu3514629794022085907.webp 760w,
               /minerias/2_datos/figures/coffee_hu5031277750654754841.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/coffee_hu12238997880869042543.webp&#34;
               width=&#34;760&#34;
               height=&#34;333&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Diferentes tipos de caracter√≠sticas (cantidad, marca, sabor, etc.)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Los datos cualitativos pueden ser m√°s interpretables, pero a veces pierden detalle.&lt;/li&gt;
&lt;li&gt;Los datos cuantitativos dan m√°s precisi√≥n, pero pueden ser m√°s dif√≠ciles de interpretar.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;datos-estructurados-vs-no-estructurados&#34;&gt;Datos estructurados vs. no estructurados&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Estructurados&lt;/strong&gt;: Se presentan en tablas con filas y columnas, es decir, cada ejemplo/instancia y sus atributos (p. ej., dataset de Titanic).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No estructurados&lt;/strong&gt;: Texto, im√°genes, audio, etc. Suelen requerir m√°s trabajo de &lt;strong&gt;vectorizaci√≥n&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-comparaci√≥n-entre-datos-en-tabla-y-datos-en-bruto&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplos de datos estructurados vs. no estructurados&#34; srcset=&#34;
               /minerias/2_datos/figures/str_vs_unstr_hu16312124660273804279.webp 400w,
               /minerias/2_datos/figures/str_vs_unstr_hu7267090381556476155.webp 760w,
               /minerias/2_datos/figures/str_vs_unstr_hu5542194265417987857.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/str_vs_unstr_hu16312124660273804279.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Comparaci√≥n entre datos en tabla y datos en bruto
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En muchos problemas, tendremos que convertir datos no estructurados a forma vectorial o tabular para poder aplicar algoritmos de ML.&lt;/p&gt;
&lt;h3 id=&#34;distancia-entre-vectores&#34;&gt;Distancia entre vectores&lt;/h3&gt;
&lt;p&gt;Cuando representamos datos como vectores, podemos comparar su &lt;strong&gt;similitud&lt;/strong&gt; o &lt;strong&gt;diferencia&lt;/strong&gt; con m√©tricas como la distancia euclidiana o el &lt;strong&gt;coseno&lt;/strong&gt; (similaridad de coseno):&lt;/p&gt;
\[
\cos(\mathbf{X}, \mathbf{X}&#39;) \;=\; 
\frac{\langle \mathbf{X}, \mathbf{X}&#39;\rangle}{\|\mathbf{X}\|\;\|\mathbf{X}&#39;\|}.
\]&lt;p&gt;















&lt;figure  id=&#34;figure-la-distancia-entre-vectores-se-puede-calcular-de-varias-maneras&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;distance_vectors&#34; srcset=&#34;
               /minerias/2_datos/figures/distance_vectors_hu9643923070251790051.webp 400w,
               /minerias/2_datos/figures/distance_vectors_hu922159784453930484.webp 760w,
               /minerias/2_datos/figures/distance_vectors_hu10091620246869096621.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/distance_vectors_hu9643923070251790051.webp&#34;
               width=&#34;760&#34;
               height=&#34;364&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La distancia entre vectores se puede calcular de varias maneras
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Esto se usa en muchas aplicaciones de clustering, recomendaci√≥n y clasificaci√≥n.&lt;/p&gt;
&lt;h3 id=&#34;extraccion-con-sklearn&#34;&gt;Extraccion con sklearn&lt;/h3&gt;
&lt;p&gt;Un ejemplo simple de one-hot encoding con scikit-learn:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;genders&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;locations&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;from Africa&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Asia&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Europe&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from US&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;browsers&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Chrome&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Firefox&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses IE&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Safari&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;enc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;preprocessing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OneHotEncoder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;genders&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;locations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;browsers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Note that for there are missing categorical values for the 2nd and 3rd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# feature&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from US&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Safari&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Europe&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Firefox&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;enc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;OneHotEncoder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;from Africa&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Asia&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Europe&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           &lt;span class=&#34;s1&#34;&gt;&amp;#39;from US&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                          &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Chrome&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Firefox&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses IE&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                           &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Safari&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;enc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;from Asia&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;uses Chrome&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toarray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;calidad-de-los-datos&#34;&gt;Calidad de los datos&lt;/h2&gt;
&lt;p&gt;Los datos reales suelen estar lejos de ser perfectos.&lt;/p&gt;
&lt;h3 id=&#34;ruido&#34;&gt;Ruido&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Ruido&lt;/strong&gt;: irregularidad aleatoria en los datos, diferencias no explicadas por el modelo. No tienen ning√∫n patr√≥n. Estos errores suelen ser &lt;strong&gt;inevitables e imprevisibles&lt;/strong&gt;. Puede provenir de:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Errores&lt;/strong&gt;: Errores de medici√≥n o muestreo que pueden distorsionar los datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Residuos&lt;/strong&gt;: Variaci√≥n intr√≠nseca no capturada en nuestras features. Incluso aunque no haya errores de medici√≥n, un modelo no suele capturar el 100% de la variabilidad, por lo que siempre existir√°n residuos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ruido-blanco-en-una-imagen-las-perturbaciones-que-habia-en-la-television-cuando-habia-mala-se√±al-el-sonido-de-fondo-cuando-capta-mal-el-telefono&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ruido blanco&#34; srcset=&#34;
               /minerias/2_datos/figures/white_noise_hu579348812110497967.webp 400w,
               /minerias/2_datos/figures/white_noise_hu10361843702748057629.webp 760w,
               /minerias/2_datos/figures/white_noise_hu15236131570812366011.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/white_noise_hu579348812110497967.webp&#34;
               width=&#34;760&#34;
               height=&#34;284&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ruido blanco en una imagen, las perturbaciones que habia en la television, cuando habia mala se√±al, el sonido de fondo cuando capta mal el telefono&amp;hellip;
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Es dif√≠cil (o imposible) de representar toda la realidad con un ensamble finito de observaciones&lt;/li&gt;
&lt;li&gt;Vamos a representar una cosa con un vector de tama√±o finito, lo que puede ser reductible al fen√≥meno inicial, es una aproximaci√≥n de la realidad&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Se va a quedar un componente de ruido que no se puede modelizar&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Si queremos modelizar \(Y = 3*X_1 - 2*X^2_2 + \epsilon\) con \(X_1\) y \(X_2\), no lo vamos a lograr.
















&lt;figure  id=&#34;figure-modelo-que-intenta-ajustar-datos-con-ruido&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ruido en el ajuste de una funci√≥n&#34; srcset=&#34;
               /minerias/2_datos/figures/ex_over-underfitting_noise_hu7160750459805610265.webp 400w,
               /minerias/2_datos/figures/ex_over-underfitting_noise_hu1258070293613913168.webp 760w,
               /minerias/2_datos/figures/ex_over-underfitting_noise_hu16428299825422072936.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/ex_over-underfitting_noise_hu7160750459805610265.webp&#34;
               width=&#34;728&#34;
               height=&#34;255&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Modelo que intenta ajustar datos con ruido
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;outliers&#34;&gt;Outliers&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplo-de-outliers-en-2-dimensiones&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Outliers en diferentes distribuciones&#34; srcset=&#34;
               /minerias/2_datos/figures/outlier_gaussians_hu18089628100723988662.webp 400w,
               /minerias/2_datos/figures/outlier_gaussians_hu11729765782774009637.webp 760w,
               /minerias/2_datos/figures/outlier_gaussians_hu4176910214133138174.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/outlier_gaussians_hu18089628100723988662.webp&#34;
               width=&#34;440&#34;
               height=&#34;310&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo de outliers en 2 dimensiones
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Un &lt;strong&gt;outlier&lt;/strong&gt; o valor at√≠pico es un punto de datos que difiere significativamente de la mayor√≠a. Pueden ser:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Outliers ruidosos&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Son datos err√≥neos (fallos de medici√≥n, errores tipogr√°ficos, etc.) o extremos por variabilidad natural que no nos interesan.&lt;/li&gt;
&lt;li&gt;Suelen distorsionar estimaciones estad√≠sticas (e.g. la media).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Outliers ‚Äú√∫tiles‚Äù&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Responden a eventos raros o an√≥malos que s√≠ queremos detectar (fraude, crisis, rarezas de inventario).&lt;/li&gt;
&lt;li&gt;Pueden ser el foco de ciertos an√°lisis (detecci√≥n de anomal√≠as).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplos-del-mvtec-anomaly-detection-dataset&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Outliers en diferentes distribuciones&#34; srcset=&#34;
               /minerias/2_datos/figures/dataset_overview_anomaly_hu12222639050208223478.webp 400w,
               /minerias/2_datos/figures/dataset_overview_anomaly_hu14348380986165943337.webp 760w,
               /minerias/2_datos/figures/dataset_overview_anomaly_hu7518922898301784344.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/dataset_overview_anomaly_hu12222639050208223478.webp&#34;
               width=&#34;760&#34;
               height=&#34;386&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplos del MVTEC Anomaly Detection Dataset
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Para identificarlos, se pueden usar:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Visualizaci√≥n (boxplots, scatter plots).&lt;/li&gt;
&lt;li&gt;M√©todos estad√≠sticos (rango intercuart√≠lico, z-score).&lt;/li&gt;
&lt;li&gt;Algoritmos de ML (Isolation Forest, Local Outlier Factor).&lt;/li&gt;
&lt;li&gt;Validaci√≥n de dominio (comprobar en la realidad si ese punto es aut√©ntico o no).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-outlier-label-detection-cleanlabhttpsgithubcomcleanlabcleanlab-allowed-to-detect-many-of-the-label-error-in-the-imagenet-dataset&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Outliers en diferentes distribuciones&#34; srcset=&#34;
               /minerias/2_datos/figures/CleanLab_hu10917344694898179941.webp 400w,
               /minerias/2_datos/figures/CleanLab_hu1141749507235822239.webp 760w,
               /minerias/2_datos/figures/CleanLab_hu413918498232524429.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/CleanLab_hu10917344694898179941.webp&#34;
               width=&#34;760&#34;
               height=&#34;447&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Outlier Label detection. &lt;a href=&#34;https://github.com/cleanlab/cleanlab&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CleanLab&lt;/a&gt; allowed to detect many of the label error in the Imagenet dataset.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;valores-faltantes&#34;&gt;Valores faltantes&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Missing values&lt;/strong&gt;: Es frecuente tener celdas vac√≠as o desconocidas, por ejemplo:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.impute&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SimpleImputer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imp_mean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SimpleImputer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;mean&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imp_mean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Podemos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Eliminar las filas&lt;/strong&gt; (si son pocas y su ausencia no afecta demasiado).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Imputar valores&lt;/strong&gt; usando la media, mediana o algoritmos como &lt;code&gt;KNNImputer&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modelos que los manejen directamente&lt;/strong&gt;: algunos estimadores permiten tratar valores faltantes sin preprocesamiento adicional.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-existen-modelos-que-pueden-manejar-los-missing-values-en-scikit&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Modelos que aceptan valores faltantes&#34; srcset=&#34;
               /minerias/2_datos/figures/estimators_missing_values_hu5552150127740906947.webp 400w,
               /minerias/2_datos/figures/estimators_missing_values_hu2966550281670234438.webp 760w,
               /minerias/2_datos/figures/estimators_missing_values_hu1414166785689099899.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/estimators_missing_values_hu5552150127740906947.webp&#34;
               width=&#34;760&#34;
               height=&#34;419&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Existen modelos que pueden manejar los missing values en scikit
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;duplicados&#34;&gt;Duplicados&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Datos duplicados&lt;/strong&gt;: aparecen al combinar fuentes o por errores de recolecci√≥n. Puede generar &lt;em&gt;sobrerepresentaci√≥n&lt;/em&gt; de ciertos ejemplos y perjudicar el entrenamiento.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Errores en la concatenaci√≥n o carga de datos desde fuentes m√∫ltiples.&lt;/li&gt;
&lt;li&gt;Recolecci√≥n repetida de la misma observaci√≥n.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Los duplicados suelen &lt;strong&gt;sobrerepresentar&lt;/strong&gt; determinados ejemplos, generando un sesgo en el entrenamiento. En casos masivos (p.ej., entrenamiento de grandes modelos de lenguaje), se ha demostrado que duplicar documentos puede perjudicar significativamente la calidad del modelo.&lt;/p&gt;
&lt;p&gt;Para mitigarlos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Comparar hashes o firmas&lt;/strong&gt; de los ejemplos (si hablamos de texto, im√°genes, etc.).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering de similitud&lt;/strong&gt; de ejemplos para detectar duplicaciones leves o parciales.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Herramientas de deduplicaci√≥n&lt;/strong&gt; espec√≠ficas (ej.: para nombres de usuarios, direcciones de correo, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Es crucial deduplicar en datasets grandes (por ejemplo, para entrenar grandes modelos de lenguaje).&lt;/p&gt;
&lt;p&gt;En caso simple de datos tabulares, se puede utilizar metodos como &lt;code&gt;pandas.DataFrames.drop_duplicates()&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;use-case-llm&#34;&gt;Use-case: LLM&lt;/h3&gt;
&lt;p&gt;Para entrenar un LLM desde zero, es necesario de colectar una grande cantidad de datos! Colectando datos del web, es imposible de tener datos limpios!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Los datos extra√≠dos de la web tienen mucho ruido y hay que limpiarlos.&lt;/li&gt;
&lt;li&gt;Marcas, roturas de sintaxis, etc&amp;hellip; todo lo que da texto no NL es perjudicial, ¬°y puede impedir la convergencia!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Se ha determinado que la deduplicaci√≥n desempe√±a un papel importante&lt;/strong&gt; en la mejora de los modelos ling√º√≠sticos (&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3359591.3359735?casa_token=AT3LybXtoLQAAAAA:LJLGtclf0beYhmJBuxCxUpAgDe4KspLeZYN2LWG9A3ePEl3Lkh21hsjczzjyyMiSx6dg7MQUbmtlLw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Allamanis, 2019&lt;/a&gt;; &lt;a href=&#34;https://arxiv.org/abs/2107.06499&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lee et al., 2022&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Se ha demostrado que la repetici√≥n de datos es cada vez m√°s perjudicial para la calidad del modelo a medida que aumenta el n√∫mero de par√°metros (&lt;a href=&#34;https://arxiv.org/abs/2205.10487&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hernandez et al., 2022&lt;/a&gt;):
&lt;ul&gt;
&lt;li&gt;para un modelo de 1B par√°metros, cien duplicados son perjudiciales;&lt;/li&gt;
&lt;li&gt;a 175B, &lt;strong&gt;incluso unos pocos duplicados&lt;/strong&gt; podr√≠an tener un efecto desproporcionado.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;limpieza-y-preprocesamiento&#34;&gt;Limpieza y preprocesamiento&lt;/h2&gt;
&lt;h3 id=&#34;estandarizaci√≥n-y-normalizaci√≥n&#34;&gt;Estandarizaci√≥n y normalizaci√≥n&lt;/h3&gt;
&lt;p&gt;Muchos algoritmos de ML (especialmente basados en distancias o gradientes) funcionan mejor cuando las &lt;strong&gt;features&lt;/strong&gt; tienen escalas comparables.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Estandarizaci√≥n&lt;/strong&gt; (StandardScaler):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Convierten cada feature a media cero y varianza uno:&lt;/p&gt;
\[
     X_{\mathrm{std}} = \frac{X - \mu_X}{\sigma_X}.
     \]&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Afecta cada atributo de forma que su distribuci√≥n resulte centrada en 0 y con desviaci√≥n est√°ndar 1.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Normalizaci√≥n&lt;/strong&gt; (Normalizer):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ajusta cada &lt;strong&gt;vector&lt;/strong&gt; para que su norma sea 1.&lt;/li&gt;
&lt;li&gt;Se suele usar en tareas donde la direcci√≥n del vector importa m√°s que su magnitud (p.ej. coseno de similaridad).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scaling&lt;/strong&gt; a un rango \([0, 1]\) (MinMaxScaler):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Se ‚Äúcomprime‚Äù cada atributo dentro de \([0..1]\):&lt;/p&gt;
\[
     X_{\mathrm{scaled}} = \frac{X - X_{\min}}{X_{\max} - X_{\min}}.
     \]&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;√ötil cuando no se desea asumir forma gaussiana y se quiere mantener la escala finita.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;¬øPor qu√© es importante?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evitar que los atributos con rangos muy grandes dominen sobre otros.&lt;/li&gt;
&lt;li&gt;Favorecer la convergencia de algoritmos de optimizaci√≥n que basan sus pasos en gradientes (como Redes Neuronales).&lt;/li&gt;
&lt;li&gt;Mejorar la calidad de m√©todos de distancia (k-NN, SVM, clustering) que asumen escalas comparables en las coordenadas.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mas info &lt;a href=&#34;https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aca&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;discretizaci√≥n&#34;&gt;Discretizaci√≥n&lt;/h3&gt;
&lt;p&gt;Dividir atributos continuos en bins (categor√≠as).&lt;/p&gt;
&lt;p&gt;La discretizacion (tambien conocida como cuantizacion o binning) permite dividir las caracterƒ±sticas continuas en valores discretos (clases). Las caracterƒ±sticas discretizadas codificadas de una sola vez pueden &lt;strong&gt;hacer que un modelo sea mas expresivo, manteniendo la interpretabilidad.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-transformar-la-variable-continua-edad-en-clases-discretas&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de discretizaci√≥n&#34; srcset=&#34;
               /minerias/2_datos/figures/age_reg_to_classif_hu17690873109572084870.webp 400w,
               /minerias/2_datos/figures/age_reg_to_classif_hu5798053001599690990.webp 760w,
               /minerias/2_datos/figures/age_reg_to_classif_hu7439249746381267252.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/age_reg_to_classif_hu17690873109572084870.webp&#34;
               width=&#34;760&#34;
               height=&#34;649&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Transformar la variable continua &amp;rsquo;edad&amp;rsquo; en clases discretas
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;polynomial-features&#34;&gt;Polynomial Features&lt;/h3&gt;
&lt;p&gt;A√±adir t√©rminos polin√≥micos (no lineales) para incrementar la complejidad de un modelo lineal.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-polynomial-helps-fitiing-more-complex-functions&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de discretizaci√≥n&#34; srcset=&#34;
               /minerias/2_datos/figures/ex_over-underfitting_polynomial_hu12296047467455913660.webp 400w,
               /minerias/2_datos/figures/ex_over-underfitting_polynomial_hu3603271985052957351.webp 760w,
               /minerias/2_datos/figures/ex_over-underfitting_polynomial_hu12325601955647240871.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/ex_over-underfitting_polynomial_hu12296047467455913660.webp&#34;
               width=&#34;732&#34;
               height=&#34;274&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Polynomial helps fitiing more complex functions
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Mas informaciones &lt;a href=&#34;https://scikit-learn.org/stable/modules/preprocessing.html%5c#generating-polynomial-features&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aca&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;inter√©s-del-sampling-muestreo&#34;&gt;Inter√©s del sampling (muestreo)&lt;/h3&gt;
&lt;p&gt;Un mal muestreo puede generar sesgos en nuestros datos y conclusiones. Existen diversas estrategias:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Muestreo estratificado&lt;/strong&gt;: Mantiene proporciones de clases o grupos.&lt;br&gt;
















&lt;figure  id=&#34;figure-muestreo-estratificado-mantiene-proporciones-en-subgrupos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de muestreo estratificado&#34; srcset=&#34;
               /minerias/2_datos/figures/stratified_sampling_hu3739506566429986846.webp 400w,
               /minerias/2_datos/figures/stratified_sampling_hu12963448647892023621.webp 760w,
               /minerias/2_datos/figures/stratified_sampling_hu9627835439692744135.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/stratified_sampling_hu3739506566429986846.webp&#34;
               width=&#34;486&#34;
               height=&#34;440&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Muestreo estratificado: mantiene proporciones en subgrupos
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Muestreo aleatorio simple&lt;/strong&gt;: Elegir instancias al azar.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Muestreo sistem√°tico&lt;/strong&gt;: Tomar cada k-√©simo elemento desde un punto inicial aleatorio.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-systematic-random-sampling-selecciona-elementos-de-una-poblaci√≥n-a-intervalos-regulares-desde-un-punto-de-partida-aleatorio&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de muestreo estratificado&#34; srcset=&#34;
               /minerias/2_datos/figures/systematic_random_sampling_hu11080984733742039593.webp 400w,
               /minerias/2_datos/figures/systematic_random_sampling_hu15285761124891998038.webp 760w,
               /minerias/2_datos/figures/systematic_random_sampling_hu15458938320889412188.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/systematic_random_sampling_hu11080984733742039593.webp&#34;
               width=&#34;760&#34;
               height=&#34;353&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Systematic Random Sampling: Selecciona elementos de una poblaci√≥n a intervalos regulares desde un punto de partida aleatorio
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;agregaciones-de-datos&#34;&gt;Agregaciones de datos&lt;/h3&gt;
&lt;p&gt;Combinar varios valores en uno solo (por ejemplo, la media diaria) puede:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reducir ruido&lt;/strong&gt; y variabilidad.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simplificar&lt;/strong&gt; el conjunto de datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resumir&lt;/strong&gt; grandes vol√∫menes de informaci√≥n.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-agregaci√≥n-en-un-d√≠a-para-medir-la-opini√≥n-general&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Agregaci√≥n diaria de tweets positivos&#34; srcset=&#34;
               /minerias/2_datos/figures/hapiness_twitter_hu869437225968806113.webp 400w,
               /minerias/2_datos/figures/hapiness_twitter_hu9597793583217252604.webp 760w,
               /minerias/2_datos/figures/hapiness_twitter_hu9500706212212640228.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/hapiness_twitter_hu869437225968806113.webp&#34;
               width=&#34;760&#34;
               height=&#34;398&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Agregaci√≥n en un d√≠a para medir la opini√≥n general
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;dimensi√≥n-cursa-y-reducci√≥n&#34;&gt;Dimensi√≥n: &lt;em&gt;Cursa&lt;/em&gt; y reducci√≥n&lt;/h3&gt;
&lt;p&gt;En altas dimensiones, los datos se dispersan y pierden significado las distancias (curse of dimensionality). Para mitigar esto:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reducci√≥n de dimensi√≥n&lt;/strong&gt; (p. ej. PCA, selecci√≥n de atributos).&lt;/li&gt;
&lt;li&gt;Eliminar o fusionar atributos irrelevantes.&lt;/li&gt;
&lt;li&gt;Acelerar el procesamiento y mejorar la interpretabilidad.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-en-dimensiones-muy-altas-los-datos-se-distribuyen-uniformemente&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ilustraci√≥n del curse of dimensionality&#34; srcset=&#34;
               /minerias/2_datos/figures/curse_of_dimensionality_hu13015040265525298778.webp 400w,
               /minerias/2_datos/figures/curse_of_dimensionality_hu17025575749590265977.webp 760w,
               /minerias/2_datos/figures/curse_of_dimensionality_hu17010720842900593354.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/2_datos/figures/curse_of_dimensionality_hu13015040265525298778.webp&#34;
               width=&#34;433&#34;
               height=&#34;347&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      En dimensiones muy altas, los datos se distribuyen uniformemente
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>(TODO) Datos II</title>
      <link>http://localhost:1313/minerias/3_datos_exp/</link>
      <pubDate>Thu, 28 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/3_datos_exp/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-not-available-heretodopdf&#34;&gt;The slides are not available &lt;a href=&#34;todo.pdf&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Intro Aprendizaje Supervisado</title>
      <link>http://localhost:1313/minerias-en/1_intro/</link>
      <pubDate>Wed, 27 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias-en/1_intro/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-heredm_intro_slpdf&#34;&gt;The slides are available &lt;a href=&#34;DM_Intro_SL.pdf&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;This class is pretty cool as you will discover the basics of the knowledge used to build Machine Learning, Deep Learning and Artifical Intelligence in general: Supervised Learning! This is a simple setting where a &lt;strong&gt;model will learn its own parameters using examples and associated labels&lt;/strong&gt;. We will revise all the important concepts of supervised learning, which are very useful for anybody who wants to become data scientist.&lt;/p&gt;
&lt;p&gt;Esta clase es bastante bacan ya que descubriran las bases del conocimiento utilizado para construir Machine Learning, Deep Learning e Inteligencia Artificial en general: Aprendizaje Supervisado! Se trata de un entorno sencillo en el que un &lt;strong&gt;modelo aprender√° sus propios par√°metros utilizando ejemplos y etiquetas asociadas&lt;/strong&gt;. Revisaremos todos los conceptos importantes del aprendizaje supervisado, que son muy √∫tiles para cualquiera que quiera trabajar como data scientist.&lt;/p&gt;
&lt;h2 id=&#34;generalidades&#34;&gt;Generalidades&lt;/h2&gt;
&lt;p&gt;El aprendizaje supervisado utiliza datos y etiquetas para aprender a un modelo a reconocer padrones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Es necesario de transformar los documentos en vectores, para poder hacer la optimizacion&lt;/li&gt;
&lt;li&gt;El modelo va a apprender sus parametros sobre un conjunto de entrenamiento&lt;/li&gt;
&lt;li&gt;El modelo entrenado puede ser usado para predicir la etiquetas de nuevos datos que nunca ha visto antes&lt;/li&gt;
&lt;li&gt;El documento puede ser cualquier dato: audio, texto, imagen, video, usuario, red,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/predictive_modeling_data_flow.png&#34; alt=&#34;predictive_modeling_data_flow&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;features-y-etiquetas&#34;&gt;Features y etiquetas&lt;/h3&gt;
&lt;p&gt;Se puede representar en un espacio los documentos como vectores. Aca cada punto es una cancion, que esta representando con su intensidad y tempo promedios. La etiqueta es la color del punto. Aca tenemos una tarea de &lt;strong&gt;clasificacion binaria de musica&lt;/strong&gt;, sengundo las preferencias de un usuario.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/classif.jpg&#34; alt=&#34;classif&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El objetivo del juego, va a ser de encontrar &lt;strong&gt;una funcion que separa el espacio en dos partes&lt;/strong&gt;. Una donde hay las canciones que le gustan a la persona, y la otra parte que no le gustan. De este manera, cuando vamos a tener un nuevo punto en este espacio, podemos decir si la persona va a gustar o no esta cancion, lo que sea &lt;strong&gt;predicir su etiqueta&lt;/strong&gt;!&lt;/p&gt;
&lt;h3 id=&#34;en-resumen&#34;&gt;En resumen&lt;/h3&gt;
&lt;p&gt;Se necesitan varias cosas para un entrenamiento&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Tener datos etiquetados&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Conjunto de datos de tama√±o $n$
, $\mathcal{D}_n = \{(\text{Doc}_i, Y_i), i=1..n\}$
&lt;/li&gt;
&lt;li&gt;$\text{Doc}$ es una muestra (por ejemplo: una persona)&lt;/li&gt;
&lt;li&gt;$Y$ son las etiquetas (por ejemplo: monto del pr√©stamo concedido)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Extraer los descriptores&lt;/strong&gt; = transformar documentos en vectores&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;$\mathbf{X}$ es un vector de observaciones (por ejemplo: edad, sexo, salario)&lt;/li&gt;
&lt;li&gt;$Y$ son las etiquetas (por ejemplo: monto del pr√©stamo concedido)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Crear un modelo matem√°tico $f_\theta$&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Modelo $f_\theta$ tal que  $f_\theta(\mathbf{X})$
 est√© cerca de $Y$ (para regresi√≥n)&lt;/li&gt;
&lt;li&gt;$\theta$ es el conjunto de par√°metros del modelo matem√°tico&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Implementar una funci√≥n de costo (error) $\ell$
 a minimizar&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Cuanto m√°s se equivoque el modelo, mayor ser√° el costo&lt;/li&gt;
&lt;li&gt;En general, se desea tener un costo peque√±o&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;Encontrar los par√°metros  $\theta^*$ 
 de manera que  $\ell(f_{\theta^*}(\mathbf{X}_i), Y_i)$ 
 sea peque√±o&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
$$\theta^* = \underset{\theta}{\arg\min}\sum_{i}\ell(f_{\theta}(\mathbf{X}_i), Y_i)$$&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;&lt;strong&gt;Probar $f_{\theta^*}$
 en nuevos datos con una m√©trica de evaluaci√≥n adecuada&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;aprendizaje&#34;&gt;Aprendizaje&lt;/h2&gt;
&lt;p&gt;Hay varios conceptos en el aprendizaje:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Datos etiquetados&lt;/strong&gt;: Regresi√≥n o Clasificaci√≥n&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Extracci√≥n de caracter√≠sticas&lt;/strong&gt;: Tono, Intensidad, Tempo o Edad, Salario, G√©nero, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modelo $f_\theta$&lt;/strong&gt;: SVM, Regresi√≥n Log√≠stica, Bosque Aleatorio, CNN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Funci√≥n de costo&lt;/strong&gt; a optimizar: P√©rdida de Bisagra, P√©rdida de Entrop√≠a Cruzada, P√©rdida Log√≠stica, P√©rdida Cuadrada, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Algoritmo de optimizaci√≥n&lt;/strong&gt;: Adam, SGD, BFGS, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;M√©trica de evaluaci√≥n&lt;/strong&gt;: Recall, Precisi√≥n, M√≠nimos Cuadrados, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;funcion-de-costo&#34;&gt;Funcion de costo&lt;/h3&gt;
&lt;p&gt;Para cuantificar las errores del modelo en la optimizacion, se necesita una funcion de costo que llamamos  $\ell$ 
. Ella representa si el modelo esta dando las buenas respuestas $y$
 segundo una entrada $X$
. Este funcion penaliza el modelo cuando comete errores, y lo que queremos hacer es optimizar los pesos del modelo, para obtener una valor minimum de este costo, lo que significaria menos errores, entonces mejor modelo.&lt;/p&gt;
&lt;p&gt;Hay que minimizar esta funci√≥n sobre el conjunto de entrenamiento (riesgo emp√≠rico) para encontrar par√°metros del modelo satisfactorios:&lt;/p&gt;
$$ f_{\hat{\theta}} =\underset{f_\theta, \theta \in \Theta}{\arg\min} \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$$&lt;p&gt;Los parametros van a cambiar para tener un valor minimum de costo:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/convergence_algo_optim.png&#34; alt=&#34;convergence_algo_optim&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;La funcion de costo expresa el error desde una perspectiva &lt;strong&gt;num√©rica&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Transmite al algoritmo de aprendizaje lo que es importante y tiene sentido para la tarea&lt;/li&gt;
&lt;li&gt;Debe ser una funci√≥n que se pueda optimizar eficientemente (convexa). &lt;strong&gt;La funci√≥n  $\ell^{0/1} = \mathds{1}_{f(\mathbf{X}) = Y}$ 
 no es utilizable&lt;/strong&gt; (ni siquiera continua).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;complejidad-de-los-modelos-y-sobresoto-aprendizaje&#34;&gt;Complejidad de los modelos y sobre/soto-aprendizaje&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt; $\mathcal{F} = \{ f: \text{ funciones medibles } \mathcal{X} \text{&amp;rarr;} \mathcal{Y}\}$ 
&lt;/li&gt;
&lt;li&gt;Mejor soluci√≥n  $f^* = \arg\min_{f \in \mathcal{F}}\mathcal{R}(f)$ 
&lt;/li&gt;
&lt;li&gt;Clase de funciones  $\mathcal{S} \subset \mathcal{F}$ 
 utilizadas como modelos&lt;/li&gt;
&lt;li&gt;Objetivo ideal en $\mathcal{S}$:  $f^*_\mathcal{S} = \arg\min_{f \in \mathcal{S}}\mathcal{R}(f)$ 
&lt;/li&gt;
&lt;li&gt;Estimaci√≥n obtenida en  $\mathcal{S}$ 
: se obtiene  $f_\mathcal{S}$ 
 tras un entrenamiento&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se pueden encontrar dos maneras de no tener el riesgo minimum optimum:&lt;/p&gt;
$$ \mathcal{R}(\hat{f_\mathcal{S}}) - \mathcal{R}(f^*) = \textcolor{red}{\underbrace{ \mathcal{R}(f_\mathcal{S}^*) - \mathcal{R}(f^*) }_{\text{error de aproximacion}}} +  \textcolor{blue}{\underbrace{ \mathcal{R}(\hat{f_\mathcal{S}}) - \mathcal{R}(f_\mathcal{S}^*) }_{\text{error de estimacion}}}$$&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/approx_estim_errors.png&#34; alt=&#34;approx_estim_errors&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El error de aproximaci√≥n puede ser grande si el modelo $\mathcal{S}$ no es adaptado, y el error de estimaci√≥n puede ser grande si el modelo es complejo.&lt;/p&gt;
&lt;p&gt;Un ejemplo simple seria un polinomio de grado P que quiere estimar un polinomio de grado N con ruido:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/ex_over-underfitting.png&#34; alt=&#34;underfitting&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Soto-aprentizaje&lt;/strong&gt;: Si no hay demasiado parametros, es imposible de estimar bien la curva,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sobre-aprentizaje&lt;/strong&gt;: Si hay demasiado parametros va a enfocar en memorizar el ruido del ensemble de entrenamiento&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;regularizacion-y-parsimonia&#34;&gt;Regularizacion y parsimonia&lt;/h3&gt;
&lt;p&gt;Una solucion para combatir el problema de no generalizacion es la regularizacion, que permite de agregar una penalizaci√≥n en relaci√≥n con la complejidad del modelo:&lt;/p&gt;

$$\arg\min_{f_\theta, \theta \in \Theta} \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) ) + pen(\theta)$$


&lt;p&gt;Hay varias posibilidades de penalizacion, generalmente se usa la norma de los pesos del modelo. La intuicion detras de eso es que disminuir la norma del modelo o su n√∫mero de coeficientes, n√∫mero de ramas del grafo (poda).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AIC:

$pen(\theta) = \lambda ||\theta||_0$


&lt;em&gt;(no convexa, parsimoniosa, poco utilizada)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Ridge:

$pen(\theta) = \lambda ||\theta||_2$ 


&lt;em&gt;(convexa, no parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Lasso:

$pen(\theta) = \lambda ||\theta||_1$ 


&lt;em&gt;(convexa, parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Elastic Net:

$pen(\theta) = \lambda_1 ||\theta||_1 + \lambda_2 ||\theta||_2$


&lt;em&gt;(convexa, parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El  $\lambda$ 
 es un nuevo hiperparametro del modelo.&lt;/p&gt;
&lt;p&gt;El lasso induce la parcimonia. Aca se pueden ver para  $n=\{0,1,2\}$ 
, las bolas  $$\mathcal{B}^n = \{x / x \in \mathbb{R}^d \text{ and } ||x||_n &lt; 1\}$$ 
:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/norms.png&#34; alt=&#34;norms&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En dimensiones grandes, la mayor√≠a de  $\mathcal{B}^1$ 
 se concentra en los ejes: &lt;strong&gt;esto equivale a tener valores nulos para otros ejes&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/Sparsityl1.png&#34; alt=&#34;Sparsityl1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;optimizacion-loss-landscape&#34;&gt;Optimizacion, &lt;em&gt;loss landscape&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;La optimizacion de la funcion de costo sobre el ensemble de entrenamiento ( $ \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$ 
) se puede hacer de manera analitica en casos simples, o de manera iterativa. La fase de optimizacion va a &lt;strong&gt;hacer converger los parametros&lt;/strong&gt; para encontrar los que van a dar un &lt;strong&gt;costo minimum en el conjunto de datos de entrenamiento&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/convergence_algo_optim.png&#34; alt=&#34;convergence_algo_optim&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En este ejemplo se puede ver los parametros $a,b$
 del modelo  $y = a\mathbf{X}+b$ 
 cambiar por cada iteracion, para tener un valor del error (sse; suma residual de cuadrados) que esta diminuando:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/regression_gif.gif&#34; alt=&#34;regression_gif&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Porque la valor del costo empirico  $ \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$ 
 es un nombre real positivo, podemos representarlo en un eje, y los parametros con unos otros ejes. Eso se llama el &lt;em&gt;loss landscape&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/LossAlps.png&#34; alt=&#34;LossAlps&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El objetivo del algoritmo de optimizacion es de encontrar la &amp;ldquo;ruta&amp;rdquo; para conducir en una &amp;ldquo;valle&amp;rdquo;, que representa un minimum local o global. Este ollo significa que los parametros sean los que dan un error peque√±a.&lt;/p&gt;
&lt;h3 id=&#34;gradiente-deciendente&#34;&gt;Gradiente deciendente&lt;/h3&gt;
&lt;p&gt;El gradiente El gradiente de una funci√≥n  $\nabla_xf(x)=(\frac{\partial f}{\partial\x_i})_{i=1..n}$ 
 es su derivativa seg√∫n cada dimensi√≥n. Es una &lt;strong&gt;aproximaci√≥n lineal de la funci√≥n al nivel local&lt;/strong&gt;. Este indica la direccion donde aumenta una funcion:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/gradient_curve1D.png&#34; alt=&#34;gradient_curve1D&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Por eso, se puede utilizar el gradiente de la funccion de costo para minimizar el costo. Despu√©s de cada c√°lculo de la funci√≥n de costo  $\ell(Y_i, f_\theta(\mathbf{X}_i) ; \theta)$ 
, se calcula el gradiente de esta funci√≥n para actualizar los par√°metros $\theta$
:&lt;/p&gt;
$$	\theta \leftarrow \theta - \alpha*\nabla_\theta \ell(Y_i, f_\theta(\mathbf{X}_i) ; \theta)$$&lt;p&gt;La tasa de aprendizaje  $\alpha$ 
 en la ecuacion precedente representa la cantidad de acutalizacion de los parametros. Es importante porque va a influir sobre la convergencia.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/learningrates.jpeg&#34; alt=&#34;learningrates&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En en &lt;em&gt;loss landscape&lt;/em&gt;, se puede representar el modelo durante la optimizacion como un vector moviendo en cada iteracion. Con este vision, la tasa de aprendizaje define mas o menos la &amp;ldquo;velocidad&amp;rdquo; de como se mueve este punto. Por eso, es simple de entender que a veces tiene que ser mas grande y otra veces mas peque√±o, por ejemplo para pasar topografias particular del &lt;em&gt;landscape&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Hay varios algoritmos de tipo gradiente decendiente para converger, con una mejora aproximacion de la tasa de aprendizaje, o la utilizacion de un momentum para ayudar el modelo
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/OtherOptimizers.gif&#34; alt=&#34;OtherOptimizers&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;metricas&#34;&gt;Metricas&lt;/h2&gt;
&lt;h3 id=&#34;tipos-de-errores&#34;&gt;Tipos de errores&lt;/h3&gt;
&lt;p&gt;Un clasificador binario debe detectar un evento. A cada prediccion puede tener una prediciccion verdadera o falsa: eso son los True/False Positives/Negatives: True Positive (TP), False Postiive (FP), False Negative (FN), True Negative (TN). Se pueden encontrar dos tipos de errores:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/error_types.jpg&#34; alt=&#34;error&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Con eso se puede crear una matriz de confusion.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/confusion_matrix.png&#34; alt=&#34;confusion_matrix&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Las matrices de confusion pueden abarcar mas de 2 clases:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;confusion_matrix&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Se puede cada vez volver a una binaria:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/conf_mat_multi.png&#34; alt=&#34;conf_mat_multi&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tipos-de-metricas-y-costo&#34;&gt;Tipos de metricas y costo&lt;/h3&gt;
&lt;p&gt;Usando los True/False Positives/Negatives, se puede calcular varias metricas segundo el tipo de applicacion. Tenemos: el accuracy al nivel general, y el recall, la precision y el F-score al nivel de las clases. Mas informacion &lt;a href=&#34;https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;por alla&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Cada tipo de error puede tener un costo differente segundo si es importante o no en la applicacion del sistema. Por eso se puede utilizar un matriz de costo, y calcular un costo global del sistema.&lt;/p&gt;
&lt;h3 id=&#34;aggregacion&#34;&gt;Aggregacion&lt;/h3&gt;
&lt;p&gt;Se puede agregar las metricas que son al nivel de clase para obtener un valor general:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Macro-averaging&lt;/strong&gt;: computar m√©trica para cada clase y luego promediar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Micro-averaging&lt;/strong&gt;: crear matriz de confusion binaria para cada clase, combinar las matrices y luego evaluar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weighted-averaging&lt;/strong&gt;: computar m√©trica para cada clase y luego promediar usando pesos segun el importancia de la clase (nombre de ejemplos)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a simple example in python obtained by the &lt;code&gt;sklearn.metrics.classification_report&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;class 0&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;class 1&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;class 2&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;              precision    recall  f1-score   support

     class 0       0.50      1.00      0.67         1
     class 1       0.00      0.00      0.00         1
     class 2       1.00      0.67      0.80         3

    accuracy                           0.60         5
   macro avg       0.50      0.56      0.49         5
weighted avg       0.70      0.60      0.61         5
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;roc--auc&#34;&gt;ROC &amp;amp; AUC&lt;/h3&gt;
&lt;p&gt;Al momento de la inferencia, nuestro clasificador binario va a dar una probabilidad que un ejemplo sea de la clase positiva. Generalmente, si es superior a $\tau = 0.5$
, significa que el ejemplo es de la clase positiva. Sin embargo, se puede jugar con este umbral $\tau$
.&lt;/p&gt;
&lt;p&gt;El ROC (Receiver Operating Characteristic) es une curva representando la performancia de un clasificador en varias situaciones y que se crea variando el umbral. Para varios valores de el umbra, se calcula la fraccion de verdaderos positivos de los positivos frente a la fraccion de falsos positivos de los negativos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/ROC.png&#34; alt=&#34;ROC&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El Area Under Curve (AUC) permite de obtener una unica valor representando la calidad de la curve. Mas grande significa mejor.&lt;/p&gt;
&lt;h3 id=&#34;regresion&#34;&gt;Regresion&lt;/h3&gt;
&lt;p&gt;Para una regresion, se utilizan metricas que que evaluan las distancias, y si el modelo representa bien la varianza de los datos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Varios calculos de errores&lt;/li&gt;
&lt;li&gt;Coeficiente de determinacion $R^2$
 representa la proporcion de la varianza explicada&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tecnicas-de-evaluacion&#34;&gt;Tecnicas de evaluacion&lt;/h2&gt;
&lt;h3 id=&#34;validacion-cruzada-cross-validation&#34;&gt;Validacion Cruzada (Cross-Validation)&lt;/h3&gt;
&lt;p&gt;Para obtener una mejora estimacion de las performancias del modelo. Para estar seguro de testear sobre cada datos, se puede hacer $V$
 experiencias, cortando el dataset en $V$
 partes, entrenar sobre $V-1$
 y testear sobre $1$
. Es un tipo de bootstrapping con los datos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/cross-val_final.png&#34; alt=&#34;cross-val_final&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Eso sirve para obtener los hiperparametros optimum, antes de entrenar el model final sobre todos los datos, y estimar las performancias sobre el ensemble de test.&lt;/p&gt;
&lt;h3 id=&#34;conjuntos-de-validacion-y-prueba-holdout&#34;&gt;Conjuntos de validacion y prueba (Holdout)&lt;/h3&gt;
&lt;p&gt;Si es imposible de hacer una validacion cruzada (porque el entrenaimento es largo), se puede crear un set de entrenamiento, de validacion, y de test.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/train_val_test.png&#34; alt=&#34;train_val_test&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tama√±o-de-la-particion&#34;&gt;Tama√±o de la particion&lt;/h3&gt;
&lt;p&gt;Un modelo que es buena usando pocos datos es interesante porque a veces obtener etiquetas puede ser costozo. Generalmente las &lt;strong&gt;perfomancias son mas variables y mas bajas con pocos datos de entrenamiento&lt;/strong&gt;, pero la &lt;strong&gt;evaluacion es mas confiable con mas datos de test&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/learning_curve.png&#34; alt=&#34;learning_curve&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Intro Aprendizaje Supervisado</title>
      <link>http://localhost:1313/minerias/4_intro_sl/</link>
      <pubDate>Wed, 27 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/4_intro_sl/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_intro_slpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Intro_SL.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;Esta clase es bastante interesante ya que descubriran las bases del conocimiento utilizado para construir Machine Learning, Deep Learning e Inteligencia Artificial en general: Aprendizaje Supervisado!&lt;/p&gt;
&lt;p&gt;Se trata de un entorno sencillo en el que un &lt;strong&gt;modelo aprender√° sus propios par√°metros utilizando ejemplos y etiquetas asociadas&lt;/strong&gt;. Revisaremos todos los conceptos importantes del aprendizaje supervisado, que son muy √∫tiles para cualquiera que quiera trabajar como data scientist.&lt;/p&gt;
&lt;h2 id=&#34;generalidades&#34;&gt;Generalidades&lt;/h2&gt;
&lt;p&gt;El aprendizaje supervisado utiliza datos y etiquetas para aprender a un modelo a reconocer padrones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Es necesario de transformar los documentos en vectores, para poder hacer la optimizacion&lt;/li&gt;
&lt;li&gt;El modelo va a apprender sus parametros sobre un conjunto de entrenamiento&lt;/li&gt;
&lt;li&gt;El modelo entrenado puede ser usado para predicir la etiquetas de nuevos datos que nunca ha visto antes&lt;/li&gt;
&lt;li&gt;El documento puede ser cualquier dato: audio, texto, imagen, video, usuario, red,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-aprendizaje-de-maquinas-predictivo-supervisado-sigue-eso&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;predictive_modeling_data_flow&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/predictive_modeling_data_flow_hu12315308385899460389.webp 400w,
               /minerias/4_intro_sl/figures/predictive_modeling_data_flow_hu9011300678791282958.webp 760w,
               /minerias/4_intro_sl/figures/predictive_modeling_data_flow_hu8943212305677280315.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/predictive_modeling_data_flow_hu12315308385899460389.webp&#34;
               width=&#34;760&#34;
               height=&#34;549&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El aprendizaje de maquinas predictivo supervisado sigue eso
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;features-y-etiquetas&#34;&gt;Features y etiquetas&lt;/h3&gt;
&lt;p&gt;Se puede representar en un espacio los documentos como vectores. Aca cada punto es una cancion, que esta representando con su intensidad y tempo promedios. La etiqueta es la color del punto. Aca tenemos una tarea de &lt;strong&gt;clasificacion binaria de musica&lt;/strong&gt;, segundo las preferencias de un usuario.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-para-las-tareas-de-clasificaciones-los-ejemplos-se-representan-como-puntos-en-un-espacio-de-dimension-de-las-observaciones-y-una-color-o-forma-para-representar-las-diferentes-clases&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;classif&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/classif_hu9702192758643128410.webp 400w,
               /minerias/4_intro_sl/figures/classif_hu1940178425719737447.webp 760w,
               /minerias/4_intro_sl/figures/classif_hu1255634141064509397.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/classif_hu9702192758643128410.webp&#34;
               width=&#34;760&#34;
               height=&#34;476&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Para las tareas de clasificaciones, los ejemplos se representan como puntos en un espacio de dimension de las observaciones, y una color o forma para representar las diferentes clases
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El objetivo del juego, va a ser de encontrar &lt;strong&gt;una funcion que separa el espacio en dos partes&lt;/strong&gt;. Una donde hay las canciones que le gustan a la persona, y la otra parte que no le gustan. De este manera, cuando vamos a tener un nuevo punto en este espacio, podemos decir si la persona va a gustar o no esta cancion, lo que sea &lt;strong&gt;predicir su etiqueta&lt;/strong&gt;!&lt;/p&gt;
&lt;h3 id=&#34;en-resumen&#34;&gt;En resumen&lt;/h3&gt;
&lt;p&gt;Se necesitan varias cosas para un entrenamiento&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Tener datos etiquetados&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Conjunto de datos de tama√±o $n$
, $\mathcal{D}_n = \{(\text{Doc}_i, Y_i), i=1..n\}$
&lt;/li&gt;
&lt;li&gt;$\text{Doc}$ es una muestra (por ejemplo: una persona)&lt;/li&gt;
&lt;li&gt;$Y$ son las etiquetas (por ejemplo: monto del pr√©stamo concedido)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Extraer los descriptores&lt;/strong&gt; = transformar documentos en vectores&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;$\mathbf{X}$ es un vector de observaciones (por ejemplo: edad, sexo, salario)&lt;/li&gt;
&lt;li&gt;$Y$ son las etiquetas (por ejemplo: monto del pr√©stamo concedido)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Crear un modelo matem√°tico $f_\theta$&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Modelo $f_\theta$ tal que  $f_\theta(\mathbf{X})$
 est√© cerca de $Y$ (para regresi√≥n)&lt;/li&gt;
&lt;li&gt;$\theta$ es el conjunto de par√°metros del modelo matem√°tico&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Implementar una funci√≥n de costo (error) $\ell$
 a minimizar&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Cuanto m√°s se equivoque el modelo, mayor ser√° el costo&lt;/li&gt;
&lt;li&gt;En general, se desea tener un costo peque√±o&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;Encontrar los par√°metros  $\theta^*$ 
 de manera que  $\ell(f_{\theta^*}(\mathbf{X}_i), Y_i)$ 
 sea peque√±o&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
$$\theta^* = \underset{\theta}{\arg\min}\sum_{i}\ell(f_{\theta}(\mathbf{X}_i), Y_i)$$&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;&lt;strong&gt;Probar $f_{\theta^*}$
 en nuevos datos con una m√©trica de evaluaci√≥n adecuada&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;aprendizaje&#34;&gt;Aprendizaje&lt;/h2&gt;
&lt;p&gt;Hay varios conceptos en el aprendizaje:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Datos etiquetados&lt;/strong&gt;: Regresi√≥n o Clasificaci√≥n&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Extracci√≥n de caracter√≠sticas&lt;/strong&gt;: Tono, Intensidad, Tempo o Edad, Salario, G√©nero, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modelo $f_\theta$&lt;/strong&gt;: SVM, Regresi√≥n Log√≠stica, Bosque Aleatorio, CNN&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Funci√≥n de costo&lt;/strong&gt; a optimizar: P√©rdida de Bisagra, P√©rdida de Entrop√≠a Cruzada, P√©rdida Log√≠stica, P√©rdida Cuadrada, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Algoritmo de optimizaci√≥n&lt;/strong&gt;: Adam, SGD, BFGS, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;M√©trica de evaluaci√≥n&lt;/strong&gt;: Recall, Precisi√≥n, M√≠nimos Cuadrados, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;funcion-de-costo&#34;&gt;Funcion de costo&lt;/h3&gt;
&lt;p&gt;Para cuantificar las errores del modelo en la optimizacion, se necesita una funcion de costo que llamamos  $\ell$ 
. Ella representa si el modelo esta dando las buenas respuestas $y$
 segundo una entrada $X$
. Este funcion penaliza el modelo cuando comete errores, y lo que queremos hacer es optimizar los pesos del modelo, para obtener una valor minimum de este costo, lo que significaria menos errores, entonces mejor modelo.&lt;/p&gt;
&lt;p&gt;Hay que minimizar esta funci√≥n sobre el conjunto de entrenamiento (riesgo emp√≠rico) para encontrar par√°metros del modelo satisfactorios:&lt;/p&gt;
$$ f_{\hat{\theta}} =\underset{f_\theta, \theta \in \Theta}{\arg\min} \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$$&lt;p&gt;Los parametros van a cambiar para tener un valor minimum de costo:
















&lt;figure  id=&#34;figure-los-pesos-cambian-poco-a-poco-para-llegar-a-los-que-van-a-dar-un-valor-de-costo-minimum-sobre-el-ensemble-de-entrenamiento&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;convergence_algo_optim&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu3361748985186866440.webp 400w,
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu3884812293168319734.webp 760w,
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu2615079541688126126.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/convergence_algo_optim_hu3361748985186866440.webp&#34;
               width=&#34;566&#34;
               height=&#34;572&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los pesos cambian poco a poco para llegar a los que van a dar un valor de costo minimum sobre el ensemble de entrenamiento
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;La funcion de costo expresa el error desde una perspectiva &lt;strong&gt;num√©rica&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Transmite al algoritmo de aprendizaje lo que es importante y tiene sentido para la tarea&lt;/li&gt;
&lt;li&gt;Debe ser una funci√≥n que se pueda optimizar eficientemente (convexa). &lt;strong&gt;La funci√≥n  $\ell^{0/1} = \mathbf{1}_{f(\mathbf{X}) = Y}$ 
 no es utilizable&lt;/strong&gt; (ni siquiera continua).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;complejidad-de-los-modelos-y-sobresoto-aprendizaje&#34;&gt;Complejidad de los modelos y sobre/soto-aprendizaje&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt; $\mathcal{F} = \{ f: \text{ funciones medibles } \mathcal{X} \text{&amp;rarr;} \mathcal{Y}\}$ 
&lt;/li&gt;
&lt;li&gt;Mejor soluci√≥n  $f^* = \arg\min_{f \in \mathcal{F}}\mathcal{R}(f)$ 
&lt;/li&gt;
&lt;li&gt;Clase de funciones  $\mathcal{S} \subset \mathcal{F}$ 
 utilizadas como modelos&lt;/li&gt;
&lt;li&gt;Objetivo ideal en $\mathcal{S}$:  $f^*_\mathcal{S} = \arg\min_{f \in \mathcal{S}}\mathcal{R}(f)$ 
&lt;/li&gt;
&lt;li&gt;Estimaci√≥n obtenida en  $\mathcal{S}$ 
: se obtiene  $f_\mathcal{S}$ 
 tras un entrenamiento&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Se pueden encontrar dos maneras de no tener el riesgo minimum optimum:&lt;/p&gt;
$$ \mathcal{R}(\hat{f_\mathcal{S}}) - \mathcal{R}(f^*) = \textcolor{red}{\underbrace{ \mathcal{R}(f_\mathcal{S}^*) - \mathcal{R}(f^*) }_{\text{error de aproximacion}}} +  \textcolor{blue}{\underbrace{ \mathcal{R}(\hat{f_\mathcal{S}}) - \mathcal{R}(f_\mathcal{S}^*) }_{\text{error de estimacion}}}$$&lt;p&gt;















&lt;figure  id=&#34;figure-los-2-tipos-de-errores-el-error-de-aproximacion-viene-de-la-eleccion-de-los-modelos-que-se-utilizan-y-el-error-de-estimacion-viene-de-un-mal-entrenamiento-del-modelo&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;approx_estim_errors&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/approx_estim_errors_hu1287908794753332032.webp 400w,
               /minerias/4_intro_sl/figures/approx_estim_errors_hu13343448165022106133.webp 760w,
               /minerias/4_intro_sl/figures/approx_estim_errors_hu4804674474612499519.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/approx_estim_errors_hu1287908794753332032.webp&#34;
               width=&#34;508&#34;
               height=&#34;435&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los 2 tipos de errores: el error de aproximacion viene de la eleccion de los modelos que se utilizan, y el error de estimacion viene de un mal entrenamiento del modelo
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El error de aproximaci√≥n puede ser grande si el modelo $\mathcal{S}$ no es adaptado, y el error de estimaci√≥n puede ser grande si el modelo es complejo.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-un-ejemplo-simple-seria-un-polinomio-de-grado-p-que-quiere-estimar-un-polinomio-de-grado-n-con-ruido-si-p-es-mas-grande-o-mas-pequeno-que-n-no-es-adaptado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;underfitting&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/ex_over-underfitting_hu10525897534329112004.webp 400w,
               /minerias/4_intro_sl/figures/ex_over-underfitting_hu2460076892096630892.webp 760w,
               /minerias/4_intro_sl/figures/ex_over-underfitting_hu9118631690023105709.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/ex_over-underfitting_hu10525897534329112004.webp&#34;
               width=&#34;760&#34;
               height=&#34;264&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un ejemplo simple seria un polinomio de grado P que quiere estimar un polinomio de grado N con ruido. Si P es mas grande o mas pequeno que N, no es adaptado.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Soto-aprentizaje&lt;/strong&gt;: Si no hay demasiado parametros, es imposible de estimar bien la curva,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sobre-aprentizaje&lt;/strong&gt;: Si hay demasiado parametros va a enfocar en memorizar el ruido del ensemble de entrenamiento&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;regularizacion-y-parsimonia&#34;&gt;Regularizacion y parsimonia&lt;/h3&gt;
&lt;p&gt;Una solucion para combatir el problema de no generalizacion es la regularizacion, que permite de agregar una penalizaci√≥n en relaci√≥n con la complejidad del modelo:&lt;/p&gt;

$$\arg\min_{f_\theta, \theta \in \Theta} \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) ) + pen(\theta)$$


&lt;p&gt;Hay varias posibilidades de penalizacion, generalmente se usa la norma de los pesos del modelo. La intuicion detras de eso es que disminuir la norma del modelo o su n√∫mero de coeficientes, n√∫mero de ramas del grafo (poda).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AIC:

$pen(\theta) = \lambda ||\theta||_0$


&lt;em&gt;(no convexa, parsimoniosa, poco utilizada)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Ridge:

$pen(\theta) = \lambda ||\theta||_2$ 


&lt;em&gt;(convexa, no parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Lasso:

$pen(\theta) = \lambda ||\theta||_1$ 


&lt;em&gt;(convexa, parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Elastic Net:

$pen(\theta) = \lambda_1 ||\theta||_1 + \lambda_2 ||\theta||_2$


&lt;em&gt;(convexa, parsimoniosa)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El  $\lambda$ 
 es un nuevo hiperparametro del modelo.&lt;/p&gt;
&lt;p&gt;El lasso induce la parcimonia. Aca se pueden ver para  $n=\{0,1,2\}$ 
, las bolas  $$\mathcal{B}^n = \{x / x \in \mathbb{R}^d \text{ and } ||x||_n &lt; 1\}$$ 
:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;norms&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/norms_hu13040269207447033896.webp 400w,
               /minerias/4_intro_sl/figures/norms_hu2484826675081491891.webp 760w,
               /minerias/4_intro_sl/figures/norms_hu549636321832970956.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/norms_hu13040269207447033896.webp&#34;
               width=&#34;760&#34;
               height=&#34;319&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En dimensiones grandes, la mayor√≠a de  $\mathcal{B}^1$ 
 se concentra en los ejes: &lt;strong&gt;esto equivale a tener valores nulos para otros ejes&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Sparsityl1&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/Sparsityl1_hu15118340912051855990.webp 400w,
               /minerias/4_intro_sl/figures/Sparsityl1_hu2311885472990105800.webp 760w,
               /minerias/4_intro_sl/figures/Sparsityl1_hu6053000379869258004.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/Sparsityl1_hu15118340912051855990.webp&#34;
               width=&#34;760&#34;
               height=&#34;308&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;optimizacion-loss-landscape&#34;&gt;Optimizacion, &lt;em&gt;loss landscape&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;La optimizacion de la funcion de costo sobre el ensemble de entrenamiento ( $ \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$ 
) se puede hacer de manera analitica en casos simples, o de manera iterativa. La fase de optimizacion va a &lt;strong&gt;hacer converger los parametros&lt;/strong&gt; para encontrar los que van a dar un &lt;strong&gt;costo minimum en el conjunto de datos de entrenamiento&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;convergence_algo_optim&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu3361748985186866440.webp 400w,
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu3884812293168319734.webp 760w,
               /minerias/4_intro_sl/figures/convergence_algo_optim_hu2615079541688126126.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/convergence_algo_optim_hu3361748985186866440.webp&#34;
               width=&#34;566&#34;
               height=&#34;572&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En este ejemplo se puede ver los parametros $a,b$
 del modelo  $y = a\mathbf{X}+b$ 
 cambiar por cada iteracion, para tener un valor del error (sse; suma residual de cuadrados) que esta diminuando:
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;regression_gif&#34;
           src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/regression_gif.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Porque la valor del costo empirico  $ \frac{1}{n}\sum_{i=1}^n \ell(Y_i, f_\theta(\mathbf{X}_i) )$ 
 es un nombre real positivo, podemos representarlo en un eje, y los parametros con unos otros ejes. Eso se llama el &lt;em&gt;loss landscape&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-loss-landscape-parece-a-un-paisaje-con-desnivel-con-el-objetivo-de-encontrar-el-lugar-con-menos-altura&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;LossAlps&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/LossAlps_hu15806339177112344745.webp 400w,
               /minerias/4_intro_sl/figures/LossAlps_hu9473298813042643160.webp 760w,
               /minerias/4_intro_sl/figures/LossAlps_hu7762387643821809596.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/LossAlps_hu15806339177112344745.webp&#34;
               width=&#34;760&#34;
               height=&#34;498&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La &lt;em&gt;loss landscape&lt;/em&gt; parece a un paisaje con desnivel, con el objetivo de encontrar el lugar con menos altura.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El objetivo del algoritmo de optimizacion es de encontrar la &amp;ldquo;ruta&amp;rdquo; para conducir en una &amp;ldquo;valle&amp;rdquo;, que representa un minimum local o global. Este ollo significa que los parametros sean los que dan un error peque√±a.&lt;/p&gt;
&lt;h3 id=&#34;gradiente-descendiente&#34;&gt;Gradiente descendiente&lt;/h3&gt;
&lt;p&gt;El gradiente de una funci√≥n  $\nabla_xf(x)=(\frac{\partial f}{\partial x_i})_{i=1..n}$ 
 es su derivativa seg√∫n cada dimensi√≥n. Es una &lt;strong&gt;aproximaci√≥n lineal de la funci√≥n al nivel local&lt;/strong&gt;. Este indica la direccion donde aumenta una funcion:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;gradient_curve1D&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/gradient_curve1D_hu10032121186573210922.webp 400w,
               /minerias/4_intro_sl/figures/gradient_curve1D_hu12987032236723031820.webp 760w,
               /minerias/4_intro_sl/figures/gradient_curve1D_hu8038234561045909677.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/gradient_curve1D_hu10032121186573210922.webp&#34;
               width=&#34;760&#34;
               height=&#34;415&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Por eso, se puede utilizar el gradiente de la funccion de costo para minimizar el costo. Despu√©s de cada c√°lculo de la funci√≥n de costo  $\ell(Y_i, f_\theta(\mathbf{X}_i) ; \theta)$ 
, se calcula el gradiente de esta funci√≥n para actualizar los par√°metros $\theta$
:&lt;/p&gt;
$$	\theta \leftarrow \theta - \alpha*\nabla_\theta \ell(Y_i, f_\theta(\mathbf{X}_i) ; \theta)$$&lt;p&gt;La tasa de aprendizaje  $\alpha$ 
 en la ecuacion precedente representa la cantidad de acutalizacion de los parametros. Es importante porque va a influir sobre la convergencia.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-tasa-de-aprendizaje-es-crucial-para-el-exito-de-la-fase-de-entrenamiento&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;learningrates&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/learningrates_hu14981630448780851733.webp 400w,
               /minerias/4_intro_sl/figures/learningrates_hu5823504888508698054.webp 760w,
               /minerias/4_intro_sl/figures/learningrates_hu11541866586040789986.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/learningrates_hu14981630448780851733.webp&#34;
               width=&#34;459&#34;
               height=&#34;414&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La tasa de aprendizaje es crucial para el exito de la fase de entrenamiento.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En en &lt;em&gt;loss landscape&lt;/em&gt;, se puede representar el modelo durante la optimizacion como un vector moviendo en cada iteracion. Con este vision, la tasa de aprendizaje define mas o menos la &amp;ldquo;velocidad&amp;rdquo; de como se mueve este punto. Por eso, es simple de entender que a veces tiene que ser mas grande y otra veces mas peque√±o, por ejemplo para pasar topografias particular del &lt;em&gt;landscape&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Hay varios algoritmos de tipo gradiente descendiente para converger, con una mejora aproximacion de la tasa de aprendizaje, o la utilizacion de un momentum para ayudar el modelo
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;OtherOptimizers&#34;
           src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/OtherOptimizers.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;metricas&#34;&gt;Metricas&lt;/h2&gt;
&lt;h3 id=&#34;tipos-de-errores&#34;&gt;Tipos de errores&lt;/h3&gt;
&lt;p&gt;Un clasificador binario debe detectar un evento. A cada prediccion puede tener una prediciccion verdadera o falsa: eso son los True/False Positives/Negatives: True Positive (TP), False Postiive (FP), False Negative (FN), True Negative (TN). Se pueden encontrar dos tipos de errores:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;error&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/error_types_hu818360641458426582.webp 400w,
               /minerias/4_intro_sl/figures/error_types_hu1763655108969077203.webp 760w,
               /minerias/4_intro_sl/figures/error_types_hu8812666687817491822.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/error_types_hu818360641458426582.webp&#34;
               width=&#34;760&#34;
               height=&#34;573&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Con eso se puede crear una matriz de confusion.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-matriz-de-confusion-tiene-las-etiquetas-en-un-eje-y-las-predicciones-en-el-otro-se-puede-representar-los-truefalse-postivenegative&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;confusion_matrix&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/confusion_matrix_hu17666632291397020102.webp 400w,
               /minerias/4_intro_sl/figures/confusion_matrix_hu6029062098124639712.webp 760w,
               /minerias/4_intro_sl/figures/confusion_matrix_hu4969514950180408067.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/confusion_matrix_hu17666632291397020102.webp&#34;
               width=&#34;596&#34;
               height=&#34;415&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La matriz de confusion tiene las etiquetas en un eje, y las predicciones en el otro. Se puede representar los True/False Postive/Negative.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Las matrices de confusion pueden abarcar mas de 2 clases:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;confusion_matrix&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Se puede cada vez volver a una binaria:
















&lt;figure  id=&#34;figure-la-matriz-de-confusion-tiene-las-etiquetas-en-un-eje-y-las-predicciones-en-el-otro-una-matriz-diagonal-significa-predicciones-perfectas&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;conf_mat_multi&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/conf_mat_multi_hu1455269705468184231.webp 400w,
               /minerias/4_intro_sl/figures/conf_mat_multi_hu7808360544726272494.webp 760w,
               /minerias/4_intro_sl/figures/conf_mat_multi_hu8975441635701126753.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/conf_mat_multi_hu1455269705468184231.webp&#34;
               width=&#34;474&#34;
               height=&#34;250&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La matriz de confusion tiene las etiquetas en un eje, y las predicciones en el otro. Una matriz diagonal significa predicciones perfectas.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tipos-de-metricas-y-costo&#34;&gt;Tipos de metricas y costo&lt;/h3&gt;
&lt;p&gt;Usando los True/False Positives/Negatives, se puede calcular varias metricas segundo el tipo de applicacion. Tenemos: el accuracy al nivel general, y el recall, la precision y el F-score al nivel de las clases. Mas informacion &lt;a href=&#34;https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;por alla&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Cada tipo de error puede tener un costo differente segundo si es importante o no en la applicacion del sistema. Por eso se puede utilizar un matriz de costo, y calcular un costo global del sistema.&lt;/p&gt;
&lt;h3 id=&#34;aggregacion&#34;&gt;Aggregacion&lt;/h3&gt;
&lt;p&gt;Se puede agregar las metricas que son al nivel de clase para obtener un valor general:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Macro-averaging&lt;/strong&gt;: computar m√©trica para cada clase y luego promediar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Micro-averaging&lt;/strong&gt;: crear matriz de confusion binaria para cada clase, combinar las matrices y luego evaluar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weighted-averaging&lt;/strong&gt;: computar m√©trica para cada clase y luego promediar usando pesos segun el importancia de la clase (nombre de ejemplos)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a simple example in python obtained by the &lt;code&gt;sklearn.metrics.classification_report&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;class 0&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;class 1&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;class 2&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;              precision    recall  f1-score   support

     class 0       0.50      1.00      0.67         1
     class 1       0.00      0.00      0.00         1
     class 2       1.00      0.67      0.80         3

    accuracy                           0.60         5
   macro avg       0.50      0.56      0.49         5
weighted avg       0.70      0.60      0.61         5
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;roc--auc&#34;&gt;ROC &amp;amp; AUC&lt;/h3&gt;
&lt;p&gt;Al momento de la inferencia, nuestro clasificador binario va a dar una probabilidad que un ejemplo sea de la clase positiva. Generalmente, si es superior a $\tau = 0.5$
, significa que el ejemplo es de la clase positiva. Sin embargo, se puede jugar con este umbral $\tau$
.&lt;/p&gt;
&lt;p&gt;El ROC (Receiver Operating Characteristic) es une curva representando la performancia de un clasificador en varias situaciones y que se crea variando el umbral. Para varios valores de el umbra, se calcula la fraccion de verdaderos positivos de los positivos frente a la fraccion de falsos positivos de los negativos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;ROC&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/ROC_hu10607619452381477277.webp 400w,
               /minerias/4_intro_sl/figures/ROC_hu3908369485916332207.webp 760w,
               /minerias/4_intro_sl/figures/ROC_hu7705981326579221202.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/ROC_hu10607619452381477277.webp&#34;
               width=&#34;760&#34;
               height=&#34;491&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El Area Under Curve (AUC) permite de obtener una unica valor representando la calidad de la curve. Mas grande significa mejor.&lt;/p&gt;
&lt;h3 id=&#34;regresion&#34;&gt;Regresion&lt;/h3&gt;
&lt;p&gt;Para una regresion, se utilizan metricas que que evaluan las distancias, y si el modelo representa bien la varianza de los datos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Varios calculos de errores&lt;/li&gt;
&lt;li&gt;Coeficiente de determinacion $R^2$
 representa la proporcion de la varianza explicada&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tecnicas-de-evaluacion&#34;&gt;Tecnicas de evaluacion&lt;/h2&gt;
&lt;h3 id=&#34;validacion-cruzada-cross-validation&#34;&gt;Validacion Cruzada (Cross-Validation)&lt;/h3&gt;
&lt;p&gt;Para obtener una mejora estimacion de las performancias del modelo. Para estar seguro de testear sobre cada datos, se puede hacer $V$
 experiencias, cortando el dataset en $V$
 partes, entrenar sobre $V-1$
 y testear sobre $1$
. Es un tipo de bootstrapping con los datos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-separar-en-3-parte-y-hacer-3-entrenamiento-permite-de-hacer-el-test-sobre-todo-el-ensemble-y-tener-una-mejora-estimacion-de-las-performancias-del-modelo&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;cross-val_final&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/cross-val_final_hu16748371362900430386.webp 400w,
               /minerias/4_intro_sl/figures/cross-val_final_hu11491613420033986625.webp 760w,
               /minerias/4_intro_sl/figures/cross-val_final_hu4516641686194685870.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/cross-val_final_hu16748371362900430386.webp&#34;
               width=&#34;760&#34;
               height=&#34;212&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Separar en 3 parte, y hacer 3 entrenamiento permite de hacer el test sobre todo el ensemble y tener una mejora estimacion de las performancias del modelo.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Eso sirve para obtener los hiperparametros optimum, antes de entrenar el model final sobre todos los datos, y estimar las performancias sobre el ensemble de test.&lt;/p&gt;
&lt;h3 id=&#34;conjuntos-de-validacion-y-prueba-holdout&#34;&gt;Conjuntos de validacion y prueba (Holdout)&lt;/h3&gt;
&lt;p&gt;Si es imposible de hacer una validacion cruzada (porque el entrenaimento es largo), se puede crear un set de entrenamiento, de validacion, y de test.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-usar-un-ensemble-de-validacion-permite-de-encontrar-los-hiperparametros-sin-usar-el-test-y-sin-usar-de-validacion-cruzada&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;train_val_test&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/train_val_test_hu13319893936448070572.webp 400w,
               /minerias/4_intro_sl/figures/train_val_test_hu11490916923281978634.webp 760w,
               /minerias/4_intro_sl/figures/train_val_test_hu7094084863204531350.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/train_val_test_hu13319893936448070572.webp&#34;
               width=&#34;760&#34;
               height=&#34;279&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Usar un ensemble de validacion permite de encontrar los hiperparametros sin usar el test, y sin usar de validacion cruzada.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;tama√±o-de-la-particion&#34;&gt;Tama√±o de la particion&lt;/h3&gt;
&lt;p&gt;Un modelo que es buena usando pocos datos es interesante porque a veces obtener etiquetas puede ser costozo. Generalmente las &lt;strong&gt;perfomancias son mas variables y mas bajas con pocos datos de entrenamiento&lt;/strong&gt;, pero la &lt;strong&gt;evaluacion es mas confiable con mas datos de test&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;learning_curve&#34; srcset=&#34;
               /minerias/4_intro_sl/figures/learning_curve_hu14578813128231917822.webp 400w,
               /minerias/4_intro_sl/figures/learning_curve_hu7895650233809507061.webp 760w,
               /minerias/4_intro_sl/figures/learning_curve_hu16581810329368848848.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/4_intro_sl/figures/learning_curve_hu14578813128231917822.webp&#34;
               width=&#34;760&#34;
               height=&#34;637&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Biases and Fairness</title>
      <link>http://localhost:1313/minerias/5_biases/</link>
      <pubDate>Tue, 26 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/5_biases/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_biasespdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Biases.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Modelos Lineales</title>
      <link>http://localhost:1313/minerias/6_modelos_lin/</link>
      <pubDate>Mon, 25 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/6_modelos_lin/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_modelos_linpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Modelos_Lin.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;Esta clase profundiza en los &lt;strong&gt;modelos de clasificaci√≥n lineal&lt;/strong&gt;, mostrando c√≥mo un &lt;strong&gt;hiperplano&lt;/strong&gt; puede separar ejemplos en un espacio de caracter√≠sticas. Adem√°s, se introduce la &lt;strong&gt;regresi√≥n lineal&lt;/strong&gt; como un caso particular de modelos lineales (cuando la variable a predecir es continua) y la regresi√≥n log√≠stica (para valores binarios o multi-clase). Finalmente, veremos una &lt;strong&gt;introducci√≥n al uso de scikit-learn&lt;/strong&gt;, la librer√≠a de Python muy popular para Machine Learning.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Puedes enfatizar en las propiedades de la linealidad, la noci√≥n de hiperplano, la forma de pasar a modelos m√°s complejos con un truco de aumento del espacio, y rematar con ejemplos en scikit-learn. Invita a la discusi√≥n de por qu√© a veces preferimos estos modelos lineales frente a otros m√°s complejos.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;modelos-de-clasificaci√≥n&#34;&gt;Modelos de Clasificaci√≥n&lt;/h2&gt;
&lt;h3 id=&#34;clasificador-lineal&#34;&gt;Clasificador lineal&lt;/h3&gt;
&lt;p&gt;El objetivo de un &lt;strong&gt;clasificador lineal&lt;/strong&gt; es separar el espacio de atributos con un &lt;strong&gt;hiperplano&lt;/strong&gt; de manera que queden los ejemplos de una clase a un lado y los de la(s) otra(s) clase(s) al otro lado.&lt;/p&gt;
&lt;h4 id=&#34;problemas-lineales-vs-no-lineales&#34;&gt;Problemas lineales vs. no lineales&lt;/h4&gt;
&lt;p&gt;En la pr√°ctica, muchas fronteras de decisi√≥n no son lineales. Sin embargo, &lt;strong&gt;a√∫n podemos aplicar modelos lineales&lt;/strong&gt; si creamos caracter√≠sticas m√°s elaboradas o hacemos transformaciones adecuadas.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplos-de-problemas-lineales-y-no-lineales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Clasificaci√≥n lineal y no lineal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/linear_vs_nonlinear_problems_hu7353041200993864283.webp 400w,
               /minerias/6_modelos_lin/figures/linear_vs_nonlinear_problems_hu17403413559867806974.webp 760w,
               /minerias/6_modelos_lin/figures/linear_vs_nonlinear_problems_hu18016639814542214630.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/linear_vs_nonlinear_problems_hu7353041200993864283.webp&#34;
               width=&#34;709&#34;
               height=&#34;297&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplos de problemas lineales y no lineales
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Una funci√≥n $f : \mathcal{X}\rightarrow \mathcal{Y}$
 es lineal si $f(\lambda \mathbf{x} + \mathbf{x}&#39;) = \lambda\,f(\mathbf{x}) + f(\mathbf{x}&#39;)$
.&lt;/li&gt;
&lt;li&gt;Un caso t√≠pico es $f(\mathbf{x}) = \theta^T \mathbf{x} = \sum_i \theta_i\,x_i$
.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;hiperplano-geometr√≠a&#34;&gt;Hiperplano (geometr√≠a)&lt;/h4&gt;
$$
w_1\,x_1 \;+\; w_2\,x_2 \;+\;\dots\;+\; w_d\,x_d \;+\; w_0 \;=\; 0.
$$&lt;p&gt;&lt;strong&gt;Interpretaci√≥n&lt;/strong&gt;: el signo de $w_1 x_1 + \dots + w_d x_d + w_0$
 indica de qu√© lado del hiperplano se encuentra $\mathbf{x}$
.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-en-2d-es-una-recta-en-3d-es-un-plano&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representaci√≥n de un hiperplano en 2D y 3D&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/affine_hu14528710492767468521.webp 400w,
               /minerias/6_modelos_lin/figures/affine_hu15839829693383708641.webp 760w,
               /minerias/6_modelos_lin/figures/affine_hu14583323748885349885.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/affine_hu14528710492767468521.webp&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      En 2D es una recta, en 3D es un plano
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Recordar que, en 2D, se llama recta; en 3D, se llama plano; y en m√°s dimensiones, se sigue llamando hiperplano.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-normal-define-la-orientaci√≥n-del-hiperplano&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representaci√≥n del plano mediante la normal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/plan_normale_hu15260604472700012555.webp 400w,
               /minerias/6_modelos_lin/figures/plan_normale_hu6943290207337226051.webp 760w,
               /minerias/6_modelos_lin/figures/plan_normale_hu9804219792372522524.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/plan_normale_hu15260604472700012555.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La normal define la orientaci√≥n del hiperplano
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En este diagrama vemos c√≥mo la &lt;strong&gt;normal&lt;/strong&gt; ($\vec{n}$
) al hiperplano define su orientaci√≥n. El t√©rmino $w_0$
 (o sesgo) desplaza el plano.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;producto-escalar-y-parte-af√≠n&#34;&gt;Producto escalar y parte af√≠n&lt;/h4&gt;
&lt;p&gt;Si &lt;strong&gt;aumentamos el espacio&lt;/strong&gt; a√±adiendo un 1 a nuestro vector de caracter√≠sticas:
$
\mathbf{x} \;=\;
\begin{pmatrix}
x_1\\
\vdots\\
x_d\\
1
\end{pmatrix},\quad
\theta \;=\;
\begin{pmatrix}
\theta_1\\
\vdots\\
\theta_d\\
\theta_0
\end{pmatrix},
$

entonces $\theta^T \mathbf{x} = w_0 + \sum_i w_i\,x_i$
. Esto permite manejar en un mismo marco la parte ‚Äúaf√≠n‚Äù del hiperplano.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representaci√≥n general de un hiperplano af√≠n&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/geom2D-plan_hu3378174178292732278.webp 400w,
               /minerias/6_modelos_lin/figures/geom2D-plan_hu1534089568248987208.webp 760w,
               /minerias/6_modelos_lin/figures/geom2D-plan_hu17731144349146713873.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/geom2D-plan_hu3378174178292732278.webp&#34;
               width=&#34;482&#34;
               height=&#34;243&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;resumen&#34;&gt;Resumen&lt;/h4&gt;
&lt;p&gt;El &lt;strong&gt;clasificador lineal&lt;/strong&gt; m√°s sencillo se define como:&lt;/p&gt;
$$
f_{\mathbf{W}, b}(\mathbf{x}) \;=\;
\begin{cases}
+1, &amp; \text{si } (\mathbf{W}^T\,\mathbf{x} + b)\;\ge\;0, \\
-1, &amp; \text{en caso contrario}.
\end{cases}
$$&lt;p&gt;O, en problemas multiclase, usamos la misma idea (hiperplano para cada clase) y elegimos la que tenga la salida m√°s alta (argmax).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-podemos-ver-la-separaci√≥n-con-una-superficie-lineal-en-el-espacio-transformado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de separaci√≥n lineal en 3D (SVM no lineal)&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/SVM_non_lin_3D_hu16934183206793690649.webp 400w,
               /minerias/6_modelos_lin/figures/SVM_non_lin_3D_hu12349553245862043253.webp 760w,
               /minerias/6_modelos_lin/figures/SVM_non_lin_3D_hu15825121860496258888.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/SVM_non_lin_3D_hu16934183206793690649.webp&#34;
               width=&#34;760&#34;
               height=&#34;703&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Podemos ver la separaci√≥n con una superficie lineal en el espacio transformado.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Recalca c√≥mo, si no es separable linealmente, podemos usar un truco de ‚Äúfeatures‚Äù que nos lleven a un espacio donde s√≠ lo sea.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-aqu√≠-el-hiperplano-es-una-simple-recta-2d&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Separando puntos con un hiperplano en 2D&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/linsep_new_hu14997818569280874164.webp 400w,
               /minerias/6_modelos_lin/figures/linsep_new_hu11636099713454292706.webp 760w,
               /minerias/6_modelos_lin/figures/linsep_new_hu16742827150983731599.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/linsep_new_hu14997818569280874164.webp&#34;
               width=&#34;760&#34;
               height=&#34;364&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Aqu√≠ el hiperplano es una simple recta 2D
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-un-hiperplano-en-d-dimensiones&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representaci√≥n m√°s gen√©rica en un espacio N-dimensional&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/Linear_Classifier_space_hu15836063779108037436.webp 400w,
               /minerias/6_modelos_lin/figures/Linear_Classifier_space_hu7924874973121578882.webp 760w,
               /minerias/6_modelos_lin/figures/Linear_Classifier_space_hu4361361228696633468.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/Linear_Classifier_space_hu15836063779108037436.webp&#34;
               width=&#34;706&#34;
               height=&#34;518&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un hiperplano en d dimensiones
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;clasificador-lineal-multinomial&#34;&gt;Clasificador lineal multinomial&lt;/h3&gt;
&lt;p&gt;Para m√°s de 2 clases, podemos tener una matriz $\mathbf{W}$
, donde cada fila corresponde a un posible ‚Äúhiperplano‚Äù que da una puntuaci√≥n a la clase. Luego:&lt;/p&gt;
$$
\hat{c}(\mathbf{x})
\;=\;
\arg\max_{c}\;\bigl(\mathbf{W}_c^T\,\mathbf{x} + b_c\bigr).
$$&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Clasificador lineal multiclase como operaci√≥n matricial&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/Linear_Classification_hu12810854765152666704.webp 400w,
               /minerias/6_modelos_lin/figures/Linear_Classification_hu8176628540058915532.webp 760w,
               /minerias/6_modelos_lin/figures/Linear_Classification_hu11231406798243868969.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/Linear_Classification_hu12810854765152666704.webp&#34;
               width=&#34;760&#34;
               height=&#34;641&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: destacar que es una operaci√≥n muy r√°pida, pues es un producto matriz-vector.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;integraci√≥n-del-sesgo&#34;&gt;Integraci√≥n del sesgo&lt;/h3&gt;
&lt;p&gt;En vez de $\mathbf{W}^T\mathbf{x} + b$
, se pasa a un producto escalar extendido:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-se-a√±ade-el-1-al-vector-de-descriptores-y-el-bias-a-los-pesos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Bias Trick&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/Bias_Trick_hu7434524410363380459.webp 400w,
               /minerias/6_modelos_lin/figures/Bias_Trick_hu14795603539966083441.webp 760w,
               /minerias/6_modelos_lin/figures/Bias_Trick_hu3757125100915727117.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/Bias_Trick_hu7434524410363380459.webp&#34;
               width=&#34;760&#34;
               height=&#34;277&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Se a√±ade el 1 al vector de descriptores y el bias a los pesos
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;aumento-del-espacio-para-no-linealidad&#34;&gt;Aumento del espacio para no linealidad&lt;/h3&gt;
&lt;p&gt;Se puede &lt;strong&gt;agregar variables no lineales&lt;/strong&gt; (por ejemplo $z = x^2 + y^2$
) para separar datos no linealmente separables en la dimensi√≥n original. La separaci√≥n sigue siendo &lt;em&gt;lineal&lt;/em&gt; en el espacio de mayor dimensi√≥n.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;De 2D a 3D para volver lineal lo no lineal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/data_2d_to_3d_hu6940047956663229860.webp 400w,
               /minerias/6_modelos_lin/figures/data_2d_to_3d_hu8538703031235704932.webp 760w,
               /minerias/6_modelos_lin/figures/data_2d_to_3d_hu13469008302112689616.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/data_2d_to_3d_hu6940047956663229860.webp&#34;
               width=&#34;760&#34;
               height=&#34;355&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;regresi√≥n-lineal&#34;&gt;Regresi√≥n Lineal&lt;/h2&gt;
&lt;p&gt;La &lt;strong&gt;Regresi√≥n Lineal&lt;/strong&gt; es un modelo lineal para predecir una variable continua $y$
. En su forma m√°s simple en 1D:&lt;/p&gt;
$$
\hat{y} \;=\; w\,x \;+\; b.
$$&lt;p&gt;O en multidimensional:&lt;/p&gt;
$$
\hat{y} \;=\; \mathbf{W}^T\,\mathbf{x} \;+\; b.
$$&lt;p&gt;















&lt;figure  id=&#34;figure-en-lugar-de-clasificar-en-un-lado-u-otro-medimos-distancias-a-la-l√≠nea&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Regresi√≥n lineal vs. clasificaci√≥n lineal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/reg_lin_hu2428590659555122744.webp 400w,
               /minerias/6_modelos_lin/figures/reg_lin_hu1609359113409240423.webp 760w,
               /minerias/6_modelos_lin/figures/reg_lin_hu16163012276799070061.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/reg_lin_hu2428590659555122744.webp&#34;
               width=&#34;386&#34;
               height=&#34;266&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      En lugar de clasificar en un lado u otro, medimos distancias a la l√≠nea
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;m√©tricas-en-regresi√≥n&#34;&gt;M√©tricas en regresi√≥n&lt;/h3&gt;
&lt;p&gt;Para estimar la calidad de la predicci√≥n:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Error Medio Absoluto: $\frac{1}{n}\sum \bigl|Y_i - f(\mathbf{X}_i)\bigr|$
&lt;/li&gt;
&lt;li&gt;Error Cuadr√°tico Medio: $\frac{1}{n}\sum \bigl(Y_i - f(\mathbf{X}_i)\bigr)^2$
&lt;/li&gt;
&lt;li&gt;Coeficiente de determinaci√≥n $R^2$
, que mide cu√°nta varianza de $Y$
 explica el modelo.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de error cuadr√°tico para la regresi√≥n lineal&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/reg_lineaire_loss_hu13269445812579728799.webp 400w,
               /minerias/6_modelos_lin/figures/reg_lineaire_loss_hu2278288848151013165.webp 760w,
               /minerias/6_modelos_lin/figures/reg_lineaire_loss_hu18217655019017418819.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/reg_lineaire_loss_hu13269445812579728799.webp&#34;
               width=&#34;640&#34;
               height=&#34;480&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Explica la interpretaci√≥n de $R^2$
 como fracci√≥n de varianza explicada.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;regresi√≥n-de-un-plano-en-3d&#34;&gt;Regresi√≥n de un plano en 3D&lt;/h3&gt;
&lt;p&gt;Para dos atributos $x_1, x_2$
 y una salida $y$
:&lt;/p&gt;
$$
\hat{y} \;=\; w_1\,x_1 \;+\; w_2\,x_2 \;+\; b.
$$&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Un plano que ajusta los datos en 3D&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/reg_plane_hu11375769634492767005.webp 400w,
               /minerias/6_modelos_lin/figures/reg_plane_hu13355732907300323387.webp 760w,
               /minerias/6_modelos_lin/figures/reg_plane_hu17520921710119118135.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/reg_plane_hu11375769634492767005.webp&#34;
               width=&#34;697&#34;
               height=&#34;399&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;regresi√≥n-log√≠stica&#34;&gt;Regresi√≥n Log√≠stica&lt;/h2&gt;
&lt;p&gt;La &lt;strong&gt;regresi√≥n log√≠stica&lt;/strong&gt; (en su forma binaria) se utiliza para convertir una &lt;strong&gt;salida lineal&lt;/strong&gt; (o ‚Äúdistancia‚Äù en el espacio de caracter√≠sticas) en una &lt;strong&gt;probabilidad&lt;/strong&gt; entre 0 y 1. Adem√°s, en el caso &lt;strong&gt;multiclase&lt;/strong&gt;, se generaliza a la llamada &lt;strong&gt;funci√≥n softmax&lt;/strong&gt;, la cual asigna una probabilidad a cada clase, de modo que la suma de todas las probabilidades es igual a 1.&lt;/p&gt;
&lt;h3 id=&#34;caso-binario&#34;&gt;Caso Binario&lt;/h3&gt;
&lt;p&gt;ara problemas de clasificaci√≥n binaria, la &lt;strong&gt;regresi√≥n log√≠stica&lt;/strong&gt; aplica la funci√≥n sigmoide o &lt;em&gt;softmax&lt;/em&gt; sobre la salida lineal. La idea principal es definir una &lt;strong&gt;funci√≥n sigmoide&lt;/strong&gt; que proyecte cualquier valor real (la salida lineal $\mathbf{W}^T \mathbf{x} + b$
) a un rango de $]0, 1[$
:&lt;/p&gt;
$$
\sigma(z) \;=\;
\frac{1}{1 + e^{-z}}
$$&lt;ul&gt;
&lt;li&gt;Cuando $z \rightarrow +\infty$
, la sigmoide se acerca a 1.&lt;/li&gt;
&lt;li&gt;Cuando $z \rightarrow -\infty$
, la sigmoide se acerca a 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Funci√≥n sigmoide&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/sigmo_hu14640827423314996410.webp 400w,
               /minerias/6_modelos_lin/figures/sigmo_hu14976402490176052729.webp 760w,
               /minerias/6_modelos_lin/figures/sigmo_hu4385362737546358557.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/sigmo_hu14640827423314996410.webp&#34;
               width=&#34;760&#34;
               height=&#34;497&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En &lt;strong&gt;regresi√≥n log√≠stica binaria&lt;/strong&gt; (dos clases), llamemos ‚Äú1‚Äù a la clase positiva y ‚Äú0‚Äù (o ‚Äú-1‚Äù) a la negativa. Entonces la probabilidad de que un ejemplo $\mathbf{x}$
 sea de la clase positiva es:&lt;/p&gt;
$$
P(Y = 1 \;|\; \mathbf{x})
\;=\;
\sigma\bigl(\mathbf{W}^T\mathbf{x} + b\bigr)
\;=\;
\frac{1}{1 + e^{-(\mathbf{W}^T\mathbf{x} + b)}}.
$$&lt;p&gt;Por ende, $P(Y=0 \;|\; \mathbf{x}) = 1 - P(Y=1 \;|\; \mathbf{x})$
. Esto nos da una probabilidad. Para la clase final, elegimos la etiqueta seg√∫n $P(Y=1) &gt; 0.5$
 (u otro umbral). En el caso binario equivale a comparar si la salida lineal es mayor o menor que 0:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Si $\mathbf{W}^T\mathbf{x} + b &gt; 0$
, predice ‚Äú1‚Äù.&lt;/li&gt;
&lt;li&gt;Si $\mathbf{W}^T\mathbf{x} + b &lt; 0$
, predice ‚Äú0‚Äù (o ‚Äú-1‚Äù).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;conexi√≥n-distancia-probabilidad&#34;&gt;Conexi√≥n distancia-probabilidad&lt;/h4&gt;
&lt;p&gt;En modelos lineales cl√°sicos (p.e., SVM), la salida $\mathbf{W}^T\mathbf{x} + b$
 indica una &lt;strong&gt;distancia&lt;/strong&gt; (o margen) respecto al hiperplano. Para convertir dicha cantidad en una &lt;strong&gt;probabilidad&lt;/strong&gt;, aplicamos la funci√≥n sigmoide, que comprime valores reales (infinitos en ambos extremos) a un rango de 0 a 1.&lt;/p&gt;
&lt;h3 id=&#34;caso-multiclase-softmax&#34;&gt;Caso Multiclase: Softmax&lt;/h3&gt;
&lt;p&gt;Para &lt;strong&gt;$C$
 clases&lt;/strong&gt;, generalizamos la funci√≥n log√≠stica a &lt;strong&gt;softmax&lt;/strong&gt;, asignando par√°metros $\theta^{(1)}, \dots, \theta^{(C)}$
 (un vector por clase) y obteniendo probabilidades que suman 1:&lt;/p&gt;
$$
P(Y = c)
\;=\;
\frac{\exp^{&lt;\theta^{(c)} \mid \mathbf{X}&gt;}}
{\sum_{j=1}^{C}
\exp^{&lt;\theta^{(j)} \mid \mathbf{X}&gt;}}
\quad,\quad
c=1,\dots,C.
$$&lt;p&gt;donde:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\theta^{(c)}$
 son los par√°metros asociados a la clase $c$
.&lt;/li&gt;
&lt;li&gt;La &lt;strong&gt;suma de probabilidades&lt;/strong&gt; sobre las $C$
 clases es igual a 1 (gracias al denominador).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La clase final se predice con la regla:&lt;/p&gt;
$$
\hat{c}(\mathbf{X})
\;=\;
\arg\max_{1 \le c \le C} 
\,P(Y=c).
$$&lt;p&gt;Es habitual agrupar todos los vectores $\theta^{(c)}$
 en una misma matriz:&lt;/p&gt;
$$
\theta \;=\;
\begin{pmatrix}
\vertbar &amp; \vertbar &amp; \cdots &amp; \vertbar \\
\theta^{(1)} &amp; \theta^{(2)} &amp; \dots &amp; \theta^{(C)} \\
\vertbar &amp; \vertbar &amp; \cdots &amp; \vertbar
\end{pmatrix}.
$$&lt;p&gt;&lt;em&gt;(Cada columna es un vector de par√°metros para la clase correspondiente.)&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;uso-de-scikit-learn&#34;&gt;Uso de Scikit-learn&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;scikit-learn&lt;/strong&gt; (&lt;code&gt;sklearn&lt;/code&gt;) es una biblioteca de Python que nos permite entrenar y probar modelos de Machine Learning con funciones normalizadas.&lt;/p&gt;
&lt;h3 id=&#34;funciones-generales&#34;&gt;Funciones generales&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-se-separan-datos-se-entrena-y-se-valida&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Flujo t√≠pico de aprendizaje supervisado con sklearn&#34; srcset=&#34;
               /minerias/6_modelos_lin/figures/supervised_scikit_learn_hu17372726708710164390.webp 400w,
               /minerias/6_modelos_lin/figures/supervised_scikit_learn_hu13489451897173136613.webp 760w,
               /minerias/6_modelos_lin/figures/supervised_scikit_learn_hu5671300666085423450.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/6_modelos_lin/figures/supervised_scikit_learn_hu17372726708710164390.webp&#34;
               width=&#34;659&#34;
               height=&#34;484&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Se separan datos, se entrena y se valida
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En &lt;code&gt;sklearn&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;load_iris&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SGDClassifier&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;load_iris&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;n&#34;&gt;test_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SGDClassifier&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tol&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1e-3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;(Para el orador: Subraya la facilidad de implementaci√≥n y las funciones de utilidad para preprocesar, hacer feature extraction, validaci√≥n cruzada, etc.)&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;conjuntos-de-datos-extracci√≥n-de-caracter√≠sticas-y-preprocesamiento&#34;&gt;Conjuntos de datos, extracci√≥n de caracter√≠sticas y preprocesamiento&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;M√∫ltiples datasets de juguete: Iris, Digits, Wine, etc.&lt;/li&gt;
&lt;li&gt;Conjuntos m√°s grandes: RCV1 (texto), Faces (im√°genes), etc.&lt;/li&gt;
&lt;li&gt;M√≥dulos como &lt;code&gt;feature_extraction&lt;/code&gt;, &lt;code&gt;feature_selection&lt;/code&gt;, &lt;code&gt;preprocessing&lt;/code&gt; para:&lt;/li&gt;
&lt;li&gt;Vectorizar texto
&lt;ul&gt;
&lt;li&gt;Seleccionar atributos relevantes&lt;/li&gt;
&lt;li&gt;Normalizar los datos&lt;/li&gt;
&lt;li&gt;Rellenar valores faltantes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: Invita a explorar la documentaci√≥n sklearn.org y mostrar un ejemplo interactivo si hay tiempo.)&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;validaci√≥n-cruzada-y-b√∫squeda-de-hiperpar√°metros&#34;&gt;Validaci√≥n cruzada y b√∫squeda de hiperpar√°metros&lt;/h3&gt;
&lt;p&gt;Incluye herramientas como:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;KFold&lt;/code&gt;, &lt;code&gt;StratifiedKFold&lt;/code&gt; para dividir los datos&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cross_val_score&lt;/code&gt; para evaluar un modelo en K particiones&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GridSearchCV&lt;/code&gt; o &lt;code&gt;RandomizedSearchCV&lt;/code&gt; para probar m√∫ltiples par√°metros y hacer validaci√≥n cruzada&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GridSearchCV&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;parameters&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;kernel&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;rbf&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;C&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;svc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;svm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SVC&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gamma&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scale&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;svc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;(Para el orador: Resaltar la importancia de la validaci√≥n cruzada para evitar sobreajustes y encontrar buenos hiperpar√°metros.)&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;conclusi√≥n&#34;&gt;Conclusi√≥n&lt;/h3&gt;
&lt;p&gt;En esta clase hemos visto:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C√≥mo un clasificador lineal separa el espacio con un hiperplano.&lt;/li&gt;
&lt;li&gt;La regresi√≥n lineal como caso de modelo lineal para predicci√≥n de variables continuas.&lt;/li&gt;
&lt;li&gt;C√≥mo extender la linealidad introduciendo variables polin√≥micas o el truco del Bias.&lt;/li&gt;
&lt;li&gt;Un breve vistazo a la regresi√≥n log√≠stica, esencial para clasificaci√≥n binaria y multi-clase con softmax.&lt;/li&gt;
&lt;li&gt;scikit-learn y sus funcionalidades para datasets, entrenamiento, validaci√≥n y selecci√≥n de hiperpar√°metros.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;(Para el orador: concluye enfatizando que, aunque hay modelos m√°s complejos como redes neuronales o ensembles, entender los modelos lineales es clave para la pr√°ctica de Machine Learning y la interpretaci√≥n de resultados.)&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Mineria de Datos</title>
      <link>http://localhost:1313/teaching/minerias/</link>
      <pubDate>Sun, 24 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teaching/minerias/</guid>
      <description>&lt;h3 id=&#34;all-the-different-classes-can-be-found-hereminerias&#34;&gt;All the different classes can be found &lt;a href=&#34;../../minerias&#34;&gt;here&lt;/a&gt;!&lt;/h3&gt;
&lt;p&gt;This is the CC5205 course from the Universidad de Chile. I restructured it so that it is more adapted to nowadays techniques and more machine learning oriented, it is heavily based on &lt;a href=&#34;https://scikit-learn.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scikit&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a summary:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;General introduction&lt;/strong&gt;: Definitions of Data Mining, Data Science, and content of the class&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data I&lt;/strong&gt;: (Un)structured data, Representation, Normalization, Noise removal, &amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Data II&lt;/strong&gt;: Basic statistics for data exploration.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Intro to Supervised Learning&lt;/strong&gt;: Basics of Machine Learning and supervised learning.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Intro to Fairness and Biases&lt;/strong&gt;: How to avoid making bad models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linear Models&lt;/strong&gt;: A very simple model, which is the base of deep neural networks!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Classifiers&lt;/strong&gt;: KNN, Naive Bayes, Decision Tree, Boosting, Bagging, Random Forests.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Dimensionality Reduction&lt;/strong&gt;: Principal Component Analysis, Independant Component Analysis, t-SNE, UMAP,&amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Clustering methods&lt;/strong&gt;: Clustering methods and associated metrics&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SVM, SVR&lt;/strong&gt;: Hinge loss, Lagrangian, KKT conditions, non-linear SVM, Kernel trick, SV Regressor&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Introduction to Neural Nets&lt;/strong&gt;: Basics of Deep Learning&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Introduction to NLP&lt;/strong&gt; (Invited Speaker: Juan Jose Alegria): How to deal with natural language.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Regularization</title>
      <link>http://localhost:1313/deep/6_regularization/</link>
      <pubDate>Sun, 24 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/6_regularization/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides6_regularizationpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/6_Regularization.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Clasificadores</title>
      <link>http://localhost:1313/minerias/7_clasificadores/</link>
      <pubDate>Sat, 23 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/7_clasificadores/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_modelos_slpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Modelos_SL.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>SVM</title>
      <link>http://localhost:1313/minerias/8_svm/</link>
      <pubDate>Fri, 22 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/8_svm/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_svmpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_SVM.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;h2 id=&#34;m√°quinas-de-vectores-de-soporte-svm&#34;&gt;M√°quinas de Vectores de Soporte (SVM)&lt;/h2&gt;
&lt;p&gt;Las &lt;strong&gt;M√°quinas de Vectores de Soporte&lt;/strong&gt; son modelos de clasificaci√≥n (o regresi√≥n) que buscan encontrar un &lt;strong&gt;hiperplano&lt;/strong&gt; o frontera de decisi√≥n que &lt;strong&gt;maximice el margen&lt;/strong&gt; entre las clases. A continuaci√≥n, veremos sus conceptos clave, la formulaci√≥n lineal, el uso de kernels y, finalmente, la extensi√≥n a la regresi√≥n (SVR).&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;separadores-de-gran-margen&#34;&gt;Separadores de Gran Margen&lt;/h3&gt;
&lt;p&gt;El objetivo de las SVM es encontrar un &lt;strong&gt;separador&lt;/strong&gt; (en dimensi√≥n \(d\), un hiperplano) que no solo divida correctamente las clases, sino que lo haga maximizando la distancia m√≠nima con cualquier punto de entrenamiento.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-svm-que-logra-una-separaci√≥n-no-lineal&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de frontera no lineal buscada por SVM&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_nonlin_hu10766200129307954814.webp 400w,
               /minerias/8_svm/figures/SVM_nonlin_hu940999748329515222.webp 760w,
               /minerias/8_svm/figures/SVM_nonlin_hu10800116435089468750.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_nonlin_hu10766200129307954814.webp&#34;
               width=&#34;760&#34;
               height=&#34;307&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      SVM que logra una separaci√≥n no lineal
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En casos lineales y perfectamente separables, puede haber varios hiperplanos que distingan las clases. La pregunta es: &lt;strong&gt;¬øCu√°l elegir?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-dos-posibles-hiperplanos-separadores&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Distintos hiperplanos posibles&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_which_hyperplan2_hu6991979370543567446.webp 400w,
               /minerias/8_svm/figures/svm_which_hyperplan2_hu671267611003501627.webp 760w,
               /minerias/8_svm/figures/svm_which_hyperplan2_hu14002891887294419535.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_which_hyperplan2_hu6991979370543567446.webp&#34;
               width=&#34;478&#34;
               height=&#34;410&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Dos posibles hiperplanos separadores
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;La SVM opta por el que maximiza el margen, buscando as√≠ una mejor &lt;strong&gt;capacidad de generalizaci√≥n&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;clasificador-lineal-recordatorio&#34;&gt;Clasificador lineal: recordatorio&lt;/h3&gt;
&lt;p&gt;Un clasificador lineal en \(\mathbb{R}^d\) se define por:&lt;/p&gt;
\[
f(\mathbf{X}) = \mathrm{signo}(\mathbf{W}^\top \mathbf{X} + b).
\]&lt;p&gt;En la siguiente figura se ilustra una separaci√≥n lineal (en 3D) que se proyecta a una separaci√≥n curva al volver al espacio 2D:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-vista-en-3d-de-datos-originalmente-no-separables-linealmente&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Espacio 3D para separar datos no lineales&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_non_lin_3D_hu2697375277477187509.webp 400w,
               /minerias/8_svm/figures/SVM_non_lin_3D_hu14481105654133733525.webp 760w,
               /minerias/8_svm/figures/SVM_non_lin_3D_hu17332218457834828460.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_non_lin_3D_hu2697375277477187509.webp&#34;
               width=&#34;760&#34;
               height=&#34;703&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Vista en 3D de datos originalmente no separables linealmente
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;svm-lineal-m√°rgenes-y-restricci√≥n-de-separabilidad&#34;&gt;SVM lineal: m√°rgenes y restricci√≥n de separabilidad&lt;/h3&gt;
&lt;p&gt;El hiperplano \(\mathbf{W}^\top \mathbf{X} + b = 0\) y los planos paralelos \(\mathbf{W}^\top \mathbf{X} + b = \pm 1\) marcan el &lt;strong&gt;margen&lt;/strong&gt;. Cuanto mayor sea la distancia entre esos planos, mayor ser√° la robustez.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-hiperplano-central-y-m√°rgenes-en-1&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;M√°rgenes alrededor del hiperplano&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_hu17965602084783293788.webp 400w,
               /minerias/8_svm/figures/SVM_hu114460994655993461.webp 760w,
               /minerias/8_svm/figures/SVM_hu14476676033574681305.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_hu17965602084783293788.webp&#34;
               width=&#34;760&#34;
               height=&#34;534&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Hiperplano central y m√°rgenes en ¬±1
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Margen geom√©trico&lt;/strong&gt;:
Consideremos los planos de decisi√≥n \(\mathbf{W}^\top \mathbf{X} + b = \pm 1\). La distancia entre esos dos planos es:&lt;/p&gt;
\[
     \frac{2}{\|\mathbf{W}\|}.
   \]&lt;p&gt;Por ello, &lt;strong&gt;maximizar&lt;/strong&gt; esa distancia es &lt;strong&gt;equivalente&lt;/strong&gt; a &lt;strong&gt;minimizar&lt;/strong&gt; \(\|\mathbf{W}\|\).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Forma habitual en SVM&lt;/strong&gt;:&lt;br&gt;
Para comodidad num√©rica, se minimiza \(\tfrac{1}{2}\|\mathbf{W}\|^2\) en lugar de \(\|\mathbf{W}\|\), pero el criterio es el mismo.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Para datos &lt;strong&gt;(casi) separables&lt;/strong&gt;, la SVM busca:&lt;/p&gt;
\[
\begin{aligned}
&amp; \min_{\mathbf{W}, b} \quad \frac{1}{2}\|\mathbf{W}\|^2 \\
&amp; \text{sujeto a } \quad 
Y_i \, (\mathbf{W}^\top \mathbf{X}_i + b)\; \ge 1,\quad \forall i.
\end{aligned}
\]&lt;p&gt;En suma, la restricci√≥n \(Y_i(\mathbf{W}^\top \mathbf{X}_i + b)\ge 1\) asegura que cada punto est√© al menos a distancia \(1/\|\mathbf{W}\|\) del hiperplano, y al reducir \(\|\mathbf{W}\|\) aumentamos este margen.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;formulaci√≥n-primal-y-dual&#34;&gt;Formulaci√≥n primal y dual&lt;/h3&gt;
&lt;p&gt;Los problemas primal y dual son equivalentes en entornos convexos.&lt;/p&gt;
&lt;p&gt;El problema Primal:&lt;/p&gt;
\[
\begin{aligned}
&amp;\min \quad z = c^t x, \\
&amp;\text{subject to} \quad A x \ge b, \\
&amp;\qquad\quad\;\; x \ge 0.
\end{aligned}
\]&lt;p&gt;El problema Dual:&lt;/p&gt;
\[
\begin{aligned}
&amp;\max \quad z = b^t y, \\
&amp;\text{subject to} \quad A^t y \le c, \\
&amp;\qquad\quad\;\; y \ge 0,
\end{aligned}
\]&lt;p&gt;En la pr√°ctica se implementan algoritmos para el &lt;strong&gt;problema dual&lt;/strong&gt;, sobre todo cuando se utilizan kernels.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-un-problema-primal&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Interpretaci√≥n visual primal-dual (izq/primal, der/dual)&#34; srcset=&#34;
               /minerias/8_svm/figures/primal_hu5214921791707174292.webp 400w,
               /minerias/8_svm/figures/primal_hu6218951539569108450.webp 760w,
               /minerias/8_svm/figures/primal_hu6179495431827664383.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/primal_hu5214921791707174292.webp&#34;
               width=&#34;581&#34;
               height=&#34;480&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un problema Primal
    &lt;/figcaption&gt;&lt;/figure&gt;
 















&lt;figure  id=&#34;figure-un-problema-dual&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Interpretaci√≥n visual primal-dual (izq/primal, der/dual)&#34; srcset=&#34;
               /minerias/8_svm/figures/dual_hu9024437098989026950.webp 400w,
               /minerias/8_svm/figures/dual_hu11370458516146254517.webp 760w,
               /minerias/8_svm/figures/dual_hu15067324994502624637.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/dual_hu9024437098989026950.webp&#34;
               width=&#34;581&#34;
               height=&#34;480&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Un problema Dual
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Para resolverlo, se introduce el &lt;strong&gt;Lagrangiano&lt;/strong&gt; y se pasa a la &lt;strong&gt;formulaci√≥n dual&lt;/strong&gt;. De este modo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Primal&lt;/strong&gt;: par√°metros \(\mathbf{W}, b\).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dual&lt;/strong&gt;: multiplicadores \(\alpha_i\).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;introducci√≥n-del-lagrangiano-y-condiciones-kkt&#34;&gt;Introducci√≥n del Lagrangiano y condiciones KKT&lt;/h3&gt;
\[
\min_{\mathbf{W},b} \quad \frac{1}{2}\|\mathbf{W}\|^2 
\quad\text{sujeto a}\quad Y_i(\mathbf{W}^\top\mathbf{X}_i + b)\;\ge\;1,
\]&lt;p&gt;
se introduce el &lt;strong&gt;Lagrangiano&lt;/strong&gt;:&lt;/p&gt;
\[
\mathcal{L}(\mathbf{W}, b, \boldsymbol{\alpha}) 
\;=\; \tfrac{1}{2}\|\mathbf{W}\|^2 
\;-\; \sum_{i=1}^n \alpha_i \,\bigl(Y_i(\mathbf{W}^\top \mathbf{X}_i + b) - 1\bigr),
\]&lt;p&gt;
donde \(\alpha_i \ge 0\) son los &lt;strong&gt;multiplicadores de Lagrange&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Las &lt;strong&gt;Condiciones de Karush-Kuhn-Tucker (KKT)&lt;/strong&gt; aplicadas a este problema especifican, entre otras, que:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\(\nabla_{\mathbf{W}} \,\mathcal{L} = 0\) y \(\nabla_b \,\mathcal{L} = 0\) (estacionaridad).&lt;/li&gt;
&lt;li&gt;\(\alpha_i \ge 0\).&lt;/li&gt;
&lt;li&gt;\(\alpha_i \,\bigl[Y_i(\mathbf{W}^\top \mathbf{X}_i + b)-1\bigr] = 0\) (complementariedad):&lt;br&gt;
esto implica que para cada \(i\), o bien la restricci√≥n se cumple con margen (estricto) o \(\alpha_i=0\).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;resolviendo-el-problema-dual-y-aparici√≥n-de-alpha_i&#34;&gt;Resolviendo el problema Dual y aparici√≥n de \(\alpha_i\)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Construcci√≥n del Dual&lt;/strong&gt;:&lt;br&gt;
Se reemplaza \(\|\mathbf{W}\|^2\) y se resuelve en funci√≥n de \(\boldsymbol{\alpha}\). El &lt;strong&gt;problema dual&lt;/strong&gt; pasa a ser:
\[
   \begin{aligned}
   &amp;\max_{\boldsymbol{\alpha}} \quad 
     \sum_{i=1}^n \alpha_i \;-\; \tfrac{1}{2}\sum_{i,j} \alpha_i \alpha_j \,Y_i Y_j \,\langle \mathbf{X}_i,\mathbf{X}_j\rangle,\\
   &amp;\text{sujeto a}\quad \alpha_i \ge 0,\;\; \sum_{i=1}^n \alpha_i Y_i = 0.
   \end{aligned}
   \]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Soluci√≥n para \(\mathbf{W}\)&lt;/strong&gt;:&lt;br&gt;
De las KKT, se deduce que
\[
     \mathbf{W} \;=\; \sum_{i=1}^n \alpha_i \,Y_i \,\mathbf{X}_i.
   \]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clasificador&lt;/strong&gt;:&lt;br&gt;
\[
     f(\mathbf{X}) \;=\; \mathrm{signo}\!\Bigl(\sum_{i=1}^n \alpha_i\,Y_i\,\langle\mathbf{X}_i,\mathbf{X}\rangle + b \Bigr).
   \]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Notar que en este punto a√∫n &lt;strong&gt;no&lt;/strong&gt; hemos introducido el concepto de &lt;strong&gt;soft margin&lt;/strong&gt;. Cuando todos los datos son separables y no hay ruido, cada punto cumple la restricci√≥n sin violarla. Una vez introducidos errores o ruido, pasaremos a la versi√≥n &lt;em&gt;soft margin&lt;/em&gt;.
mal-dual (izq/primal, der/dual)](figures/dual.png &amp;ldquo;Un problema Dual&amp;rdquo;)&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;vectores-de-soporte&#34;&gt;Vectores de Soporte&lt;/h3&gt;
\[
\mathbf{W} = \sum_{i=1}^{n} \alpha_i \, Y_i \, \mathbf{X}_i
\]\[
f(\mathbf{X}) = \mathrm{signo}\!\Big(\sum_{i=1}^{n} \alpha_i \,Y_i\;\langle \mathbf{X}_i,\mathbf{X}\rangle + b\Big).
\]&lt;p&gt;Solo los puntos con \(\alpha_i \neq 0\) se llaman &lt;strong&gt;vectores de soporte&lt;/strong&gt;, aquellos que ‚Äúsoportan‚Äù el margen.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-vectores-de-soporte-definen-el-hiperplano-final&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Puntos soportando el margen&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_support_hu9573517152434623081.webp 400w,
               /minerias/8_svm/figures/svm_support_hu3030785379930506308.webp 760w,
               /minerias/8_svm/figures/svm_support_hu13275145611349553827.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_support_hu9573517152434623081.webp&#34;
               width=&#34;760&#34;
               height=&#34;667&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los vectores de soporte definen el hiperplano final
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;soft-margin-y-ruido&#34;&gt;Soft margin y ruido&lt;/h3&gt;
&lt;p&gt;Cuando hay ruido, el plan optimal no es necesariamente el mejor:
















&lt;figure  id=&#34;figure-ejemplo-de-hiperplanos-con-ruido-y-errores&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo con ruido; margen distinto seg√∫n C&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_bruit_hu15490994747521239547.webp 400w,
               /minerias/8_svm/figures/SVM_bruit_hu9950590124400274101.webp 760w,
               /minerias/8_svm/figures/SVM_bruit_hu4310381433717407342.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_bruit_hu15490994747521239547.webp&#34;
               width=&#34;760&#34;
               height=&#34;641&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo de hiperplanos con ruido y errores
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Cuando los datos no son perfectamente separables (o hay ruido), se permiten &lt;strong&gt;variables de holgura&lt;/strong&gt; \(\xi_i \ge 0\). Esto penaliza los errores o los puntos dentro del margen:&lt;/p&gt;
\[
\begin{aligned}
&amp; \min_{\mathbf{W},b} \quad \frac{1}{2}\|\mathbf{W}\|^2 + C \sum_{i}\xi_i \\
&amp; \text{sujeto a} \quad Y_i(\mathbf{W}^\top \mathbf{X}_i + b) \ge 1 - \xi_i,\quad \xi_i \ge 0.
\end{aligned}
\]&lt;p&gt;















&lt;figure  id=&#34;figure-las-variables-de-holgura-permiten-el-ruido-en-los-datos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Epsilon&#34; srcset=&#34;
               /minerias/8_svm/figures/SVM_non_lin_hu8821990965519421223.webp 400w,
               /minerias/8_svm/figures/SVM_non_lin_hu13426229250700642069.webp 760w,
               /minerias/8_svm/figures/SVM_non_lin_hu5029092690650428657.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/SVM_non_lin_hu8821990965519421223.webp&#34;
               width=&#34;356&#34;
               height=&#34;335&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Las variables de holgura permiten el ruido en los datos.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;El par√°metro \(C\) balancea la &lt;strong&gt;complejidad&lt;/strong&gt; vs. el &lt;strong&gt;n√∫mero de errores&lt;/strong&gt;, y es un parametro de regularizacion.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;resoluci√≥n-dual-con-kkt&#34;&gt;Resoluci√≥n Dual con KKT&lt;/h4&gt;
&lt;p&gt;Tras introducir variables de holgura \(\xi_i \ge 0\), la &lt;strong&gt;formulaci√≥n primal&lt;/strong&gt; se convierte en:&lt;/p&gt;
\[
\begin{aligned}
&amp; \min_{\mathbf{W}, b, \{\xi_i\}} \quad 
   \frac{1}{2}\|\mathbf{W}\|^2 + C\sum_{i=1}^n \xi_i, \\
&amp; \text{sujeto a} \quad
   Y_i(\mathbf{W}^\top\mathbf{X}_i + b)\;\ge\;1 - \xi_i,\quad \xi_i \ge 0.
\end{aligned}
\]&lt;p&gt;En el &lt;strong&gt;Lagrangiano&lt;/strong&gt;, aparecen ahora multiplicadores \(\alpha_i\) y \(\mu_i\) para manejar las restricciones asociadas a \(\xi_i\). Se obtienen condiciones KKT adicionales, incluyendo&lt;/p&gt;
\[
\alpha_i \,\bigl[Y_i(\mathbf{W}^\top\mathbf{X}_i + b)-1+\xi_i\bigr] \;=\; 0,\quad
\mu_i\,\xi_i \;=\; 0,\quad 
0 \;\le\;\alpha_i \;\le\; C.
\]&lt;p&gt;El problema &lt;strong&gt;dual&lt;/strong&gt; final para la SVM con soft margin vuelve a ser:&lt;/p&gt;
\[
\begin{aligned}
&amp; \max_{\boldsymbol{\alpha}} \quad 
   \sum_{i=1}^n \alpha_i \;-\; \tfrac{1}{2}\sum_{i,j} \alpha_i \alpha_j \,Y_i Y_j \,\langle \mathbf{X}_i,\mathbf{X}_j\rangle,\\
&amp; \text{sujeto a} \quad 0 \;\le\;\alpha_i \;\le\; C,\quad \sum_{i=1}^n \alpha_i Y_i = 0.
\end{aligned}
\]&lt;p&gt;Aqu√≠, los puntos para los que \(\alpha_i\) est√° en el rango \((0, C)\) se convierten en los &lt;strong&gt;vectores de soporte&lt;/strong&gt;, y la resoluci√≥n sigue an√°loga al caso separable.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;equivalente-de-regularizaci√≥n-hinge-loss&#34;&gt;Equivalente de regularizaci√≥n (Hinge loss)&lt;/h4&gt;
&lt;p&gt;Otra forma de ver la &lt;strong&gt;SVM lineal&lt;/strong&gt; es como un caso especial de &lt;strong&gt;p√©rdida bisagra (hinge loss)&lt;/strong&gt; con regularizaci√≥n en la norma de \(\mathbf{W}\).&lt;br&gt;
En el &lt;strong&gt;espacio primal&lt;/strong&gt;, la minimizaci√≥n se puede escribir como:&lt;/p&gt;
\[
\underset{\mathbf{W}, b}{\min} \;\; \sum_{i=1}^{n} \max\bigl(0,\,1 - Y_i\bigl(\mathbf{W}^\top \mathbf{X}_i + b\bigr)\bigr) \;+\; \lambda \,\|\mathbf{W}\|^2,
\]&lt;p&gt;donde \(\lambda\) es un par√°metro de regularizaci√≥n relacionado inversamente con \(C\).&lt;/p&gt;
&lt;p&gt;La p√©rdida (bisagra) \(\max(0,\,1 - Y_i(\mathbf{W}^\top \mathbf{X}_i + b))\) fuerza cada ejemplo a estar, idealmente, al menos a 1 de distancia del hiperplano, y penaliza las violaciones a ese margen. As√≠, minimizar la norma de \(\mathbf{W}\) y el costo bisagra conduce al mismo criterio de ‚Äúgran margen‚Äù que describimos antes.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;kernel-trick-y-espacio-aumentado&#34;&gt;Kernel Trick y espacio aumentado&lt;/h3&gt;
&lt;p&gt;La separaci√≥n lineal puede no ser posible en el espacio original, pero s√≠ en una &lt;strong&gt;dimensi√≥n mayor&lt;/strong&gt;. Aun as√≠, no es necesario calcular expl√≠citamente dicha transformaci√≥n \(\varphi(\mathbf{X})\). El &lt;strong&gt;truco del kernel&lt;/strong&gt; nos dice que:&lt;/p&gt;
\[
k(\mathbf{X},\mathbf{X}&#39;) = \langle \varphi(\mathbf{X}), \,\varphi(\mathbf{X}&#39;) \rangle.
\]&lt;h4 id=&#34;aumento-del-espacio-idea&#34;&gt;Aumento del espacio (idea)&lt;/h4&gt;
&lt;p&gt;En el nuevo espacio, la separaci√≥n lineal puede existir aunque en el original no:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-aumento-de-dimensi√≥n-para-separar-datos-no-lineales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Otra vista del aumento de dimensi√≥n&#34; srcset=&#34;
               /minerias/8_svm/figures/data_2d_to_3d_2_hu15601119294237896571.webp 400w,
               /minerias/8_svm/figures/data_2d_to_3d_2_hu12492001661735803246.webp 760w,
               /minerias/8_svm/figures/data_2d_to_3d_2_hu7038276523966741848.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/data_2d_to_3d_2_hu15601119294237896571.webp&#34;
               width=&#34;760&#34;
               height=&#34;369&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Aumento de dimensi√≥n para separar datos no lineales
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Cuidado con la alta dimensionalidad si \(d\) es muy grande.)&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;ejemplo-de-kernel-trick&#34;&gt;Ejemplo de Kernel Trick&lt;/h4&gt;
&lt;p&gt;Supongamos que queremos clasificar datos en \(\mathbb{R}^2\) usando un &lt;strong&gt;n√∫cleo polinomial de grado 2&lt;/strong&gt;. Podemos definir una transformaci√≥n expl√≠cita:&lt;/p&gt;
\[
\varphi: (x_1,x_2) \;\mapsto\; (\,x_1^2,\;\sqrt{2}\,x_1x_2,\;x_2^2,\;\sqrt{2}\,x_1,\;\sqrt{2}\,x_2,\;1\,).
\]&lt;p&gt;Al calcular el producto punto en este espacio, se observa que:&lt;/p&gt;
\[
\langle \varphi(\mathbf{X}),\varphi(\mathbf{X}&#39;)\rangle 
\;=\; \bigl(\langle \mathbf{X},\mathbf{X}&#39;\rangle + 1\bigr)^2
\]&lt;p&gt;De modo que el &lt;strong&gt;kernel&lt;/strong&gt; asociado es:&lt;/p&gt;
\[
k(\mathbf{X},\mathbf{X}&#39;) 
\;=\; \bigl( \mathbf{X}\cdot\mathbf{X}&#39; + 1 \bigr)^2.
\]&lt;p&gt;Esto permite a la SVM trabajar impl√≠citamente con una dimensi√≥n m√°s alta sin calcular \(\varphi(\mathbf{X})\) ni \(\varphi(\mathbf{X}&#39;)\) de forma expl√≠cita.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-truco-del-kernel-permite-separar-datos-no-lineales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Otra vista del aumento de dimensi√≥n&#34; srcset=&#34;
               /minerias/8_svm/figures/kernel_SVM_hu6299395877450182764.webp 400w,
               /minerias/8_svm/figures/kernel_SVM_hu11090577963053166792.webp 760w,
               /minerias/8_svm/figures/kernel_SVM_hu7485170395093064274.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/kernel_SVM_hu6299395877450182764.webp&#34;
               width=&#34;760&#34;
               height=&#34;472&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El truco del kernel permite separar datos no lineales.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;tipos-de-kernel-comunes&#34;&gt;Tipos de kernel comunes&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
\[
  k(\mathbf{X},\mathbf{X}&#39;) \;=\; \langle \mathbf{X},\;\mathbf{X}&#39; \rangle
  \]&lt;/li&gt;
&lt;li&gt;
\[
  k(\mathbf{X},\mathbf{X}&#39;) \;=\; \bigl(\langle \mathbf{X}, \mathbf{X}&#39; \rangle + c\bigr)^{d}
  \]&lt;/li&gt;
&lt;li&gt;
\[
  k(\mathbf{X},\mathbf{X}&#39;) \;=\; \exp\!\bigl(-\gamma\,\|\mathbf{X}-\mathbf{X}&#39;\|^2\bigr)
  \]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Lineal&lt;/strong&gt;&lt;br&gt;
















&lt;figure  id=&#34;figure-separaci√≥n-lineal-con-kernel-lineal&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kernel lineal&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_kernel_lin_hu15985672093414640765.webp 400w,
               /minerias/8_svm/figures/svm_kernel_lin_hu5215183063117229496.webp 760w,
               /minerias/8_svm/figures/svm_kernel_lin_hu13743402759049042516.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_kernel_lin_hu15985672093414640765.webp&#34;
               width=&#34;760&#34;
               height=&#34;576&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Separaci√≥n lineal con kernel lineal
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Polinomial&lt;/strong&gt;&lt;br&gt;
















&lt;figure  id=&#34;figure-separaci√≥n-con-kernel-polinomial&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kernel polinomial&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_kernel_poly_hu2205477111260707794.webp 400w,
               /minerias/8_svm/figures/svm_kernel_poly_hu14329925200945324446.webp 760w,
               /minerias/8_svm/figures/svm_kernel_poly_hu12127295301654093412.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_kernel_poly_hu2205477111260707794.webp&#34;
               width=&#34;760&#34;
               height=&#34;576&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Separaci√≥n con kernel polinomial
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gaussiano&lt;/strong&gt;&lt;br&gt;
















&lt;figure  id=&#34;figure-separaci√≥n-con-kernel-gaussiano&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Kernel RBF&#34; srcset=&#34;
               /minerias/8_svm/figures/svm_kernel_gauss_hu2637743137941300484.webp 400w,
               /minerias/8_svm/figures/svm_kernel_gauss_hu2121526416713396169.webp 760w,
               /minerias/8_svm/figures/svm_kernel_gauss_hu5837164105067530359.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svm_kernel_gauss_hu2637743137941300484.webp&#34;
               width=&#34;760&#34;
               height=&#34;576&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Separaci√≥n con kernel gaussiano
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;conclusi√≥n-de-svm&#34;&gt;Conclusi√≥n de SVM&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Se basa en &lt;strong&gt;maximizar el margen&lt;/strong&gt; (reduce sobreajuste).&lt;/li&gt;
&lt;li&gt;La soluci√≥n surge de un problema de &lt;strong&gt;optimizaci√≥n convexa&lt;/strong&gt; que se puede abordar en su versi√≥n dual.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Los vectores de soporte&lt;/strong&gt; son los √∫nicos puntos relevantes para la frontera de decisi√≥n.&lt;/li&gt;
&lt;li&gt;Permite &lt;strong&gt;kernels&lt;/strong&gt; para manejar no linealidades.&lt;/li&gt;
&lt;li&gt;Ajustar hiperpar√°metros (ej. \(C\), grado del polinomio, \(\gamma\) en el gaussiano) puede ser costoso.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;support-vector-regressor-svr&#34;&gt;Support Vector Regressor (SVR)&lt;/h2&gt;
&lt;p&gt;La SVM tambi√©n puede adaptarse a &lt;strong&gt;tareas de regresi√≥n&lt;/strong&gt;. En vez de separar puntos en clases, se busca que la predicci√≥n \(\hat{y}\) caiga en un &lt;strong&gt;tubo de ancho \(\epsilon\)&lt;/strong&gt; en torno al valor real \(y\). A esto se lo denomina &lt;strong&gt;p√©rdida \(\epsilon\)-insensible&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;principio&#34;&gt;Principio&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-svr-con-zona-sin-penalizaci√≥n-si-el-error--Œµ&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Tubo Œµ-insensible en SVR&#34; srcset=&#34;
               /minerias/8_svm/figures/svr_hu8880163900142633628.webp 400w,
               /minerias/8_svm/figures/svr_hu4001860459484953900.webp 760w,
               /minerias/8_svm/figures/svr_hu17612073410467756993.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svr_hu8880163900142633628.webp&#34;
               width=&#34;760&#34;
               height=&#34;306&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      SVR con zona sin penalizaci√≥n si el error &amp;lt; Œµ
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Si \(|\hat{y} - y| \leq \epsilon\), no se incurre en penalizaci√≥n. Caso contrario, se agregan variables \(\xi_i, \xi_i^*\) que miden el exceso del error respecto de \(\epsilon\).&lt;/p&gt;
&lt;h3 id=&#34;formulaci√≥n&#34;&gt;Formulaci√≥n&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
\[
  \min_{\mathbf{W},b} \;\; \tfrac{1}{2}\|\mathbf{W}\|^2 + C\sum_i (\xi_i + \xi_i^*)
  \]\[
  \begin{cases}
  y_i - f(\mathbf{X}_i) \;\le\; \epsilon + \xi_i, \\
  f(\mathbf{X}_i) - y_i \;\le\; \epsilon + \xi_i^*, \\
  \xi_i,\xi_i^*\ge0.
  \end{cases}
  \]&lt;/li&gt;
&lt;li&gt;
\[
  f(\mathbf{X}) \;=\; \sum_{i=1}^{n} (\alpha_i - \alpha_i^*)\,k(\mathbf{X}_i,\mathbf{X})\;+\;b.
  \]&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ejemplo&#34;&gt;Ejemplo&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-svr-ajustando-una-curva-y-mostrando-el-tubo-Œµ&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de ajuste con SVR&#34; srcset=&#34;
               /minerias/8_svm/figures/svr_ex_hu6641046939284454635.webp 400w,
               /minerias/8_svm/figures/svr_ex_hu10964327218363507417.webp 760w,
               /minerias/8_svm/figures/svr_ex_hu9191617817313677244.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/8_svm/figures/svr_ex_hu6641046939284454635.webp&#34;
               width=&#34;760&#34;
               height=&#34;563&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      SVR ajustando una curva y mostrando el tubo ¬±Œµ
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Solo los puntos que quedan fuera del tubo (por encima de \(\epsilon\)) se convierten en vectores de soporte.&lt;/p&gt;
&lt;h4 id=&#34;resumen-svr&#34;&gt;Resumen SVR&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Extiende la SVM a &lt;strong&gt;regresi√≥n&lt;/strong&gt;, usando la idea de &lt;em&gt;m√°ximo margen&lt;/em&gt; alrededor de la curva aprendida.&lt;/li&gt;
&lt;li&gt;El &lt;strong&gt;par√°metro \(\epsilon\)&lt;/strong&gt; controla el ancho de la zona ‚Äúsin costo‚Äù; \(\xi_i,\xi_i^*\) miden el exceso.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;\(C\)&lt;/strong&gt; regula la penalizaci√≥n por exceder \(\epsilon\).&lt;/li&gt;
&lt;li&gt;Se pueden usar &lt;strong&gt;kernels&lt;/strong&gt; para la parte no lineal, igual que en la clasificaci√≥n.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;¬°Eso es todo sobre &lt;strong&gt;SVM&lt;/strong&gt; y &lt;strong&gt;SVR&lt;/strong&gt;! Son m√©todos muy potentes y ampliamente utilizados en Machine Learning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SVM&lt;/strong&gt; para clasificaci√≥n binaria (y extensiones a multiclase).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SVR&lt;/strong&gt; para regresi√≥n con m√°rgenes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kernels&lt;/strong&gt; para no linealidad en ambos casos.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Clustering</title>
      <link>http://localhost:1313/minerias/9_clustering/</link>
      <pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/9_clustering/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_clusteringpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Clustering.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;En &lt;strong&gt;aprendizaje no supervisado&lt;/strong&gt;, no hay una variable objetivo \(Y\) etiquetada que queramos predecir. El objetivo es &lt;strong&gt;descubrir estructuras&lt;/strong&gt; en los datos, como &lt;strong&gt;grupos (clusters)&lt;/strong&gt;, &lt;strong&gt;patrones&lt;/strong&gt; o &lt;strong&gt;regularidades&lt;/strong&gt;. Esto difiere del &lt;strong&gt;aprendizaje supervisado&lt;/strong&gt;, donde s√≠ conocemos las etiquetas \((\mathbf{X}_i, Y_i)\) y buscamos una funci√≥n \(f\) que prediga \(Y\) a partir de \(\mathbf{X}\).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-aprendizaje-non-supervisado-es-mas-complejo-y-menos-performante-que-el-supervisado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Aprendizaje supervisado vs. no supervisado&#34; srcset=&#34;
               /minerias/9_clustering/figures/tweet_socher_unsupervised_hu5197646474298531310.webp 400w,
               /minerias/9_clustering/figures/tweet_socher_unsupervised_hu4366812009784522218.webp 760w,
               /minerias/9_clustering/figures/tweet_socher_unsupervised_hu11863700504794312954.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/tweet_socher_unsupervised_hu5197646474298531310.webp&#34;
               width=&#34;760&#34;
               height=&#34;219&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El aprendizaje non supervisado es mas complejo y menos performante que el supervisado.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;clustering-principio&#34;&gt;Clustering: Principio&lt;/h2&gt;
&lt;h3 id=&#34;por-qu√©-cl√∫steres&#34;&gt;¬øPor qu√© cl√∫steres?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Topic modeling&lt;/strong&gt;: agrupar documentos o comentarios seg√∫n su tema.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;An√°lisis de sentimientos&lt;/strong&gt;: reagrupar comentarios de usuarios para descubrir cr√≠ticas comunes o elogios.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Segmentaci√≥n de clientes&lt;/strong&gt;: en marketing, agrupar clientes con comportamientos similares.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eficiencia&lt;/strong&gt;: entrenar submodelos especializados en cada cl√∫ster de datos.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ambig√ºedad&#34;&gt;Ambig√ºedad&lt;/h3&gt;
&lt;p&gt;Distintas particiones pueden ser igualmente v√°lidas:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-distintas-clusterizaciones-posibles-por-una-misma&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Distintas clusterizaciones posibles&#34; srcset=&#34;
               /minerias/9_clustering/figures/different_clusterizations_2_hu15775732108812300988.webp 400w,
               /minerias/9_clustering/figures/different_clusterizations_2_hu12295819656352621145.webp 760w,
               /minerias/9_clustering/figures/different_clusterizations_2_hu15640061247686310699.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/different_clusterizations_2_hu15775732108812300988.webp&#34;
               width=&#34;760&#34;
               height=&#34;424&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Distintas clusterizaciones posibles por una misma
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;No siempre hay una sola respuesta a ‚Äúc√≥mo‚Äù agrupar.&lt;/p&gt;
&lt;h3 id=&#34;objetivo-intuitivo&#34;&gt;Objetivo intuitivo&lt;/h3&gt;
&lt;p&gt;Disminuir la &lt;strong&gt;distancia intra-cluster&lt;/strong&gt; (los puntos de un mismo grupo est√°n juntos)
y aumentar la &lt;strong&gt;distancia inter-cluster&lt;/strong&gt; (grupos lejos entre s√≠):&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-buscamos-que-los-puntos-de-un-mismo-cl√∫ster-est√©n-cerca-y-los-distintos-cl√∫steres-lejos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Inter/intra distancias&#34; srcset=&#34;
               /minerias/9_clustering/figures/cluster_inter_intra_hu7865371396031803691.webp 400w,
               /minerias/9_clustering/figures/cluster_inter_intra_hu2172439649587475770.webp 760w,
               /minerias/9_clustering/figures/cluster_inter_intra_hu17635859847885416538.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/cluster_inter_intra_hu7865371396031803691.webp&#34;
               width=&#34;760&#34;
               height=&#34;637&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Buscamos que los puntos de un mismo cl√∫ster est√©n cerca, y los distintos cl√∫steres lejos.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;k-means&#34;&gt;K-means&lt;/h2&gt;
&lt;h3 id=&#34;idea-general&#34;&gt;Idea general&lt;/h3&gt;
&lt;p&gt;Separar los datos en \(K\) grupos usando ‚Äúcentroides‚Äù (medias de cada cl√∫ster):&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-centroides-se-ajustan-iterando-la-asignaci√≥n-de-puntos-y-rec√°lculo-de-medias&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;K-means ejemplo simple&#34; srcset=&#34;
               /minerias/9_clustering/figures/k_means_ex1_hu2736599721081469354.webp 400w,
               /minerias/9_clustering/figures/k_means_ex1_hu6532534073349502683.webp 760w,
               /minerias/9_clustering/figures/k_means_ex1_hu11178902821246344841.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/k_means_ex1_hu2736599721081469354.webp&#34;
               width=&#34;760&#34;
               height=&#34;505&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los centroides se ajustan iterando la asignaci√≥n de puntos y rec√°lculo de medias.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;minimizar-la-sse-sum-of-squared-errors&#34;&gt;Minimizar la SSE (Sum of Squared Errors)&lt;/h3&gt;
&lt;p&gt;K-means particiona los datos \(\Xb_i\) en \(K\) cl√∫steres \(\{\mathcal{C}_1,\dots,\mathcal{C}_K\}\) para &lt;strong&gt;minimizar&lt;/strong&gt;:&lt;/p&gt;
\[
G(\mathcal{C}_1,\dots,\mathcal{C}_K)
= \sum_{k=1}^K 
  \sum_{i\in\mathcal{C}_k} \|\Xb_i - \mu_k\|^2,
\]&lt;p&gt;donde \(\mu_k\) es el &lt;strong&gt;centroide&lt;/strong&gt; del cl√∫ster \(k\). Cada punto se asigna al \(\mu_k\) m√°s cercano en norma Eucl√≠dea.&lt;/p&gt;
&lt;h3 id=&#34;algoritmo-iterativo&#34;&gt;Algoritmo iterativo&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Asignaci√≥n&lt;/strong&gt;: Conociendo los centroides \(\mu_k\), cada punto se asigna al m√°s cercano.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Actualizaci√≥n&lt;/strong&gt;: Conociendo la asignaci√≥n, se recalculan los centroides \(\mu_k\)
como la media de los puntos en cada cl√∫ster.&lt;/li&gt;
&lt;li&gt;Se repite hasta que la inercia (SSE) deje de disminuir significativamente.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Paso de asignaci√≥n y actualizaci√≥n&#34; srcset=&#34;
               /minerias/9_clustering/figures/steps-of-kmeans_hu6095530476482662818.webp 400w,
               /minerias/9_clustering/figures/steps-of-kmeans_hu14495224545641776934.webp 760w,
               /minerias/9_clustering/figures/steps-of-kmeans_hu16240963076215426502.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/steps-of-kmeans_hu6095530476482662818.webp&#34;
               width=&#34;760&#34;
               height=&#34;246&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;dependencia-de-la-inicializaci√≥n&#34;&gt;Dependencia de la inicializaci√≥n&lt;/h3&gt;
&lt;p&gt;Es un problema no convexo, por lo que su soluci√≥n depende de la semilla inicial:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-una-primera-inicializacion-da-un-primer-resultado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Distintas inicializaciones llevan a diferentes soluciones&#34; srcset=&#34;
               /minerias/9_clustering/figures/K_mean_conv_ex_1_hu13723184752837687416.webp 400w,
               /minerias/9_clustering/figures/K_mean_conv_ex_1_hu18197821088450864026.webp 760w,
               /minerias/9_clustering/figures/K_mean_conv_ex_1_hu381108850359093404.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/K_mean_conv_ex_1_hu13723184752837687416.webp&#34;
               width=&#34;760&#34;
               height=&#34;661&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Una primera inicializacion da un primer resultado.
    &lt;/figcaption&gt;&lt;/figure&gt;

















&lt;figure  id=&#34;figure-una-otra-inicializacion-da-un-otro-resultado&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Otra inicializaci√≥n distinta&#34; srcset=&#34;
               /minerias/9_clustering/figures/K_mean_conv_ex_2_hu2276176246617213499.webp 400w,
               /minerias/9_clustering/figures/K_mean_conv_ex_2_hu17439637570382563269.webp 760w,
               /minerias/9_clustering/figures/K_mean_conv_ex_2_hu4315955420995951315.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/K_mean_conv_ex_2_hu2276176246617213499.webp&#34;
               width=&#34;760&#34;
               height=&#34;661&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Una otra inicializacion da un otro resultado
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Soluci√≥n&lt;/strong&gt;: ejecutar K-means varias veces y elegir la partici√≥n con menor SSE.&lt;/p&gt;
&lt;h3 id=&#34;elecci√≥n-de-k&#34;&gt;Elecci√≥n de \(K\)&lt;/h3&gt;
&lt;p&gt;El n√∫mero de cl√∫steres debe fijarse antes. Se puede explorar varios valores y usar el
&lt;strong&gt;m√©todo del codo (elbow method)&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-codo-indica-un-buen-trade-off-no-reduce-mucho-m√°s-la-varianza-al-aumentar-k&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Elbow method en K-means&#34; srcset=&#34;
               /minerias/9_clustering/figures/kmeans_elbow_hu14641282044619962302.webp 400w,
               /minerias/9_clustering/figures/kmeans_elbow_hu13047655996396632350.webp 760w,
               /minerias/9_clustering/figures/kmeans_elbow_hu7513878213620665158.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/kmeans_elbow_hu14641282044619962302.webp&#34;
               width=&#34;389&#34;
               height=&#34;278&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El codo indica un buen trade-off: no reduce mucho m√°s la varianza al aumentar K.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dbscan&#34;&gt;DBSCAN&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;DBSCAN (Density-Based Spatial Clustering of Applications with Noise)&lt;/strong&gt; busca regiones densas y marca los puntos dispersos como ruido.&lt;/p&gt;
&lt;h3 id=&#34;ejemplo&#34;&gt;Ejemplo&lt;/h3&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-dbscan-puede-reconocer-clusters-y-eliminar-ruido-al-mismo-tiempo&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;DBSCAN puede eliminar ruido&#34;
           src=&#34;http://localhost:1313/minerias/9_clustering/figures/DBSCAN.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      DBSCAN puede reconocer clusters y eliminar ruido al mismo tiempo.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;principios&#34;&gt;Principios&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Par√°metros:
&lt;ul&gt;
&lt;li&gt;\(\texttt{eps} (\varepsilon)\): radio de vecindad.&lt;/li&gt;
&lt;li&gt;\(\texttt{min\_samples}\): m√≠nimo de puntos para que un punto sea n√∫cleo (core).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clasifica en &lt;strong&gt;core&lt;/strong&gt;, &lt;strong&gt;border&lt;/strong&gt;, &lt;strong&gt;noise&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Core&lt;/strong&gt;: al menos \(\texttt{min\_samples}\) puntos en su vecindad.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Border&lt;/strong&gt;: no llega a ese umbral, pero est√° dentro del vecindario de un core.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Noise&lt;/strong&gt;: no pertenece a core ni al vecindario de un core.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-principio-de-dbscan-puntos-core-border-noise&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Puntos Core, Border, Noise&#34; srcset=&#34;
               /minerias/9_clustering/figures/dbscan-principle_hu181525653378491942.webp 400w,
               /minerias/9_clustering/figures/dbscan-principle_hu2428826805354743809.webp 760w,
               /minerias/9_clustering/figures/dbscan-principle_hu8842561263444215320.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/dbscan-principle_hu181525653378491942.webp&#34;
               width=&#34;358&#34;
               height=&#34;168&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Principio de DBSCAN: Puntos Core, Border, Noise
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;ventajas-y-desventajas&#34;&gt;Ventajas y Desventajas&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Ventajas&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detecta formas arbitrarias (no s√≥lo esferas).&lt;/li&gt;
&lt;li&gt;Identifica outliers (ruido).&lt;/li&gt;
&lt;li&gt;Menos par√°metros que m√©todos jer√°rquicos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Desventajas&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sensible a \(\texttt{eps}\) y \(\texttt{min\_samples}\).&lt;/li&gt;
&lt;li&gt;Si la densidad var√≠a dr√°sticamente, un √∫nico \(\texttt{eps}\) no es apropiado.&lt;/li&gt;
&lt;li&gt;Dif√≠cil en alta dimensionalidad.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-mal-ajuste-con-eps-grandepeque√±o&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/dbscan_disvantages_2.png&#34; alt=&#34;Mal ajuste con eps grande/peque√±o&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Mal ajuste con eps grande/peque√±o
    &lt;/figcaption&gt;&lt;/figure&gt;

















&lt;figure  id=&#34;figure-ruido-o-clusters&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;figures/dbscan_disvantages_1.png&#34; alt=&#34;Ruido o clusters?&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ruido o clusters?
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;elecci√≥n-de-textttminpts-y-varepsilon&#34;&gt;Elecci√≥n de \(\texttt{minPts}\) y \(\varepsilon\)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;\(\texttt{minPts}\)&lt;/strong&gt;: regla de pulgar \(\texttt{minPts}\ge D+1\) (donde \(D\) = dimensi√≥n).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;\(\varepsilon\)&lt;/strong&gt;: usar gr√°fico de k-dist y buscar el ‚Äúcodo‚Äù.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;OPTICS&lt;/em&gt; es una alternativa m√°s avanzada que ajusta la densidad de forma variable.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;clustering-jer√°rquico&#34;&gt;Clustering Jer√°rquico&lt;/h2&gt;
&lt;h3 id=&#34;bisecting-k-means&#34;&gt;Bisecting K-means&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Bisecting K-means&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Arranca con todos los puntos como un cl√∫ster.&lt;/li&gt;
&lt;li&gt;Aplica K-means con \(k=2\) (bisect) para dividirlo en 2.&lt;/li&gt;
&lt;li&gt;Escoge el cl√∫ster con mayor SSE y lo subdivide.&lt;/li&gt;
&lt;li&gt;Repite hasta lograr \(K\) cl√∫steres.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Bisecting K-means diagrama&#34; srcset=&#34;
               /minerias/9_clustering/figures/bisecting_kmeans_hu3410477381541693384.webp 400w,
               /minerias/9_clustering/figures/bisecting_kmeans_hu4900784332573473429.webp 760w,
               /minerias/9_clustering/figures/bisecting_kmeans_hu3758992962579795936.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/bisecting_kmeans_hu3410477381541693384.webp&#34;
               width=&#34;760&#34;
               height=&#34;234&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ventajas&lt;/strong&gt;: combinan jerarqu√≠a y rapidez de K-means.&lt;br&gt;
&lt;strong&gt;Algoritmo&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Pseudoc√≥digo de Bisecting K-means&#34; srcset=&#34;
               /minerias/9_clustering/figures/Bissected_KMEANS_algo_hu5885889109457301429.webp 400w,
               /minerias/9_clustering/figures/Bissected_KMEANS_algo_hu15649835566660434353.webp 760w,
               /minerias/9_clustering/figures/Bissected_KMEANS_algo_hu9289569499455429687.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/Bissected_KMEANS_algo_hu5885889109457301429.webp&#34;
               width=&#34;401&#34;
               height=&#34;705&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;jer√°rquico-aglomerativo-hac&#34;&gt;Jer√°rquico Aglomerativo (HAC)&lt;/h3&gt;
&lt;p&gt;Otro enfoque jer√°rquico:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cada punto inicia como un cl√∫ster propio.&lt;/li&gt;
&lt;li&gt;Se fusionan iterativamente los 2 cl√∫steres m√°s cercanos.&lt;/li&gt;
&lt;li&gt;Se actualiza la distancia con el nuevo cl√∫ster.&lt;/li&gt;
&lt;li&gt;Hasta que quede un solo cl√∫ster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-fusi√≥n-jer√°rquica-paso-a-paso&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fusi√≥n jer√°rquica paso a paso&#34;
           src=&#34;http://localhost:1313/minerias/9_clustering/figures/Merging_Clusters.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fusi√≥n jer√°rquica paso a paso
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Distancia entre cl√∫steres (Linkage):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-como-cuantificar-la-similitud-entre-2-clusters&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Criterios de linkage&#34; srcset=&#34;
               /minerias/9_clustering/figures/Cluster_sim_1_hu14647459013340444117.webp 400w,
               /minerias/9_clustering/figures/Cluster_sim_1_hu11785271453636633236.webp 760w,
               /minerias/9_clustering/figures/Cluster_sim_1_hu15281884628367069891.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/Cluster_sim_1_hu14647459013340444117.webp&#34;
               width=&#34;760&#34;
               height=&#34;329&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Como cuantificar la similitud entre 2 clusters?
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Se define la ‚Äúdistancia‚Äù entre dos grupos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Single linkage&lt;/strong&gt;: menor distancia entre pares de puntos (sensibilidad al ruido).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Complete linkage&lt;/strong&gt;: mayor distancia entre pares de puntos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Average linkage&lt;/strong&gt;: promedio de distancias entre pares (compromiso).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Centroid&lt;/strong&gt; linkage: distancia entre centroides.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;hdbscan&#34;&gt;HDBSCAN&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;HDBSCAN&lt;/strong&gt;: extensi√≥n jer√°rquica de DBSCAN&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Explora m√∫ltiples densidades.&lt;/li&gt;
&lt;li&gt;No fija un √∫nico \(\varepsilon\).&lt;/li&gt;
&lt;li&gt;Elige subconjuntos estables dentro de la jerarqu√≠a de densidad.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://hdbscan.readthedocs.io/en/latest&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentaci√≥n HDBSCAN&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;m√©tricas-de-validaci√≥n&#34;&gt;M√©tricas de Validaci√≥n&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;A diferencia del aprendizaje supervisado&lt;/strong&gt;, muchas veces no hay etiquetas para evaluar la calidad de un clustering. Dos enfoques:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;M√©tricas externas&lt;/strong&gt; (hay etiquetas reales):
&lt;ul&gt;
&lt;li&gt;Homogeneidad, Completeness, V-measure.&lt;/li&gt;
&lt;li&gt;Rand Index, Fowlkes‚ÄìMallows.&lt;/li&gt;
&lt;li&gt;Mutual Information (MI).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;M√©tricas internas&lt;/strong&gt; (s√≥lo datos y cl√∫steres):
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Silhouette&lt;/strong&gt; (valores entre -1 y 1).&lt;/li&gt;
&lt;li&gt;SSE (inercia en K-means).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;resumen-r√°pido&#34;&gt;Resumen r√°pido&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Homogeneidad&lt;/strong&gt;: cada cl√∫ster contiene s√≥lo puntos de una clase.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Completeness&lt;/strong&gt;: cada clase est√° contenida en un √∫nico cl√∫ster.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;V-measure&lt;/strong&gt;: media arm√≥nica de las dos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fowlkes‚ÄìMallows&lt;/strong&gt;: ve pares de puntos coincidentes en la etiqueta y en el cluster.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Silhouette&lt;/strong&gt;: cohesi√≥n y separaci√≥n sin usar clases reales.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;otros-m√©todos-de-clustering&#34;&gt;Otros m√©todos de clustering&lt;/h2&gt;
&lt;p&gt;Existen varias alternativas seg√∫n forma de los cl√∫steres, ruido, densidad variable, etc.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;clustering_examples.png&#34; alt=&#34;Galer√≠a de m√©todos de clustering&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Tabla de referencia (Scikit-learn):&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Method Name&lt;/th&gt;
          &lt;th&gt;Parameters&lt;/th&gt;
          &lt;th&gt;Scalability&lt;/th&gt;
          &lt;th&gt;Use Case&lt;/th&gt;
          &lt;th&gt;Geometry (Metric Used)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#k-means&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;K-Means&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters&lt;/td&gt;
          &lt;td&gt;Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt; with MiniBatch code&lt;/td&gt;
          &lt;td&gt;General-purpose, even cluster size, flat geometry, not too many clusters, inductive&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#affinity-propagation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Affinity Propagation&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Damping, sample preference&lt;/td&gt;
          &lt;td&gt;Not scalable with &lt;code&gt;n_samples&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Many clusters, uneven cluster size, non-flat geometry, inductive&lt;/td&gt;
          &lt;td&gt;Graph distance (e.g., nearest-neighbor graph)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#mean-shift&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Mean-Shift&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Bandwidth&lt;/td&gt;
          &lt;td&gt;Not scalable with &lt;code&gt;n_samples&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Many clusters, uneven cluster size, non-flat geometry, inductive&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#spectral-clustering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Spectral Clustering&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters&lt;/td&gt;
          &lt;td&gt;Medium &lt;code&gt;n_samples&lt;/code&gt;, small &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Few clusters, even cluster size, non-flat geometry, transductive&lt;/td&gt;
          &lt;td&gt;Graph distance (e.g., nearest-neighbor graph)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Ward Hierarchical Clustering&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters or distance threshold&lt;/td&gt;
          &lt;td&gt;Large &lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Many clusters, possibly connectivity constraints, transductive&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Agglomerative Clustering&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters or distance threshold, linkage type, distance&lt;/td&gt;
          &lt;td&gt;Large &lt;code&gt;n_samples&lt;/code&gt; and &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Many clusters, possibly connectivity constraints, non-Euclidean distances, transductive&lt;/td&gt;
          &lt;td&gt;Any pairwise distance&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#dbscan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;DBSCAN&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Neighborhood size&lt;/td&gt;
          &lt;td&gt;Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Non-flat geometry, uneven cluster sizes, outlier removal, transductive&lt;/td&gt;
          &lt;td&gt;Distances between nearest points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#hdbscan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;HDBSCAN&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Minimum cluster membership, minimum point neighbors&lt;/td&gt;
          &lt;td&gt;Large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Non-flat geometry, uneven cluster sizes, outlier removal, transductive, hierarchical, variable cluster density&lt;/td&gt;
          &lt;td&gt;Distances between nearest points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#optics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;OPTICS&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Minimum cluster membership&lt;/td&gt;
          &lt;td&gt;Very large &lt;code&gt;n_samples&lt;/code&gt;, large &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Non-flat geometry, uneven cluster sizes, variable cluster density, outlier removal, transductive&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#gaussian-mixture&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Gaussian Mixtures&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Many&lt;/td&gt;
          &lt;td&gt;Not scalable&lt;/td&gt;
          &lt;td&gt;Flat geometry, good for density estimation, inductive&lt;/td&gt;
          &lt;td&gt;Mahalanobis distances to centers&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#birch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;BIRCH&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Branching factor, threshold, optional global clusterer&lt;/td&gt;
          &lt;td&gt;Large &lt;code&gt;n_clusters&lt;/code&gt; and &lt;code&gt;n_samples&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;Large dataset, outlier removal, data reduction, inductive&lt;/td&gt;
          &lt;td&gt;Euclidean distance between points&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#bisecting-k-means&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Bisecting K-Means&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Number of clusters&lt;/td&gt;
          &lt;td&gt;Very large &lt;code&gt;n_samples&lt;/code&gt;, medium &lt;code&gt;n_clusters&lt;/code&gt;&lt;/td&gt;
          &lt;td&gt;General-purpose, even cluster size, flat geometry, no empty clusters, inductive, hierarchical&lt;/td&gt;
          &lt;td&gt;Distances between points&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;M√°s info en: &lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;clustering scikit-learn docs&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;use-case-bertopic&#34;&gt;Use-case: BERTopic&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;BERTopic&lt;/strong&gt; es una librer√≠a que combina embeddings (BERT) + clustering para &lt;strong&gt;topic modeling&lt;/strong&gt; sobre textos.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;BERTopic Ejemplo&#34; srcset=&#34;
               /minerias/9_clustering/figures/BERTopic_pres_hu16487685084505827816.webp 400w,
               /minerias/9_clustering/figures/BERTopic_pres_hu4264554082630846410.webp 760w,
               /minerias/9_clustering/figures/BERTopic_pres_hu2358273787969741926.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/9_clustering/figures/BERTopic_pres_hu16487685084505827816.webp&#34;
               width=&#34;760&#34;
               height=&#34;429&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Puede:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Agrupar oraciones/documentos en ‚Äútemas‚Äù usando embeddings.&lt;/li&gt;
&lt;li&gt;Visualizar la &lt;strong&gt;evoluci√≥n&lt;/strong&gt; de temas en el tiempo (dynamic topic modeling).&lt;/li&gt;
&lt;li&gt;Hacer &lt;strong&gt;clustering jer√°rquico&lt;/strong&gt; en temas descubiertos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://maartengr.github.io/BERTopic/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BERTopic docs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-permite-un-tracking-din√°mico-de-la-evoluci√≥n-de-topics-ademas-se-puede-ver-que-las-palabras-las-mas-importante-para-cada-topic-evoluan-en-el-tiempo&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Visualizaci√≥n de temas en el tiempo&#34;
           src=&#34;http://localhost:1313/minerias/9_clustering/figures/BERTopic_time.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Permite un tracking din√°mico de la evoluci√≥n de topics. Ademas se puede ver que las palabras las mas importante para cada topic evoluan en el tiempo.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Computer Vision Architectures</title>
      <link>http://localhost:1313/deep/9_cnn_architectures/</link>
      <pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/9_cnn_architectures/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides9_cnn_architecturespdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/9_CNN_Architectures.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Dimensionality Reduction</title>
      <link>http://localhost:1313/minerias/10_reduccion_atributos/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/10_reduccion_atributos/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_disminucion_dimensionespdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_Disminucion_Dimensiones.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;p&gt;Las &lt;strong&gt;t√©cnicas de reducci√≥n de dimensi√≥n&lt;/strong&gt; buscan simplificar la representaci√≥n de los datos, sea eliminando atributos innecesarios (selecci√≥n de caracter√≠sticas) o encontrando una proyecci√≥n m√°s compacta que mantenga la mayor parte de la informaci√≥n. A continuaci√≥n, veremos m√©todos tanto &lt;strong&gt;supervisados&lt;/strong&gt; (wrappers, filters) como &lt;strong&gt;no supervisados&lt;/strong&gt; (PCA, entre otros).&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;motivaciones-para-una-dimensi√≥n-m√°s-baja&#34;&gt;Motivaciones para una Dimensi√≥n m√°s Baja&lt;/h2&gt;
&lt;h3 id=&#34;selecci√≥n-y-reducci√≥n-de-atributos&#34;&gt;Selecci√≥n y Reducci√≥n de Atributos&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Motivaci√≥n General&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;En muchos problemas de aprendizaje, hay &lt;strong&gt;atributos irrelevantes&lt;/strong&gt; o &lt;strong&gt;redundantes&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Pueden perjudicar el desempe√±o de un clasificador o incrementar el costo de entrenamiento.&lt;/li&gt;
&lt;li&gt;Dos enfoques principales:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Selecci√≥n de atributos (supervisado)&lt;/strong&gt;: escoger un &lt;strong&gt;subconjunto&lt;/strong&gt; relevante para la tarea (clasificaci√≥n, regresi√≥n&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reducci√≥n de dimensionalidad (no supervisado)&lt;/strong&gt;: encontrar una &lt;strong&gt;proyecci√≥n&lt;/strong&gt; de menor dimensi√≥n que concentre la informaci√≥n de los datos.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;razones-para-seleccionar-atributos&#34;&gt;Razones para Seleccionar Atributos&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;√Årboles de decisi√≥n&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Aunque tratan de escoger atributos relevantes, si hay muchos atributos basura, puede aparecer sobreajuste (‚Äúaprender‚Äù ruido con √°rboles muy profundos).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;KNN&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Se ve muy afectado por atributos irrelevantes, pues todas las dimensiones contribuyen igual al &lt;strong&gt;c√°lculo de distancias&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Na√Øve Bayes&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Robusto a atributos irrelevantes (los ignora en la probabilidad a posteriori), pero sufre con atributos muy &lt;strong&gt;correlacionados&lt;/strong&gt; (redundantes).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;En general, se quiere &lt;strong&gt;mitigar la curse of dimensionality&lt;/strong&gt; (maldici√≥n de la dimensionalidad).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;selecci√≥n-de-atributos&#34;&gt;Selecci√≥n de Atributos&lt;/h2&gt;
&lt;h3 id=&#34;filtros-vs-envoltura&#34;&gt;Filtros vs. Envoltura&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Feature-based (Filtros)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eval√∫an atributos por &lt;strong&gt;propiedades de los datos&lt;/strong&gt; (p.ej. varianza, correlaci√≥n, informaci√≥n mutua).&lt;/li&gt;
&lt;li&gt;Independientes del clasificador.&lt;/li&gt;
&lt;li&gt;M√°s r√°pidos y con menos riesgo de sobreajuste, pero &lt;strong&gt;no captan&lt;/strong&gt; interacciones complejas con la tarea predictiva.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Model-based (Wrappers)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Entrenan un &lt;strong&gt;clasificador&lt;/strong&gt; sobre cada subconjunto para medir qu√© tan bueno es.&lt;/li&gt;
&lt;li&gt;Objetivo: maximizar la capacidad predictiva del modelo espec√≠fico.&lt;/li&gt;
&lt;li&gt;Pueden ser computacionalmente costosos y propensos a sobreajuste, pero suelen encontrar subconjuntos de atributos &lt;strong&gt;m√°s espec√≠ficos a la tarea&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;m√©todos-feature-based-univariate&#34;&gt;M√©todos Feature-based (Univariate)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Independientes de un modelo&lt;/strong&gt; (univariate feature selection).&lt;/li&gt;
&lt;li&gt;Usan &lt;strong&gt;m√©tricas&lt;/strong&gt; generales (entrop√≠a, Information Gain, correlaci√≥n, \(\chi^2\)&amp;hellip;).&lt;/li&gt;
&lt;li&gt;Ejemplos:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Information Gain&lt;/strong&gt; (basado en entrop√≠a).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mutual Information&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Correlation-based Feature Selection (CFS)&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Low variance&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Son r√°pidos y simples, pero &lt;strong&gt;no consideran&lt;/strong&gt; c√≥mo cada atributo interact√∫a con un clasificador concreto.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Mutual Information y \(\chi^2\) son √∫tiles cuando los datos son dispersos (sparse).&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h4 id=&#34;correlation-based-feature-selection-cfs&#34;&gt;Correlation-based Feature Selection (CFS)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Se eval√∫a un subconjunto de atributos seg√∫n correlaciones en los datos:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Alta correlaci√≥n&lt;/strong&gt; con la clase.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Baja correlaci√≥n&lt;/strong&gt; entre atributos (evitar redundancia).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Se suele usar &lt;em&gt;symmetric uncertainty&lt;/em&gt; para medir correlaciones entre atributos categ√≥ricos:&lt;/li&gt;
&lt;/ul&gt;
\[
\text{SymmUnc}(A,B) 
= \frac{2 \times (H(A) - H(A|B))}{H(A)+H(B)} 
= \frac{2 \times IG(A,B)}{H(A)+H(B)},
\]&lt;p&gt;
donde \(H(\cdot)\) es la entrop√≠a, e \(IG(A,B)\) la ganancia de informaci√≥n.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;B√∫squeda de subconjuntos&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;El total de subconjuntos es \(\mathcal{O}(2^n)\).&lt;/li&gt;
&lt;li&gt;Se aplican heur√≠sticas &lt;strong&gt;greedy&lt;/strong&gt; (Forward selection, Backward elimination) o m√°s avanzadas (Best-first search, Beam search, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;model-based-scheme-specific&#34;&gt;Model-based (Scheme-Specific)&lt;/h3&gt;
&lt;h4 id=&#34;selecci√≥n-basada-en-importancia-de-atributos&#34;&gt;Selecci√≥n basada en importancia de atributos&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Tras entrenar un &lt;strong&gt;modelo&lt;/strong&gt; (ej. √°rbol, regresi√≥n lineal, random forest), se obtiene la &lt;strong&gt;importancia&lt;/strong&gt; de cada atributo (coeficientes o feature importances).&lt;/li&gt;
&lt;li&gt;Se descartan los que &lt;strong&gt;no&lt;/strong&gt; superan cierto umbral.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SelectFromModel de scikit-learn&lt;/a&gt; permite automatizarlo.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Regularizaci√≥n \(\ell_1\) (Lasso)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Induce &lt;strong&gt;parcimonia&lt;/strong&gt;: algunos coeficientes se anulan.&lt;/li&gt;
&lt;li&gt;Ideal para selecci√≥n en modelos lineales (regresi√≥n, log√≠stica).&lt;/li&gt;
&lt;li&gt;Penaliza \(\sum |w_j|\), forzando algunos \(w_j\) a 0.&lt;/li&gt;
&lt;li&gt;Integra f√°cilmente con &lt;code&gt;SelectFromModel&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;selecci√≥n-por-wrapper-performance-based&#34;&gt;Selecci√≥n por Wrapper (Performance-based)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Se prueban subconjuntos entrenando un modelo y midiendo su &lt;strong&gt;performance&lt;/strong&gt; (accuracy, F1, AUC&amp;hellip;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Muy costoso&lt;/strong&gt;: reentrenar el modelo para cada subconjunto potencial.&lt;/li&gt;
&lt;li&gt;A menudo se hace &lt;strong&gt;greedy&lt;/strong&gt; (Forward o Backward).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recursive Feature Elimination (RFE)&lt;/strong&gt;:
&lt;ol&gt;
&lt;li&gt;Entrena estimador, extrae la &lt;strong&gt;importancia&lt;/strong&gt; de atributos,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Descarta&lt;/strong&gt; los menos importantes,&lt;/li&gt;
&lt;li&gt;Repite con el subconjunto reducido hasta lograr la cantidad de atributos deseada.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reducci√≥n-de-dimensi√≥n&#34;&gt;Reducci√≥n de Dimensi√≥n&lt;/h2&gt;
&lt;p&gt;M√°s all√° de ‚Äúquitar‚Äù atributos, a veces &lt;strong&gt;transformamos&lt;/strong&gt; los datos a una dimensi√≥n menor con un m√©todo no supervisado.&lt;/p&gt;
&lt;h3 id=&#34;intereses-de-la-reducci√≥n-de-dimensi√≥n&#34;&gt;Intereses de la Reducci√≥n de Dimensi√≥n&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Simplificar los datos&lt;/strong&gt;: Menos ruido, mejor generalizaci√≥n.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reducir costo computacional&lt;/strong&gt;: Entrenar y predecir con menos dimensiones es m√°s r√°pido.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualizaci√≥n&lt;/strong&gt;: Proyecciones 2D o 3D para entender la estructura de los datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evitar la curse of dimensionality&lt;/strong&gt;: M√©todos basados en distancia sufren en alta dimensi√≥n.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compresi√≥n&lt;/strong&gt;: Reducir espacio de almacenamiento.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;an√°lisis-de-componentes-principales-pca&#34;&gt;An√°lisis de Componentes Principales (PCA)&lt;/h2&gt;
&lt;p&gt;PCA es un m√©todo &lt;strong&gt;lineal&lt;/strong&gt; que halla vectores propios de la matriz de &lt;strong&gt;covarianza&lt;/strong&gt;. Permitten de representar la mayor parte de los datos, con menos vectores en la base del espacio.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-cada-dato-se-representa-como-una-suma-ponderada-de-vectores-de-una-nueva-base-que-permite-de-representar-bien-la-mayor-parte-de-los-datos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de eigenfaces (PCA en im√°genes)&#34; srcset=&#34;
               /minerias/10_reduccion_atributos/figures/pca_matrices_val_hu2261646820185605856.webp 400w,
               /minerias/10_reduccion_atributos/figures/pca_matrices_val_hu4505522404744315614.webp 760w,
               /minerias/10_reduccion_atributos/figures/pca_matrices_val_hu4178062851371759896.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/pca_matrices_val_hu2261646820185605856.webp&#34;
               width=&#34;760&#34;
               height=&#34;417&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cada dato se representa como una suma ponderada de vectores de una nueva base, que permite de representar bien la mayor parte de los datos.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-eigenfaces-como-vectores-base-de-pca-obtenidos-con-pca-en-un-dataset-de-rostros&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Eigenfaces obtenidos con PCA en un dataset de rostros&#34; srcset=&#34;
               /minerias/10_reduccion_atributos/figures/eigenfaces2_hu6363039486458666921.webp 400w,
               /minerias/10_reduccion_atributos/figures/eigenfaces2_hu8512282051007263862.webp 760w,
               /minerias/10_reduccion_atributos/figures/eigenfaces2_hu15806552021475915375.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/eigenfaces2_hu6363039486458666921.webp&#34;
               width=&#34;576&#34;
               height=&#34;237&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Eigenfaces como vectores base de PCA obtenidos con PCA en un dataset de rostros.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;por-qu√©-pca&#34;&gt;¬øPor qu√© PCA?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reduce dimensi√≥n&lt;/strong&gt; para an√°lisis, visualizaci√≥n o compresi√≥n.&lt;/li&gt;
&lt;li&gt;Encuentra un &lt;strong&gt;sistema de coordenadas&lt;/strong&gt; donde los ejes (componentes principales) corresponden a las direcciones de &lt;strong&gt;mayor varianza&lt;/strong&gt; en los datos.&lt;/li&gt;
&lt;li&gt;Base calculada con las &lt;strong&gt;autovectores&lt;/strong&gt; de la covarianza.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ejemplo-e-ilustraci√≥n&#34;&gt;Ejemplo e Ilustraci√≥n&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PCA ve la redundancia (varias variables correlacionadas) y la condensa en &lt;strong&gt;componentes&lt;/strong&gt; que explican la mayor parte de la varianza.&lt;/li&gt;
&lt;li&gt;Datos \(\mathbf{X}_0\) &lt;strong&gt;centrados&lt;/strong&gt; (o estandarizados) se proyectan en el subespacio donde la &lt;strong&gt;varianza&lt;/strong&gt; proyectada es m√°xima.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplo-pca-de-2d-a-1d&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo PCA 2D -&amp;gt; 1D&#34;
           src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/EX_PCA.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo PCA de 2D a 1D.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Se pueden visualizar transformaciones o la reconstrucci√≥n aproximada:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-la-data-inicial-normalizada-transformada-y-reconstruida&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Data normalized transformed reconstructed&#34;
           src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/PCA_data_original_normalized_transformed_reconstructed.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      La data inicial, normalizada, transformada y reconstruida
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;fundamento-matem√°tico&#34;&gt;Fundamento Matem√°tico&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Normalizamos \(\mathbf{X}\) a \(\mathbf{X}_0\) (restando la media, opcionalmente dividiendo por la desviaci√≥n est√°ndar).&lt;/li&gt;
&lt;li&gt;Calculamos \(\Sigma = \mathbf{X}_0^\top \mathbf{X}_0\) (matriz de covarianza).&lt;/li&gt;
&lt;li&gt;Hallamos &lt;strong&gt;vectores propios&lt;/strong&gt; \(u_k\) y valores propios \(\lambda_k\) de \(\Sigma\).&lt;/li&gt;
&lt;li&gt;Elegimos los \(L\) vectores con mayores \(\lambda_k\) para capturar, p. ej., 99% de la varianza.&lt;/li&gt;
&lt;li&gt;Proyectamos los datos en esos vectores: se obtiene la &lt;strong&gt;representaci√≥n&lt;/strong&gt; de \(\mathbf{X}_0\) en dimensi√≥n \(L\).&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;PCA&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pasos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Centrar&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datos&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Calcular&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;covarianza&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Eigen&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;decomposition&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Elegir&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;top&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;L&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;componentes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Proyectar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Reconstruir&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;ejemplos-visuales&#34;&gt;Ejemplos Visuales&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Ejemplo con 32 im√°genes y Reconstrucci√≥n con 4 componentes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-ejemplo-de-datos-originales-y-reconstrucci√≥n-con-solo-4-componentes-principales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;32 im√°genes antes de la reducci√≥n de dimensi√≥n (PCA)&#34;
           src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/pca_raw.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Ejemplo de datos originales, y reconstrucci√≥n con solo 4 componentes principales.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
\[
    0,078 \mathbf{u}_1 + 0,062 \mathbf{u}_2 - 0,182 \mathbf{u}_3 + 0,179\mathbf{u}_4
\]&lt;p&gt;















&lt;figure  id=&#34;figure-reconstruccion&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pca_ex.png&#34; srcset=&#34;
               /minerias/10_reduccion_atributos/figures/pca_ex_hu15294993851617418670.webp 400w,
               /minerias/10_reduccion_atributos/figures/pca_ex_hu26270393708423628.webp 760w,
               /minerias/10_reduccion_atributos/figures/pca_ex_hu942683097186566598.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/pca_ex_hu15294993851617418670.webp&#34;
               width=&#34;760&#34;
               height=&#34;151&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Reconstruccion
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;En im√°genes de caras (eigenfaces):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-vectores-base-se-llaman-eigenfaces-en-este-caso&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de eigenfaces (PCA en im√°genes)&#34; srcset=&#34;
               /minerias/10_reduccion_atributos/figures/eigenfaces_hu4547894862833859281.webp 400w,
               /minerias/10_reduccion_atributos/figures/eigenfaces_hu9446926744243638575.webp 760w,
               /minerias/10_reduccion_atributos/figures/eigenfaces_hu2553934778585337579.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/10_reduccion_atributos/figures/eigenfaces_hu4547894862833859281.webp&#34;
               width=&#34;760&#34;
               height=&#34;475&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los vectores base se llaman eigenfaces en este caso.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;vectores-propios-y-covarianza&#34;&gt;Vectores Propios y Covarianza&lt;/h3&gt;
&lt;p&gt;Para &lt;strong&gt;reducir la dimensi√≥n&lt;/strong&gt; con PCA, se calcula la \textbf{matriz de covarianza} de los datos centrados y se obtienen sus \textbf{valores y vectores propios}. Recordemos:&lt;/p&gt;
\[
\text{cov}(X,Y) \;=\; \mathbb{E}\bigl[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])\bigr].
\]&lt;ul&gt;
&lt;li&gt;\(\text{cov}(X,Y) &gt; 0\) indica relaci√≥n lineal directa (si \(X\) aumenta, \(Y\) tambi√©n).&lt;/li&gt;
&lt;li&gt;\(\text{cov}(X,Y) &lt; 0\) indica relaci√≥n lineal inversa.&lt;/li&gt;
&lt;li&gt;\(\text{cov}(X,Y) = 0\) sugiere ausencia de relaci√≥n lineal aparente.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En \textbf{matriz de covarianza} \(\mathbf{\Sigma}\) (dimensi√≥n \(d\times d\)), cada entrada \(\Sigma_{ij}\) es la covarianza entre el atributo \(i\) y el atributo \(j\). Si tenemos datos centrados \(\mathbf{X}_0\), se define:&lt;/p&gt;
\[
\mathbf{\Sigma} 
\;=\; \mathbf{X}_0^\top \,\mathbf{X}_0 
\quad (\text{o bien } \tfrac{1}{n}\mathbf{X}_0^\top \mathbf{X}_0 \,\text{dependiendo de la convenci√≥n de normalizaci√≥n}).
\]&lt;p&gt;Los \textbf{valores propios} \(\lambda\) y \textbf{vectores propios} \(\mathbf{u}\) de \(\mathbf{\Sigma}\) satisfacen&lt;/p&gt;
\[
\mathbf{\Sigma}\,\mathbf{u} 
\;=\; \lambda \,\mathbf{u}.
\]&lt;p&gt;Los \(\lambda\) m√°s grandes corresponder√°n a las \textbf{direcciones de mayor varianza} en los datos.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;pca-aproximaci√≥n-de-los-datos&#34;&gt;PCA: Aproximaci√≥n de los Datos&lt;/h3&gt;
&lt;p&gt;En PCA, se busca aproximar el conjunto de datos \(\mathbf{X}\) con un subespacio de dimensi√≥n \(L\). Sean \(\{\mathbf{b}_i\}_{i=1..L}\) vectores ortonormales que generan ese subespacio (los ejes principales). El error de proyecci√≥n se minimiza cuando:&lt;/p&gt;
\[
(\mathbf{b}_i)_{i=1..L} 
\;=\;
\underset{(\mathbf{b}_i)_{i=1..L}}{\arg\max}\;
\sum_{i=1}^{L}\,
\mathbf{b}_i^\top \,\mathrm{cov}(\mathbf{X})\,\mathbf{b}_i.
\]&lt;ul&gt;
&lt;li&gt;\(\mathrm{cov}(\mathbf{X})\) denota la matriz de covarianza de los datos centrados.&lt;/li&gt;
&lt;li&gt;La mejor base \(\{\mathbf{b}_1, \dots, \mathbf{b}_L\}\) corresponde, en la pr√°ctica, a los \(\mathbf{u}_1,\dots,\mathbf{u}_L\) vectores propios de \(\mathrm{cov}(\mathbf{X})\) asociados a los \(\lambda\) m√°s grandes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En notaci√≥n concreta:&lt;/p&gt;
\[
\mathrm{cov}(\mathbf{X})
\;=\;
(\mathbf{X} - \mu_\mathbf{X})^\top (\mathbf{X} - \mu_\mathbf{X}),
\]&lt;p&gt;
donde \(\mu_\mathbf{X}\) es la media de \(\mathbf{X}\).&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;pca-normalizaci√≥n-centrado-de-los-datos&#34;&gt;PCA: Normalizaci√≥n (Centrado) de los Datos&lt;/h3&gt;
&lt;p&gt;Sea \(\mathbf{X}\) una matriz \(d \times n\) (d: n√∫mero de atributos, n: n√∫mero de ejemplos). Para construir \(\mathbf{X}_0\) centrada:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Calcule la media de cada columna (atributo):
\[
   \mu_i = \tfrac{1}{d}\,\sum_{k=1}^d \mathbf{X}_i^{(k)} 
   \quad\bigl(\text{o a veces} \tfrac{1}{n}\,\sum_{k=1}^n \text{depende de filas/columnas}\bigr).
   \]&lt;/li&gt;
&lt;li&gt;Reste esa media a la columna:
\[
   \mathbf{X}_0 = 
   \mathbf{X} - \mu.
   \]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;En cada columna, la suma (o media) pasa a ser 0, eliminando el \textbf{sesgo}. Opcionalmente, se divide adem√°s por la desviaci√≥n est√°ndar para escalarlos. As√≠, evitamos que atributos con escalas grandes dominen la varianza total.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Xb -&amp;gt; (Xb - media_col)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   -&amp;gt; (opcional) / desviacion_col
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;pca-principio-y-m√©todo&#34;&gt;PCA: Principio y M√©todo&lt;/h3&gt;
&lt;p&gt;Dado un dataset \(\mathbf{X}\), el algoritmo PCA se realiza t√≠picamente as√≠:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Crear&lt;/strong&gt; la matriz de datos \(\mathbf{X}\) (dimensi√≥n \(d \times n\)), donde cada columna representa un ejemplo (o cada fila, seg√∫n convenci√≥n).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
\[
   \mathbf{X}_0 = \mathbf{X} - \mu
   \]&lt;p&gt;
\(\mu\) es la media por atributo (o por componente), de modo que la media de cada columna quede en 0.&lt;br&gt;
&lt;em&gt;(Opcionalmente, se puede escalar adem√°s por la desviaci√≥n est√°ndar para igualar las escalas.)&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
\[
   \mathbf{\Sigma} = \mathbf{X}_0^\top \,\mathbf{X}_0 
   \]&lt;p&gt;
(o a veces dividido por \(n\), seg√∫n la convenci√≥n estad√≠stica).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Obtener&lt;/strong&gt; los vectores propios \(\mathbf{u}_k\) y valores propios \(\lambda_k\) de \(\mathbf{\Sigma}\):&lt;/p&gt;
\[
   \mathbf{\Sigma} \mathbf{u}_k = \lambda_k \mathbf{u}_k.
   \]&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ordenar&lt;/strong&gt; los vectores propios en orden decreciente de \(\lambda_k\).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Elegir&lt;/strong&gt; los \(L\) vectores con valores propios m√°s grandes, cumpliendo por ejemplo que&lt;/p&gt;
\[ 
   \frac{\sum_{k=1}^{L}\,\lambda_k}{\sum_{k=1}^{n}\,\lambda_k} &gt; 0.95  \quad (\text{o el umbral deseado de varianza explicada}).
  \]&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Proyectar&lt;/strong&gt; los datos sobre esos \(L\) vectores para obtener una &lt;strong&gt;representaci√≥n de dimensi√≥n menor&lt;/strong&gt; (\(\mathbb{R}^L\)). Cada ejemplo se convierte en \(\mathbf{u}_1^\top \mathbf{X}_0, \dots, \mathbf{u}_L^\top \mathbf{X}_0\).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Opcional) &lt;strong&gt;Reconstruir&lt;/strong&gt; los datos en la dimensi√≥n original si se desea una aproximaci√≥n de \(\mathbf{X}\), sabiendo que hay una p√©rdida de informaci√≥n si \(L &lt; d\).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h4 id=&#34;intuici√≥n-m√°xima-varianza&#34;&gt;Intuici√≥n: M√°xima Varianza&lt;/h4&gt;
&lt;p&gt;La idea fundamental de PCA es buscar direcciones (vectores) que &lt;strong&gt;maximicen&lt;/strong&gt; la varianza de la proyecci√≥n. En particular, la primera componente principal es:&lt;/p&gt;
\[
\max_{\|\mathbf{u}\|=1}
\ 
\mathbf{u}^\top 
\bigl(\mathbf{X}_0^\top\,\mathbf{X}_0\bigr)\,
\mathbf{u},
\]&lt;p&gt;
y la \(\mathbf{u}\) que soluciona esto es el &lt;strong&gt;vector propio&lt;/strong&gt; de \(\mathbf{\Sigma} = \mathbf{X}_0^\top \mathbf{X}_0\) con &lt;strong&gt;mayor&lt;/strong&gt; valor propio \(\lambda\). Despu√©s, la segunda componente es la direcci√≥n ortogonal a la primera que maximiza la varianza restante, y as√≠ sucesivamente.&lt;/p&gt;
&lt;p&gt;La proyecci√≥n en los primeros \(L\) vectores propios captura &lt;strong&gt;buena parte&lt;/strong&gt; de la varianza total, reduciendo la dimensi√≥n mientras preserva la mayor informaci√≥n posible.&lt;/p&gt;
&lt;h2 id=&#34;otros-algoritmos&#34;&gt;Otros Algoritmos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multidimensional Scaling (MDS)&lt;/strong&gt;: Preserva distancias entre puntos en la proyecci√≥n.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;t-SNE&lt;/strong&gt;: Modela la cercan√≠a de puntos en alta dimensi√≥n a una proyecci√≥n 2D:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=NEaUSP4YerM&#34; title=&#34;Video sobre t-SNE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video explicativo t-SNE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ICA (Independent Component Analysis)&lt;/strong&gt;: Busca componentes estad√≠sticamente independientes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;UMAP&lt;/strong&gt;: Se basa en geometr√≠a riemanniana y topolog√≠a algebraica:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nq6iPZVUxZU&#34; title=&#34;Video sobre UMAP&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;M√°s detalles en video UMAP&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autoencoder&lt;/strong&gt;: Red neuronal no supervisada para comprimir (encoder) y reconstruir (decoder), usando la capa latente como reducci√≥n de dimensi√≥n.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusiones&#34;&gt;Conclusiones&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Selecci√≥n de atributos&lt;/strong&gt; (filtrada o basada en un modelo) reduce complejidad y puede mejorar rendimiento, sobre todo en m√©todos sensibles a ruido y correlaciones.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reducci√≥n de dimensionalidad&lt;/strong&gt; (PCA, t-SNE, UMAP, etc.) proyecta los datos a un espacio de menor dimensi√≥n, lo que facilita la visualizaci√≥n, disminuye ruido y puede acelerar el entrenamiento.&lt;/li&gt;
&lt;li&gt;Hay que equilibrar la &lt;strong&gt;simplicidad&lt;/strong&gt; lograda y la &lt;strong&gt;p√©rdida de informaci√≥n&lt;/strong&gt; al desechar o proyectar atributos.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Transfer Learning</title>
      <link>http://localhost:1313/deep/10_transferlearning/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/10_transferlearning/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides10_transferlearningpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/10_TransferLearning.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Object Detection</title>
      <link>http://localhost:1313/deep/11_computervision/</link>
      <pubDate>Tue, 19 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/11_computervision/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslides11_computervisionpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/11_ComputerVision.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Redes Neuronales</title>
      <link>http://localhost:1313/minerias/11_nn/</link>
      <pubDate>Tue, 19 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/11_nn/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esdm_nnetpdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/DM_NNet.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
&lt;hr&gt;
&lt;h2 id=&#34;perceptr√≥n&#34;&gt;Perceptr√≥n&lt;/h2&gt;
&lt;p&gt;Las &lt;strong&gt;Redes Neuronales&lt;/strong&gt; se inspiran ligeramente en la biolog√≠a de las neuronas, tratando de simular c√≥mo la se√±al fluye entre capas de neuronas. El &lt;strong&gt;Perceptr√≥n&lt;/strong&gt; es la unidad b√°sica que origin√≥ muchos avances en este campo.&lt;/p&gt;
&lt;h3 id=&#34;por-qu√©-este-nombre&#34;&gt;¬øPor qu√© este nombre?&lt;/h3&gt;
&lt;p&gt;En biolog√≠a, una neurona:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Recibe&lt;/strong&gt; neurotransmisores por las dendritas, provenientes de sinapsis de otras neuronas.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Se activa&lt;/strong&gt; al superar un cierto umbral de estimulaci√≥n.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Emite&lt;/strong&gt; a su vez se√±al el√©ctrica por el ax√≥n, y libera neurotransmisores en sus sinapsis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-las-dendritas-reciben-informaci√≥n-si-supera-un-umbral-la-neurona-dispara-por-el-ax√≥n&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Esquema de neurona biol√≥gica&#34; srcset=&#34;
               /minerias/11_nn/figures/neurone_bio_hu5042147682634696871.webp 400w,
               /minerias/11_nn/figures/neurone_bio_hu8780734665714482128.webp 760w,
               /minerias/11_nn/figures/neurone_bio_hu11577556031772479973.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/neurone_bio_hu5042147682634696871.webp&#34;
               width=&#34;760&#34;
               height=&#34;560&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Las dendritas reciben informaci√≥n; si supera un umbral, la neurona dispara por el ax√≥n.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En un &lt;strong&gt;perceptr√≥n&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Las entradas (an√°logo de dendritas) se combinan con ciertos pesos (\(w_i\)) y pasan por una funci√≥n de activaci√≥n que decide si hay salida (dispara) o no.&lt;/li&gt;
&lt;li&gt;Si supera un &lt;strong&gt;umbral&lt;/strong&gt;, la ‚Äúneurona‚Äù artificial se activa.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;perceptr√≥n-presentaci√≥n&#34;&gt;Perceptr√≥n: Presentaci√≥n&lt;/h3&gt;
&lt;p&gt;El perceptr√≥n m√°s simple (con dos entradas \(x_1\) y \(x_2\)) se representa como:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Un &lt;strong&gt;suma ponderada&lt;/strong&gt; \(\sum_j x_j w_j - b\)&lt;/li&gt;
&lt;li&gt;Una &lt;strong&gt;funci√≥n de activaci√≥n&lt;/strong&gt; &lt;code&gt;f&lt;/code&gt; que decide la salida \(y\).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;En la versi√≥n binaria m√°s elemental:&lt;/p&gt;
\[
y = f\bigl(x_1 w_1 + x_2 w_2 - b\bigr) = f\bigl(W^TX- b\bigr)
\]&lt;p&gt;Donde \(f\) es (en teor√≠a) la funci√≥n &lt;strong&gt;Heaviside&lt;/strong&gt;:&lt;/p&gt;
\[
f(z) = 
\begin{cases}
1, &amp; z \ge 0\\
0, &amp; z &lt; 0
\end{cases}
\]&lt;p&gt;Si \(x_1 w_1 + x_2 w_2 \) supera el umbral \(b\), la salida es \(1\).&lt;/p&gt;
&lt;p&gt;Algunas representaciones gr√°ficas:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-perceptron-con-la-capa-de-entrada-x-la-funcion-de-activacion-f-la-salida-y&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Perceptr√≥n con umbral binario&#34;
           src=&#34;http://localhost:1313/minerias/11_nn/figures/Binary_valued_threshold.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El perceptron, con la capa de entrada \(X\), la funcion de activacion \(f\), la salida \(y\)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;perceptr√≥n-multicapa-mlp&#34;&gt;Perceptr√≥n Multicapa (MLP)&lt;/h2&gt;
&lt;p&gt;Para resolver tareas m√°s complejas, se agregan &lt;strong&gt;capas&lt;/strong&gt; de neuronas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Capa de entrada&lt;/strong&gt;: Recibe las caracter√≠sticas (\(x\) o \(\mathbf{a}^{(1)}\)).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Capas ocultas&lt;/strong&gt;: Transforman la informaci√≥n de forma intermedia.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Capa de salida&lt;/strong&gt;: Emite la predicci√≥n final (clase, valor, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ejemplo-de-un-mlp&#34;&gt;Ejemplo de un MLP&lt;/h3&gt;
&lt;p&gt;La se√±al va propag√°ndose hacia adelante, capa por capa (‚Äúfeed-forward‚Äù):
















&lt;figure  id=&#34;figure-propagaci√≥n-en-un-mlp-con-2-capas-de-neuronas-intermedias&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;MLP de 2 capas ocultas&#34;
           src=&#34;http://localhost:1313/minerias/11_nn/figures/MLP2_L.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Propagaci√≥n en un MLP, con 2 capas de neuronas intermedias
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;ecuaciones-y-composici√≥n&#34;&gt;Ecuaciones y Composici√≥n&lt;/h3&gt;
&lt;h4 id=&#34;principio-de-una-capa&#34;&gt;Principio de una capa&lt;/h4&gt;
&lt;p&gt;Si la capa \(\ell\) tiene \(n_\ell\) neuronas, y recibimos como entrada \(\mathbf{a}^{(\ell)}\), la salida \(\mathbf{a}^{(\ell+1)}\) se obtiene aplicando:&lt;/p&gt;
\[
\mathbf{a}^{(\ell+1)} 
= f\bigl( \mathbf{W}^{(\ell,\ell+1)} \; \mathbf{a}^{(\ell)} \bigr)
\]&lt;p&gt;donde \(f\) es la funci√≥n de activaci√≥n elemento a elemento, y \(\mathbf{W}^{(\ell,\ell+1)}\) es la matriz de pesos entre la capa \(\ell\) y la capa \(\ell+1\).&lt;/p&gt;
&lt;p&gt;Por ejemplo, para una sola neurona \(j\) en la capa \(\ell+1\):&lt;/p&gt;
\[
a_j^{(\ell+1)} 
= f\Bigl(\sum_i w_{ji}^{(\ell,\ell+1)} \; a_i^{(\ell)}\Bigr)
\]&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Ejemplo de una capa con 4 neuronas de salida&#34; srcset=&#34;
               /minerias/11_nn/figures/MLP2_L0_hu9982466221484515949.webp 400w,
               /minerias/11_nn/figures/MLP2_L0_hu13782756864887087107.webp 760w,
               /minerias/11_nn/figures/MLP2_L0_hu17769283940668246020.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/MLP2_L0_hu9982466221484515949.webp&#34;
               width=&#34;544&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;mlp-composici√≥n-de-capas&#34;&gt;MLP: composici√≥n de capas&lt;/h4&gt;
&lt;p&gt;Un MLP con \(L\) capas puede verse como una &lt;strong&gt;composici√≥n de funciones&lt;/strong&gt;:&lt;/p&gt;
\[
\mathbf{a}^{(2)} = h^{(1,2)}(\mathbf{a}^{(1)}), 
\quad
\mathbf{a}^{(3)} = h^{(2,3)}(\mathbf{a}^{(2)}) 
\quad \ldots \quad
\mathbf{a}^{(L)} = h^{(L-1,L)}(\mathbf{a}^{(L-1)}).
\]&lt;p&gt;Por tanto:&lt;/p&gt;
\[
\mathbf{a}^{(L)} 
= h^{(L-1,L)} \circ \cdots \circ h^{(1,2)}\;(\mathbf{a}^{(1)}).
\]&lt;p&gt;Esta \(\mathbf{a}^{(L)}\) es la &lt;strong&gt;salida final&lt;/strong&gt; del MLP.&lt;/p&gt;
&lt;p&gt;Se puede escribir una funcion del MLP:&lt;/p&gt;
\[
MLP = h^{(L-1, L)} \circ h^{(L-2, L-1)} \circ ... \circ h^{(1,2)} \text{ \textbf{tal que} } MLP(\mathbf{a}^{(1)}) = \mathbf{a}^{(L)}
\]&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Conclusi√≥n&lt;/strong&gt;: un MLP es una &lt;strong&gt;funci√≥n no lineal&lt;/strong&gt; compuesta. A mayor n√∫mero de capas (profundidad), mayor &lt;strong&gt;capacidad&lt;/strong&gt; de representar funciones complejas.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;funciones-de-activaci√≥n&#34;&gt;Funciones de Activaci√≥n&lt;/h2&gt;
&lt;p&gt;La funci√≥n de activaci√≥n en cada neurona &lt;strong&gt;rompe la linealidad&lt;/strong&gt;. Sin ella, el modelo ser√≠a solo una combinaci√≥n lineal de los datos. Algunas funciones t√≠picas:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;strong&gt;Nombre&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Gr√°fico&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Ecuaci√≥n&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Valores en&lt;/strong&gt; \(\pm\infty\)&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Valores derivada en&lt;/strong&gt; \(\pm\infty\)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Heaviside&lt;/strong&gt; (te√≥rica)&lt;/td&gt;
          &lt;td&gt;[No derivable]&lt;/td&gt;
          &lt;td&gt;\(f(z)=\mathbf{1}_{z\ge0}\)&lt;/td&gt;
          &lt;td&gt;0,1&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Sigmoide&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;sigmoide&#34; srcset=&#34;
               /minerias/11_nn/figures/sigmoide_hu2258526441697663153.webp 400w,
               /minerias/11_nn/figures/sigmoide_hu11249631941563051249.webp 760w,
               /minerias/11_nn/figures/sigmoide_hu6025699800413662374.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/sigmoide_hu2258526441697663153.webp&#34;
               width=&#34;250&#34;
               height=&#34;106&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;\(f(z)=\frac{1}{1+e^{-z}}\)&lt;/td&gt;
          &lt;td&gt;0; 1&lt;/td&gt;
          &lt;td&gt;0; 0&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Tanh&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;tanh&#34; srcset=&#34;
               /minerias/11_nn/figures/tanh_hu2161236630147589151.webp 400w,
               /minerias/11_nn/figures/tanh_hu13683484027632460599.webp 760w,
               /minerias/11_nn/figures/tanh_hu7537390151399161997.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/tanh_hu2161236630147589151.webp&#34;
               width=&#34;250&#34;
               height=&#34;106&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;\(f(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}\)&lt;/td&gt;
          &lt;td&gt;-1; 1&lt;/td&gt;
          &lt;td&gt;0; 0&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;ReLU&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;relu&#34; srcset=&#34;
               /minerias/11_nn/figures/relu_hu14682383464111917821.webp 400w,
               /minerias/11_nn/figures/relu_hu247199606108359105.webp 760w,
               /minerias/11_nn/figures/relu_hu1501887440186754615.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/relu_hu14682383464111917821.webp&#34;
               width=&#34;250&#34;
               height=&#34;106&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;\(f(z)=\max(0,z)\)&lt;/td&gt;
          &lt;td&gt;0; \(z\)&lt;/td&gt;
          &lt;td&gt;0; 1&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;ELU&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;elu&#34; srcset=&#34;
               /minerias/11_nn/figures/elu_hu3293995043550659080.webp 400w,
               /minerias/11_nn/figures/elu_hu16152205053403592329.webp 760w,
               /minerias/11_nn/figures/elu_hu15040008162705597673.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/elu_hu3293995043550659080.webp&#34;
               width=&#34;250&#34;
               height=&#34;100&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
          &lt;td&gt;\(f(z)=\begin{cases}\alpha(e^z-1)&amp;z&lt;0\\ z&amp;z\ge0\end{cases}\)&lt;/td&gt;
          &lt;td&gt;\(-\alpha\); \(z\)&lt;/td&gt;
          &lt;td&gt;0; 1&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Heaviside&lt;/strong&gt; (original) no es derivable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sigmoide / Tanh&lt;/strong&gt;: buenas para salidas en [0,1] o [-1,1], pero pueden saturarse.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReLU&lt;/strong&gt;: muy popular en redes profundas.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ELU&lt;/strong&gt;: variante suavizada por debajo de 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;recuerdos-de-optimizaci√≥n-y-entrenamiento&#34;&gt;Recuerdos de Optimizaci√≥n y Entrenamiento&lt;/h2&gt;
&lt;p&gt;Para entrenar la red, definimos una &lt;strong&gt;funci√≥n de costo&lt;/strong&gt; (\(\ell\)), por ejemplo el error entre salidas reales y predichas. Queremos &lt;strong&gt;minimizar&lt;/strong&gt; esa funci√≥n respecto de los &lt;strong&gt;pesos&lt;/strong&gt; de la red.&lt;/p&gt;
&lt;h3 id=&#34;descenso-del-gradiente&#34;&gt;Descenso del Gradiente&lt;/h3&gt;
&lt;p&gt;Si \(\theta\) representa todos los pesos:&lt;/p&gt;
\[
\theta \leftarrow \theta - \alpha \; \nabla_\theta \ell(\theta)
\]&lt;p&gt;donde \(\alpha\) es la &lt;strong&gt;tasa de aprendizaje&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-visualizaci√≥n-conceptual&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Convergencia en un valle del ‚Äúpaisaje de costos‚Äù&#34; srcset=&#34;
               /minerias/11_nn/figures/LossAlps_hu15806339177112344745.webp 400w,
               /minerias/11_nn/figures/LossAlps_hu9473298813042643160.webp 760w,
               /minerias/11_nn/figures/LossAlps_hu7762387643821809596.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/LossAlps_hu15806339177112344745.webp&#34;
               width=&#34;760&#34;
               height=&#34;498&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Visualizaci√≥n conceptual
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Se pueden usar mini-batches (stochastic gradient descent - SGD) para computar gradientes parciales y hacer actualizaciones m√°s frecuentes.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;backpropagation-el-n√∫cleo-del-entrenamiento&#34;&gt;Backpropagation: el n√∫cleo del entrenamiento&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Backpropagation&lt;/strong&gt; (o retropropagaci√≥n del error) es el algoritmo que:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Calcula&lt;/strong&gt; la salida de la red (forward pass).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eval√∫a&lt;/strong&gt; el error (funci√≥n de costo).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Propaga&lt;/strong&gt; gradientes hacia atr√°s (desde la salida a cada capa) usando la &lt;strong&gt;regla de la cadena&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Actualiza&lt;/strong&gt; cada peso seg√∫n su gradiente parcial.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Explicaci√≥n m√°s detallada:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tras un &lt;strong&gt;forward pass&lt;/strong&gt;, conocemos la salida \(\mathbf{a}^{(L)}\).&lt;/li&gt;
&lt;li&gt;Comparamos con la etiqueta real y obtenemos el &lt;strong&gt;error&lt;/strong&gt; \(\ell\).&lt;/li&gt;
&lt;li&gt;Para cada capa \(\ell\), la &lt;strong&gt;derivada&lt;/strong&gt; de \(\ell\) respecto a \(\mathbf{W}^{(\ell,\ell+1)}\) se computa recursivamente, empezando por la capa de salida y yendo hacia la capa de entrada.&lt;/li&gt;
&lt;li&gt;Esto es posible gracias a que
\[
  \frac{\partial \ell}{\partial \mathbf{W}^{(\ell,\ell+1)}} 
  = \frac{\partial \ell}{\partial \mathbf{a}^{(\ell+1)}} 
  \cdot \frac{\partial \mathbf{a}^{(\ell+1)}}{\partial \mathbf{z}^{(\ell+1)}} 
  \cdot \frac{\partial \mathbf{z}^{(\ell+1)}}{\partial \mathbf{W}^{(\ell,\ell+1)}}.
  \]&lt;/li&gt;
&lt;li&gt;Se multiplican derivadas (regla de la cadena) y se obtiene la direcci√≥n de ajuste de cada peso.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-el-error-fluye-hacia-atr√°s-para-ajustar-cada-capa&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Representaci√≥n esquem√°tica de backpropagation (imagen ilustrativa)&#34; srcset=&#34;
               /minerias/11_nn/figures/backprop_hu5437070840985716372.webp 400w,
               /minerias/11_nn/figures/backprop_hu525999881374688638.webp 760w,
               /minerias/11_nn/figures/backprop_hu15532578210586162933.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/backprop_hu5437070840985716372.webp&#34;
               width=&#34;760&#34;
               height=&#34;543&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      El error fluye hacia atr√°s para ajustar cada capa
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;En la pr√°ctica, librer√≠as como &lt;strong&gt;PyTorch&lt;/strong&gt; o &lt;strong&gt;TensorFlow&lt;/strong&gt; hacen esto autom√°ticamente mediante &lt;strong&gt;autograd&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;representaciones&#34;&gt;Representaciones&lt;/h2&gt;
&lt;p&gt;En un MLP, cada capa oculta \(\mathbf{a}^{(\ell)}\) forma una &lt;strong&gt;representaci√≥n&lt;/strong&gt; distinta de los datos. Al componer varias capas, se construyen representaciones de nivel creciente de abstracci√≥n.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-cada-capa-genera-un-nuevo-vector-de-caracter√≠sticas-activaciones&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;MLP con 2 capas ocultas y salidas intermedias (activaciones)&#34; srcset=&#34;
               /minerias/11_nn/figures/MLP2_L6_hu2654510542182663165.webp 400w,
               /minerias/11_nn/figures/MLP2_L6_hu9619913887787023670.webp 760w,
               /minerias/11_nn/figures/MLP2_L6_hu6647341152618120042.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/MLP2_L6_hu2654510542182663165.webp&#34;
               width=&#34;760&#34;
               height=&#34;594&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Cada capa genera un nuevo vector de caracter√≠sticas (activaciones)
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;En im√°genes: capas iniciales detectan contornos, capas intermedias detectan partes (nariz, ojo&amp;hellip;), capas finales reconocen objetos concretos.&lt;/li&gt;
&lt;li&gt;En texto: capas iniciales identifican gram√°tica, capas intermedias reconocen entidades, capas profundas comprenden significados complejos (sentimientos, intenciones‚Ä¶).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;composicionalidad-de-las-representaciones&#34;&gt;Composicionalidad de las representaciones&lt;/h3&gt;
&lt;p&gt;En CNN u otras redes, se pueden visualizar ‚Äúfiltros‚Äù que activan sobre patrones (bordes, texturas, etc.).&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-se-compone-con-los-filtros-mas-basicos-los-filtros-mas-complejos-una-cara-se-compone-de-2-ojos-una-nariz-y-una-boca&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Visualizaci√≥n de filtros (composici√≥n de caracter√≠sticas)&#34; srcset=&#34;
               /minerias/11_nn/figures/filters_visualization_hu17234472207453702754.webp 400w,
               /minerias/11_nn/figures/filters_visualization_hu9084227478072464886.webp 760w,
               /minerias/11_nn/figures/filters_visualization_hu7053406489742120465.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/filters_visualization_hu17234472207453702754.webp&#34;
               width=&#34;679&#34;
               height=&#34;672&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Se compone con los filtros mas basicos los filtros mas complejos: una cara se compone de 2 ojos una nariz y una boca.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;visibilidad-de-filtros&#34;&gt;Visibilidad de filtros&lt;/h3&gt;
&lt;p&gt;Una video muy interesante de la &lt;a href=&#34;https://www.youtube.com/watch?v=AgkfIQ4IGaM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Visualization Toolbox&lt;/a&gt; para ver en tiempo real lo que activa los diferentes neuronas, las imagenes del dataset que les activan lo mas, y imagenes artificiales optimizada para activar los filtros.&lt;/p&gt;
&lt;p&gt;La visualizacion de las imagenes que activan el mas los filtros de un AlexNet en &lt;a href=&#34;https://distill.pub/2017/feature-visualization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Distill.pub: Feature Visualization&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-los-primeros-filtros-son-lo-mas-simple-como-detecor-de-edge-y-se-van-complejando-tipo-texturas-y-despues-objetos&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Visualizaci√≥n de filtros (composici√≥n de caracter√≠sticas)&#34; srcset=&#34;
               /minerias/11_nn/figures/feature_vis_hu12627367647364061408.webp 400w,
               /minerias/11_nn/figures/feature_vis_hu3957077363820538824.webp 760w,
               /minerias/11_nn/figures/feature_vis_hu7687384663625210479.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/feature_vis_hu12627367647364061408.webp&#34;
               width=&#34;760&#34;
               height=&#34;284&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Los primeros filtros son lo mas simple como detecor de edge, y se van complejando tipo texturas y despues objetos.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;representation-learning-for-transfer&#34;&gt;Representation Learning for Transfer&lt;/h2&gt;
&lt;h3 id=&#34;aprendizaje-de-representaciones&#34;&gt;Aprendizaje de Representaciones&lt;/h3&gt;
&lt;p&gt;El &lt;strong&gt;aprendizaje de representaciones&lt;/strong&gt; (Representation Learning) se basa en que la red neuronal aprende, de forma autom√°tica, &lt;strong&gt;caracter√≠sticas&lt;/strong&gt; o &lt;strong&gt;features&lt;/strong&gt; √∫tiles directamente desde los datos brutos (im√°genes, texto, etc.). Estas capas ocultas (o &lt;em&gt;embeddings&lt;/em&gt;) pueden:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Generalizar&lt;/strong&gt; mejor que las caracter√≠sticas dise√±adas a mano (hand-crafted features).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Adaptarse&lt;/strong&gt; a distintas tareas si se transfieren.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Los intereses son varios, por ejemplo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cada capa proporciona una representaci√≥n de los datos de entrada con dimensiones m√°s bajas.&lt;/li&gt;
&lt;li&gt;Esas representaciones provenientes √∫nicamente de los datos brutos a veces superan conjuntos de descriptores cl√°sicos \(\rightarrow\) &lt;a href=&#34;https://arxiv.org/pdf/1609.08675&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube-8M&lt;/a&gt;: Representaciones con LogReg superaban a todos los clasificadores de vanguardia en muchas tareas.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-las-representaciones-en-altas-dimensiones-se-proyectan-a-2d-y-muestran-agrupaciones-naturales&#34;&gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;t-SNE de representaciones de AlexNet&#34; srcset=&#34;
               /minerias/11_nn/figures/tsne_hu6012296096494109504.webp 400w,
               /minerias/11_nn/figures/tsne_hu6407126937998179609.webp 760w,
               /minerias/11_nn/figures/tsne_hu17633236819676664136.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/tsne_hu6012296096494109504.webp&#34;
               width=&#34;760&#34;
               height=&#34;283&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Las representaciones en altas dimensiones se proyectan a 2D y muestran agrupaciones naturales.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Ejemplo: despu√©s de entrenar en ImageNet, las capas profundas ‚Äúentienden‚Äù rasgos b√°sicos de las im√°genes. Si queremos clasificar perros vs. gatos, basta con re-entrenar poco.)&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;transferencia&#34;&gt;Transferencia&lt;/h3&gt;
&lt;p&gt;Una red entrenada en una tarea (p. ej. reconocimiento de objetos en im√°genes) puede servir como base para otras tareas (p. ej. detectar nuevos tipos de objetos). Se aprovecha el &lt;strong&gt;transfer learning&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Entrenamos una red (p. ej. CNN) en una gran base (ImageNet).&lt;/li&gt;
&lt;li&gt;Se ‚Äútoman‚Äù sus capas iniciales como &lt;strong&gt;extractor de caracter√≠sticas&lt;/strong&gt; (al estar entrenadas en millones de im√°genes, captan contornos y patrones generales).&lt;/li&gt;
&lt;li&gt;Para una nueva tarea con pocos datos, se conectan la capa final (llamado head) nueva o se re-entrena ligeramente (fine-tuning).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;De este modo, la &lt;strong&gt;representaci√≥n&lt;/strong&gt; (las activaciones intermedias) es &lt;strong&gt;reutilizada&lt;/strong&gt;. Esto ahorra tiempo y datos:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;El MLP o CNN grande provee features gen√©ricas.&lt;/li&gt;
&lt;li&gt;S√≥lo ajustamos parcialmente la red (o las √∫ltimas capas) a la tarea espec√≠fica.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;frameworks-populares&#34;&gt;Frameworks Populares&lt;/h2&gt;
&lt;h3 id=&#34;keras&#34;&gt;Keras&lt;/h3&gt;
&lt;p&gt;Biblioteca de Python de alto nivel para Redes Neuronales, sobre TensorFlow u otros backends.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Keras logo&#34; srcset=&#34;
               /minerias/11_nn/figures/keras_hu1035629169656843260.webp 400w,
               /minerias/11_nn/figures/keras_hu8780139607811972134.webp 760w,
               /minerias/11_nn/figures/keras_hu15459690173681857519.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/keras_hu1035629169656843260.webp&#34;
               width=&#34;760&#34;
               height=&#34;220&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ejemplo CNN preentrenada (VGG16)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorial RNN-LSTM seq2seq&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Embeddings de palabras preentrenados&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pytorch&#34;&gt;PyTorch&lt;/h3&gt;
&lt;p&gt;Biblioteca de Python centrada en el c√°lculo autom√°tico de gradientes y en el aprendizaje profundo.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;PyTorch logo&#34; srcset=&#34;
               /minerias/11_nn/figures/pytorch_hu8893412317164389539.webp 400w,
               /minerias/11_nn/figures/pytorch_hu16231463881976280037.webp 760w,
               /minerias/11_nn/figures/pytorch_hu894001013880019535.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/pytorch_hu8893412317164389539.webp&#34;
               width=&#34;512&#34;
               height=&#34;256&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorial Transfer Learning con ResNet18&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pytorch.org/audio/stable/tutorials/speech_recognition_pipeline_tutorial.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Speech recognition con Wav2Vec2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RNN-GRU seq2seq para traducci√≥n&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;huggingface-transformers&#34;&gt;HuggingFace Transformers&lt;/h3&gt;
&lt;p&gt;Biblioteca en Python para modelos tipo &lt;strong&gt;Transformers&lt;/strong&gt; (BERT, GPT, etc.).&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;HuggingFace logo&#34; srcset=&#34;
               /minerias/11_nn/figures/hf_logo_hu4463973729321469342.webp 400w,
               /minerias/11_nn/figures/hf_logo_hu16750015608575083964.webp 760w,
               /minerias/11_nn/figures/hf_logo_hu855115890972270235.webp 1200w&#34;
               src=&#34;http://localhost:1313/minerias/11_nn/figures/hf_logo_hu4463973729321469342.webp&#34;
               width=&#34;760&#34;
               height=&#34;175&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Soporta modelos &lt;strong&gt;preentrenados&lt;/strong&gt; en texto, visi√≥n, audio&amp;hellip;&lt;/li&gt;
&lt;li&gt;Otras librer√≠as: &lt;code&gt;Diffusers&lt;/code&gt; (im√°genes generativas), &lt;code&gt;Datasets&lt;/code&gt;, &lt;code&gt;Accelerate&lt;/code&gt;, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1 id=&#34;see-you-in-the-classroom&#34;&gt;See you in the classroom!&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Intro a la NLP</title>
      <link>http://localhost:1313/minerias/12_nlp/</link>
      <pubDate>Mon, 18 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/12_nlp/</guid>
      <description>&lt;p&gt;This is a class from an invited speaker, &lt;a href=&#34;https://cl.linkedin.com/in/juanjo-alegria&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Juan Jose Alegria&lt;/a&gt;!&lt;/p&gt;
&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc5205-mineria-datos-contentrawrefsheadsmainslides_esc12_introduccion_nlppdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC5205-Mineria-Datos-Content/raw/refs/heads/main/slides_es/c12_introduccio%cc%81n_nlp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Generative LLMs</title>
      <link>http://localhost:1313/deep/n_generative_llms/</link>
      <pubDate>Mon, 11 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/n_generative_llms/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslidesn_generative_llmspdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/N_Generative_LLMs.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Large Multimodal Models</title>
      <link>http://localhost:1313/deep/n_multimodal_models/</link>
      <pubDate>Sun, 10 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/deep/n_multimodal_models/</guid>
      <description>&lt;h2 id=&#34;the-slides-are-available-herehttpsgithubcomvalbarrierecc6204-deep-learningrawrefsheadsmainslidesn_multimodal_modelspdf&#34;&gt;The slides are available &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/raw/refs/heads/main/Slides/N_Multimodal_Models.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;!&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>http://localhost:1313/teaching/deep/</link>
      <pubDate>Sat, 24 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teaching/deep/</guid>
      <description>&lt;h3 id=&#34;all-the-different-classes-can-be-found-heredeep-index&#34;&gt;All the different classes can be found &lt;a href=&#34;../../deep-index&#34;&gt;here&lt;/a&gt;!&lt;/h3&gt;
&lt;p&gt;This is the CC66204 course from the Universidad de Chile. Based on the class of &lt;a href=&#34;https://github.com/ivansipiran&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ivan Sipiran&lt;/a&gt;, I added details in each of the classes, allowing to understand on how we get to the recent large multimodal models. The github is &lt;a href=&#34;https://github.com/valbarriere/CC6204-Deep-Learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;br&gt;
Here&amp;rsquo;s a summary:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;General introduction&lt;/strong&gt;: Overview of the class, reminders from Machine Learning,&amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Basics&lt;/strong&gt;: Perceptron, Vanilla Gradient Descent, MLP, Backprop,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Losses and Activations&lt;/strong&gt;: General losses, Softmax, CE, Activation functions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Initialization and Optimization&lt;/strong&gt;: Weights initialization, Complex gradient descents&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Penalization, Dropout, Data augmentation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Convolutional Layer&lt;/strong&gt;: Convolution, Padding, Pooling, LeNet&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Computer Vision Architectures&lt;/strong&gt;: ImageNet, Revolution of depth, Classical classifiers architectures&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transfer Learning&lt;/strong&gt;: Motivation, Principle, Types of TL, Weights unfreezing, Pre-training datasets, SoTA&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Object Detection&lt;/strong&gt;: Principle, IoU and mAP, Classical Object Detection, Segmentation and Mask-RCNN, SoTA&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Recurrent Layer&lt;/strong&gt;: Sequential Modeling, RNN, LSTM, GRU,&amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Attention&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[TODO] Transformers&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generative Large Language Models&lt;/strong&gt;: Language Modeling and Temperature, Abilities and In-Context-Learning, Tokenization, Instructions, Alignments, Reasonings, Training and Evaluating in Practice, LLMs as Agents&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Large Multimodal Models&lt;/strong&gt;: Multimodality, Fusion, Original tasks and datasets, Early multimodal transformers, CLIP and text2image Diffusion, Frozen encoders, BLIP 1/2/3 and LMM Assistants, Open-source training datasets, LMM evaluation, Video, Multimodal Tokenization&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Deep Natural Language Feature Learning for Interpretable Prediction</title>
      <link>http://localhost:1313/publication/emnlp23-nllf/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/emnlp23-nllf/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Targeted Image Data Augmentation Increases Basic Skills Captioning Robustness</title>
      <link>http://localhost:1313/publication/gem23-tida/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/gem23-tida/</guid>
      <description></description>
    </item>
    
    <item>
      <title>üéâ Easily create your own simple yet highly customizable blog</title>
      <link>http://localhost:1313/not_used/post/get-started/</link>
      <pubDate>Fri, 27 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/get-started/</guid>
      <description>&lt;p&gt;Welcome üëã&lt;/p&gt;



&lt;details class=&#34;print:hidden xl:hidden&#34; open&gt;
  &lt;summary&gt;Table of Contents&lt;/summary&gt;
  &lt;div class=&#34;text-sm&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#get-started&#34;&gt;Get Started&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#-click-here-to-become-a-sponsor-and-help-support-hugo-bloxs-future-httpshugobloxcomsponsor&#34;&gt;&lt;a href=&#34;https://hugoblox.com/sponsor/&#34;&gt;‚ù§Ô∏è Click here to become a sponsor and help support Hugo Blox&amp;rsquo;s future ‚ù§Ô∏è&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#ecosystem&#34;&gt;Ecosystem&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#inspiration&#34;&gt;Inspiration&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#features&#34;&gt;Features&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#themes&#34;&gt;Themes&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
  &lt;/div&gt;
&lt;/details&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The Hugo Blox website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site&lt;/li&gt;
&lt;li&gt;The template can be modified and customised to suit your needs. It&amp;rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a &lt;strong&gt;no-code solution (write in Markdown and customize with YAML parameters)&lt;/strong&gt; and having &lt;strong&gt;flexibility to later add even deeper personalization with HTML and CSS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;get-started&#34;&gt;Get Started&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;üëâ &lt;a href=&#34;https://hugoblox.com/templates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Create a new site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üìö &lt;a href=&#34;https://docs.hugoblox.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Personalize your site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üí¨ &lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chat with the &lt;strong&gt;Hugo Blox community&lt;/strong&gt;&lt;/a&gt; or &lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Hugo community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üê¶ Twitter: &lt;a href=&#34;https://twitter.com/GetResearchDev&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@GetResearchDev&lt;/a&gt; &lt;a href=&#34;https://twitter.com/GeorgeCushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@GeorgeCushen&lt;/a&gt; #MadeWithHugoBlox&lt;/li&gt;
&lt;li&gt;üí° &lt;a href=&#34;https://github.com/HugoBlox/hugo-blox-builder/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Request a &lt;strong&gt;feature&lt;/strong&gt; or report a &lt;strong&gt;bug&lt;/strong&gt; for &lt;em&gt;Hugo Blox&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;‚¨ÜÔ∏è &lt;strong&gt;Updating Hugo Blox?&lt;/strong&gt; View the &lt;a href=&#34;https://docs.hugoblox.com/reference/update/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Update Guide&lt;/a&gt; and &lt;a href=&#34;https://github.com/HugoBlox/hugo-blox-builder/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/h2&gt;
&lt;p&gt;To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.&lt;/p&gt;
&lt;h3 id=&#34;-click-here-to-become-a-sponsor-and-help-support-hugo-bloxs-future-httpshugobloxcomsponsor&#34;&gt;&lt;a href=&#34;https://hugoblox.com/sponsor/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;‚ù§Ô∏è Click here to become a sponsor and help support Hugo Blox&amp;rsquo;s future ‚ù§Ô∏è&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As a token of appreciation for sponsoring, you can &lt;strong&gt;unlock &lt;a href=&#34;https://hugoblox.com/sponsor/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;these&lt;/a&gt; awesome rewards and extra features ü¶Ñ‚ú®&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;ecosystem&#34;&gt;Ecosystem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/GetRD/academic-file-converter&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bibtex To Markdown&lt;/a&gt;:&lt;/strong&gt; Automatically import publications from BibTeX&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;inspiration&#34;&gt;Inspiration&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://hugoblox.com/creators/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learn what other &lt;strong&gt;creators&lt;/strong&gt;&lt;/a&gt; are building with this template.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page builder&lt;/strong&gt; - Create &lt;em&gt;anything&lt;/em&gt; with no-code &lt;a href=&#34;https://hugoblox.com/blocks/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;blocks&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;elements&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit any type of content&lt;/strong&gt; - Blog posts, publications, talks, slides, projects, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create content&lt;/strong&gt; in &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.hugoblox.com/getting-started/cms/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&lt;/a&gt;, or &lt;a href=&#34;https://docs.hugoblox.com/getting-started/cms/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt; - Fully customizable &lt;a href=&#34;https://docs.hugoblox.com/getting-started/customize/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;color&lt;/strong&gt; and &lt;strong&gt;font themes&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Code and Math&lt;/strong&gt; - Code syntax highlighting and LaTeX math supported&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrations&lt;/strong&gt; - &lt;a href=&#34;https://analytics.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Analytics&lt;/a&gt;, &lt;a href=&#34;https://disqus.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disqus commenting&lt;/a&gt;, Maps, Contact Forms, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beautiful Site&lt;/strong&gt; - Simple and refreshing one-page design&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry-Leading SEO&lt;/strong&gt; - Help get your website found on search engines and social media&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Media Galleries&lt;/strong&gt; - Display your images and videos with captions in a customizable gallery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile Friendly&lt;/strong&gt; - Look amazing on every screen with a mobile friendly version of your site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-language&lt;/strong&gt; - 35+ language packs including English, ‰∏≠Êñá, and Portugu√™s&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt; - Each author gets their own profile page&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privacy Pack&lt;/strong&gt; - Assists with GDPR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stand Out&lt;/strong&gt; - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-Click Deployment&lt;/strong&gt; - No servers. No databases. Only files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;p&gt;Hugo Blox and its templates come with &lt;strong&gt;automatic day (light) and night (dark) mode&lt;/strong&gt; built-in. Visitors can choose their preferred mode by clicking the sun/moon icon in the header.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.hugoblox.com/getting-started/customize/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Choose a stunning &lt;strong&gt;theme&lt;/strong&gt; and &lt;strong&gt;font&lt;/strong&gt;&lt;/a&gt; for your site. Themes are fully customizable.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2016-present &lt;a href=&#34;https://georgecushen.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;George Cushen&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Released under the &lt;a href=&#34;https://github.com/HugoBlox/hugo-blox-builder/blob/main/LICENSE.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>üß† Sharpen your thinking with a second brain</title>
      <link>http://localhost:1313/not_used/post/second-brain/</link>
      <pubDate>Thu, 26 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/second-brain/</guid>
      <description>&lt;p&gt;Create a personal knowledge base and share your knowledge with your peers.&lt;/p&gt;
&lt;p&gt;Hugo Blox web framework empowers you with one of the most flexible note-taking capabilities out there.&lt;/p&gt;
&lt;p&gt;Create a powerful knowledge base that works on top of a local folder of plain text Markdown files.&lt;/p&gt;
&lt;p&gt;Use it as your second brain, either publicly sharing your knowledge with your peers via your website, or via a private GitHub repository and password-protected site just for yourself.&lt;/p&gt;
&lt;h2 id=&#34;mindmaps&#34;&gt;Mindmaps&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports a Markdown extension for mindmaps.&lt;/p&gt;
&lt;p&gt;With this open format, can even edit your mindmaps in other popular tools such as Obsidian.&lt;/p&gt;
&lt;p&gt;Simply insert a Markdown code block labelled as &lt;code&gt;markmap&lt;/code&gt; and optionally set the height of the mindmap as shown in the example below.&lt;/p&gt;
&lt;p&gt;Mindmaps can be created by simply writing the items as a Markdown list within the &lt;code&gt;markmap&lt;/code&gt; code block, indenting each item to create as many sub-levels as you need:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap {height=&#34;200px&#34;}
- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Anh here&amp;rsquo;s a more advanced mindmap with formatting, code blocks, and math:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap
- Mindmaps
  - Links
    - [Hugo Blox Docs](https://docs.hugoblox.com/)
    - [Discord Community](https://discord.gg/z8wNYzb)
    - [GitHub](https://github.com/HugoBlox/hugo-blox-builder)
  - Features
    - Markdown formatting
    - **inline** ~~text~~ *styles*
    - multiline
      text
    - `inline code`
    -
      ```js
      console.log(&#39;hello&#39;);
      console.log(&#39;code block&#39;);
      ```
    - Math: $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 500px;&#34;&gt;

&lt;pre&gt;- Mindmaps
  - Links
    - [Hugo Blox Docs](https://docs.hugoblox.com/)
    - [Discord Community](https://discord.gg/z8wNYzb)
    - [GitHub](https://github.com/HugoBlox/hugo-blox-builder)
  - Features
    - Markdown formatting
    - **inline** ~~text~~ *styles*
    - multiline
      text
    - `inline code`
    -
      ```js
      console.log(&#39;hello&#39;);
      console.log(&#39;code block&#39;);
      ```
    - Math: $x = {-b \pm \sqrt{b^2-4ac} \over 2a}$&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&#34;highlighting&#34;&gt;Highlighting&lt;/h2&gt;
&lt;p&gt;&lt;mark&gt;Highlight&lt;/mark&gt; important text with &lt;code&gt;mark&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;Highlighted text&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;mark&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;callouts&#34;&gt;Callouts&lt;/h2&gt;
&lt;p&gt;Use &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/#callouts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;callouts&lt;/a&gt; (aka &lt;em&gt;asides&lt;/em&gt;, &lt;em&gt;hints&lt;/em&gt;, or &lt;em&gt;alerts&lt;/em&gt;) to draw attention to notes, tips, and warnings.&lt;/p&gt;
&lt;p&gt;By wrapping a paragraph in &lt;code&gt;{{% callout note %}} ... {{% /callout %}}&lt;/code&gt;, it will render as an aside.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% callout note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% /callout %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Or use the &lt;code&gt;warning&lt;/code&gt; callout type so your readers don&amp;rsquo;t miss critical details:&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-yellow-100 dark:bg-yellow-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-red-400&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0zM12 15.75h.007v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;A Markdown aside is useful for displaying notices, hints, or definitions to your readers.&lt;/span&gt;
&lt;/div&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>üìà Communicate your results effectively with the best data visualizations</title>
      <link>http://localhost:1313/not_used/post/data-visualization/</link>
      <pubDate>Wed, 25 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/data-visualization/</guid>
      <description>&lt;p&gt;Hugo Blox is designed to give technical content creators a seamless experience. You can focus on the content and Hugo Blox handles the rest.&lt;/p&gt;
&lt;p&gt;Use popular tools such as Plotly, Mermaid, and data frames.&lt;/p&gt;
&lt;h2 id=&#34;charts&#34;&gt;Charts&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the popular &lt;a href=&#34;https://plot.ly/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Plotly&lt;/a&gt; format for interactive data visualizations. With Plotly, you can design almost any kind of visualization you can imagine!&lt;/p&gt;
&lt;p&gt;Save your Plotly JSON in your page folder, for example &lt;code&gt;line-chart.json&lt;/code&gt;, and then add the &lt;code&gt;{{&amp;lt; chart data=&amp;quot;line-chart&amp;quot; &amp;gt;}}&lt;/code&gt; shortcode where you would like the chart to appear.&lt;/p&gt;
&lt;p&gt;Demo:&lt;/p&gt;




&lt;div id=&#34;chart-217684953&#34; class=&#34;chart&#34;&gt;&lt;/div&gt;
&lt;script&gt;
  async function fetchChartJSON() {
    console.debug(&#39;Hugo Blox fetching chart JSON...&#39;)
    const response = await fetch(&#39;.\/line-chart.json&#39;);
    return await response.json();
  }

  (function() {
    let a = setInterval( function() {
      if ( typeof window.Plotly === &#39;undefined&#39; ) {
        console.debug(&#39;Plotly not loaded yet...&#39;)
        return;
      }
      clearInterval( a );

      fetchChartJSON().then(chart =&gt; {
        console.debug(&#39;Plotting chart...&#39;)
        window.Plotly.newPlot(&#39;chart-217684953&#39;, chart.data, chart.layout, {responsive: true});
      });
    }, 500 );
  })();
&lt;/script&gt;

&lt;p&gt;You might also find the &lt;a href=&#34;http://plotly-json-editor.getforge.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Plotly JSON Editor&lt;/a&gt; useful.&lt;/p&gt;
&lt;h2 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the &lt;em&gt;Mermaid&lt;/em&gt; Markdown extension for diagrams.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;flowchart&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;graph TD
A[Hard] --&gt;|Text| B(Round)
B --&gt; C{Decision}
C --&gt;|One| D[Result 1]
C --&gt;|Two| E[Result 2]
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;sequence diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;sequenceDiagram
Alice-&gt;&gt;John: Hello John, how are you?
loop Healthcheck
    John-&gt;&gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&gt;&gt;Alice: Great!
John-&gt;&gt;Bob: How about you?
Bob--&gt;&gt;John: Jolly good!
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;class diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
Class03 *-- Class04
Class05 o-- Class06
Class07 .. Class08
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
Class08 &amp;lt;--&amp;gt; C2: Cool label
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;classDiagram
Class01 &lt;|-- AveryLongClass : Cool
Class03 *-- Class04
Class05 o-- Class06
Class07 .. Class08
Class09 --&gt; C2 : Where am i?
Class09 --* C3
Class09 --|&gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
Class08 &lt;--&gt; C2: Cool label
&lt;/div&gt;
&lt;p&gt;An example &lt;strong&gt;state diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;stateDiagram
[*] --&gt; Still
Still --&gt; [*]
Still --&gt; Moving
Moving --&gt; Still
Moving --&gt; Crash
Crash --&gt; [*]
&lt;/div&gt;
&lt;h2 id=&#34;data-frames&#34;&gt;Data Frames&lt;/h2&gt;
&lt;p&gt;Save your spreadsheet as a CSV file in your page&amp;rsquo;s folder and then render it by adding the &lt;em&gt;Table&lt;/em&gt; shortcode to your page:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;results.csv&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;header&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;caption&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Table 1: My results&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;














&lt;table class=&#34;table-auto w-full&#34;&gt;
  
    
    
    &lt;thead&gt;
      &lt;tr&gt;  &lt;th class=&#34;border-b dark:border-slate-600 font-medium p-4 pt-0 pb-3 text-slate-400 dark:text-slate-200 text-left&#34;&gt;customer_id&lt;/th&gt;  &lt;th class=&#34;border-b dark:border-slate-600 font-medium p-4 pt-0 pb-3 text-slate-400 dark:text-slate-200 text-left&#34;&gt;score&lt;/th&gt;  &lt;/tr&gt;
    &lt;/thead&gt;
  
  &lt;tbody&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;1&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;0&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;2&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;text&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;0.5&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
    &lt;tr&gt;
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;3&lt;/td&gt;
        
      
        
          &lt;td data-table-dtype=&#34;number&#34; class=&#34;border-b border-slate-100 dark:border-slate-700 p-4 text-slate-500 dark:text-slate-400&#34;&gt;1&lt;/td&gt;
        
      
    &lt;/tr&gt;
  
  &lt;/tbody&gt;
  
    &lt;caption class=&#34;table-caption&#34;&gt;Table 1: My results&lt;/caption&gt;
  
&lt;/table&gt;

&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>üë©üèº‚Äçüè´ Teach academic courses</title>
      <link>http://localhost:1313/not_used/post/teach-courses/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/teach-courses/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube D2vj0WcvH5c &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili BV1WV4y1r7DF &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;w-full h-auto aspect-video relative&#34;&gt;
  &lt;iframe src=&#34;//player.bilibili.com/player.html?bvid=BV1WV4y1r7DF&amp;page=1&#34;
  allow=&#34;accelerometer; clipboard-write; encrypted-media; gyroscope; fullscreen; picture-in-picture;&#34;
  class=&#34;w-full h-full&#34;
  &gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;http://localhost:1313/not_used/post/teach-courses/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;üëâ Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;üëâ Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me üéâ
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. Enable math by setting the &lt;code&gt;math: true&lt;/code&gt; option in your page&amp;rsquo;s front matter, or enable math for your entire site by toggling math in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;enable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;$...$&lt;/code&gt; or &lt;code&gt;$$...$$&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;$\nabla F(\mathbf{x}_{n})$&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Learn JavaScript</title>
      <link>http://localhost:1313/teachingini/js/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teachingini/js/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube w7Ft2ymGmfc &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili id=&amp;quot;BV1WV4y1r7DF&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;http://localhost:1313/teachingini/js/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;üëâ Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;üëâ Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me üéâ
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;{{&amp;lt; math &amp;gt;}}$...${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; or &lt;code&gt;{{&amp;lt; math &amp;gt;}}$$...$${{&amp;lt; /math &amp;gt;}}&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;We wrap the LaTeX math in the Hugo Blox &lt;em&gt;math&lt;/em&gt; shortcode to prevent Hugo rendering our math as Markdown.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;

$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$


&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;{{&amp;lt; math &amp;gt;}}$\nabla F(\mathbf{x}_{n})${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$
.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;


$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$



&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Learn Python</title>
      <link>http://localhost:1313/teachingini/python/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teachingini/python/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube w7Ft2ymGmfc &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili id=&amp;quot;BV1WV4y1r7DF&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;http://localhost:1313/teachingini/python/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;üëâ Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;üëâ Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me üéâ
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;{{&amp;lt; math &amp;gt;}}$...${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; or &lt;code&gt;{{&amp;lt; math &amp;gt;}}$$...$${{&amp;lt; /math &amp;gt;}}&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;We wrap the LaTeX math in the Hugo Blox &lt;em&gt;math&lt;/em&gt; shortcode to prevent Hugo rendering our math as Markdown.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;

$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$


&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;{{&amp;lt; math &amp;gt;}}$\nabla F(\mathbf{x}_{n})${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$
.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;


$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$



&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Test Python</title>
      <link>http://localhost:1313/minerias/python/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/minerias/python/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hugoblox.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; is designed to give technical content creators a seamless experience. You can focus on the content and the Hugo Blox Builder which this template is built upon handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embed videos, podcasts, code, LaTeX math, and even test students!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Hugo Blox.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;
&lt;p&gt;Teach your course by sharing videos with your students. Choose from one of the following approaches:&lt;/p&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/D2vj0WcvH5c?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Youtube&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; youtube w7Ft2ymGmfc &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bilibili&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; bilibili id=&amp;quot;BV1WV4y1r7DF&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Video file&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Videos may be added to a page by either placing them in your &lt;code&gt;assets/media/&lt;/code&gt; media library or in your &lt;a href=&#34;https://gohugo.io/content-management/page-bundles/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page&amp;rsquo;s folder&lt;/a&gt;, and then embedding them with the &lt;em&gt;video&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; video src=&amp;quot;my_video.mp4&amp;quot; controls=&amp;quot;yes&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;podcast&#34;&gt;Podcast&lt;/h2&gt;
&lt;p&gt;You can add a podcast or music to a page by placing the MP3 file in the page&amp;rsquo;s folder or the media library folder and then embedding the audio on your page with the &lt;em&gt;audio&lt;/em&gt; shortcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{&amp;lt; audio src=&amp;quot;ambient-piano.mp3&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try it out:&lt;/p&gt;








  








&lt;audio controls &gt;
  &lt;source src=&#34;http://localhost:1313/minerias/python/ambient-piano.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;test-students&#34;&gt;Test students&lt;/h2&gt;
&lt;p&gt;Provide a simple yet fun self-assessment by revealing the solutions to challenges with the &lt;code&gt;spoiler&lt;/code&gt; shortcode:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;üëâ Click to view the solution&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;You found me!
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spoiler&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary class=&#34;cursor-pointer&#34;&gt;üëâ Click to view the solution&lt;/summary&gt;
  &lt;div class=&#34;rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2&#34;&gt;
    You found me üéâ
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;{{&amp;lt; math &amp;gt;}}$...${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; or &lt;code&gt;{{&amp;lt; math &amp;gt;}}$$...$${{&amp;lt; /math &amp;gt;}}&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;We wrap the LaTeX math in the Hugo Blox &lt;em&gt;math&lt;/em&gt; shortcode to prevent Hugo rendering our math as Markdown.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\gamma&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\frac&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{ &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; | &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n} &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^T &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; x_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; |}{&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\left&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\nabla&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; F&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\mathbf&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{x}_{n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\right&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\|&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;

$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$


&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;{{&amp;lt; math &amp;gt;}}$\nabla F(\mathbf{x}_{n})${{&amp;lt; /math &amp;gt;}}&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$
.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the math linebreak (&lt;code&gt;\\&lt;/code&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;$$&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;k;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;, &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;p_{&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;}^{&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;} &amp;amp; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\text&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{if }k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{cases}&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;$$&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;{{&lt;/span&gt;&amp;lt; /math &amp;gt;&lt;span class=&#34;nb&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;


$$
f(k;p_{0}^{*}) = \begin{cases}p_{0}^{*} &amp; \text{if }k=1, \\
1-p_{0}^{*} &amp; \text{if }k=0.\end{cases}
$$



&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Hugo Blox Builder utilises Hugo&amp;rsquo;s Markdown extension for highlighting code syntax. The code theme can be selected in the &lt;code&gt;config/_default/params.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;data.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;inline-images&#34;&gt;Inline Images&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&amp;lt;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;icon&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;}}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; height=&#34;1em&#34; viewBox=&#34;0 0 448 512&#34; fill=&#34;currentColor&#34;&gt;&lt;path d=&#34;M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Python&lt;/p&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>‚úÖ Manage your projects</title>
      <link>http://localhost:1313/not_used/post/project-management/</link>
      <pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/not_used/post/project-management/</guid>
      <description>&lt;p&gt;Easily manage your projects - create ideation mind maps, Gantt charts, todo lists, and more!&lt;/p&gt;
&lt;h2 id=&#34;ideation&#34;&gt;Ideation&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports a Markdown extension for mindmaps.&lt;/p&gt;
&lt;p&gt;Simply insert a Markdown code block labelled as &lt;code&gt;markmap&lt;/code&gt; and optionally set the height of the mindmap as shown in the example below.&lt;/p&gt;
&lt;p&gt;Mindmaps can be created by simply writing the items as a Markdown list within the &lt;code&gt;markmap&lt;/code&gt; code block, indenting each item to create as many sub-levels as you need:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;
&lt;code&gt;
```markmap {height=&#34;200px&#34;}
- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal
```
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;markmap&#34; style=&#34;height: 200px;&#34;&gt;

&lt;pre&gt;- Hugo Modules
  - Hugo Blox
  - blox-plugins-netlify
  - blox-plugins-netlify-cms
  - blox-plugins-reveal&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h2&gt;
&lt;p&gt;Hugo Blox supports the &lt;em&gt;Mermaid&lt;/em&gt; Markdown extension for diagrams.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;Gantt diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
&lt;/div&gt;
&lt;h2 id=&#34;todo-lists&#34;&gt;Todo lists&lt;/h2&gt;
&lt;p&gt;You can even write your todo lists in Markdown too:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write math example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;- [x]&lt;/span&gt; Write diagram example
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;- [ ]&lt;/span&gt; Do something else
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;renders as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write math example
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write diagram example&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Do something else&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>WASSA Workshop @ ACL 23</title>
      <link>http://localhost:1313/event/wassa23/</link>
      <pubDate>Fri, 14 Jul 2023 13:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/wassa23/</guid>
      <description>&lt;p&gt;We are orgnizing the 13th edition of the WASSA workshop this year at &lt;a href=&#34;https://2023.aclweb.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL23&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Our keynote speakers will be David Jurgens and Emily √ñhman&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-david-jurgens&#34;&gt;Invited Talk: David Jurgens&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://wassa-workshop.github.io/assets/images/david_jurgens.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;the-social-dimensions-of-communication-how-context-shapes-language-use-and-interpretation&#34;&gt;The Social Dimensions of Communication: How Context Shapes Language Use and Interpretation&lt;/h4&gt;
&lt;p&gt;NLP studies of communication often focus on the individual: What we say, when we say it, and how we say it. Yet, the larger social context beyond the individual also plays an important role in our communication ‚Äî just think of things you can say to your friends but not your parents. How does the social context influence our communication style and content? In this talk, I will describe recent work from my group studying the influence of this context by examining how we choose who to communicate with, how we interpret messages, and how we phrase messages. Across these studies, I will motivate a causal approach for NLP when studying communication behavior to move beyond descriptive analyses to more precise estimates of the effects of social context.&lt;/p&gt;
&lt;h4 id=&#34;bio&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;David Jurgens is an assistant professor at the University of Michigan School of Information where he leads the Blablablab. He holds a PhD in Computer Science from the University of California, Los Angeles. His research focuses on the intersection between NLP and computational social science venues and has won the Cozzarelli Prize, Cialdini Prize, best paper at ICWSM and W-NUT, and best paper nomination at ACL and Web Science.&lt;/p&gt;
&lt;h3 id=&#34;invited-talk-emily-√∂hman&#34;&gt;Invited Talk: Emily √ñhman&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://wassa-workshop.github.io/assets/images/emilyohman.jpeg&#34; alt=&#34;image&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;affective-datafication-of-narratives-measuring-affect-emotion-and-mood-in-literary-texts&#34;&gt;Affective Datafication of Narratives: measuring affect, emotion, and mood in literary texts&lt;/h4&gt;
&lt;p&gt;Our understanding of affect, emotion, and mood - despite the distinct nuances each term holds - often becomes blurred, leading to a usage that is almost interchangeable, particularly within sentiment analysis and NLP. In contrast, traditional fields such as literary studies hold on to more rigid definitions of these terms and how they are understood both in theory and practice. This can easily foster a disconnect between emerging fields such as computational literary studies and the more established qualitative counterparts. This disconnect unfortunately hinders the free exchange of innovative research ideas and methodologies. This talk aims to bridge this gap, highlighting the unique roles of affect, emotion, and mood in narratives and how we can attempt to robustly measure them. We will delve into the interplay of these terms, exploring how they shape and are shaped by authors, readers, and researchers focusing on the operationalization and translation involved in the analysis of emotion-laden phenomena. This exploration will underscore the need for a more comprehensive and nuanced understanding, encouraging synergy between tradition and innovation in emotion detection in general and literary research in particular.&lt;/p&gt;
&lt;h4 id=&#34;bio-1&#34;&gt;Bio&lt;/h4&gt;
&lt;p&gt;Emily √ñhman is currently a tenure-track Assistant professor of Digital Humanities at Waseda University. She received her PhD in Language Technology from the University of Helsinki, where her work centered on building multilingual emotion detection resources for downstream tasks.&lt;/p&gt;
&lt;p&gt;Her research interests lie within digital humanities and NLP, more specifically sentiment analysis and emotion detection, often doing collaborations with various disciplines such as history, literature, and political science. Her recent projects have focused on negative emotions in literature using affect as a proxy for the literary concept of mood and most recently contrasting the semantic spaces of shame and guilt in Japanese and English social media posts.&lt;/p&gt;
&lt;h2 id=&#34;about-wassa&#34;&gt;About WASSA&lt;/h2&gt;
&lt;p&gt;The aim of WASSA 2023 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text. For this edition, we encourage the submission of long and short research and demo papers including, but not restricted to the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resources for subjectivity, sentiment, emotion and social media analysis&lt;/li&gt;
&lt;li&gt;Opinion retrieval, extraction, categorization, aggregation and summarization&lt;/li&gt;
&lt;li&gt;Humor, Irony and Sarcasm detection&lt;/li&gt;
&lt;li&gt;Mis- and disinformation analysis and the role of affective attributes&lt;/li&gt;
&lt;li&gt;Aspect and topic-based sentiment and emotion analysis&lt;/li&gt;
&lt;li&gt;Analysis of stable traits of social media users, incl. personality analysis and profiling&lt;/li&gt;
&lt;li&gt;Transfer learning for domain, language and genre portability of sentiment analysis&lt;/li&gt;
&lt;li&gt;Modelling commonsense knowledge for subjectivity, sentiment or emotion analysis&lt;/li&gt;
&lt;li&gt;Improvement of NLP tasks using subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;Intrinsic and extrinsic evaluation of subjectivity and/or sentiment analysis&lt;/li&gt;
&lt;li&gt;The role of emotions in argument mining&lt;/li&gt;
&lt;li&gt;Application of theories from related fields to subjectivity and sentiment analysis&lt;/li&gt;
&lt;li&gt;Multimodal emotion detection and classification&lt;/li&gt;
&lt;li&gt;Applications of sentiment and emotion mining&lt;/li&gt;
&lt;li&gt;Public sentiments and communication patterns of public health emergencies.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We furthermore encourage submissions to the special theme Ethics in Affective Computing, including opinion papers, as well as experimental papers. This includes the following topics, but is not limited to them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Which properties of a model render a automatic analysis task unethical?&lt;/li&gt;
&lt;li&gt;Which characteristics of an annotation task are to be considered in ethical considerations?&lt;/li&gt;
&lt;li&gt;What are appropriate methods to analyze data and models from an ethical perspective?&lt;/li&gt;
&lt;li&gt;What aspects are particular important for affective analysis tasks, in contrast to other NLP settings?&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Findings of WASSA 2023 Shared Task on Empathy, Emotion and Personality Detection in Conversation and Reactions to News Articles</title>
      <link>http://localhost:1313/publication/wassa23-task/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wassa23-task/</guid>
      <description>&lt;p&gt;Third shared task related to Empathy we organized at WASSA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multilingual Multi-Target Stance Recognition in Online Public Consultations</title>
      <link>http://localhost:1313/publication/mdpi23-participatory/</link>
      <pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/mdpi23-participatory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CoFE: A New Dataset of Intra-Multilingual Multi-target Stance Classification from an Online European Participatory Democracy Platform</title>
      <link>http://localhost:1313/publication/aacl22-cofe/</link>
      <pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/aacl22-cofe/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Debating Europe: A Multilingual Multi-Target Stance Classification Dataset of Online Debates</title>
      <link>http://localhost:1313/publication/lrec22-deurope/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec22-deurope/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Opinions in Interactions : New Annotations of the SEMAINE Database</title>
      <link>http://localhost:1313/publication/lrec22-opinions/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/lrec22-opinions/</guid>
      <description></description>
    </item>
    
    <item>
      <title>WASSA 2022 Shared Task: Predicting Empathy, Emotion and Personality in Reaction to News Stories</title>
      <link>http://localhost:1313/publication/wassa22-task/</link>
      <pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/wassa22-task/</guid>
      <description>&lt;p&gt;Second shared task related to Empathy we organized at WASSA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How does a Pre-Trained Transformer Integrate Contextual Keywords? Application to Humanitarian Computing</title>
      <link>http://localhost:1313/publication/iscram21-meta/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/iscram21-meta/</guid>
      <description>&lt;p&gt;It is possible to integrate textual metadata into transformers in order to help the model improve its performances. We show the model uses the semantics of the keyword metadata analyzing the attention interaction between the metadata and the text to classify. We applied this to a humanitarian classification task over tweets, using the disaster event type as context, and finally show this method is also useful to caracterize a new event like a hurricane in a data-driven way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving Sentiment Analysis over non-English Tweets using Multilingual Transformers and Automatic Translation for Data-Augmentation</title>
      <link>http://localhost:1313/publication/coling20-mling/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/coling20-mling/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Apprentissage Machine</title>
      <link>http://localhost:1313/teaching/fouilledonnees/</link>
      <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/teaching/fouilledonnees/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Valentin Barriere</title>
      <link></link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid></guid>
      <description>&lt;h2 id=&#34;about-me&#34;&gt;About Me&lt;/h2&gt;
&lt;p&gt;Valentin Barriere is an AI profesor in the CS department of the University of Chile, specialized in multimodal machine learning for social interactions studies, with a focus on natural language processing. He also work on multilingual debates analysis, social biases detection, explainable IA, and also multimodal satellite data processing. Before this, he worked for public institutions such as the Supreme Court (Cour de Cassation) and the European Commission&amp;rsquo;s Joint Research Center.&lt;/p&gt;
&lt;p&gt;He is director of several projects focused on the use of Machine Learning for social good with public Chilean institutions, and involved as IA advisor of the CopernicusLAC program in Chile with the aim to develop general multi-modal and multi-resolution models for satellite data processing.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
